# Reality Trace Panel

**Pillars:** [Reality][DevX]

[Reality] - Makes mocks feel like real backends through observability and debugging
[DevX] - Developer experience improvements for understanding mock behavior

## Overview

The Reality Trace Panel provides deep introspection into how MockForge generates responses. It answers the critical question: **"Why did I get this response?"** by showing exactly how reality levels, personas, scenarios, chaos profiles, and data sources combine to create each mock response.

## Accessing the Reality Trace Panel

### In the Playground

1. Navigate to the **Playground** tab in the Admin UI
2. Execute a request to any endpoint
3. The Reality Trace Panel appears automatically below the response
4. Click on any persona, scenario, or chaos profile to navigate to its configuration

### In the Admin Request Log

1. Navigate to the **Logs** tab in the Admin UI
2. Find the request you want to inspect in the request log
3. Click the **"View Trace"** button on any log entry
4. The Response Trace Modal opens showing detailed response generation information
5. The Reality Trace Panel is also available below the response in the Playground

## What Information It Shows

### Reality Level and Continuum Type

- **Reality Level**: A number (1-5) indicating the overall realism level
- **Continuum Type**: One of:
  - **Synthetic**: Pure mock data, no real upstream calls
  - **Blended**: Mix of mock and real data
  - **Live**: Real upstream data with minimal mocking

### Data Source Breakdown

Shows the percentage of data from each source:
- **Recorded**: Data from recorded fixtures/replays
- **Generator**: Data generated by MockForge's data generators
- **Upstream**: Data fetched from real upstream services

This helps you understand the composition of your response.

### Active Persona

- **Persona ID**: The active persona used for this request
- **Deep Link**: Click the persona ID (with external link icon) to navigate to AI Studio personas tab
- Shows which persona's traits and lifecycle state influenced the response
- **Implementation**: The persona ID is clickable and triggers navigation to the persona configuration page

### Active Scenario

- **Scenario Name**: The active scenario (if any) for this request
- **Deep Link**: Click the scenario name (with external link icon) to navigate to Scenario Studio
- Scenarios can override default behavior and apply specific rules
- **Implementation**: The scenario name is clickable and triggers navigation to the scenario configuration page

### Active Chaos Profiles

- Lists all active chaos engineering profiles applied to this request
- **Deep Links**: Click any profile name (with external link icon) to navigate to Chaos Engineering page
- Shows which latency, faults, or traffic shaping rules were active
- **Implementation**: Each chaos profile badge is clickable and triggers navigation to the chaos configuration page

### Active Latency Profiles

- Lists latency profiles that affected response timing
- Shows network condition simulation applied to the request

## "Why Did I Get This Response?" Button

Located in the GraphQL/REST playground and admin UI request details, this button opens a detailed modal explaining the complete response generation process.

### Accessing the Response Trace

1. **In Playground**: After executing a request, click the **"Why Did I Get This Response?"** button
2. **In Request Logs**: Click the **"View Trace"** button on any log entry
3. The Response Trace Modal opens with complete response generation details

### What It Shows

#### Template & Fixture Selection

- **Template Path**: Which template file was used
- **Fixture Path**: Which fixture file was used (if any)
- **Selection Mode**: How the response was chosen:
  - First Available
  - Scenario-Based
  - Round-Robin (Sequential)
  - Random
  - Weighted Random
- **Selected Example**: The specific example/scenario selected

#### Persona Graph Nodes Used

Shows which persona graph nodes were traversed:
- **Persona ID**: The persona used
- **Entity Type**: Type of entity (user, order, payment, etc.)
- **Usage Type**: How the node was used (data_source, relationship_traversal, etc.)
- **Relationship Path**: The path through the graph (e.g., `user → order → payment`)

#### Rules & Hooks Executed

Lists all rules and hook scripts that fired:
- **Rule Name**: Name of the rule/hook
- **Rule Type**: Type (hook, consistency_rule, mutation_rule, etc.)
- **Condition Matched**: Whether the rule's condition was met
- **Actions Executed**: What actions the rule performed
- **Execution Time**: How long the rule took to execute
- **Errors**: Any errors that occurred during execution

#### Template Expansion Steps

Shows how template variables were expanded:
- **Template**: The template expression (e.g., `{{user.name}}`)
- **Value**: The expanded value
- **Source**: Where the value came from (persona, faker, context, etc.)
- **Step**: The order in which expansions occurred

#### Reality Blending Decision

If reality continuum is enabled:
- **Blend Ratio**: The ratio of real to mock data (0.0 = mock, 1.0 = real)
- **Ratio Source**: Where the ratio came from (global, route_rule, time_schedule)
- **Blended**: Whether blending was actually performed
- **Merge Strategy**: The strategy used for blending
- **Field-Level Decisions**: Per-field blending decisions

#### Final Resolved Payload

The complete response body that was sent to the client, after all transformations:
- Template expansions
- Persona graph enrichments
- Rule/hook modifications
- Reality blending

Displayed as formatted JSON for easy inspection.

#### Schema Validation Diff

Compares the final payload against the contract schema:
- **Valid Payload**: Shows a green checkmark if the payload matches the schema
- **Validation Errors**: Lists any mismatches:
  - **Path**: JSON path to the field with the issue
  - **Expected**: What the schema expects
  - **Found**: What was actually in the payload
  - **Error Type**: Classification (type_mismatch, required_missing, etc.)
  - **Schema Info**: Additional schema constraints (data type, format, min/max, etc.)

This helps you identify when mock responses don't match your API contract.

## Interpreting Trace Data for Debugging

### Common Scenarios

#### Response Doesn't Match Expected Format

1. Check **Schema Validation Diff** section
2. Look for validation errors showing mismatched fields
3. Review **Template Expansion Steps** to see how values were generated
4. Check **Persona Graph Nodes** to see if persona data influenced the response

#### Response Has Unexpected Values

1. Check **Active Persona** - persona traits may be influencing values
2. Review **Rules Executed** - rules may have modified the response
3. Check **Reality Blending Decision** - blended data may differ from pure mocks
4. Review **Template Expansion Steps** - see the exact values used

#### Response Timing Issues

1. Check **Active Latency Profiles** - latency injection may be affecting timing
2. Review **Rules Executed** - rules may add artificial delays
3. Check execution times in rule details

#### Inconsistent Data Across Requests

1. Check **Active Persona** - ensure the same persona is used
2. Review **Response Selection Mode** - sequential/random modes affect consistency
3. Check **Persona Graph Nodes** - graph state may be changing between requests

## Examples

### Example 1: Understanding a User Response

```
Reality Trace:
- Reality Level: 3 (Moderate)
- Continuum Type: Blended
- Data Source: 60% Generator, 40% Recorded
- Active Persona: user:premium-001
- Active Scenario: premium-user-flow

"Why Did I Get This Response?" shows:
- Template: user-template.json
- Persona Graph: user:premium-001 → subscription:premium → payment:card-123
- Rules: premium_user_enrichment (matched, added premium features)
- Final Payload: { "id": "premium-001", "tier": "premium", ... }
- Schema Validation: ✅ Valid
```

### Example 2: Debugging a Schema Mismatch

```
Schema Validation Diff shows:
- Path: billing.amount
- Expected: number
- Found: string "29.99"
- Error Type: type_mismatch
- Message: Amount should be a number, not a string

Template Expansion Steps shows:
- Template: {{billing.amount}}
- Value: "29.99"
- Source: persona (premium_user.billing_amount)
- Issue: Persona trait stored amount as string, but schema expects number
```

## Best Practices

1. **Use Reality Trace for Debugging**: When a response seems wrong, check the trace first
2. **Verify Schema Compliance**: Always check Schema Validation Diff to ensure mocks match contracts
3. **Understand Data Sources**: Use Data Source Breakdown to see if you're getting real or mock data
4. **Follow Deep Links**: Click persona/scenario/chaos links to understand their configuration
5. **Review Rules**: Check which rules fired to understand response modifications
6. **Monitor Blending**: If using reality continuum, verify blend ratios match expectations

## Related Documentation

- [PERSONAS.md](PERSONAS.md) - Learn about personas and persona graphs
- [REALITY_CONTINUUM.md](REALITY_CONTINUUM.md) - Understand reality blending
- [OBSERVABILITY.md](OBSERVABILITY.md) - General observability features
- [LIFECYCLES_AND_TIME.md](LIFECYCLES_AND_TIME.md) - Lifecycle presets and time travel

