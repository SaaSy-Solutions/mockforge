<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>MockForge Documentation</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="A comprehensive mocking framework for APIs, gRPC, and WebSockets">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="custom.css">


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "light";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "searchindex.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">MockForge Documentation</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/SaaSy-Solutions/mockforge" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <i class="fa fa-spinner fa-spin"></i>
                            </div>
                        </div>
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="mockforge"><a class="header" href="#mockforge">MockForge</a></h1>
<p><a href="https://crates.io/crates/mockforge"><img src="https://img.shields.io/crates/v/mockforge.svg" alt="Crates.io" /></a>
<a href="https://docs.rs/mockforge"><img src="https://docs.rs/mockforge/badge.svg" alt="Documentation" /></a>
<a href="https://github.com/SaaSy-Solutions/mockforge/actions"><img src="https://github.com/SaaSy-Solutions/mockforge/workflows/CI/badge.svg" alt="CI" /></a>
<a href="https://github.com/SaaSy-Solutions/mockforge/blob/main/LICENSE"><img src="https://img.shields.io/badge/license-MIT%20OR%20Apache--2.0-blue.svg" alt="License" /></a></p>
<p>MockForge is a comprehensive mocking framework for APIs, gRPC services, and WebSockets. It provides a unified interface for creating, managing, and deploying mock servers across different protocols.</p>
<h2 id="features"><a class="header" href="#features">Features</a></h2>
<ul>
<li><strong>Multi-Protocol Support</strong>: HTTP REST APIs, gRPC services, and WebSocket connections</li>
<li><strong>Dynamic Response Generation</strong>: Create realistic mock responses with configurable latency and failure rates</li>
<li><strong>Scenario Management</strong>: Define complex interaction scenarios with state management</li>
<li><strong>CLI Tool</strong>: Easy-to-use command-line interface for local development</li>
<li><strong>Admin UI</strong>: Web-based interface for managing mock servers</li>
<li><strong>Extensible Architecture</strong>: Plugin system for custom response generators</li>
</ul>
<h2 id="quick-start"><a class="header" href="#quick-start">Quick Start</a></h2>
<h3 id="installation"><a class="header" href="#installation">Installation</a></h3>
<pre><code class="language-bash">cargo install mockforge-cli
</code></pre>
<h3 id="basic-usage"><a class="header" href="#basic-usage">Basic Usage</a></h3>
<pre><code class="language-bash"># Start a mock server with an OpenAPI spec
cargo run -p mockforge-cli -- serve --spec examples/openapi-demo.json --http-port 3000

# Add WebSocket support with replay file
MOCKFORGE_WS_REPLAY_FILE=examples/ws-demo.jsonl cargo run -p mockforge-cli -- serve --ws-port 3001

# Full configuration with Admin UI
MOCKFORGE_WS_REPLAY_FILE=examples/ws-demo.jsonl \
MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true \
cargo run -p mockforge-cli -- serve --spec examples/openapi-demo.json --admin --admin-port 8080

# Use configuration file
cargo run -p mockforge-cli -- serve --config demo-config.yaml
</code></pre>
<h3 id="docker"><a class="header" href="#docker">Docker</a></h3>
<pre><code class="language-bash">docker run -p 3000:3000 -p 3001:3001 -p 50051:50051 SaaSy-Solutions/mockforge
</code></pre>
<h2 id="documentation-structure"><a class="header" href="#documentation-structure">Documentation Structure</a></h2>
<ul>
<li><a href="getting-started.html">Getting Started</a> - Installation and basic setup</li>
<li><a href="http-mocking.html">HTTP Mocking</a> - REST API mocking guide</li>
<li><a href="grpc-mocking.html">gRPC Mocking</a> - gRPC service mocking</li>
<li><a href="websocket-mocking.html">WebSocket Mocking</a> - WebSocket connection mocking</li>
<li><a href="configuration.html">Configuration</a> - Advanced configuration options</li>
<li><a href="api-reference.html">API Reference</a> - Complete API documentation</li>
<li><a href="contributing.html">Contributing</a> - How to contribute to MockForge</li>
<li><a href="faq.html">FAQ</a> - Frequently asked questions</li>
</ul>
<h2 id="examples"><a class="header" href="#examples">Examples</a></h2>
<p>Check out the <a href="../examples/"><code>examples/</code></a> directory for sample configurations and use cases.</p>
<h2 id="community"><a class="header" href="#community">Community</a></h2>
<ul>
<li><a href="https://github.com/SaaSy-Solutions/mockforge/issues">GitHub Issues</a> - Report bugs and request features</li>
<li><a href="https://github.com/SaaSy-Solutions/mockforge/discussions">GitHub Discussions</a> - Ask questions and share ideas</li>
<li><a href="https://discord.gg/mockforge">Discord</a> - Join our community chat</li>
</ul>
<h2 id="license"><a class="header" href="#license">License</a></h2>
<p>Licensed under either of:</p>
<ul>
<li>Apache License, Version 2.0 (<a href="https://github.com/SaaSy-Solutions/mockforge/blob/main/LICENSE-APACHE">LICENSE-APACHE</a>)</li>
<li>MIT License (<a href="https://github.com/SaaSy-Solutions/mockforge/blob/main/LICENSE-MIT">LICENSE-MIT</a>)</li>
</ul>
<p>at your option.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="installation-1"><a class="header" href="#installation-1">Installation</a></h1>
<p>MockForge can be installed through multiple methods depending on your needs and environment. Choose the installation method that best fits your workflow.</p>
<h2 id="prerequisites"><a class="header" href="#prerequisites">Prerequisites</a></h2>
<p>Before installing MockForge, ensure you have one of the following:</p>
<ul>
<li><strong>Rust toolchain</strong> (for cargo installation or building from source)</li>
<li><strong>Docker</strong> (for containerized deployment)</li>
<li><strong>Pre-built binaries</strong> (when available)</li>
</ul>
<h2 id="method-1-cargo-install-recommended"><a class="header" href="#method-1-cargo-install-recommended">Method 1: Cargo Install (Recommended)</a></h2>
<p>The easiest way to install MockForge is through Cargo, Rust’s package manager:</p>
<pre><code class="language-bash">cargo install mockforge-cli
</code></pre>
<p>This installs the MockForge CLI globally on your system. After installation, you can verify it’s working:</p>
<pre><code class="language-bash">mockforge --version
</code></pre>
<h3 id="updating"><a class="header" href="#updating">Updating</a></h3>
<p>To update to the latest version:</p>
<pre><code class="language-bash">cargo install mockforge-cli --force
</code></pre>
<h2 id="method-2-docker-containerized"><a class="header" href="#method-2-docker-containerized">Method 2: Docker (Containerized)</a></h2>
<p>MockForge is also available as a Docker image, which is ideal for:</p>
<ul>
<li>Isolated environments</li>
<li>CI/CD pipelines</li>
<li>Systems without Rust installed</li>
</ul>
<h3 id="pull-from-docker-hub"><a class="header" href="#pull-from-docker-hub">Pull from Docker Hub</a></h3>
<pre><code class="language-bash">docker pull SaaSy-Solutions/mockforge
</code></pre>
<h3 id="run-with-basic-configuration"><a class="header" href="#run-with-basic-configuration">Run with basic configuration</a></h3>
<pre><code class="language-bash">docker run -p 3000:3000 -p 3001:3001 -p 50051:50051 -p 8080:8080 \
  -e MOCKFORGE_ADMIN_ENABLED=true \
  -e MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true \
  mockforge
</code></pre>
<h3 id="build-from-source"><a class="header" href="#build-from-source">Build from source</a></h3>
<pre><code class="language-bash">git clone https://github.com/SaaSy-Solutions/mockforge.git
cd mockforge
docker build -t mockforge .
</code></pre>
<h2 id="method-3-building-from-source"><a class="header" href="#method-3-building-from-source">Method 3: Building from Source</a></h2>
<p>For development or custom builds, you can build MockForge from source:</p>
<pre><code class="language-bash">git clone https://github.com/SaaSy-Solutions/mockforge.git
cd mockforge
cargo build --release
</code></pre>
<p>The binary will be available at <code>target/release/mockforge</code>.</p>
<p>To install it system-wide after building:</p>
<pre><code class="language-bash">cargo install --path crates/mockforge-cli
</code></pre>
<h2 id="verification"><a class="header" href="#verification">Verification</a></h2>
<p>After installation, verify MockForge is working:</p>
<pre><code class="language-bash"># Check version
mockforge --version

# View help
mockforge --help

# Start with example configuration
mockforge serve --spec examples/openapi-demo.json --http-port 3000
</code></pre>
<h2 id="platform-support"><a class="header" href="#platform-support">Platform Support</a></h2>
<p>MockForge supports:</p>
<ul>
<li><strong>Linux</strong> (x86_64, aarch64)</li>
<li><strong>macOS</strong> (x86_64, aarch64)</li>
<li><strong>Windows</strong> (x86_64)</li>
<li><strong>Docker</strong> (any platform with Docker support)</li>
</ul>
<h2 id="troubleshooting-installation"><a class="header" href="#troubleshooting-installation">Troubleshooting Installation</a></h2>
<h3 id="cargo-installation-fails"><a class="header" href="#cargo-installation-fails">Cargo installation fails</a></h3>
<p>If <code>cargo install</code> fails, ensure you have Rust installed:</p>
<pre><code class="language-bash">curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
source $HOME/.cargo/env
</code></pre>
<h3 id="docker-permission-issues"><a class="header" href="#docker-permission-issues">Docker permission issues</a></h3>
<p>If Docker commands fail with permission errors:</p>
<pre><code class="language-bash"># Add user to docker group (Linux)
sudo usermod -aG docker $USER
# Log out and back in for changes to take effect
</code></pre>
<h3 id="port-conflicts"><a class="header" href="#port-conflicts">Port conflicts</a></h3>
<p>If default ports (3000, 3001, 8080, 50051) are in use:</p>
<pre><code class="language-bash"># Check what's using the ports
lsof -i :3000
lsof -i :3001

# Kill conflicting processes or use different ports
mockforge serve --http-port 3001 --ws-port 3002 --admin-port 8081
</code></pre>
<h2 id="next-steps"><a class="header" href="#next-steps">Next Steps</a></h2>
<p>Once installed, proceed to the <a href="getting-started/quick-start.html">Quick Start</a> guide to create your first mock server, or read about <a href="getting-started/concepts.html">Basic Concepts</a> to understand how MockForge works.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="quick-start-1"><a class="header" href="#quick-start-1">Quick Start</a></h1>
<p>Get MockForge running in under 5 minutes with this hands-on guide. We’ll create a mock API server and test it with real HTTP requests.</p>
<h2 id="prerequisites-1"><a class="header" href="#prerequisites-1">Prerequisites</a></h2>
<p>Ensure MockForge is <a href="getting-started/installation.html">installed</a> and available in your PATH.</p>
<h2 id="step-1-start-a-basic-http-mock-server"><a class="header" href="#step-1-start-a-basic-http-mock-server">Step 1: Start a Basic HTTP Mock Server</a></h2>
<p>MockForge can serve mock APIs defined in OpenAPI specifications. Let’s use the included example:</p>
<pre><code class="language-bash"># Navigate to the MockForge directory (if building from source)
cd mockforge

# Start the server with the demo OpenAPI spec
mockforge serve --spec examples/openapi-demo.json --http-port 3000
</code></pre>
<p>You should see output like:</p>
<pre><code>MockForge v0.1.0 starting...
HTTP server listening on 0.0.0.0:3000
OpenAPI spec loaded from examples/openapi-demo.json
Ready to serve requests at http://localhost:3000
</code></pre>
<h2 id="step-2-test-your-mock-api"><a class="header" href="#step-2-test-your-mock-api">Step 2: Test Your Mock API</a></h2>
<p>Open a new terminal and test the API endpoints:</p>
<pre><code class="language-bash"># Health check endpoint
curl http://localhost:3000/ping
</code></pre>
<p>Expected response:</p>
<pre><code class="language-json">{
  "status": "pong",
  "timestamp": "2025-09-12T17:20:01.512504405+00:00",
  "requestId": "550e8400-e29b-41d4-a716-446655440000"
}
</code></pre>
<pre><code class="language-bash"># List users endpoint
curl http://localhost:3000/users
</code></pre>
<p>Expected response:</p>
<pre><code class="language-json">[
  {
    "id": "550e8400-e29b-41d4-a716-446655440001",
    "name": "John Doe",
    "email": "john@example.com",
    "createdAt": "2025-09-12T17:20:01.512504405+00:00",
    "active": true
  }
]
</code></pre>
<pre><code class="language-bash"># Create a new user
curl -X POST http://localhost:3000/users \
  -H "Content-Type: application/json" \
  -d '{"name": "Jane Smith", "email": "jane@example.com"}'
</code></pre>
<pre><code class="language-bash"># Get user by ID (path parameter)
curl http://localhost:3000/users/123
</code></pre>
<h2 id="step-3-enable-template-expansion"><a class="header" href="#step-3-enable-template-expansion">Step 3: Enable Template Expansion</a></h2>
<p>MockForge supports dynamic content generation. Enable template expansion for more realistic data:</p>
<pre><code class="language-bash"># Stop the current server (Ctrl+C), then restart with templates enabled
MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true \
mockforge serve --spec examples/openapi-demo.json --http-port 3000
</code></pre>
<p>Now test the endpoints again - you’ll see different UUIDs and timestamps each time!</p>
<h2 id="step-4-add-websocket-support"><a class="header" href="#step-4-add-websocket-support">Step 4: Add WebSocket Support</a></h2>
<p>MockForge can also mock WebSocket connections. Let’s add WebSocket support to our server:</p>
<pre><code class="language-bash"># Stop the server, then restart with WebSocket support
MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true \
MOCKFORGE_WS_REPLAY_FILE=examples/ws-demo.jsonl \
mockforge serve --spec examples/openapi-demo.json --ws-port 3001 --http-port 3000
</code></pre>
<h2 id="step-5-test-websocket-connection"><a class="header" href="#step-5-test-websocket-connection">Step 5: Test WebSocket Connection</a></h2>
<p>Test the WebSocket endpoint (requires Node.js or a WebSocket client):</p>
<pre><code class="language-bash"># Using Node.js
node -e "
const WebSocket = require('ws');
const ws = new WebSocket('ws://localhost:3001/ws');
ws.on('open', () =&gt; {
  console.log('Connected! Sending CLIENT_READY...');
  ws.send('CLIENT_READY');
});
ws.on('message', (data) =&gt; {
  console.log('Received:', data.toString());
  if (data.toString().includes('ACK')) {
    ws.send('ACK');
  }
  if (data.toString().includes('CONFIRMED')) {
    ws.send('CONFIRMED');
  }
});
ws.on('close', () =&gt; console.log('Connection closed'));
"
</code></pre>
<p>Expected WebSocket message flow:</p>
<ol>
<li>Send <code>CLIENT_READY</code></li>
<li>Receive welcome message with session ID</li>
<li>Receive data message, respond with <code>ACK</code></li>
<li>Receive heartbeat messages</li>
<li>Receive notification, respond with <code>CONFIRMED</code></li>
</ol>
<h2 id="step-6-enable-admin-ui-optional"><a class="header" href="#step-6-enable-admin-ui-optional">Step 6: Enable Admin UI (Optional)</a></h2>
<p>For a visual interface to manage your mock server:</p>
<pre><code class="language-bash"># Stop the server, then restart with admin UI
MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true \
MOCKFORGE_WS_REPLAY_FILE=examples/ws-demo.jsonl \
mockforge serve --spec examples/openapi-demo.json \
  --admin --admin-port 8080 \
  --http-port 3000 --ws-port 3001
</code></pre>
<p>Access the admin interface at: http://localhost:8080</p>
<h2 id="step-7-using-configuration-files"><a class="header" href="#step-7-using-configuration-files">Step 7: Using Configuration Files</a></h2>
<p>Instead of environment variables, you can use a configuration file:</p>
<pre><code class="language-bash"># Stop the server, then start with config file
mockforge serve --config demo-config.yaml
</code></pre>
<h2 id="step-8-docker-alternative"><a class="header" href="#step-8-docker-alternative">Step 8: Docker Alternative</a></h2>
<p>If you prefer Docker:</p>
<pre><code class="language-bash"># Build and run with Docker
docker build -t mockforge .
docker run -p 3000:3000 -p 3001:3001 -p 8080:8080 \
  -e MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true \
  -e MOCKFORGE_WS_REPLAY_FILE=examples/ws-demo.jsonl \
  mockforge
</code></pre>
<h2 id="whats-next"><a class="header" href="#whats-next">What’s Next?</a></h2>
<p>Congratulations! You now have a fully functional mock server running. Here are some next steps:</p>
<ul>
<li>Learn about <a href="getting-started/concepts.html">Basic Concepts</a> to understand how MockForge works</li>
<li>Explore <a href="getting-started/../user-guide/http-mocking.html">HTTP Mocking</a> for advanced REST API features</li>
<li>Try <a href="getting-started/../user-guide/websocket-mocking.html">WebSocket Mocking</a> for real-time communication</li>
<li>Check out the <a href="getting-started/../user-guide/admin-ui.html">Admin UI</a> for visual management</li>
</ul>
<h2 id="troubleshooting"><a class="header" href="#troubleshooting">Troubleshooting</a></h2>
<h3 id="server-wont-start"><a class="header" href="#server-wont-start">Server won’t start</a></h3>
<ul>
<li>Check if ports 3000, 3001, or 8080 are already in use</li>
<li>Verify the OpenAPI spec file path is correct</li>
<li>Ensure MockForge is properly installed</li>
</ul>
<h3 id="template-variables-not-working"><a class="header" href="#template-variables-not-working">Template variables not working</a></h3>
<ul>
<li>Make sure <code>MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true</code> is set</li>
<li>Check that template syntax <code>{{variable}}</code> is used correctly</li>
</ul>
<h3 id="websocket-connection-fails"><a class="header" href="#websocket-connection-fails">WebSocket connection fails</a></h3>
<ul>
<li>Verify WebSocket port (default 3001) is accessible</li>
<li>Check that <code>MOCKFORGE_WS_REPLAY_FILE</code> points to a valid replay file</li>
<li>Ensure the replay file uses the correct JSONL format</li>
</ul>
<h3 id="need-help"><a class="header" href="#need-help">Need help?</a></h3>
<ul>
<li>Check the <a href="getting-started/../../examples/README.html">examples README</a> for detailed testing scripts</li>
<li>Review <a href="getting-started/../configuration/files.html">Configuration Files</a> for advanced setup</li>
<li>Visit the <a href="getting-started/../reference/troubleshooting.html">Troubleshooting</a> guide</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="basic-concepts"><a class="header" href="#basic-concepts">Basic Concepts</a></h1>
<p>Understanding MockForge’s core concepts will help you make the most of its capabilities. This guide explains the fundamental ideas behind MockForge’s design and functionality.</p>
<h2 id="multi-protocol-architecture"><a class="header" href="#multi-protocol-architecture">Multi-Protocol Architecture</a></h2>
<p>MockForge is designed to mock multiple communication protocols within a single, unified framework:</p>
<h3 id="httprest-apis"><a class="header" href="#httprest-apis">HTTP/REST APIs</a></h3>
<ul>
<li><strong>OpenAPI/Swagger Support</strong>: Define API contracts using industry-standard OpenAPI specifications</li>
<li><strong>Dynamic Response Generation</strong>: Generate realistic responses based on request parameters</li>
<li><strong>Request/Response Matching</strong>: Route requests to appropriate mock responses based on HTTP methods, paths, and parameters</li>
</ul>
<h3 id="websocket-connections"><a class="header" href="#websocket-connections">WebSocket Connections</a></h3>
<ul>
<li><strong>Replay Mode</strong>: Simulate scripted message sequences from recorded interactions</li>
<li><strong>Interactive Mode</strong>: Respond dynamically to client messages</li>
<li><strong>State Management</strong>: Maintain connection state across message exchanges</li>
</ul>
<h3 id="grpc-services"><a class="header" href="#grpc-services">gRPC Services</a></h3>
<ul>
<li><strong>Protocol Buffer Integration</strong>: Mock services defined with .proto files</li>
<li><strong>Dynamic Service Discovery</strong>: Automatically discover and compile .proto files</li>
<li><strong>Streaming Support</strong>: Handle unary, server streaming, client streaming, and bidirectional streaming</li>
<li><strong>Reflection Support</strong>: Built-in gRPC reflection for service discovery</li>
</ul>
<h2 id="response-generation-strategies"><a class="header" href="#response-generation-strategies">Response Generation Strategies</a></h2>
<p>MockForge offers multiple approaches to generating mock responses:</p>
<h3 id="1-static-responses"><a class="header" href="#1-static-responses">1. Static Responses</a></h3>
<p>Define fixed response payloads that are returned for matching requests:</p>
<pre><code class="language-json">{
  "status": "success",
  "data": {
    "id": 123,
    "name": "Example Item"
  }
}
</code></pre>
<h3 id="2-template-based-dynamic-responses"><a class="header" href="#2-template-based-dynamic-responses">2. Template-Based Dynamic Responses</a></h3>
<p>Use template variables for dynamic content generation:</p>
<pre><code class="language-json">{
  "id": "{{uuid}}",
  "timestamp": "{{now}}",
  "randomValue": "{{randInt 1 100}}",
  "userData": "{{request.body}}"
}
</code></pre>
<h3 id="3-scenario-based-responses"><a class="header" href="#3-scenario-based-responses">3. Scenario-Based Responses</a></h3>
<p>Define complex interaction scenarios with conditional logic and state management.</p>
<h3 id="4-advanced-data-synthesis-grpc"><a class="header" href="#4-advanced-data-synthesis-grpc">4. Advanced Data Synthesis (gRPC)</a></h3>
<p>For gRPC services, MockForge provides sophisticated data synthesis capabilities:</p>
<ul>
<li><strong>Smart Field Inference</strong>: Automatically detects data types from field names (emails, phones, IDs)</li>
<li><strong>Deterministic Generation</strong>: Reproducible test data with seeded randomness</li>
<li><strong>Relationship Awareness</strong>: Maintains referential integrity across related entities</li>
<li><strong>RAG-Driven Generation</strong>: Uses domain knowledge for contextually appropriate data</li>
</ul>
<h2 id="template-system"><a class="header" href="#template-system">Template System</a></h2>
<p>MockForge’s template system enables dynamic content generation using Handlebars-style syntax:</p>
<h3 id="built-in-template-functions"><a class="header" href="#built-in-template-functions">Built-in Template Functions</a></h3>
<h4 id="data-generation"><a class="header" href="#data-generation">Data Generation</a></h4>
<ul>
<li><code>{{uuid}}</code> - Generate unique UUID v4 identifiers</li>
<li><code>{{now}}</code> - Current timestamp in ISO 8601 format</li>
<li><code>{{now+1h}}</code> - Future timestamps with offset support</li>
<li><code>{{randInt min max}}</code> - Random integers within a range</li>
<li><code>{{randFloat min max}}</code> - Random floating-point numbers</li>
</ul>
<h4 id="request-data-access"><a class="header" href="#request-data-access">Request Data Access</a></h4>
<ul>
<li><code>{{request.body}}</code> - Access complete request body</li>
<li><code>{{request.body.field}}</code> - Access specific JSON fields</li>
<li><code>{{request.path.param}}</code> - Access URL path parameters</li>
<li><code>{{request.query.param}}</code> - Access query string parameters</li>
<li><code>{{request.header.name}}</code> - Access HTTP headers</li>
</ul>
<h4 id="conditional-logic"><a class="header" href="#conditional-logic">Conditional Logic</a></h4>
<ul>
<li><code>{{#if condition}}content{{/if}}</code> - Conditional content rendering</li>
<li><code>{{#each array}}item{{/each}}</code> - Iterate over arrays</li>
</ul>
<h3 id="template-expansion-control"><a class="header" href="#template-expansion-control">Template Expansion Control</a></h3>
<p>Templates are only processed when explicitly enabled:</p>
<pre><code class="language-bash"># Enable template expansion
MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true
</code></pre>
<p>This security feature prevents accidental template processing in production environments.</p>
<h2 id="configuration-hierarchy"><a class="header" href="#configuration-hierarchy">Configuration Hierarchy</a></h2>
<p>MockForge supports multiple configuration methods with clear precedence:</p>
<h3 id="1-command-line-arguments-highest-priority"><a class="header" href="#1-command-line-arguments-highest-priority">1. Command Line Arguments (Highest Priority)</a></h3>
<pre><code class="language-bash">mockforge serve --http-port 3000 --ws-port 3001 --spec api.json
</code></pre>
<h3 id="2-environment-variables"><a class="header" href="#2-environment-variables">2. Environment Variables</a></h3>
<pre><code class="language-bash">MOCKFORGE_HTTP_PORT=3000
MOCKFORGE_WS_PORT=3001
MOCKFORGE_OPENAPI_SPEC=api.json
</code></pre>
<h3 id="3-configuration-files-lowest-priority"><a class="header" href="#3-configuration-files-lowest-priority">3. Configuration Files (Lowest Priority)</a></h3>
<pre><code class="language-yaml"># config.yaml
server:
  http_port: 3000
  ws_port: 3001
spec: api.json
</code></pre>
<h2 id="server-modes"><a class="header" href="#server-modes">Server Modes</a></h2>
<h3 id="development-mode"><a class="header" href="#development-mode">Development Mode</a></h3>
<ul>
<li><strong>Template Expansion</strong>: Enabled by default for dynamic content</li>
<li><strong>Verbose Logging</strong>: Detailed request/response logging</li>
<li><strong>Admin UI</strong>: Enabled for visual server management</li>
<li><strong>CORS</strong>: Permissive cross-origin requests</li>
</ul>
<h3 id="production-mode"><a class="header" href="#production-mode">Production Mode</a></h3>
<ul>
<li><strong>Template Expansion</strong>: Disabled by default for security</li>
<li><strong>Minimal Logging</strong>: Essential information only</li>
<li><strong>Performance Optimized</strong>: Reduced overhead for high-throughput scenarios</li>
</ul>
<h2 id="request-matching"><a class="header" href="#request-matching">Request Matching</a></h2>
<p>MockForge uses a sophisticated matching system to route requests to appropriate responses:</p>
<h3 id="http-request-matching"><a class="header" href="#http-request-matching">HTTP Request Matching</a></h3>
<ol>
<li><strong>Method Matching</strong>: GET, POST, PUT, DELETE, PATCH</li>
<li><strong>Path Matching</strong>: Exact path or parameterized routes</li>
<li><strong>Query Parameter Matching</strong>: Optional query string conditions</li>
<li><strong>Header Matching</strong>: Conditional responses based on request headers</li>
<li><strong>Body Matching</strong>: Match against request payload structure</li>
</ol>
<h3 id="priority-order"><a class="header" href="#priority-order">Priority Order</a></h3>
<ol>
<li>Most specific match first (method + path + query + headers + body)</li>
<li>Fall back to less specific matches</li>
<li>Default response for unmatched requests</li>
</ol>
<h2 id="state-management"><a class="header" href="#state-management">State Management</a></h2>
<p>For complex scenarios, MockForge supports maintaining state across requests:</p>
<h3 id="session-state"><a class="header" href="#session-state">Session State</a></h3>
<ul>
<li><strong>Connection-specific data</strong> persists across WebSocket messages</li>
<li><strong>HTTP session cookies</strong> maintain state between requests</li>
<li><strong>Scenario progression</strong> tracks interaction flow</li>
</ul>
<h3 id="global-state"><a class="header" href="#global-state">Global State</a></h3>
<ul>
<li><strong>Shared data</strong> accessible across all connections</li>
<li><strong>Configuration updates</strong> applied dynamically</li>
<li><strong>Metrics and counters</strong> maintained server-wide</li>
</ul>
<h2 id="extensibility"><a class="header" href="#extensibility">Extensibility</a></h2>
<p>MockForge is designed for extension through multiple mechanisms:</p>
<h3 id="custom-response-generators"><a class="header" href="#custom-response-generators">Custom Response Generators</a></h3>
<p>Implement custom logic for generating complex responses based on business rules.</p>
<h3 id="plugin-system"><a class="header" href="#plugin-system">Plugin System</a></h3>
<p>Extend functionality through compiled plugins for specialized use cases.</p>
<h3 id="configuration-extensions"><a class="header" href="#configuration-extensions">Configuration Extensions</a></h3>
<p>Add custom configuration options for domain-specific requirements.</p>
<h2 id="security-considerations"><a class="header" href="#security-considerations">Security Considerations</a></h2>
<h3 id="template-injection-prevention"><a class="header" href="#template-injection-prevention">Template Injection Prevention</a></h3>
<ul>
<li>Templates are disabled by default in production</li>
<li>Explicit opt-in required for template processing</li>
<li>Input validation prevents malicious template injection</li>
</ul>
<h3 id="access-control"><a class="header" href="#access-control">Access Control</a></h3>
<ul>
<li>Configurable CORS policies</li>
<li>Request rate limiting options</li>
<li>Authentication simulation support</li>
</ul>
<h3 id="data-privacy"><a class="header" href="#data-privacy">Data Privacy</a></h3>
<ul>
<li>Request/response logging controls</li>
<li>Sensitive data masking capabilities</li>
<li>Compliance-friendly configuration options</li>
</ul>
<h2 id="performance-characteristics"><a class="header" href="#performance-characteristics">Performance Characteristics</a></h2>
<h3 id="throughput"><a class="header" href="#throughput">Throughput</a></h3>
<ul>
<li><strong>HTTP APIs</strong>: 10,000+ requests/second (depending on response complexity)</li>
<li><strong>WebSocket</strong>: 1,000+ concurrent connections</li>
<li><strong>Memory Usage</strong>: Minimal overhead per connection</li>
</ul>
<h3 id="scalability"><a class="header" href="#scalability">Scalability</a></h3>
<ul>
<li><strong>Horizontal Scaling</strong>: Multiple instances behind load balancer</li>
<li><strong>Resource Efficiency</strong>: Low CPU and memory footprint</li>
<li><strong>Concurrent Users</strong>: Support for thousands of simultaneous connections</li>
</ul>
<h2 id="integration-patterns"><a class="header" href="#integration-patterns">Integration Patterns</a></h2>
<p>MockForge works well in various development and testing scenarios:</p>
<h3 id="api-development"><a class="header" href="#api-development">API Development</a></h3>
<ul>
<li><strong>Contract-First Development</strong>: Mock APIs before implementation</li>
<li><strong>Parallel Development</strong>: Frontend and backend teams work independently</li>
<li><strong>Integration Testing</strong>: Validate API contracts between services</li>
</ul>
<h3 id="microservices-testing"><a class="header" href="#microservices-testing">Microservices Testing</a></h3>
<ul>
<li><strong>Service Virtualization</strong>: Mock dependent services during testing</li>
<li><strong>Chaos Engineering</strong>: Simulate service failures and latency</li>
<li><strong>Load Testing</strong>: Generate realistic traffic patterns</li>
</ul>
<h3 id="cicd-pipelines"><a class="header" href="#cicd-pipelines">CI/CD Pipelines</a></h3>
<ul>
<li><strong>Automated Testing</strong>: Mock external dependencies in test environments</li>
<li><strong>Deployment Validation</strong>: Verify application behavior with mock services</li>
<li><strong>Performance Benchmarking</strong>: Consistent test conditions across environments</li>
</ul>
<p>This foundation will help you understand how to effectively use MockForge for your specific use case. The following guides provide detailed instructions for configuring and using each protocol and feature.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="http-mocking"><a class="header" href="#http-mocking">HTTP Mocking</a></h1>
<p>MockForge provides comprehensive HTTP API mocking capabilities with OpenAPI specification support, dynamic response generation, and advanced request matching. This guide covers everything you need to create realistic REST API mocks.</p>
<h2 id="openapi-integration"><a class="header" href="#openapi-integration">OpenAPI Integration</a></h2>
<p>MockForge uses OpenAPI (formerly Swagger) specifications as the foundation for HTTP API mocking. This industry-standard approach ensures your mocks accurately reflect real API contracts.</p>
<h3 id="loading-openapi-specifications"><a class="header" href="#loading-openapi-specifications">Loading OpenAPI Specifications</a></h3>
<pre><code class="language-bash"># Load from JSON file
mockforge serve --spec api-spec.json --http-port 3000

# Load from YAML file
mockforge serve --spec api-spec.yaml --http-port 3000

# Load from URL
mockforge serve --spec https://api.example.com/openapi.json --http-port 3000
</code></pre>
<h3 id="openapi-specification-structure"><a class="header" href="#openapi-specification-structure">OpenAPI Specification Structure</a></h3>
<p>MockForge supports OpenAPI 3.0+ specifications with the following key components:</p>
<ul>
<li><strong>Paths</strong>: API endpoint definitions</li>
<li><strong>Methods</strong>: HTTP verbs (GET, POST, PUT, DELETE, PATCH)</li>
<li><strong>Parameters</strong>: Path, query, and header parameters</li>
<li><strong>Request Bodies</strong>: JSON/XML payload schemas</li>
<li><strong>Responses</strong>: Status codes and response schemas</li>
<li><strong>Components</strong>: Reusable schemas and examples</li>
</ul>
<h3 id="example-openapi-specification"><a class="header" href="#example-openapi-specification">Example OpenAPI Specification</a></h3>
<pre><code class="language-yaml">openapi: 3.0.3
info:
  title: User Management API
  version: 1.0.0
paths:
  /users:
    get:
      summary: List users
      parameters:
        - name: limit
          in: query
          schema:
            type: integer
            default: 10
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: '#/components/schemas/User'
    post:
      summary: Create user
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/UserInput'
      responses:
        '201':
          description: User created
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/User'

  /users/{id}:
    get:
      summary: Get user by ID
      parameters:
        - name: id
          in: path
          required: true
          schema:
            type: string
      responses:
        '200':
          description: User found
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/User'
        '404':
          description: User not found

components:
  schemas:
    User:
      type: object
      properties:
        id:
          type: string
          format: uuid
        name:
          type: string
        email:
          type: string
          format: email
        createdAt:
          type: string
          format: date-time
    UserInput:
      type: object
      required:
        - name
        - email
      properties:
        name:
          type: string
        email:
          type: string
</code></pre>
<h2 id="dynamic-response-generation"><a class="header" href="#dynamic-response-generation">Dynamic Response Generation</a></h2>
<p>MockForge generates realistic responses automatically based on your OpenAPI schemas, with support for dynamic data through templates.</p>
<h3 id="automatic-response-generation"><a class="header" href="#automatic-response-generation">Automatic Response Generation</a></h3>
<p>For basic use cases, MockForge can generate responses directly from your OpenAPI schemas:</p>
<pre><code class="language-bash"># Start server with automatic response generation
mockforge serve --spec api-spec.json --http-port 3000
</code></pre>
<p>This generates:</p>
<ul>
<li><strong>UUIDs</strong> for ID fields</li>
<li><strong>Random data</strong> for string/number fields</li>
<li><strong>Current timestamps</strong> for date-time fields</li>
<li><strong>Valid email addresses</strong> for email fields</li>
</ul>
<h3 id="template-enhanced-responses"><a class="header" href="#template-enhanced-responses">Template-Enhanced Responses</a></h3>
<p>For more control, use MockForge’s template system in your OpenAPI examples:</p>
<pre><code class="language-yaml">paths:
  /users:
    get:
      responses:
        '200':
          description: List of users
          content:
            application/json:
              example:
                users:
                  - id: "{{uuid}}"
                    name: "John Doe"
                    email: "john@example.com"
                    createdAt: "{{now}}"
                    lastLogin: "{{now-1d}}"
                  - id: "{{uuid}}"
                    name: "Jane Smith"
                    email: "jane@example.com"
                    createdAt: "{{now-7d}}"
                    lastLogin: "{{now-2h}}"
</code></pre>
<h3 id="template-functions"><a class="header" href="#template-functions">Template Functions</a></h3>
<h4 id="data-generation-templates"><a class="header" href="#data-generation-templates">Data Generation Templates</a></h4>
<ul>
<li><code>{{uuid}}</code> - Generate unique UUID</li>
<li><code>{{now}}</code> - Current timestamp</li>
<li><code>{{now+1h}}</code> - Future timestamp</li>
<li><code>{{now-1d}}</code> - Past timestamp</li>
<li><code>{{randInt 1 100}}</code> - Random integer</li>
<li><code>{{randFloat 0.0 1.0}}</code> - Random float</li>
</ul>
<h4 id="request-data-templates"><a class="header" href="#request-data-templates">Request Data Templates</a></h4>
<ul>
<li><code>{{request.path.id}}</code> - Access path parameters</li>
<li><code>{{request.query.limit}}</code> - Access query parameters</li>
<li><code>{{request.header.Authorization}}</code> - Access headers</li>
<li><code>{{request.body.name}}</code> - Access request body fields</li>
</ul>
<h2 id="request-matching-and-routing"><a class="header" href="#request-matching-and-routing">Request Matching and Routing</a></h2>
<p>MockForge uses sophisticated matching to route requests to appropriate responses.</p>
<h3 id="matching-priority"><a class="header" href="#matching-priority">Matching Priority</a></h3>
<ol>
<li><strong>Exact Path + Method Match</strong></li>
<li><strong>Parameterized Path Match</strong> (e.g., <code>/users/{id}</code>)</li>
<li><strong>Query Parameter Conditions</strong></li>
<li><strong>Header-Based Conditions</strong></li>
<li><strong>Request Body Matching</strong></li>
<li><strong>Default Response</strong> (catch-all)</li>
</ol>
<h3 id="path-parameter-handling"><a class="header" href="#path-parameter-handling">Path Parameter Handling</a></h3>
<pre><code class="language-yaml">/users/{id}:
  get:
    parameters:
      - name: id
        in: path
        required: true
        schema:
          type: string
    responses:
      '200':
        content:
          application/json:
            example:
              id: "{{request.path.id}}"
              name: "User {{request.path.id}}"
              retrievedAt: "{{now}}"
</code></pre>
<h3 id="query-parameter-filtering"><a class="header" href="#query-parameter-filtering">Query Parameter Filtering</a></h3>
<pre><code class="language-yaml">/users:
  get:
    parameters:
      - name: status
        in: query
        schema:
          type: string
          enum: [active, inactive]
      - name: limit
        in: query
        schema:
          type: integer
          default: 10
    responses:
      '200':
        content:
          application/json:
            example: "{{#if (eq request.query.status 'active')}}active_users{{else}}all_users{{/if}}"
</code></pre>
<h2 id="response-scenarios"><a class="header" href="#response-scenarios">Response Scenarios</a></h2>
<p>MockForge supports multiple response scenarios for testing different conditions.</p>
<h3 id="success-responses"><a class="header" href="#success-responses">Success Responses</a></h3>
<pre><code class="language-yaml">responses:
  '200':
    description: Success
    content:
      application/json:
        example:
          status: "success"
          data: { ... }
</code></pre>
<h3 id="error-responses"><a class="header" href="#error-responses">Error Responses</a></h3>
<pre><code class="language-yaml">responses:
  '400':
    description: Bad Request
    content:
      application/json:
        example:
          error: "INVALID_INPUT"
          message: "The provided input is invalid"
  '404':
    description: Not Found
    content:
      application/json:
        example:
          error: "NOT_FOUND"
          message: "Resource not found"
  '500':
    description: Internal Server Error
    content:
      application/json:
        example:
          error: "INTERNAL_ERROR"
          message: "An unexpected error occurred"
</code></pre>
<h3 id="conditional-responses"><a class="header" href="#conditional-responses">Conditional Responses</a></h3>
<p>Use templates to return different responses based on request data:</p>
<pre><code class="language-yaml">responses:
  '200':
    content:
      application/json:
        example: |
          {{#if (eq request.query.format 'detailed')}}
          {
            "id": "{{uuid}}",
            "name": "Detailed User",
            "email": "user@example.com",
            "profile": {
              "bio": "Detailed user profile",
              "preferences": { ... }
            }
          }
          {{else}}
          {
            "id": "{{uuid}}",
            "name": "Basic User",
            "email": "user@example.com"
          }
          {{/if}}
</code></pre>
<h2 id="advanced-features"><a class="header" href="#advanced-features">Advanced Features</a></h2>
<h3 id="response-latency-simulation"><a class="header" href="#response-latency-simulation">Response Latency Simulation</a></h3>
<pre><code class="language-bash"># Add random latency (100-500ms)
MOCKFORGE_LATENCY_ENABLED=true \
MOCKFORGE_LATENCY_MIN_MS=100 \
MOCKFORGE_LATENCY_MAX_MS=500 \
mockforge serve --spec api-spec.json
</code></pre>
<h3 id="failure-injection"><a class="header" href="#failure-injection">Failure Injection</a></h3>
<pre><code class="language-bash"># Enable random failures (10% chance)
MOCKFORGE_FAILURES_ENABLED=true \
MOCKFORGE_FAILURE_RATE=0.1 \
mockforge serve --spec api-spec.json
</code></pre>
<h3 id="requestresponse-recording"><a class="header" href="#requestresponse-recording">Request/Response Recording</a></h3>
<pre><code class="language-bash"># Record all HTTP interactions
MOCKFORGE_RECORD_ENABLED=true \
mockforge serve --spec api-spec.json
</code></pre>
<h3 id="response-replay"><a class="header" href="#response-replay">Response Replay</a></h3>
<pre><code class="language-bash"># Replay recorded responses
MOCKFORGE_REPLAY_ENABLED=true \
mockforge serve --spec api-spec.json
</code></pre>
<h2 id="testing-your-mocks"><a class="header" href="#testing-your-mocks">Testing Your Mocks</a></h2>
<h3 id="manual-testing-with-curl"><a class="header" href="#manual-testing-with-curl">Manual Testing with curl</a></h3>
<pre><code class="language-bash"># Test GET endpoint
curl http://localhost:3000/users

# Test POST endpoint
curl -X POST http://localhost:3000/users \
  -H "Content-Type: application/json" \
  -d '{"name": "Test User", "email": "test@example.com"}'

# Test path parameters
curl http://localhost:3000/users/123

# Test query parameters
curl "http://localhost:3000/users?limit=5&amp;status=active"

# Test error scenarios
curl http://localhost:3000/users/999  # Should return 404
</code></pre>
<h3 id="automated-testing"><a class="header" href="#automated-testing">Automated Testing</a></h3>
<pre><code class="language-bash">#!/bin/bash
# test-api.sh

BASE_URL="http://localhost:3000"

echo "Testing User API..."

# Test user creation
USER_RESPONSE=$(curl -s -X POST $BASE_URL/users \
  -H "Content-Type: application/json" \
  -d '{"name": "Test User", "email": "test@example.com"}')

echo "Created user: $USER_RESPONSE"

# Extract user ID (assuming response contains id)
USER_ID=$(echo $USER_RESPONSE | jq -r '.id')

# Test user retrieval
RETRIEVED_USER=$(curl -s $BASE_URL/users/$USER_ID)
echo "Retrieved user: $RETRIEVED_USER"

# Test user listing
USER_LIST=$(curl -s $BASE_URL/users)
echo "User list: $USER_LIST"

echo "API tests completed!"
</code></pre>
<h2 id="best-practices"><a class="header" href="#best-practices">Best Practices</a></h2>
<h3 id="openapi-specification-tips"><a class="header" href="#openapi-specification-tips">OpenAPI Specification Tips</a></h3>
<ol>
<li><strong>Use descriptive operation IDs</strong> for better organization</li>
<li><strong>Include examples</strong> in your OpenAPI spec for consistent responses</li>
<li><strong>Define reusable components</strong> for common schemas</li>
<li><strong>Use appropriate HTTP status codes</strong> for different scenarios</li>
<li><strong>Document all parameters</strong> clearly</li>
</ol>
<h3 id="template-usage-guidelines"><a class="header" href="#template-usage-guidelines">Template Usage Guidelines</a></h3>
<ol>
<li><strong>Enable templates only when needed</strong> for security</li>
<li><strong>Use meaningful template variables</strong> for maintainability</li>
<li><strong>Test template expansion</strong> thoroughly</li>
<li><strong>Avoid complex logic in templates</strong> - keep it simple</li>
</ol>
<h3 id="response-design-principles"><a class="header" href="#response-design-principles">Response Design Principles</a></h3>
<ol>
<li><strong>Match real API behavior</strong> as closely as possible</li>
<li><strong>Include appropriate error responses</strong> for testing</li>
<li><strong>Use consistent data formats</strong> across endpoints</li>
<li><strong>Consider pagination</strong> for list endpoints</li>
<li><strong>Include metadata</strong> like timestamps and request IDs</li>
</ol>
<h3 id="performance-considerations"><a class="header" href="#performance-considerations">Performance Considerations</a></h3>
<ol>
<li><strong>Use static responses</strong> when dynamic data isn’t needed</li>
<li><strong>Limit template complexity</strong> to maintain response times</li>
<li><strong>Configure appropriate timeouts</strong> for your use case</li>
<li><strong>Monitor memory usage</strong> with large response payloads</li>
</ol>
<h2 id="troubleshooting-1"><a class="header" href="#troubleshooting-1">Troubleshooting</a></h2>
<h3 id="common-issues"><a class="header" href="#common-issues">Common Issues</a></h3>
<p><strong>Templates not expanding</strong>: Ensure <code>MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true</code></p>
<p><strong>OpenAPI spec not loading</strong>: Check file path and JSON/YAML syntax</p>
<p><strong>Wrong response returned</strong>: Verify request matching rules and parameter handling</p>
<p><strong>Performance issues</strong>: Reduce template complexity or use static responses</p>
<p><strong>Port conflicts</strong>: Change default ports with <code>--http-port</code> option</p>
<p>For more advanced HTTP mocking features, see the following guides:</p>
<ul>
<li><a href="user-guide/http-mocking/openapi.html">OpenAPI Integration</a> - Advanced OpenAPI features</li>
<li><a href="user-guide/http-mocking/custom-responses.html">Custom Responses</a> - Complex response scenarios</li>
<li><a href="user-guide/http-mocking/dynamic-data.html">Dynamic Data</a> - Advanced templating techniques</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="openapi-integration-1"><a class="header" href="#openapi-integration-1">OpenAPI Integration</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="custom-responses"><a class="header" href="#custom-responses">Custom Responses</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="dynamic-data"><a class="header" href="#dynamic-data">Dynamic Data</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="grpc-mocking"><a class="header" href="#grpc-mocking">gRPC Mocking</a></h1>
<p>MockForge provides comprehensive gRPC service mocking with dynamic Protocol Buffer discovery, streaming support, and flexible service registration. This enables testing of gRPC-based microservices and APIs with realistic mock responses.</p>
<h2 id="overview"><a class="header" href="#overview">Overview</a></h2>
<p>MockForge’s gRPC mocking system offers:</p>
<ul>
<li><strong>Dynamic Proto Discovery</strong>: Automatically discovers and compiles <code>.proto</code> files from configurable directories</li>
<li><strong>Flexible Service Registration</strong>: Register and mock any gRPC service without hardcoding</li>
<li><strong>Streaming Support</strong>: Full support for unary, server streaming, client streaming, and bidirectional streaming</li>
<li><strong>Reflection Support</strong>: Built-in gRPC reflection for service discovery and testing</li>
<li><strong>Template Integration</strong>: Use MockForge’s template system for dynamic response generation</li>
<li><strong>Advanced Data Synthesis</strong>: Intelligent mock data generation with deterministic seeding, relationship awareness, and RAG-driven domain knowledge</li>
</ul>
<h2 id="quick-start-2"><a class="header" href="#quick-start-2">Quick Start</a></h2>
<h3 id="basic-grpc-server"><a class="header" href="#basic-grpc-server">Basic gRPC Server</a></h3>
<p>Start a gRPC mock server with default configuration:</p>
<pre><code class="language-bash"># Start with default proto directory (proto/)
mockforge serve --grpc-port 50051
</code></pre>
<h3 id="with-custom-proto-directory"><a class="header" href="#with-custom-proto-directory">With Custom Proto Directory</a></h3>
<pre><code class="language-bash"># Specify custom proto directory
MOCKFORGE_PROTO_DIR=my-protos mockforge serve --grpc-port 50051
</code></pre>
<h3 id="complete-example"><a class="header" href="#complete-example">Complete Example</a></h3>
<pre><code class="language-bash"># Start MockForge with HTTP, WebSocket, and gRPC support
MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true \
MOCKFORGE_WS_REPLAY_FILE=examples/ws-demo.jsonl \
MOCKFORGE_PROTO_DIR=examples/grpc-protos \
mockforge serve \
  --spec examples/openapi-demo.json \
  --http-port 3000 \
  --ws-port 3001 \
  --grpc-port 50051 \
  --admin --admin-port 8080
</code></pre>
<h2 id="proto-file-setup"><a class="header" href="#proto-file-setup">Proto File Setup</a></h2>
<h3 id="directory-structure"><a class="header" href="#directory-structure">Directory Structure</a></h3>
<p>MockForge automatically discovers <code>.proto</code> files in a configurable directory:</p>
<pre><code>your-project/
├── proto/                    # Default proto directory
│   ├── user_service.proto   # Will be discovered
│   ├── payment.proto        # Will be discovered
│   └── subdir/
│       └── analytics.proto  # Will be discovered (recursive)
└── examples/
    └── grpc-protos/         # Custom proto directory
        └── service.proto
</code></pre>
<h3 id="sample-proto-file"><a class="header" href="#sample-proto-file">Sample Proto File</a></h3>
<pre><code class="language-protobuf">syntax = "proto3";
package mockforge.user;

service UserService {
  rpc GetUser(GetUserRequest) returns (UserResponse);
  rpc ListUsers(ListUsersRequest) returns (stream UserResponse);
  rpc CreateUser(stream CreateUserRequest) returns (UserResponse);
  rpc Chat(stream ChatMessage) returns (stream ChatMessage);
}

message GetUserRequest {
  string user_id = 1;
}

message UserResponse {
  string user_id = 1;
  string name = 2;
  string email = 3;
  int64 created_at = 4;
  Status status = 5;
}

message ListUsersRequest {
  int32 limit = 1;
  string filter = 2;
}

message CreateUserRequest {
  string name = 1;
  string email = 2;
}

message ChatMessage {
  string user_id = 1;
  string content = 2;
  int64 timestamp = 3;
}

enum Status {
  UNKNOWN = 0;
  ACTIVE = 1;
  INACTIVE = 2;
  SUSPENDED = 3;
}
</code></pre>
<h2 id="dynamic-response-generation-1"><a class="header" href="#dynamic-response-generation-1">Dynamic Response Generation</a></h2>
<p>MockForge generates responses automatically based on your proto message schemas, with support for templates and custom logic.</p>
<h3 id="automatic-response-generation-1"><a class="header" href="#automatic-response-generation-1">Automatic Response Generation</a></h3>
<p>For basic use cases, MockForge generates responses from proto schemas:</p>
<ul>
<li><strong>Strings</strong>: Random realistic values</li>
<li><strong>Integers</strong>: Random numbers in appropriate ranges</li>
<li><strong>Timestamps</strong>: Current time or future dates</li>
<li><strong>Enums</strong>: Random valid enum values</li>
<li><strong>Messages</strong>: Nested objects with generated data</li>
<li><strong>Repeated fields</strong>: Arrays with multiple generated items</li>
</ul>
<h3 id="template-enhanced-responses-1"><a class="header" href="#template-enhanced-responses-1">Template-Enhanced Responses</a></h3>
<p>Use MockForge templates in proto comments for custom responses:</p>
<pre><code class="language-protobuf">message UserResponse {
  string user_id = 1; // {{uuid}}
  string name = 2; // {{request.user_id == "123" ? "John Doe" : "Jane Smith"}}
  string email = 3; // {{name | replace(" ", ".") | lower}}@example.com
  int64 created_at = 4; // {{now}}
  Status status = 5; // ACTIVE
}
</code></pre>
<h3 id="request-context-access"><a class="header" href="#request-context-access">Request Context Access</a></h3>
<p>Access request data in templates:</p>
<pre><code class="language-protobuf">message UserResponse {
  string user_id = 1; // {{request.user_id}}
  string requested_by = 2; // {{request.metadata.user_id}}
  string message = 3; // User {{request.user_id}} was retrieved
}
</code></pre>
<h2 id="testing-grpc-services"><a class="header" href="#testing-grpc-services">Testing gRPC Services</a></h2>
<h3 id="using-grpc-cli-tools"><a class="header" href="#using-grpc-cli-tools">Using gRPC CLI Tools</a></h3>
<h4 id="grpcurl-recommended"><a class="header" href="#grpcurl-recommended">grpcurl (Recommended)</a></h4>
<pre><code class="language-bash"># Install grpcurl
go install github.com/fullstorydev/grpcurl/cmd/grpcurl@latest

# List available services
grpcurl -plaintext localhost:50051 list

# Call a unary method
grpcurl -plaintext -d '{"user_id": "123"}' \
  localhost:50051 mockforge.user.UserService/GetUser

# Call a server streaming method
grpcurl -plaintext -d '{"limit": 5}' \
  localhost:50051 mockforge.user.UserService/ListUsers

# Call a client streaming method
echo '{"name": "Alice", "email": "alice@example.com"}' | \
grpcurl -plaintext -d @ \
  localhost:50051 mockforge.user.UserService/CreateUser
</code></pre>
<h4 id="grpcui-web-interface"><a class="header" href="#grpcui-web-interface">grpcui (Web Interface)</a></h4>
<pre><code class="language-bash"># Install grpcui
go install github.com/fullstorydev/grpcui/cmd/grpcui@latest

# Start web interface
grpcui -plaintext localhost:50051

# Open http://localhost:2633 in your browser
</code></pre>
<h3 id="programmatic-testing"><a class="header" href="#programmatic-testing">Programmatic Testing</a></h3>
<h4 id="nodejs-with-grpc-js"><a class="header" href="#nodejs-with-grpc-js">Node.js with grpc-js</a></h4>
<pre><code class="language-javascript">const grpc = require('@grpc/grpc-js');
const protoLoader = require('@grpc/proto-loader');

const packageDefinition = protoLoader.loadSync(
  'proto/user_service.proto',
  {
    keepCase: true,
    longs: String,
    enums: String,
    defaults: true,
    oneofs: true
  }
);

const protoDescriptor = grpc.loadPackageDefinition(packageDefinition);
const client = new protoDescriptor.mockforge.user.UserService(
  'localhost:50051',
  grpc.credentials.createInsecure()
);

// Unary call
client.GetUser({ user_id: '123' }, (error, response) =&gt; {
  if (error) {
    console.error('Error:', error);
  } else {
    console.log('Response:', response);
  }
});

// Server streaming
const stream = client.ListUsers({ limit: 5 });
stream.on('data', (response) =&gt; {
  console.log('User:', response);
});
stream.on('end', () =&gt; {
  console.log('Stream ended');
});
</code></pre>
<h4 id="python-with-grpcio"><a class="header" href="#python-with-grpcio">Python with grpcio</a></h4>
<pre><code class="language-python">import grpc
from user_service_pb2 import GetUserRequest
from user_service_pb2_grpc import UserServiceStub

channel = grpc.insecure_channel('localhost:50051')
stub = UserServiceStub(channel)

# Unary call
request = GetUserRequest(user_id='123')
response = stub.GetUser(request)
print(f"User: {response.name}, Email: {response.email}")

# Streaming
for user in stub.ListUsers(ListUsersRequest(limit=5)):
    print(f"User: {user.name}")
</code></pre>
<h2 id="advanced-configuration"><a class="header" href="#advanced-configuration">Advanced Configuration</a></h2>
<h3 id="custom-response-mappings"><a class="header" href="#custom-response-mappings">Custom Response Mappings</a></h3>
<p>Create custom response logic by implementing service handlers:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_grpc::{ServiceRegistry, ServiceImplementation};
use std::collections::HashMap;

struct CustomUserService {
    user_data: HashMap&lt;String, UserResponse&gt;,
}

impl ServiceImplementation for CustomUserService {
    fn handle_unary(&amp;self, method: &amp;str, request: &amp;[u8]) -&gt; Vec&lt;u8&gt; {
        match method {
            "GetUser" =&gt; {
                let req: GetUserRequest = prost::Message::decode(request).unwrap();
                let response = self.user_data.get(&amp;req.user_id)
                    .cloned()
                    .unwrap_or_else(|| UserResponse {
                        user_id: req.user_id,
                        name: "Unknown User".to_string(),
                        email: "unknown@example.com".to_string(),
                        created_at: std::time::SystemTime::now()
                            .duration_since(std::time::UNIX_EPOCH)
                            .unwrap().as_secs() as i64,
                        status: Status::Unknown as i32,
                    });
                let mut buf = Vec::new();
                response.encode(&amp;mut buf).unwrap();
                buf
            }
            _ =&gt; Vec::new(),
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="environment-variables"><a class="header" href="#environment-variables">Environment Variables</a></h3>
<pre><code class="language-bash"># Proto file configuration
MOCKFORGE_PROTO_DIR=proto/              # Directory containing .proto files
MOCKFORGE_GRPC_PORT=50051               # gRPC server port

# Service behavior
MOCKFORGE_GRPC_LATENCY_ENABLED=true     # Enable response latency
MOCKFORGE_GRPC_LATENCY_MIN_MS=10        # Minimum latency
MOCKFORGE_GRPC_LATENCY_MAX_MS=100       # Maximum latency

# Reflection settings
MOCKFORGE_GRPC_REFLECTION_ENABLED=true  # Enable gRPC reflection
</code></pre>
<h3 id="configuration-file"><a class="header" href="#configuration-file">Configuration File</a></h3>
<pre><code class="language-yaml">grpc:
  port: 50051
  proto_dir: "proto/"
  enable_reflection: true
  latency:
    enabled: true
    min_ms: 10
    max_ms: 100
  services:
    - name: "mockforge.user.UserService"
      implementation: "dynamic"
    - name: "custom.Service"
      implementation: "custom_handler"
</code></pre>
<h2 id="streaming-support"><a class="header" href="#streaming-support">Streaming Support</a></h2>
<p>MockForge supports all gRPC streaming patterns:</p>
<h3 id="unary-request--response"><a class="header" href="#unary-request--response">Unary (Request → Response)</a></h3>
<pre><code class="language-protobuf">rpc GetUser(GetUserRequest) returns (UserResponse);
</code></pre>
<p>Standard request-response pattern used for simple operations.</p>
<h3 id="server-streaming-request--stream-of-responses"><a class="header" href="#server-streaming-request--stream-of-responses">Server Streaming (Request → Stream of Responses)</a></h3>
<pre><code class="language-protobuf">rpc ListUsers(ListUsersRequest) returns (stream UserResponse);
</code></pre>
<p>Single request that returns multiple responses over time.</p>
<h3 id="client-streaming-stream-of-requests--response"><a class="header" href="#client-streaming-stream-of-requests--response">Client Streaming (Stream of Requests → Response)</a></h3>
<pre><code class="language-protobuf">rpc CreateUsers(stream CreateUserRequest) returns (UserSummary);
</code></pre>
<p>Multiple requests sent as a stream, single response returned.</p>
<h3 id="bidirectional-streaming-stream--stream"><a class="header" href="#bidirectional-streaming-stream--stream">Bidirectional Streaming (Stream ↔ Stream)</a></h3>
<pre><code class="language-protobuf">rpc Chat(stream ChatMessage) returns (stream ChatMessage);
</code></pre>
<p>Both client and server can send messages independently.</p>
<h2 id="error-handling"><a class="header" href="#error-handling">Error Handling</a></h2>
<h3 id="grpc-status-codes"><a class="header" href="#grpc-status-codes">gRPC Status Codes</a></h3>
<p>MockForge supports all standard gRPC status codes:</p>
<pre><code class="language-protobuf">// In proto comments for custom error responses
rpc GetUser(GetUserRequest) returns (UserResponse);
// @error NOT_FOUND User not found
// @error INVALID_ARGUMENT Invalid user ID format
// @error INTERNAL Server error occurred
</code></pre>
<h3 id="custom-error-responses"><a class="header" href="#custom-error-responses">Custom Error Responses</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Custom error handling
fn handle_unary(&amp;self, method: &amp;str, request: &amp;[u8]) -&gt; Result&lt;Vec&lt;u8&gt;, tonic::Status&gt; {
    match method {
        "GetUser" =&gt; {
            let req: GetUserRequest = prost::Message::decode(request)?;

            if !is_valid_user_id(&amp;req.user_id) {
                return Err(tonic::Status::invalid_argument("Invalid user ID"));
            }

            match self.get_user(&amp;req.user_id) {
                Some(user) =&gt; {
                    let mut buf = Vec::new();
                    user.encode(&amp;mut buf)?;
                    Ok(buf)
                }
                None =&gt; Err(tonic::Status::not_found("User not found")),
            }
        }
        _ =&gt; Err(tonic::Status::unimplemented("Method not implemented")),
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="integration-patterns-1"><a class="header" href="#integration-patterns-1">Integration Patterns</a></h2>
<h3 id="microservices-testing-1"><a class="header" href="#microservices-testing-1">Microservices Testing</a></h3>
<pre><code class="language-bash"># Start multiple gRPC services
MOCKFORGE_PROTO_DIR=user-proto mockforge serve --grpc-port 50051 &amp;
MOCKFORGE_PROTO_DIR=payment-proto mockforge serve --grpc-port 50052 &amp;
MOCKFORGE_PROTO_DIR=inventory-proto mockforge serve --grpc-port 50053 &amp;

# Test service communication
grpcurl -plaintext localhost:50051 mockforge.user.UserService/GetUser \
  -d '{"user_id": "123"}'
</code></pre>
<h3 id="load-testing"><a class="header" href="#load-testing">Load Testing</a></h3>
<pre><code class="language-bash"># Simple load test with hey
hey -n 1000 -c 10 \
  grpcurl -plaintext -d '{"user_id": "123"}' \
    localhost:50051 mockforge.user.UserService/GetUser

# Advanced load testing with ghz
ghz --insecure \
    --proto proto/user_service.proto \
    --call mockforge.user.UserService.GetUser \
    --data '{"user_id": "123"}' \
    --concurrency 10 \
    --total 1000 \
    localhost:50051
</code></pre>
<h3 id="cicd-integration"><a class="header" href="#cicd-integration">CI/CD Integration</a></h3>
<pre><code class="language-yaml"># .github/workflows/test.yml
name: gRPC Tests
on: [push, pull_request]

jobs:
  grpc-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Setup Rust
        uses: actions-rust-lang/setup-rust-toolchain@v1
      - name: Start MockForge
        run: |
          cargo run --bin mockforge-cli -- serve --grpc-port 50051 &amp;
          sleep 5
      - name: Run gRPC Tests
        run: |
          npm install -g grpcurl
          grpcurl -plaintext localhost:50051 list
          # Add your test commands here
</code></pre>
<h2 id="best-practices-1"><a class="header" href="#best-practices-1">Best Practices</a></h2>
<h3 id="proto-file-organization"><a class="header" href="#proto-file-organization">Proto File Organization</a></h3>
<ol>
<li><strong>Clear Package Names</strong>: Use descriptive package names that reflect service domains</li>
<li><strong>Consistent Naming</strong>: Follow protobuf naming conventions</li>
<li><strong>Versioning</strong>: Include version information in package names when appropriate</li>
<li><strong>Documentation</strong>: Add comments to proto files for better API documentation</li>
</ol>
<h3 id="service-design"><a class="header" href="#service-design">Service Design</a></h3>
<ol>
<li><strong>Appropriate Streaming</strong>: Choose the right streaming pattern for your use case</li>
<li><strong>Error Handling</strong>: Define clear error conditions and status codes</li>
<li><strong>Pagination</strong>: Implement pagination for large result sets</li>
<li><strong>Backwards Compatibility</strong>: Design for evolution and backwards compatibility</li>
</ol>
<h3 id="testing-strategies"><a class="header" href="#testing-strategies">Testing Strategies</a></h3>
<ol>
<li><strong>Unit Tests</strong>: Test individual service methods</li>
<li><strong>Integration Tests</strong>: Test service interactions</li>
<li><strong>Load Tests</strong>: Verify performance under load</li>
<li><strong>Chaos Tests</strong>: Test failure scenarios and recovery</li>
</ol>
<h3 id="performance-optimization"><a class="header" href="#performance-optimization">Performance Optimization</a></h3>
<ol>
<li><strong>Response Caching</strong>: Cache frequently requested data</li>
<li><strong>Connection Pooling</strong>: Reuse gRPC connections</li>
<li><strong>Async Processing</strong>: Use async operations for I/O bound tasks</li>
<li><strong>Memory Management</strong>: Monitor and optimize memory usage</li>
</ol>
<h2 id="troubleshooting-2"><a class="header" href="#troubleshooting-2">Troubleshooting</a></h2>
<h3 id="common-issues-1"><a class="header" href="#common-issues-1">Common Issues</a></h3>
<p><strong>Proto files not found</strong>: Check <code>MOCKFORGE_PROTO_DIR</code> environment variable and directory permissions</p>
<p><strong>Service not available</strong>: Verify proto compilation succeeded and service names match</p>
<p><strong>Connection refused</strong>: Ensure gRPC port is accessible and not blocked by firewall</p>
<p><strong>Template errors</strong>: Check template syntax and available context variables</p>
<h3 id="debug-commands"><a class="header" href="#debug-commands">Debug Commands</a></h3>
<pre><code class="language-bash"># Check proto compilation
cargo build --verbose

# List available services
grpcurl -plaintext localhost:50051 list

# Check service methods
grpcurl -plaintext localhost:50051 describe mockforge.user.UserService

# Test with verbose output
grpcurl -plaintext -v -d '{"user_id": "123"}' \
  localhost:50051 mockforge.user.UserService/GetUser
</code></pre>
<h3 id="log-analysis"><a class="header" href="#log-analysis">Log Analysis</a></h3>
<pre><code class="language-bash"># View gRPC logs
tail -f mockforge.log | grep -i grpc

# Count requests by service
grep "grpc.*call" mockforge.log | cut -d' ' -f5 | sort | uniq -c

# Monitor errors
grep -i "grpc.*error" mockforge.log
</code></pre>
<p>For detailed implementation guides, see:</p>
<ul>
<li><a href="user-guide/grpc-mocking/protobuf.html">Protocol Buffers</a> - Working with .proto files</li>
<li><a href="user-guide/grpc-mocking/streaming.html">Streaming</a> - Advanced streaming patterns</li>
<li><a href="user-guide/grpc-mocking/advanced-data-synthesis.html">Advanced Data Synthesis</a> - Intelligent data generation with RAG and validation</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="protocol-buffers"><a class="header" href="#protocol-buffers">Protocol Buffers</a></h1>
<p>Protocol Buffers (protobuf) are the interface definition language used by gRPC services. MockForge provides comprehensive support for working with protobuf files, including automatic discovery, compilation, and dynamic service generation.</p>
<h2 id="understanding-proto-files"><a class="header" href="#understanding-proto-files">Understanding Proto Files</a></h2>
<h3 id="basic-structure"><a class="header" href="#basic-structure">Basic Structure</a></h3>
<p>A <code>.proto</code> file defines the service interface and message formats:</p>
<pre><code class="language-protobuf">syntax = "proto3";

package myapp.user;

import "google/protobuf/timestamp.proto";

// Service definition
service UserService {
  rpc GetUser(GetUserRequest) returns (User);
  rpc ListUsers(ListUsersRequest) returns (stream User);
  rpc CreateUser(CreateUserRequest) returns (User);
  rpc UpdateUser(UpdateUserRequest) returns (User);
  rpc DeleteUser(DeleteUserRequest) returns (google.protobuf.Empty);
}

// Message definitions
message GetUserRequest {
  string user_id = 1;
}

message User {
  string user_id = 1;
  string email = 2;
  string name = 3;
  google.protobuf.Timestamp created_at = 4;
  google.protobuf.Timestamp updated_at = 5;
  UserStatus status = 6;
  repeated string roles = 7;
}

message ListUsersRequest {
  int32 page_size = 1;
  string page_token = 2;
  string filter = 3;
}

message CreateUserRequest {
  string email = 1;
  string name = 2;
  repeated string roles = 3;
}

message UpdateUserRequest {
  string user_id = 1;
  string email = 2;
  string name = 3;
  repeated string roles = 4;
}

message DeleteUserRequest {
  string user_id = 1;
}

enum UserStatus {
  UNKNOWN = 0;
  ACTIVE = 1;
  INACTIVE = 2;
  SUSPENDED = 3;
}
</code></pre>
<h3 id="key-components"><a class="header" href="#key-components">Key Components</a></h3>
<h4 id="syntax-declaration"><a class="header" href="#syntax-declaration">Syntax Declaration</a></h4>
<pre><code class="language-protobuf">syntax = "proto3";
</code></pre>
<p>Declares the protobuf version. MockForge supports proto3.</p>
<h4 id="package-declaration"><a class="header" href="#package-declaration">Package Declaration</a></h4>
<pre><code class="language-protobuf">package myapp.user;
</code></pre>
<p>Defines the namespace for the service and messages.</p>
<h4 id="imports"><a class="header" href="#imports">Imports</a></h4>
<pre><code class="language-protobuf">import "google/protobuf/timestamp.proto";
</code></pre>
<p>Imports common protobuf types and other proto files.</p>
<h4 id="service-definition"><a class="header" href="#service-definition">Service Definition</a></h4>
<pre><code class="language-protobuf">service UserService {
  rpc GetUser(GetUserRequest) returns (User);
  // ... more methods
}
</code></pre>
<p>Defines the RPC methods available in the service.</p>
<h4 id="message-definitions"><a class="header" href="#message-definitions">Message Definitions</a></h4>
<pre><code class="language-protobuf">message User {
  string user_id = 1;
  string email = 2;
  // ... more fields
}
</code></pre>
<p>Defines the structure of data exchanged between client and server.</p>
<h4 id="enum-definitions"><a class="header" href="#enum-definitions">Enum Definitions</a></h4>
<pre><code class="language-protobuf">enum UserStatus {
  UNKNOWN = 0;
  ACTIVE = 1;
  // ... more values
}
</code></pre>
<p>Defines enumerated types with named constants.</p>
<h2 id="field-types"><a class="header" href="#field-types">Field Types</a></h2>
<h3 id="scalar-types"><a class="header" href="#scalar-types">Scalar Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Proto Type</th><th>Go Type</th><th>Java Type</th><th>C++ Type</th><th>Notes</th></tr></thead><tbody>
<tr><td>double</td><td>float64</td><td>double</td><td>double</td><td></td></tr>
<tr><td>float</td><td>float32</td><td>float</td><td>float</td><td></td></tr>
<tr><td>int32</td><td>int32</td><td>int</td><td>int32</td><td>Uses variable-length encoding</td></tr>
<tr><td>int64</td><td>int64</td><td>long</td><td>int64</td><td>Uses variable-length encoding</td></tr>
<tr><td>uint32</td><td>uint32</td><td>int</td><td>uint32</td><td>Uses variable-length encoding</td></tr>
<tr><td>uint64</td><td>uint64</td><td>long</td><td>uint64</td><td>Uses variable-length encoding</td></tr>
<tr><td>sint32</td><td>int32</td><td>int</td><td>int32</td><td>Uses zigzag encoding</td></tr>
<tr><td>sint64</td><td>int64</td><td>long</td><td>int64</td><td>Uses zigzag encoding</td></tr>
<tr><td>fixed32</td><td>uint32</td><td>int</td><td>uint32</td><td>Always 4 bytes</td></tr>
<tr><td>fixed64</td><td>uint64</td><td>long</td><td>uint64</td><td>Always 8 bytes</td></tr>
<tr><td>sfixed32</td><td>int32</td><td>int</td><td>int32</td><td>Always 4 bytes</td></tr>
<tr><td>sfixed64</td><td>int64</td><td>long</td><td>int64</td><td>Always 8 bytes</td></tr>
<tr><td>bool</td><td>bool</td><td>boolean</td><td>bool</td><td></td></tr>
<tr><td>string</td><td>string</td><td>String</td><td>string</td><td>UTF-8 encoded</td></tr>
<tr><td>bytes</td><td>[]byte</td><td>ByteString</td><td>string</td><td></td></tr>
</tbody></table>
</div>
<h3 id="repeated-fields"><a class="header" href="#repeated-fields">Repeated Fields</a></h3>
<pre><code class="language-protobuf">message SearchResponse {
  repeated Result results = 1;
}
</code></pre>
<p>Creates an array/list of the specified type.</p>
<h3 id="nested-messages"><a class="header" href="#nested-messages">Nested Messages</a></h3>
<pre><code class="language-protobuf">message Address {
  string street = 1;
  string city = 2;
  string country = 3;
}

message Person {
  string name = 1;
  Address address = 2;
}
</code></pre>
<p>Messages can contain other messages as fields.</p>
<h3 id="oneof-fields"><a class="header" href="#oneof-fields">Oneof Fields</a></h3>
<pre><code class="language-protobuf">message Person {
  string name = 1;
  oneof contact_info {
    string email = 2;
    string phone = 3;
  }
}
</code></pre>
<p>Only one of the specified fields can be set at a time.</p>
<h3 id="maps"><a class="header" href="#maps">Maps</a></h3>
<pre><code class="language-protobuf">message Config {
  map&lt;string, string&gt; settings = 1;
}
</code></pre>
<p>Creates a key-value map structure.</p>
<h2 id="service-patterns"><a class="header" href="#service-patterns">Service Patterns</a></h2>
<h3 id="unary-rpc"><a class="header" href="#unary-rpc">Unary RPC</a></h3>
<pre><code class="language-protobuf">service Calculator {
  rpc Add(AddRequest) returns (AddResponse);
}
</code></pre>
<p>Standard request-response pattern.</p>
<h3 id="server-streaming"><a class="header" href="#server-streaming">Server Streaming</a></h3>
<pre><code class="language-protobuf">service NotificationService {
  rpc Subscribe(SubscribeRequest) returns (stream Notification);
}
</code></pre>
<p>Server sends multiple responses for a single request.</p>
<h3 id="client-streaming"><a class="header" href="#client-streaming">Client Streaming</a></h3>
<pre><code class="language-protobuf">service UploadService {
  rpc Upload(stream UploadChunk) returns (UploadResponse);
}
</code></pre>
<p>Client sends multiple requests, server responds once.</p>
<h3 id="bidirectional-streaming"><a class="header" href="#bidirectional-streaming">Bidirectional Streaming</a></h3>
<pre><code class="language-protobuf">service ChatService {
  rpc Chat(stream ChatMessage) returns (stream ChatMessage);
}
</code></pre>
<p>Both client and server can send messages independently.</p>
<h2 id="proto-file-organization-1"><a class="header" href="#proto-file-organization-1">Proto File Organization</a></h2>
<h3 id="directory-structure-1"><a class="header" href="#directory-structure-1">Directory Structure</a></h3>
<pre><code>proto/
├── user/
│   ├── v1/
│   │   ├── user.proto
│   │   └── user_service.proto
│   └── v2/
│       ├── user.proto
│       └── user_service.proto
├── payment/
│   ├── payment.proto
│   └── payment_service.proto
└── common/
    ├── types.proto
    └── errors.proto
</code></pre>
<h3 id="versioning"><a class="header" href="#versioning">Versioning</a></h3>
<pre><code class="language-protobuf">// user/v1/user.proto
syntax = "proto3";
package myapp.user.v1;

// Version-specific message
message User {
  string id = 1;
  string name = 2;
  string email = 3;
}
</code></pre>
<pre><code class="language-protobuf">// user/v2/user.proto
syntax = "proto3";
package myapp.user.v2;

// Extended version with new fields
message User {
  string id = 1;
  string name = 2;
  string email = 3;
  string phone = 4;  // New field
  repeated string tags = 5;  // New field
}
</code></pre>
<h2 id="mockforge-integration"><a class="header" href="#mockforge-integration">MockForge Integration</a></h2>
<h3 id="automatic-discovery"><a class="header" href="#automatic-discovery">Automatic Discovery</a></h3>
<p>MockForge automatically discovers <code>.proto</code> files in the configured directory:</p>
<pre><code class="language-bash"># Default proto directory
mockforge serve --grpc-port 50051

# Custom proto directory
MOCKFORGE_PROTO_DIR=my-protos mockforge serve --grpc-port 50051
</code></pre>
<h3 id="service-registration"><a class="header" href="#service-registration">Service Registration</a></h3>
<p>MockForge automatically registers all discovered services:</p>
<pre><code class="language-bash"># List available services
grpcurl -plaintext localhost:50051 list

# Output:
# grpc.reflection.v1alpha.ServerReflection
# myapp.user.UserService
# myapp.payment.PaymentService
</code></pre>
<h3 id="dynamic-response-generation-2"><a class="header" href="#dynamic-response-generation-2">Dynamic Response Generation</a></h3>
<p>MockForge generates responses based on proto message schemas:</p>
<pre><code class="language-protobuf">message UserResponse {
  string user_id = 1;    // Generates UUID
  string name = 2;       // Generates random name
  string email = 3;      // Generates valid email
  int64 created_at = 4;  // Generates timestamp
  UserStatus status = 5; // Random enum value
}
</code></pre>
<h3 id="template-support"><a class="header" href="#template-support">Template Support</a></h3>
<p>Use MockForge templates for custom responses:</p>
<pre><code class="language-protobuf">message UserResponse {
  string user_id = 1;    // {{uuid}}
  string name = 2;       // {{request.user_id == "123" ? "John Doe" : "Jane Smith"}}
  string email = 3;      // {{name | replace(" ", ".") | lower}}@example.com
  int64 created_at = 4;  // {{now}}
  UserStatus status = 5; // ACTIVE
}
</code></pre>
<h2 id="best-practices-2"><a class="header" href="#best-practices-2">Best Practices</a></h2>
<h3 id="naming-conventions"><a class="header" href="#naming-conventions">Naming Conventions</a></h3>
<ol>
<li><strong>Packages</strong>: Use lowercase with dots (e.g., <code>myapp.user.v1</code>)</li>
<li><strong>Services</strong>: Use PascalCase with “Service” suffix (e.g., <code>UserService</code>)</li>
<li><strong>Messages</strong>: Use PascalCase (e.g., <code>UserProfile</code>)</li>
<li><strong>Fields</strong>: Use snake_case (e.g., <code>user_id</code>, <code>created_at</code>)</li>
<li><strong>Enums</strong>: Use PascalCase for type, SCREAMING_SNAKE_CASE for values</li>
</ol>
<h3 id="field-numbering"><a class="header" href="#field-numbering">Field Numbering</a></h3>
<ol>
<li><strong>Reserve numbers</strong>: Don’t reuse field numbers from deleted fields</li>
<li><strong>Start from 1</strong>: Field numbers start from 1</li>
<li><strong>Gap for extensions</strong>: Leave gaps for future extensions</li>
<li><strong>Document reservations</strong>: Comment reserved field numbers</li>
</ol>
<pre><code class="language-protobuf">message User {
  string user_id = 1;
  string name = 2;
  string email = 3;
  // reserved 4, 5, 6;  // Reserved for future use
  int64 created_at = 7;
}
</code></pre>
<h3 id="import-organization"><a class="header" href="#import-organization">Import Organization</a></h3>
<ol>
<li><strong>Standard imports</strong>: Import well-known protobuf types first</li>
<li><strong>Local imports</strong>: Import project-specific proto files</li>
<li><strong>Relative paths</strong>: Use relative paths for local imports</li>
</ol>
<pre><code class="language-protobuf">syntax = "proto3";

import "google/protobuf/timestamp.proto";
import "google/protobuf/empty.proto";

import "common/types.proto";
import "user/profile.proto";

package myapp.user;
</code></pre>
<h3 id="documentation"><a class="header" href="#documentation">Documentation</a></h3>
<ol>
<li><strong>Service comments</strong>: Document what each service does</li>
<li><strong>Method comments</strong>: Explain each RPC method</li>
<li><strong>Field comments</strong>: Describe field purposes and constraints</li>
<li><strong>Enum comments</strong>: Document enum value meanings</li>
</ol>
<pre><code class="language-protobuf">// User management service
service UserService {
  // Get a user by ID
  rpc GetUser(GetUserRequest) returns (User);

  // List users with pagination
  rpc ListUsers(ListUsersRequest) returns (ListUsersResponse);
}

message User {
  string user_id = 1;  // Unique identifier for the user
  string email = 2;    // User's email address (must be valid)
  UserStatus status = 3; // Current account status
}

enum UserStatus {
  UNKNOWN = 0;   // Default value
  ACTIVE = 1;    // Account is active
  INACTIVE = 2;  // Account is deactivated
  SUSPENDED = 3; // Account is temporarily suspended
}
</code></pre>
<h2 id="migration-and-evolution"><a class="header" href="#migration-and-evolution">Migration and Evolution</a></h2>
<h3 id="adding-fields"><a class="header" href="#adding-fields">Adding Fields</a></h3>
<pre><code class="language-protobuf">// Original
message User {
  string user_id = 1;
  string name = 2;
}

// Extended (backwards compatible)
message User {
  string user_id = 1;
  string name = 2;
  string email = 3;      // New field
  bool active = 4;       // New field
}
</code></pre>
<h3 id="reserved-fields"><a class="header" href="#reserved-fields">Reserved Fields</a></h3>
<pre><code class="language-protobuf">message User {
  reserved 5, 6, 7;        // Reserved for future use
  reserved "old_field";    // Reserved field name

  string user_id = 1;
  string name = 2;
  string email = 3;
}
</code></pre>
<h3 id="versioning-strategy"><a class="header" href="#versioning-strategy">Versioning Strategy</a></h3>
<ol>
<li><strong>Package versioning</strong>: Include version in package name</li>
<li><strong>Service evolution</strong>: Extend services with new methods</li>
<li><strong>Deprecation notices</strong>: Mark deprecated fields</li>
<li><strong>Breaking changes</strong>: Create new service versions</li>
</ol>
<h2 id="validation"><a class="header" href="#validation">Validation</a></h2>
<h3 id="proto-file-validation"><a class="header" href="#proto-file-validation">Proto File Validation</a></h3>
<pre><code class="language-bash"># Validate proto syntax
protoc --proto_path=. --error_format=json myproto.proto

# Generate descriptors
protoc --proto_path=. --descriptor_set_out=descriptor.pb myproto.proto
</code></pre>
<h3 id="mockforge-integration-testing"><a class="header" href="#mockforge-integration-testing">MockForge Integration Testing</a></h3>
<pre><code class="language-bash"># Test proto compilation
MOCKFORGE_PROTO_DIR=my-protos cargo build

# Verify service discovery
mockforge serve --grpc-port 50051 &amp;
sleep 2
grpcurl -plaintext localhost:50051 list
</code></pre>
<h3 id="cross-language-compatibility"><a class="header" href="#cross-language-compatibility">Cross-Language Compatibility</a></h3>
<pre><code class="language-bash"># Generate code for multiple languages
protoc --proto_path=. \
  --go_out=. \
  --java_out=. \
  --python_out=. \
  --cpp_out=. \
  myproto.proto
</code></pre>
<h2 id="troubleshooting-3"><a class="header" href="#troubleshooting-3">Troubleshooting</a></h2>
<h3 id="common-proto-issues"><a class="header" href="#common-proto-issues">Common Proto Issues</a></h3>
<p><strong>Import resolution</strong>: Ensure all imported proto files are available in the proto path</p>
<p><strong>Field conflicts</strong>: Check for duplicate field numbers or names within messages</p>
<p><strong>Circular imports</strong>: Avoid circular dependencies between proto files</p>
<p><strong>Syntax errors</strong>: Use <code>protoc</code> to validate proto file syntax</p>
<h3 id="mockforge-specific-issues"><a class="header" href="#mockforge-specific-issues">MockForge-Specific Issues</a></h3>
<p><strong>Services not discovered</strong>: Check proto directory configuration and file permissions</p>
<p><strong>Invalid responses</strong>: Verify proto message definitions match expected schemas</p>
<p><strong>Compilation failures</strong>: Check for proto syntax errors and missing dependencies</p>
<p><strong>Template errors</strong>: Ensure template variables are properly escaped in proto comments</p>
<h3 id="debug-commands-1"><a class="header" href="#debug-commands-1">Debug Commands</a></h3>
<pre><code class="language-bash"># Check proto file discovery
find proto/ -name "*.proto" -type f

# Validate proto files
for file in $(find proto/ -name "*.proto"); do
  echo "Validating $file..."
  protoc --proto_path=. --error_format=json "$file" &gt; /dev/null
done

# Test service compilation
MOCKFORGE_PROTO_DIR=proto/ cargo check -p mockforge-grpc

# Inspect generated code
cargo doc --open --package mockforge-grpc
</code></pre>
<p>Protocol Buffers provide a robust foundation for gRPC service definitions. By following these guidelines and leveraging MockForge’s dynamic discovery capabilities, you can create well-structured, maintainable, and testable gRPC services.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="streaming"><a class="header" href="#streaming">Streaming</a></h1>
<p>gRPC supports four fundamental communication patterns, with three involving streaming. MockForge provides comprehensive support for all streaming patterns, enabling realistic testing of real-time and batch data scenarios.</p>
<h2 id="streaming-patterns"><a class="header" href="#streaming-patterns">Streaming Patterns</a></h2>
<h3 id="unary-request--response-1"><a class="header" href="#unary-request--response-1">Unary (Request → Response)</a></h3>
<p>Standard request-response pattern - one message in, one message out.</p>
<h3 id="server-streaming-request--stream-of-responses-1"><a class="header" href="#server-streaming-request--stream-of-responses-1">Server Streaming (Request → Stream of Responses)</a></h3>
<p>Single request initiates a stream of responses from server to client.</p>
<h3 id="client-streaming-stream-of-requests--response-1"><a class="header" href="#client-streaming-stream-of-requests--response-1">Client Streaming (Stream of Requests → Response)</a></h3>
<p>Client sends multiple messages, server responds once with aggregated result.</p>
<h3 id="bidirectional-streaming-stream--stream-1"><a class="header" href="#bidirectional-streaming-stream--stream-1">Bidirectional Streaming (Stream ↔ Stream)</a></h3>
<p>Both client and server can send messages independently and simultaneously.</p>
<h2 id="server-streaming-1"><a class="header" href="#server-streaming-1">Server Streaming</a></h2>
<h3 id="basic-server-streaming"><a class="header" href="#basic-server-streaming">Basic Server Streaming</a></h3>
<pre><code class="language-protobuf">service NotificationService {
  rpc Subscribe(SubscribeRequest) returns (stream Notification);
}

message SubscribeRequest {
  repeated string topics = 1;
  SubscriptionType type = 2;
}

message Notification {
  string topic = 1;
  string message = 2;
  google.protobuf.Timestamp timestamp = 3;
  Severity severity = 4;
}

enum SubscriptionType {
  REALTIME = 0;
  BATCH = 1;
}

enum Severity {
  INFO = 0;
  WARNING = 1;
  ERROR = 2;
  CRITICAL = 3;
}
</code></pre>
<h3 id="mockforge-configuration"><a class="header" href="#mockforge-configuration">MockForge Configuration</a></h3>
<p>Server streaming generates multiple responses based on configuration:</p>
<pre><code class="language-jsonl">// Basic server streaming - fixed number of responses
{"ts":0,"dir":"out","text":"{\"topic\":\"system\",\"message\":\"Connected\",\"severity\":\"INFO\"}"}
{"ts":1000,"dir":"out","text":"{\"topic\":\"user\",\"message\":\"New user registered\",\"severity\":\"INFO\"}"}
{"ts":2000,"dir":"out","text":"{\"topic\":\"payment\",\"message\":\"Payment processed\",\"severity\":\"INFO\"}"}
{"ts":3000,"dir":"out","text":"{\"topic\":\"system\",\"message\":\"Maintenance scheduled\",\"severity\":\"WARNING\"}"}
</code></pre>
<h3 id="dynamic-server-streaming"><a class="header" href="#dynamic-server-streaming">Dynamic Server Streaming</a></h3>
<pre><code class="language-jsonl">// Template-based dynamic responses
{"ts":0,"dir":"out","text":"{\"topic\":\"{{request.topics[0]}}\",\"message\":\"Subscribed to {{request.topics.length}} topics\",\"timestamp\":\"{{now}}\"}"}
{"ts":1000,"dir":"out","text":"{\"topic\":\"{{randFromArray request.topics}}\",\"message\":\"{{randParagraph}}\",\"timestamp\":\"{{now}}\"}"}
{"ts":2000,"dir":"out","text":"{\"topic\":\"{{randFromArray request.topics}}\",\"message\":\"{{randSentence}}\",\"timestamp\":\"{{now}}\"}"}
{"ts":5000,"dir":"out","text":"{\"topic\":\"system\",\"message\":\"Stream ending\",\"timestamp\":\"{{now}}\"}"}
</code></pre>
<h3 id="testing-server-streaming"><a class="header" href="#testing-server-streaming">Testing Server Streaming</a></h3>
<h4 id="using-grpcurl"><a class="header" href="#using-grpcurl">Using grpcurl</a></h4>
<pre><code class="language-bash"># Test server streaming
grpcurl -plaintext -d '{"topics": ["user", "payment"], "type": "REALTIME"}' \
  localhost:50051 myapp.NotificationService/Subscribe
</code></pre>
<h4 id="using-nodejs"><a class="header" href="#using-nodejs">Using Node.js</a></h4>
<pre><code class="language-javascript">const grpc = require('@grpc/grpc-js');
const protoLoader = require('@grpc/proto-loader');

const packageDefinition = protoLoader.loadSync('proto/notification.proto');
const proto = grpc.loadPackageDefinition(packageDefinition);

const client = new proto.myapp.NotificationService(
  'localhost:50051',
  grpc.credentials.createInsecure()
);

const call = client.Subscribe({
  topics: ['user', 'payment'],
  type: 'REALTIME'
});

call.on('data', (notification) =&gt; {
  console.log('Notification:', notification);
});

call.on('end', () =&gt; {
  console.log('Stream ended');
});

call.on('error', (error) =&gt; {
  console.error('Error:', error);
});
</code></pre>
<h2 id="client-streaming-1"><a class="header" href="#client-streaming-1">Client Streaming</a></h2>
<h3 id="basic-client-streaming"><a class="header" href="#basic-client-streaming">Basic Client Streaming</a></h3>
<pre><code class="language-protobuf">service UploadService {
  rpc UploadFile(stream FileChunk) returns (UploadResponse);
}

message FileChunk {
  bytes data = 1;
  int32 sequence = 2;
  bool is_last = 3;
}

message UploadResponse {
  string file_id = 1;
  int64 total_size = 2;
  string checksum = 3;
  UploadStatus status = 4;
}

enum UploadStatus {
  SUCCESS = 0;
  FAILED = 1;
  PARTIAL = 2;
}
</code></pre>
<h3 id="mockforge-configuration-1"><a class="header" href="#mockforge-configuration-1">MockForge Configuration</a></h3>
<p>Client streaming processes multiple incoming messages and returns a single response:</p>
<pre><code class="language-jsonl">// Client streaming - processes multiple chunks
{"ts":0,"dir":"in","text":".*","response":"{\"file_id\":\"{{uuid}}\",\"total_size\":1024,\"status\":\"SUCCESS\"}"}
</code></pre>
<h3 id="advanced-client-streaming"><a class="header" href="#advanced-client-streaming">Advanced Client Streaming</a></h3>
<pre><code class="language-jsonl">// Process chunks and maintain state
{"ts":0,"dir":"in","text":"{\"sequence\":0}","response":"Chunk 0 received","state":"uploading","chunks":1}
{"ts":0,"dir":"in","text":"{\"sequence\":1}","response":"Chunk 1 received","chunks":"{{request.ws.state.chunks + 1}}"}
{"ts":0,"dir":"in","text":"{\"is_last\":true}","response":"{\"file_id\":\"{{uuid}}\",\"total_size\":\"{{request.ws.state.chunks * 1024}}\",\"status\":\"SUCCESS\"}"}
</code></pre>
<h3 id="testing-client-streaming"><a class="header" href="#testing-client-streaming">Testing Client Streaming</a></h3>
<h4 id="using-grpcurl-1"><a class="header" href="#using-grpcurl-1">Using grpcurl</a></h4>
<pre><code class="language-bash"># Send multiple messages for client streaming
echo '{"data": "chunk1", "sequence": 0}' | \
grpcurl -plaintext -d @ localhost:50051 myapp.UploadService/UploadFile

echo '{"data": "chunk2", "sequence": 1}' | \
grpcurl -plaintext -d @ localhost:50051 myapp.UploadService/UploadFile

echo '{"data": "chunk3", "sequence": 2, "is_last": true}' | \
grpcurl -plaintext -d @ localhost:50051 myapp.UploadService/UploadFile
</code></pre>
<h4 id="using-python"><a class="header" href="#using-python">Using Python</a></h4>
<pre><code class="language-python">import grpc
from upload_pb2 import FileChunk
from upload_pb2_grpc import UploadServiceStub

def generate_chunks():
    # Simulate file chunks
    chunks = [
        b"chunk1",
        b"chunk2",
        b"chunk3"
    ]

    for i, chunk in enumerate(chunks):
        yield FileChunk(
            data=chunk,
            sequence=i,
            is_last=(i == len(chunks) - 1)
        )

channel = grpc.insecure_channel('localhost:50051')
stub = UploadServiceStub(channel)

response = stub.UploadFile(generate_chunks())
print(f"Upload result: {response}")
</code></pre>
<h2 id="bidirectional-streaming-1"><a class="header" href="#bidirectional-streaming-1">Bidirectional Streaming</a></h2>
<h3 id="basic-bidirectional-streaming"><a class="header" href="#basic-bidirectional-streaming">Basic Bidirectional Streaming</a></h3>
<pre><code class="language-protobuf">service ChatService {
  rpc Chat(stream ChatMessage) returns (stream ChatMessage);
}

message ChatMessage {
  string user_id = 1;
  string content = 2;
  MessageType type = 3;
  google.protobuf.Timestamp timestamp = 4;
}

enum MessageType {
  TEXT = 0;
  JOIN = 1;
  LEAVE = 2;
  SYSTEM = 3;
}
</code></pre>
<h3 id="mockforge-configuration-2"><a class="header" href="#mockforge-configuration-2">MockForge Configuration</a></h3>
<p>Bidirectional streaming handles both incoming and outgoing messages:</p>
<pre><code class="language-jsonl">// Welcome message on connection
{"ts":0,"dir":"out","text":"{\"user_id\":\"system\",\"content\":\"Welcome to chat!\",\"type\":\"SYSTEM\"}"}

// Handle join messages
{"ts":0,"dir":"in","text":"{\"type\":\"JOIN\"}","response":"{\"user_id\":\"system\",\"content\":\"{{request.ws.message.user_id}} joined the chat\",\"type\":\"SYSTEM\"}"}

// Handle text messages
{"ts":0,"dir":"in","text":"{\"type\":\"TEXT\"}","response":"{\"user_id\":\"{{request.ws.message.user_id}}\",\"content\":\"{{request.ws.message.content}}\",\"type\":\"TEXT\"}"}

// Handle leave messages
{"ts":0,"dir":"in","text":"{\"type\":\"LEAVE\"}","response":"{\"user_id\":\"system\",\"content\":\"{{request.ws.message.user_id}} left the chat\",\"type\":\"SYSTEM\"}"}

// Periodic system messages
{"ts":30000,"dir":"out","text":"{\"user_id\":\"system\",\"content\":\"Server uptime: {{randInt 1 24}} hours\",\"type\":\"SYSTEM\"}"}
</code></pre>
<h3 id="advanced-bidirectional-patterns"><a class="header" href="#advanced-bidirectional-patterns">Advanced Bidirectional Patterns</a></h3>
<pre><code class="language-jsonl">// State-aware responses
{"ts":0,"dir":"in","text":".*","condition":"{{!request.ws.state.authenticated}}","response":"Please authenticate first"}
{"ts":0,"dir":"in","text":"AUTH","response":"Authenticated","state":"authenticated"}

{"ts":0,"dir":"in","text":".*","condition":"{{request.ws.state.authenticated}}","response":"{{request.ws.message}}"}

{"ts":0,"dir":"in","text":"HELP","response":"Available commands: MSG, QUIT, STATUS"}
{"ts":0,"dir":"in","text":"STATUS","response":"Connected users: {{randInt 1 50}}"}
{"ts":0,"dir":"in","text":"QUIT","response":"Goodbye!","close":true}
</code></pre>
<h3 id="testing-bidirectional-streaming"><a class="header" href="#testing-bidirectional-streaming">Testing Bidirectional Streaming</a></h3>
<h4 id="using-nodejs-1"><a class="header" href="#using-nodejs-1">Using Node.js</a></h4>
<pre><code class="language-javascript">const grpc = require('@grpc/grpc-js');
const protoLoader = require('@grpc/proto-loader');

const packageDefinition = protoLoader.loadSync('proto/chat.proto');
const proto = grpc.loadPackageDefinition(packageDefinition);

const client = new proto.myapp.ChatService(
  'localhost:50051',
  grpc.credentials.createInsecure()
);

const call = client.Chat();

// Handle incoming messages
call.on('data', (message) =&gt; {
  console.log('Received:', message);
});

// Send messages
setInterval(() =&gt; {
  call.write({
    user_id: 'user123',
    content: 'Hello from client',
    type: 'TEXT'
  });
}, 2000);

// Send join message
call.write({
  user_id: 'user123',
  content: 'Joined chat',
  type: 'JOIN'
});

// Handle stream end
call.on('end', () =&gt; {
  console.log('Stream ended');
});

// Close after 30 seconds
setTimeout(() =&gt; {
  call.write({
    user_id: 'user123',
    content: 'Leaving chat',
    type: 'LEAVE'
  });
  call.end();
}, 30000);
</code></pre>
<h2 id="streaming-configuration"><a class="header" href="#streaming-configuration">Streaming Configuration</a></h2>
<h3 id="environment-variables-1"><a class="header" href="#environment-variables-1">Environment Variables</a></h3>
<pre><code class="language-bash"># Streaming behavior
MOCKFORGE_GRPC_STREAM_TIMEOUT=30000        # Stream timeout in ms
MOCKFORGE_GRPC_MAX_STREAM_MESSAGES=1000    # Max messages per stream
MOCKFORGE_GRPC_STREAM_BUFFER_SIZE=1024     # Buffer size for streaming

# Response timing
MOCKFORGE_GRPC_LATENCY_MIN_MS=10          # Minimum response latency
MOCKFORGE_GRPC_LATENCY_MAX_MS=100         # Maximum response latency
</code></pre>
<h3 id="stream-control-templates"><a class="header" href="#stream-control-templates">Stream Control Templates</a></h3>
<pre><code class="language-jsonl">// Conditional streaming
{"ts":0,"dir":"out","text":"Starting stream","condition":"{{request.stream_enabled}}"}
{"ts":1000,"dir":"out","text":"Stream data","condition":"{{request.ws.state.active}}"}
{"ts":0,"dir":"out","text":"Stream ended","condition":"{{request.ws.message.type === 'END'}}","close":true}

// Dynamic intervals
{"ts":"{{randInt 1000 5000}}","dir":"out","text":"Random interval message"}
{"ts":"{{request.interval || 2000}}","dir":"out","text":"Custom interval message"}
</code></pre>
<h2 id="performance-considerations-1"><a class="header" href="#performance-considerations-1">Performance Considerations</a></h2>
<h3 id="memory-management"><a class="header" href="#memory-management">Memory Management</a></h3>
<pre><code class="language-jsonl">// Limit message history
{"ts":0,"dir":"in","text":".*","condition":"{{(request.ws.state.messageCount || 0) &lt; 100}}","response":"Message received","messageCount":"{{(request.ws.state.messageCount || 0) + 1}}"}
{"ts":0,"dir":"in","text":".*","condition":"{{(request.ws.state.messageCount || 0) &gt;= 100}}","response":"Message limit reached"}
</code></pre>
<h3 id="connection-limits"><a class="header" href="#connection-limits">Connection Limits</a></h3>
<pre><code class="language-jsonl">// Global connection tracking (requires custom implementation)
{"ts":0,"dir":"out","text":"Connection {{request.ws.connectionId}} established"}
{"ts":300000,"dir":"out","text":"Connection timeout","close":true}
</code></pre>
<h3 id="load-balancing"><a class="header" href="#load-balancing">Load Balancing</a></h3>
<pre><code class="language-jsonl">// Simulate load balancer behavior
{"ts":"{{randInt 100 1000}}","dir":"out","text":"Response from server {{randInt 1 3}}"}
{"ts":"{{randInt 2000 5000}}","dir":"out","text":"Health check from server {{randInt 1 3}}"}
</code></pre>
<h2 id="error-handling-in-streams"><a class="header" href="#error-handling-in-streams">Error Handling in Streams</a></h2>
<h3 id="stream-errors"><a class="header" href="#stream-errors">Stream Errors</a></h3>
<pre><code class="language-jsonl">// Handle invalid messages
{"ts":0,"dir":"in","text":"","response":"Empty message not allowed"}
{"ts":0,"dir":"in","text":".{500,}","response":"Message too long (max 500 chars)"}

// Simulate network errors
{"ts":5000,"dir":"out","text":"Network error occurred","error":true,"close":true}
</code></pre>
<h3 id="recovery-patterns"><a class="header" href="#recovery-patterns">Recovery Patterns</a></h3>
<pre><code class="language-jsonl">// Automatic reconnection
{"ts":0,"dir":"out","text":"Connection lost, attempting reconnect..."}
{"ts":2000,"dir":"out","text":"Reconnected successfully"}
{"ts":100,"dir":"out","text":"Resuming stream from message {{request.ws.state.lastMessageId}}"}
</code></pre>
<h2 id="testing-strategies-1"><a class="header" href="#testing-strategies-1">Testing Strategies</a></h2>
<h3 id="unit-testing-streams"><a class="header" href="#unit-testing-streams">Unit Testing Streams</a></h3>
<pre><code class="language-javascript">// test-streaming.js
const { expect } = require('chai');

describe('gRPC Streaming', () =&gt; {
  it('should handle server streaming', (done) =&gt; {
    const call = client.subscribeNotifications({ topics: ['test'] });

    let messageCount = 0;
    call.on('data', (notification) =&gt; {
      messageCount++;
      expect(notification).to.have.property('topic');
      expect(notification).to.have.property('message');
    });

    call.on('end', () =&gt; {
      expect(messageCount).to.be.greaterThan(0);
      done();
    });

    // End test after 5 seconds
    setTimeout(() =&gt; call.cancel(), 5000);
  });

  it('should handle client streaming', (done) =&gt; {
    const call = client.uploadFile((error, response) =&gt; {
      expect(error).to.be.null;
      expect(response).to.have.property('file_id');
      expect(response.status).to.equal('SUCCESS');
      done();
    });

    // Send test chunks
    call.write({ data: Buffer.from('test'), sequence: 0 });
    call.write({ data: Buffer.from('data'), sequence: 1, is_last: true });
    call.end();
  });
});
</code></pre>
<h3 id="load-testing-1"><a class="header" href="#load-testing-1">Load Testing</a></h3>
<pre><code class="language-bash">#!/bin/bash
# load-test-streams.sh

CONCURRENT_STREAMS=10
DURATION=60

echo "Load testing $CONCURRENT_STREAMS concurrent streams for ${DURATION}s"

for i in $(seq 1 $CONCURRENT_STREAMS); do
  node stream-client.js &amp;
done

# Wait for test duration
sleep $DURATION

# Kill all clients
pkill -f stream-client.js

echo "Load test completed"
</code></pre>
<h2 id="best-practices-3"><a class="header" href="#best-practices-3">Best Practices</a></h2>
<h3 id="stream-design"><a class="header" href="#stream-design">Stream Design</a></h3>
<ol>
<li><strong>Appropriate Patterns</strong>: Choose the right streaming pattern for your use case</li>
<li><strong>Message Size</strong>: Keep individual messages reasonably sized</li>
<li><strong>Heartbeat Messages</strong>: Include periodic keepalive messages for long-running streams</li>
<li><strong>Error Recovery</strong>: Implement proper error handling and recovery mechanisms</li>
</ol>
<h3 id="performance-optimization-1"><a class="header" href="#performance-optimization-1">Performance Optimization</a></h3>
<ol>
<li><strong>Buffering</strong>: Use appropriate buffer sizes for your throughput requirements</li>
<li><strong>Compression</strong>: Enable compression for large message streams</li>
<li><strong>Connection Reuse</strong>: Reuse connections when possible</li>
<li><strong>Resource Limits</strong>: Set appropriate limits on concurrent streams and message rates</li>
</ol>
<h3 id="monitoring-and-debugging"><a class="header" href="#monitoring-and-debugging">Monitoring and Debugging</a></h3>
<ol>
<li><strong>Stream Metrics</strong>: Monitor stream duration, message counts, and error rates</li>
<li><strong>Logging</strong>: Enable detailed logging for debugging streaming issues</li>
<li><strong>Tracing</strong>: Implement request tracing across stream messages</li>
<li><strong>Health Checks</strong>: Regular health checks for long-running streams</li>
</ol>
<h3 id="client-compatibility"><a class="header" href="#client-compatibility">Client Compatibility</a></h3>
<ol>
<li><strong>Protocol Versions</strong>: Ensure compatibility with different gRPC versions</li>
<li><strong>Language Support</strong>: Test with multiple client language implementations</li>
<li><strong>Network Conditions</strong>: Test under various network conditions (latency, packet loss)</li>
<li><strong>Browser Support</strong>: Consider WebSocket fallback for web clients</li>
</ol>
<h2 id="troubleshooting-4"><a class="header" href="#troubleshooting-4">Troubleshooting</a></h2>
<h3 id="common-streaming-issues"><a class="header" href="#common-streaming-issues">Common Streaming Issues</a></h3>
<p><strong>Stream doesn’t start</strong>: Check proto file definitions and service registration</p>
<p><strong>Messages not received</strong>: Verify message encoding and template syntax</p>
<p><strong>Stream hangs</strong>: Check for proper stream termination and timeout settings</p>
<p><strong>Performance degradation</strong>: Monitor resource usage and adjust buffer sizes</p>
<p><strong>Client disconnects</strong>: Implement proper heartbeat and reconnection logic</p>
<h3 id="debug-commands-2"><a class="header" href="#debug-commands-2">Debug Commands</a></h3>
<pre><code class="language-bash"># Monitor active streams
grpcurl -plaintext localhost:50051 list

# Check stream status
netstat -tlnp | grep :50051

# View stream logs
tail -f mockforge.log | grep -E "(stream|grpc)"

# Test basic connectivity
grpcurl -plaintext localhost:50051 grpc.reflection.v1alpha.ServerReflection/ServerReflectionInfo
</code></pre>
<h3 id="performance-profiling"><a class="header" href="#performance-profiling">Performance Profiling</a></h3>
<pre><code class="language-bash"># Profile gRPC performance
cargo flamegraph --bin mockforge-cli -- serve --grpc-port 50051

# Monitor system resources
htop -p $(pgrep mockforge)

# Network monitoring
iftop -i lo
</code></pre>
<p>Streaming patterns enable powerful real-time communication scenarios. MockForge’s comprehensive streaming support allows you to create sophisticated mock environments that accurately simulate production streaming services for thorough testing and development.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="advanced-data-synthesis"><a class="header" href="#advanced-data-synthesis">Advanced Data Synthesis</a></h1>
<p>MockForge provides sophisticated data synthesis capabilities that go beyond simple random data generation. The advanced data synthesis system combines intelligent field inference, deterministic seeding, relationship-aware generation, and cross-endpoint validation to create realistic, coherent, and reproducible test data.</p>
<h2 id="overview-1"><a class="header" href="#overview-1">Overview</a></h2>
<p>The advanced data synthesis system consists of four main components:</p>
<ol>
<li><strong>Smart Mock Generator</strong> - Intelligent field-based mock data generation with deterministic seeding</li>
<li><strong>Schema Graph Extraction</strong> - Automatic discovery of relationships from protobuf schemas</li>
<li><strong>RAG-Driven Synthesis</strong> - Domain-aware data generation using Retrieval-Augmented Generation</li>
<li><strong>Validation Framework</strong> - Cross-endpoint consistency and integrity validation</li>
</ol>
<p>These components work together to provide enterprise-grade test data generation that maintains referential integrity across your entire gRPC service ecosystem.</p>
<h2 id="smart-mock-generator"><a class="header" href="#smart-mock-generator">Smart Mock Generator</a></h2>
<p>The Smart Mock Generator provides intelligent mock data generation based on field names, types, and patterns. It automatically detects the intent behind field names and generates appropriate realistic data.</p>
<h3 id="field-name-intelligence"><a class="header" href="#field-name-intelligence">Field Name Intelligence</a></h3>
<p>The generator automatically infers appropriate data types based on field names:</p>
<div class="table-wrapper"><table><thead><tr><th>Field Pattern</th><th>Generated Data Type</th><th>Example Values</th></tr></thead><tbody>
<tr><td><code>email</code>, <code>email_address</code></td><td>Realistic email addresses</td><td><code>user@example.com</code>, <code>alice.smith@company.org</code></td></tr>
<tr><td><code>phone</code>, <code>mobile</code>, <code>phone_number</code></td><td>Formatted phone numbers</td><td><code>+1-555-0123</code>, <code>(555) 123-4567</code></td></tr>
<tr><td><code>id</code>, <code>user_id</code>, <code>order_id</code></td><td>Sequential or UUID-based IDs</td><td><code>user_001</code>, <code>550e8400-e29b-41d4-a716-446655440000</code></td></tr>
<tr><td><code>name</code>, <code>first_name</code>, <code>last_name</code></td><td>Realistic names</td><td><code>John Doe</code>, <code>Alice</code>, <code>Johnson</code></td></tr>
<tr><td><code>created_at</code>, <code>updated_at</code>, <code>timestamp</code></td><td>ISO timestamps</td><td><code>2023-10-15T14:30:00Z</code></td></tr>
<tr><td><code>latitude</code>, <code>longitude</code></td><td>Geographic coordinates</td><td><code>40.7128</code>, <code>-74.0060</code></td></tr>
<tr><td><code>url</code>, <code>website</code></td><td>Valid URLs</td><td><code>https://example.com</code></td></tr>
<tr><td><code>token</code>, <code>api_key</code></td><td>Security tokens</td><td><code>sk_live_4eC39HqLyjWDarjtT1zdp7dc</code></td></tr>
</tbody></table>
</div>
<h3 id="deterministic-generation"><a class="header" href="#deterministic-generation">Deterministic Generation</a></h3>
<p>For reproducible test fixtures, the Smart Mock Generator supports deterministic seeding:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_grpc::reflection::smart_mock_generator::{SmartMockGenerator, SmartMockConfig};

// Create a deterministic generator with a fixed seed
let mut generator = SmartMockGenerator::new_with_seed(
    SmartMockConfig::default(),
    12345 // seed value
);

// Generate reproducible data
let uuid1 = generator.generate_uuid();
let email = generator.generate_random_string(10);

// Reset to regenerate same data
generator.reset();
let uuid2 = generator.generate_uuid(); // Same as uuid1
<span class="boring">}</span></code></pre></pre>
<p>This ensures that your tests produce consistent results across different runs and environments.</p>
<h2 id="schema-graph-extraction"><a class="header" href="#schema-graph-extraction">Schema Graph Extraction</a></h2>
<p>The schema graph extraction system analyzes your protobuf definitions to automatically discover relationships and foreign key patterns between entities.</p>
<h3 id="foreign-key-detection"><a class="header" href="#foreign-key-detection">Foreign Key Detection</a></h3>
<p>The system uses naming conventions to detect foreign key relationships:</p>
<pre><code class="language-protobuf">message Order {
  string id = 1;
  string user_id = 2;     // → Detected as foreign key to User
  string customer_ref = 3; // → Detected as reference to Customer  
  int64 timestamp = 4;
}

message User {
  string id = 1;          // → Detected as primary key
  string name = 2;
  string email = 3;
}
</code></pre>
<p><strong>Common Foreign Key Patterns:</strong></p>
<ul>
<li><code>user_id</code> → references <code>User</code> entity</li>
<li><code>orderId</code> → references <code>Order</code> entity</li>
<li><code>customer_ref</code> → references <code>Customer</code> entity</li>
</ul>
<h3 id="relationship-types"><a class="header" href="#relationship-types">Relationship Types</a></h3>
<p>The system identifies various relationship types:</p>
<ul>
<li><strong>Foreign Key</strong>: Direct ID references (<code>user_id</code> → <code>User</code>)</li>
<li><strong>Embedded</strong>: Nested message types within other messages</li>
<li><strong>One-to-Many</strong>: Repeated field relationships</li>
<li><strong>Composition</strong>: Ownership relationships between entities</li>
</ul>
<h2 id="rag-driven-data-synthesis"><a class="header" href="#rag-driven-data-synthesis">RAG-Driven Data Synthesis</a></h2>
<p>RAG (Retrieval-Augmented Generation) enables context-aware data generation using domain knowledge from documentation, examples, and business rules.</p>
<h3 id="configuration"><a class="header" href="#configuration">Configuration</a></h3>
<pre><code class="language-yaml">grpc:
  data_synthesis:
    rag:
      enabled: true
      api_endpoint: "https://api.openai.com/v1/chat/completions"
      model: "gpt-3.5-turbo" 
      embedding_model: "text-embedding-ada-002"
      similarity_threshold: 0.7
      max_documents: 5
    context_sources:
      - id: "user_docs"
        type: "documentation"
        path: "./docs/user_guide.md"
        weight: 1.0
      - id: "examples"
        type: "examples"
        path: "./examples/sample_data.json" 
        weight: 0.8
</code></pre>
<h3 id="business-rule-extraction"><a class="header" href="#business-rule-extraction">Business Rule Extraction</a></h3>
<p>The RAG system automatically extracts business rules from your documentation:</p>
<ul>
<li><strong>Email Validation</strong>: “Email fields must follow valid email format”</li>
<li><strong>Phone Formatting</strong>: “Phone numbers should be in international format”</li>
<li><strong>ID Requirements</strong>: “User IDs must be alphanumeric and 8 characters long”</li>
<li><strong>Relationship Constraints</strong>: “Orders must reference valid existing users”</li>
</ul>
<h3 id="domain-aware-generation"><a class="header" href="#domain-aware-generation">Domain-Aware Generation</a></h3>
<p>Instead of generic random data, RAG generates contextually appropriate values:</p>
<pre><code class="language-protobuf">message User {
  string role = 1; // Context: "admin", "user", "moderator" 
  string department = 2; // Context: "engineering", "marketing", "sales"
  string location = 3; // Context: "San Francisco", "New York", "London"
}
</code></pre>
<h2 id="cross-endpoint-validation"><a class="header" href="#cross-endpoint-validation">Cross-Endpoint Validation</a></h2>
<p>The validation framework ensures data coherence across different endpoints and validates referential integrity.</p>
<h3 id="validation-rules"><a class="header" href="#validation-rules">Validation Rules</a></h3>
<p>The framework supports multiple types of validation rules:</p>
<p><strong>Built-in Validations:</strong></p>
<ul>
<li>Foreign key existence validation</li>
<li>Field format validation (email, phone, URL)</li>
<li>Range validation for numeric fields</li>
<li>Unique constraint validation</li>
</ul>
<p><strong>Custom Validation Rules:</strong></p>
<pre><code class="language-yaml">grpc:
  data_synthesis:
    validation:
      enabled: true
      strict_mode: false
      custom_rules:
        - name: "email_format"
          applies_to: ["User", "Customer"]
          fields: ["email"]
          type: "format"
          pattern: "^[^@\\s]+@[^@\\s]+\\.[^@\\s]+$"
          error: "Invalid email format"
        - name: "age_range" 
          applies_to: ["User"]
          fields: ["age"]
          type: "range"
          min: 0
          max: 120
          error: "Age must be between 0 and 120"
</code></pre>
<h3 id="referential-integrity"><a class="header" href="#referential-integrity">Referential Integrity</a></h3>
<p>The validator automatically checks that:</p>
<ul>
<li>Foreign key references point to existing entities</li>
<li>Required relationships are satisfied</li>
<li>Cross-service data dependencies are maintained</li>
<li>Business constraints are enforced</li>
</ul>
<h2 id="configuration-1"><a class="header" href="#configuration-1">Configuration</a></h2>
<h3 id="environment-variables-2"><a class="header" href="#environment-variables-2">Environment Variables</a></h3>
<pre><code class="language-bash"># Enable advanced data synthesis
MOCKFORGE_DATA_SYNTHESIS_ENABLED=true

# Deterministic generation  
MOCKFORGE_DATA_SYNTHESIS_SEED=12345
MOCKFORGE_DATA_SYNTHESIS_DETERMINISTIC=true

# RAG configuration
MOCKFORGE_RAG_ENABLED=true
MOCKFORGE_RAG_API_KEY=your-api-key
MOCKFORGE_RAG_MODEL=gpt-3.5-turbo

# Validation settings
MOCKFORGE_VALIDATION_ENABLED=true
MOCKFORGE_VALIDATION_STRICT_MODE=false
</code></pre>
<h3 id="configuration-file-1"><a class="header" href="#configuration-file-1">Configuration File</a></h3>
<pre><code class="language-yaml">grpc:
  port: 50051
  proto_dir: "proto/"
  data_synthesis:
    enabled: true
    smart_generator:
      field_inference: true
      use_faker: true
      deterministic: true
      seed: 42
      max_depth: 5
    rag:
      enabled: true
      api_endpoint: "https://api.openai.com/v1/chat/completions"
      api_key: "${RAG_API_KEY}"
      model: "gpt-3.5-turbo"
      embedding_model: "text-embedding-ada-002"  
      similarity_threshold: 0.7
      max_context_length: 2000
      cache_contexts: true
    validation:
      enabled: true
      strict_mode: false
      max_validation_depth: 3
      cache_results: true
    schema_extraction:
      extract_relationships: true
      detect_foreign_keys: true
      confidence_threshold: 0.8
</code></pre>
<h2 id="example-usage"><a class="header" href="#example-usage">Example Usage</a></h2>
<h3 id="basic-smart-generation"><a class="header" href="#basic-smart-generation">Basic Smart Generation</a></h3>
<pre><code class="language-bash"># Start MockForge with advanced data synthesis
MOCKFORGE_DATA_SYNTHESIS_ENABLED=true \
MOCKFORGE_DATA_SYNTHESIS_SEED=12345 \
mockforge serve --grpc-port 50051
</code></pre>
<h3 id="with-rag-enhancement"><a class="header" href="#with-rag-enhancement">With RAG Enhancement</a></h3>
<pre><code class="language-bash"># Start with RAG-powered domain awareness
MOCKFORGE_DATA_SYNTHESIS_ENABLED=true \
MOCKFORGE_RAG_ENABLED=true \
MOCKFORGE_RAG_API_KEY=your-api-key \
MOCKFORGE_VALIDATION_ENABLED=true \
mockforge serve --grpc-port 50051
</code></pre>
<h3 id="testing-deterministic-generation"><a class="header" href="#testing-deterministic-generation">Testing Deterministic Generation</a></h3>
<pre><code class="language-bash"># Generate data twice with same seed - should be identical
grpcurl -plaintext -d '{"user_id": "123"}' \
  localhost:50051 com.example.UserService/GetUser

# Reset and call again - will generate same response
grpcurl -plaintext -d '{"user_id": "123"}' \
  localhost:50051 com.example.UserService/GetUser
</code></pre>
<h2 id="best-practices-4"><a class="header" href="#best-practices-4">Best Practices</a></h2>
<h3 id="deterministic-testing"><a class="header" href="#deterministic-testing">Deterministic Testing</a></h3>
<ul>
<li>Use fixed seeds in CI/CD pipelines for reproducible tests</li>
<li>Reset generators between test cases for consistency</li>
<li>Document seed values used in critical test scenarios</li>
</ul>
<h3 id="schema-design-for-synthesis"><a class="header" href="#schema-design-for-synthesis">Schema Design for Synthesis</a></h3>
<ul>
<li>Use consistent naming conventions for foreign keys (<code>user_id</code>, <code>customer_ref</code>)</li>
<li>Add comments to proto files describing business rules</li>
<li>Consider field naming that indicates data type (<code>email_address</code> vs <code>contact</code>)</li>
</ul>
<h3 id="rag-integration"><a class="header" href="#rag-integration">RAG Integration</a></h3>
<ul>
<li>Provide high-quality domain documentation as context sources</li>
<li>Use specific, actionable descriptions in documentation</li>
<li>Monitor API costs and implement appropriate caching</li>
</ul>
<h3 id="validation-strategy"><a class="header" href="#validation-strategy">Validation Strategy</a></h3>
<ul>
<li>Start with lenient validation and gradually add stricter rules</li>
<li>Use warnings for potential issues, errors for critical problems</li>
<li>Provide helpful error messages with suggested fixes</li>
</ul>
<h2 id="advanced-scenarios"><a class="header" href="#advanced-scenarios">Advanced Scenarios</a></h2>
<h3 id="multi-service-data-coherence"><a class="header" href="#multi-service-data-coherence">Multi-Service Data Coherence</a></h3>
<p>When mocking multiple related gRPC services, ensure data coherence:</p>
<pre><code class="language-bash"># Start user service
MOCKFORGE_DATA_SYNTHESIS_SEED=100 \
mockforge serve --grpc-port 50051 --proto-dir user-proto &amp;

# Start order service with same seed for consistency  
MOCKFORGE_DATA_SYNTHESIS_SEED=100 \
mockforge serve --grpc-port 50052 --proto-dir order-proto &amp;
</code></pre>
<h3 id="custom-field-overrides"><a class="header" href="#custom-field-overrides">Custom Field Overrides</a></h3>
<p>Override specific fields with custom values:</p>
<pre><code class="language-yaml">grpc:
  data_synthesis:
    field_overrides:
      "admin_email": "admin@company.com"
      "api_version": "v2.1"
      "environment": "testing"
</code></pre>
<h3 id="business-rule-templates"><a class="header" href="#business-rule-templates">Business Rule Templates</a></h3>
<p>Define reusable business rule templates:</p>
<pre><code class="language-yaml">grpc:
  data_synthesis:
    rule_templates:
      - name: "financial_data"
        applies_to: ["Invoice", "Payment", "Transaction"]
        rules:
          - field_pattern: "*_amount"
            type: "range" 
            min: 0.01
            max: 10000.00
          - field_pattern: "*_currency"
            type: "enum"
            values: ["USD", "EUR", "GBP"]
</code></pre>
<h2 id="troubleshooting-5"><a class="header" href="#troubleshooting-5">Troubleshooting</a></h2>
<h3 id="common-issues-2"><a class="header" href="#common-issues-2">Common Issues</a></h3>
<p><strong>Generated data not realistic enough</strong></p>
<ul>
<li>Enable RAG synthesis with domain documentation</li>
<li>Check field naming conventions for better inference</li>
<li>Add custom business rules for specific constraints</li>
</ul>
<p><strong>Non-deterministic behavior</strong></p>
<ul>
<li>Ensure <code>deterministic: true</code> and provide a <code>seed</code> value</li>
<li>Reset generators between test runs</li>
<li>Check for external randomness sources</li>
</ul>
<p><strong>Validation failures</strong></p>
<ul>
<li>Review foreign key naming conventions</li>
<li>Ensure referenced entities are generated before referencing ones</li>
<li>Check custom validation rule patterns</li>
</ul>
<p><strong>RAG not working</strong></p>
<ul>
<li>Verify API credentials and endpoints</li>
<li>Check context source file paths and permissions</li>
<li>Monitor API rate limits and error responses</li>
</ul>
<h3 id="debug-commands-3"><a class="header" href="#debug-commands-3">Debug Commands</a></h3>
<pre><code class="language-bash"># Test data synthesis configuration
mockforge validate-config

# Show detected schema relationships
mockforge analyze-schema --proto-dir proto/

# Test deterministic generation
MOCKFORGE_DATA_SYNTHESIS_DEBUG=true \
mockforge serve --grpc-port 50051
</code></pre>
<p>Advanced data synthesis transforms MockForge from a simple mocking tool into a comprehensive test data management platform, enabling realistic, consistent, and validated test scenarios across your entire service architecture.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="websocket-mocking"><a class="header" href="#websocket-mocking">WebSocket Mocking</a></h1>
<p>MockForge provides comprehensive WebSocket connection mocking with support for both scripted replay scenarios and interactive real-time communication. This enables testing of WebSocket-based applications, real-time APIs, and event-driven systems.</p>
<h2 id="websocket-mocking-modes"><a class="header" href="#websocket-mocking-modes">WebSocket Mocking Modes</a></h2>
<p>MockForge supports two primary WebSocket mocking approaches:</p>
<h3 id="1-replay-mode-scripted"><a class="header" href="#1-replay-mode-scripted">1. Replay Mode (Scripted)</a></h3>
<p>Pre-recorded message sequences that play back on schedule, simulating server behavior with precise timing control.</p>
<h3 id="2-interactive-mode-real-time"><a class="header" href="#2-interactive-mode-real-time">2. Interactive Mode (Real-time)</a></h3>
<p>Dynamic responses based on client messages, enabling complex interactive scenarios and stateful communication.</p>
<h2 id="configuration-2"><a class="header" href="#configuration-2">Configuration</a></h2>
<h3 id="basic-websocket-setup"><a class="header" href="#basic-websocket-setup">Basic WebSocket Setup</a></h3>
<pre><code class="language-bash"># Start MockForge with WebSocket support
mockforge serve --ws-port 3001 --ws-replay-file ws-scenario.jsonl
</code></pre>
<h3 id="environment-variables-3"><a class="header" href="#environment-variables-3">Environment Variables</a></h3>
<pre><code class="language-bash"># WebSocket configuration
MOCKFORGE_WS_ENABLED=true                    # Enable WebSocket support (default: false)
MOCKFORGE_WS_PORT=3001                       # WebSocket server port
MOCKFORGE_WS_BIND=0.0.0.0                    # Bind address
MOCKFORGE_WS_REPLAY_FILE=path/to/file.jsonl  # Path to replay file
MOCKFORGE_WS_PATH=/ws                         # WebSocket endpoint path (default: /ws)
MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true      # Enable template processing
</code></pre>
<h3 id="command-line-options"><a class="header" href="#command-line-options">Command Line Options</a></h3>
<pre><code class="language-bash">mockforge serve \
  --ws-port 3001 \
  --ws-replay-file examples/ws-demo.jsonl \
  --ws-path /websocket
</code></pre>
<h2 id="replay-mode"><a class="header" href="#replay-mode">Replay Mode</a></h2>
<p>Replay mode uses JSONL-formatted files to define scripted message sequences with precise timing control.</p>
<h3 id="replay-file-format"><a class="header" href="#replay-file-format">Replay File Format</a></h3>
<p>Each line in the replay file is a JSON object with the following structure:</p>
<pre><code class="language-json">{
  "ts": 0,
  "dir": "out",
  "text": "Hello, client!",
  "waitFor": "^CLIENT_READY$"
}
</code></pre>
<h3 id="field-definitions"><a class="header" href="#field-definitions">Field Definitions</a></h3>
<ul>
<li><strong><code>ts</code></strong> (number, required): Timestamp offset in milliseconds from connection start</li>
<li><strong><code>dir</code></strong> (string, required): Message direction
<ul>
<li><code>"out"</code> - Message sent from server to client</li>
<li><code>"in"</code> - Expected message from client (for validation)</li>
</ul>
</li>
<li><strong><code>text</code></strong> (string, required): Message content (supports templates)</li>
<li><strong><code>waitFor</code></strong> (string, optional): Regular expression to wait for before proceeding</li>
</ul>
<h3 id="basic-replay-example"><a class="header" href="#basic-replay-example">Basic Replay Example</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"Welcome to MockForge WebSocket server","waitFor":"^HELLO$"}
{"ts":1000,"dir":"out","text":"Connection established"}
{"ts":2000,"dir":"out","text":"Sending data: 42"}
{"ts":3000,"dir":"out","text":"Goodbye"}
</code></pre>
<h3 id="advanced-replay-features"><a class="header" href="#advanced-replay-features">Advanced Replay Features</a></h3>
<h4 id="template-support-1"><a class="header" href="#template-support-1">Template Support</a></h4>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"Session {{uuid}} started at {{now}}"}
{"ts":1000,"dir":"out","text":"Random value: {{randInt 1 100}}"}
{"ts":2000,"dir":"out","text":"Future event at {{now+5m}}"}
</code></pre>
<h4 id="interactive-elements"><a class="header" href="#interactive-elements">Interactive Elements</a></h4>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"Please authenticate","waitFor":"^AUTH .+$"}
{"ts":100,"dir":"out","text":"Authentication successful"}
{"ts":200,"dir":"out","text":"Choose option (A/B/C)","waitFor":"^(A|B|C)$"}
</code></pre>
<h4 id="complex-message-structures"><a class="header" href="#complex-message-structures">Complex Message Structures</a></h4>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"{\"type\":\"welcome\",\"user\":{\"id\":\"{{uuid}}\",\"name\":\"John\"}}"}
{"ts":1000,"dir":"out","text":"{\"type\":\"data\",\"payload\":{\"items\":[{\"id\":1,\"value\":\"{{randInt 10 99}}\"},{\"id\":2,\"value\":\"{{randInt 100 999}}\"}]}}"}
</code></pre>
<h3 id="replay-file-management"><a class="header" href="#replay-file-management">Replay File Management</a></h3>
<h4 id="creating-replay-files"><a class="header" href="#creating-replay-files">Creating Replay Files</a></h4>
<pre><code class="language-bash"># Record from live WebSocket connection
# (Feature in development - manual creation for now)

# Create from application logs
# Extract WebSocket messages and convert to JSONL format

# Generate programmatically
node -e "
const fs = require('fs');
const messages = [
  {ts: 0, dir: 'out', text: 'HELLO', waitFor: '^HI$'},
  {ts: 1000, dir: 'out', text: 'DATA: 42'}
];
fs.writeFileSync('replay.jsonl', messages.map(JSON.stringify).join('\n'));
"
</code></pre>
<h4 id="validation-1"><a class="header" href="#validation-1">Validation</a></h4>
<pre><code class="language-bash"># Validate replay file syntax
node -e "
const fs = require('fs');
const lines = fs.readFileSync('replay.jsonl', 'utf8').split('\n');
lines.forEach((line, i) =&gt; {
  if (line.trim()) {
    try {
      const msg = JSON.parse(line);
      if (!msg.ts || !msg.dir || !msg.text) {
        console.log(\`Line \${i+1}: Missing required fields\`);
      }
    } catch (e) {
      console.log(\`Line \${i+1}: Invalid JSON\`);
    }
  }
});
console.log('Validation complete');
"
</code></pre>
<h2 id="interactive-mode"><a class="header" href="#interactive-mode">Interactive Mode</a></h2>
<p>Interactive mode enables dynamic responses based on client messages, supporting complex conversational patterns and state management.</p>
<h3 id="basic-interactive-setup"><a class="header" href="#basic-interactive-setup">Basic Interactive Setup</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"What is your name?","waitFor":"^NAME .+$"}
{"ts":100,"dir":"out","text":"Hello {{request.ws.lastMessage.match(/^NAME (.+)$/)[1]}}!"}
</code></pre>
<h3 id="state-management-1"><a class="header" href="#state-management-1">State Management</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"Welcome! Type 'START' to begin","waitFor":"^START$"}
{"ts":100,"dir":"out","text":"Game started. Score: 0","state":"playing"}
{"ts":200,"dir":"out","text":"Choose: ROCK/PAPER/SCISSORS","waitFor":"^(ROCK|PAPER|SCISSORS)$"}
{"ts":300,"dir":"out","text":"You chose {{request.ws.lastMessage}}. I chose ROCK. You win!","waitFor":"^PLAY_AGAIN$"}
</code></pre>
<h3 id="conditional-logic-1"><a class="header" href="#conditional-logic-1">Conditional Logic</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"Enter command","waitFor":".+","condition":"{{request.ws.message.length &gt; 0}}"}
{"ts":100,"dir":"out","text":"Processing: {{request.ws.message}}"}
{"ts":200,"dir":"out","text":"Command completed"}
</code></pre>
<h2 id="testing-websocket-connections"><a class="header" href="#testing-websocket-connections">Testing WebSocket Connections</a></h2>
<h3 id="using-websocket-clients"><a class="header" href="#using-websocket-clients">Using WebSocket Clients</a></h3>
<h4 id="nodejs-client"><a class="header" href="#nodejs-client">Node.js Client</a></h4>
<pre><code class="language-javascript">const WebSocket = require('ws');

const ws = new WebSocket('ws://localhost:3001/ws');

ws.on('open', () =&gt; {
  console.log('Connected to MockForge WebSocket');
  ws.send('CLIENT_READY');
});

ws.on('message', (data) =&gt; {
  const message = data.toString();
  console.log('Received:', message);

  // Auto-respond to common prompts
  if (message.includes('ACK')) {
    ws.send('ACK');
  }
  if (message.includes('CONFIRMED')) {
    ws.send('CONFIRMED');
  }
  if (message.includes('AUTH')) {
    ws.send('AUTH token123');
  }
});

ws.on('close', () =&gt; {
  console.log('Connection closed');
});

ws.on('error', (err) =&gt; {
  console.error('WebSocket error:', err);
});
</code></pre>
<h4 id="browser-javascript"><a class="header" href="#browser-javascript">Browser JavaScript</a></h4>
<pre><code class="language-javascript">const ws = new WebSocket('ws://localhost:3001/ws');

ws.onopen = () =&gt; {
  console.log('Connected');
  ws.send('CLIENT_READY');
};

ws.onmessage = (event) =&gt; {
  console.log('Received:', event.data);
  // Handle server messages
};

ws.onclose = () =&gt; {
  console.log('Connection closed');
};
</code></pre>
<h4 id="command-line-tools"><a class="header" href="#command-line-tools">Command Line Tools</a></h4>
<pre><code class="language-bash"># Using websocat
websocat ws://localhost:3001/ws

# Using curl (WebSocket support experimental)
curl --include \
     --no-buffer \
     --header "Connection: Upgrade" \
     --header "Upgrade: websocket" \
     --header "Sec-WebSocket-Key: x3JJHMbDL1EzLkh9GBhXDw==" \
     --header "Sec-WebSocket-Version: 13" \
     ws://localhost:3001/ws
</code></pre>
<h3 id="automated-testing-1"><a class="header" href="#automated-testing-1">Automated Testing</a></h3>
<pre><code class="language-bash">#!/bin/bash
# test-websocket.sh

echo "Testing WebSocket connection..."

# Test with Node.js
node -e "
const WebSocket = require('ws');
const ws = new WebSocket('ws://localhost:3001/ws');

ws.on('open', () =&gt; {
  console.log('✓ Connection established');
  ws.send('CLIENT_READY');
});

ws.on('message', (data) =&gt; {
  console.log('✓ Message received:', data.toString());
  ws.close();
});

ws.on('close', () =&gt; {
  console.log('✓ Connection closed successfully');
  process.exit(0);
});

ws.on('error', (err) =&gt; {
  console.error('✗ WebSocket error:', err);
  process.exit(1);
});

// Timeout after 10 seconds
setTimeout(() =&gt; {
  console.error('✗ Test timeout');
  process.exit(1);
}, 10000);
"
</code></pre>
<h2 id="advanced-features-1"><a class="header" href="#advanced-features-1">Advanced Features</a></h2>
<h3 id="connection-pooling"><a class="header" href="#connection-pooling">Connection Pooling</a></h3>
<pre><code class="language-bash"># Support multiple concurrent connections
MOCKFORGE_WS_MAX_CONNECTIONS=100
MOCKFORGE_WS_CONNECTION_TIMEOUT=30000
</code></pre>
<h3 id="message-filtering"><a class="header" href="#message-filtering">Message Filtering</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"in","text":".*","filter":"{{request.ws.message.startsWith('VALID_')}}"}
{"ts":100,"dir":"out","text":"Valid message received"}
</code></pre>
<h3 id="error-simulation"><a class="header" href="#error-simulation">Error Simulation</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"Error occurred","error":"true","code":1006}
{"ts":100,"dir":"out","text":"Connection will close","close":"true"}
</code></pre>
<h3 id="binary-message-support"><a class="header" href="#binary-message-support">Binary Message Support</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"AQIDBAU=","binary":"true"}
{"ts":1000,"dir":"out","text":"Binary data sent"}
</code></pre>
<h2 id="integration-patterns-2"><a class="header" href="#integration-patterns-2">Integration Patterns</a></h2>
<h3 id="real-time-applications"><a class="header" href="#real-time-applications">Real-time Applications</a></h3>
<ul>
<li><strong>Chat Applications</strong>: Mock user conversations and bot responses</li>
<li><strong>Live Updates</strong>: Simulate real-time data feeds and notifications</li>
<li><strong>Gaming</strong>: Mock multiplayer game state and player interactions</li>
</ul>
<h3 id="api-testing"><a class="header" href="#api-testing">API Testing</a></h3>
<ul>
<li><strong>WebSocket APIs</strong>: Test GraphQL subscriptions and real-time queries</li>
<li><strong>Event Streams</strong>: Mock server-sent events and push notifications</li>
<li><strong>Live Dashboards</strong>: Simulate real-time metrics and monitoring data</li>
</ul>
<h3 id="development-workflows"><a class="header" href="#development-workflows">Development Workflows</a></h3>
<ul>
<li><strong>Frontend Development</strong>: Mock WebSocket backends during UI development</li>
<li><strong>Integration Testing</strong>: Test WebSocket handling in microservices</li>
<li><strong>Load Testing</strong>: Simulate thousands of concurrent WebSocket connections</li>
</ul>
<h2 id="best-practices-5"><a class="header" href="#best-practices-5">Best Practices</a></h2>
<h3 id="replay-file-organization"><a class="header" href="#replay-file-organization">Replay File Organization</a></h3>
<ol>
<li><strong>Modular Files</strong>: Break complex scenarios into smaller, focused replay files</li>
<li><strong>Version Control</strong>: Keep replay files in Git for collaboration</li>
<li><strong>Documentation</strong>: Comment complex scenarios with clear descriptions</li>
<li><strong>Validation</strong>: Always validate replay files before deployment</li>
</ol>
<h3 id="performance-considerations-2"><a class="header" href="#performance-considerations-2">Performance Considerations</a></h3>
<ol>
<li><strong>Message Volume</strong>: Limit concurrent connections based on system resources</li>
<li><strong>Memory Usage</strong>: Monitor memory usage with large replay files</li>
<li><strong>Timing Accuracy</strong>: Consider system clock precision for time-sensitive scenarios</li>
<li><strong>Connection Limits</strong>: Set appropriate connection pool sizes</li>
</ol>
<h3 id="security-considerations-1"><a class="header" href="#security-considerations-1">Security Considerations</a></h3>
<ol>
<li><strong>Input Validation</strong>: Validate all client messages in interactive mode</li>
<li><strong>Rate Limiting</strong>: Implement connection rate limits for production</li>
<li><strong>Authentication</strong>: Mock authentication handshakes appropriately</li>
<li><strong>Data Sanitization</strong>: Avoid exposing sensitive data in replay files</li>
</ol>
<h3 id="debugging-tips"><a class="header" href="#debugging-tips">Debugging Tips</a></h3>
<ol>
<li><strong>Verbose Logging</strong>: Enable detailed WebSocket logging for troubleshooting</li>
<li><strong>Connection Monitoring</strong>: Track connection lifecycle and message flow</li>
<li><strong>Replay Debugging</strong>: Step through replay files manually</li>
<li><strong>Client Compatibility</strong>: Test with multiple WebSocket client libraries</li>
</ol>
<h2 id="troubleshooting-6"><a class="header" href="#troubleshooting-6">Troubleshooting</a></h2>
<h3 id="common-issues-3"><a class="header" href="#common-issues-3">Common Issues</a></h3>
<p><strong>Connection fails</strong>: Check that WebSocket port is not blocked by firewall</p>
<p><strong>Messages not received</strong>: Verify replay file path and JSONL format</p>
<p><strong>Templates not expanding</strong>: Ensure <code>MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true</code></p>
<p><strong>Timing issues</strong>: Check system clock and timestamp calculations</p>
<h3 id="debug-commands-4"><a class="header" href="#debug-commands-4">Debug Commands</a></h3>
<pre><code class="language-bash"># Check WebSocket port
netstat -tlnp | grep :3001

# Monitor connections
ss -tlnp | grep :3001

# Test basic connectivity
curl -I http://localhost:3001/health  # If HTTP health endpoint exists
</code></pre>
<h3 id="log-analysis-1"><a class="header" href="#log-analysis-1">Log Analysis</a></h3>
<pre><code class="language-bash"># View WebSocket logs
tail -f mockforge.log | grep -i websocket

# Count connections
grep "WebSocket connection" mockforge.log | wc -l

# Find errors
grep -i "websocket.*error" mockforge.log
</code></pre>
<p>For detailed implementation guides, see:</p>
<ul>
<li><a href="user-guide/websocket-mocking/replay.html">Replay Mode</a> - Advanced scripted scenarios</li>
<li><a href="user-guide/websocket-mocking/interactive.html">Interactive Mode</a> - Dynamic real-time communication</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="replay-mode-1"><a class="header" href="#replay-mode-1">Replay Mode</a></h1>
<p>Replay mode provides precise, scripted WebSocket message sequences that execute on a predetermined schedule. This mode is ideal for testing deterministic scenarios, reproducing specific interaction patterns, and validating client behavior against known server responses.</p>
<h2 id="core-concepts"><a class="header" href="#core-concepts">Core Concepts</a></h2>
<h3 id="message-timeline"><a class="header" href="#message-timeline">Message Timeline</a></h3>
<p>Replay files define a sequence of messages that execute based on timestamps relative to connection establishment. Each message has a precise timing offset ensuring consistent playback.</p>
<h3 id="deterministic-execution"><a class="header" href="#deterministic-execution">Deterministic Execution</a></h3>
<p>Replay scenarios execute identically each time, making them perfect for:</p>
<ul>
<li>Automated testing</li>
<li>Regression testing</li>
<li>Client behavior validation</li>
<li>Demo environments</li>
</ul>
<h2 id="replay-file-structure"><a class="header" href="#replay-file-structure">Replay File Structure</a></h2>
<h3 id="jsonl-format"><a class="header" href="#jsonl-format">JSONL Format</a></h3>
<p>Replay files use JSON Lines format where each line contains a complete JSON object representing a single message or directive.</p>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"Welcome message"}
{"ts":1000,"dir":"out","text":"Data update","waitFor":"^ACK$"}
{"ts":2000,"dir":"out","text":"Connection closing"}
</code></pre>
<h3 id="message-object-schema"><a class="header" href="#message-object-schema">Message Object Schema</a></h3>
<pre><code class="language-typescript">interface ReplayMessage {
  ts: number;           // Timestamp offset in milliseconds
  dir: "out" | "in";    // Message direction
  text: string;         // Message content
  waitFor?: string;     // Optional regex pattern to wait for
  binary?: boolean;     // Binary message flag
  close?: boolean;      // Close connection after this message
  error?: boolean;      // Send as error frame
}
</code></pre>
<h2 id="basic-replay-examples"><a class="header" href="#basic-replay-examples">Basic Replay Examples</a></h2>
<h3 id="simple-chat-simulation"><a class="header" href="#simple-chat-simulation">Simple Chat Simulation</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"Chat server connected. Welcome!"}
{"ts":500,"dir":"out","text":"Type 'hello' to start chatting","waitFor":"^hello$"}
{"ts":100,"dir":"out","text":"Hello! How can I help you today?"}
{"ts":2000,"dir":"out","text":"Are you still there?","waitFor":".*"}
{"ts":500,"dir":"out","text":"Thanks for chatting! Goodbye."}
</code></pre>
<h3 id="api-status-monitoring"><a class="header" href="#api-status-monitoring">API Status Monitoring</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"{\"type\":\"status\",\"message\":\"Monitor connected\"}"}
{"ts":1000,"dir":"out","text":"{\"type\":\"metrics\",\"cpu\":45,\"memory\":67}"}
{"ts":2000,"dir":"out","text":"{\"type\":\"metrics\",\"cpu\":42,\"memory\":68}"}
{"ts":3000,"dir":"out","text":"{\"type\":\"metrics\",\"cpu\":47,\"memory\":66}"}
{"ts":4000,"dir":"out","text":"{\"type\":\"alert\",\"level\":\"warning\",\"message\":\"High CPU usage\"}"}
</code></pre>
<h3 id="game-state-synchronization"><a class="header" href="#game-state-synchronization">Game State Synchronization</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"{\"action\":\"game_start\",\"player_id\":\"{{uuid}}\",\"game_id\":\"{{uuid}}\"}"}
{"ts":1000,"dir":"out","text":"{\"action\":\"state_update\",\"position\":{\"x\":10,\"y\":20},\"score\":0}"}
{"ts":2000,"dir":"out","text":"{\"action\":\"enemy_spawn\",\"enemy_id\":\"{{uuid}}\",\"position\":{\"x\":50,\"y\":30}}"}
{"ts":1500,"dir":"out","text":"{\"action\":\"powerup\",\"type\":\"speed\",\"position\":{\"x\":25,\"y\":15}}"}
{"ts":3000,"dir":"out","text":"{\"action\":\"game_over\",\"final_score\":1250,\"reason\":\"timeout\"}"}
</code></pre>
<h2 id="advanced-replay-techniques"><a class="header" href="#advanced-replay-techniques">Advanced Replay Techniques</a></h2>
<h3 id="conditional-branching"><a class="header" href="#conditional-branching">Conditional Branching</a></h3>
<p>While replay mode is inherently linear, you can simulate branching using multiple replay files and external logic:</p>
<pre><code class="language-jsonl">// File: login-success.jsonl
{"ts":0,"dir":"out","text":"Login successful","waitFor":"^ready$"}
{"ts":100,"dir":"out","text":"Welcome to your dashboard"}

// File: login-failed.jsonl
{"ts":0,"dir":"out","text":"Invalid credentials"}
{"ts":500,"dir":"out","text":"Connection will close","close":true}
</code></pre>
<h3 id="template-integration"><a class="header" href="#template-integration">Template Integration</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"Session {{uuid}} established at {{now}}"}
{"ts":1000,"dir":"out","text":"Your lucky number is: {{randInt 1 100}}"}
{"ts":2000,"dir":"out","text":"Next maintenance window: {{now+24h}}"}
{"ts":3000,"dir":"out","text":"Server load: {{randInt 20 80}}%"}
</code></pre>
<h3 id="binary-message-support-1"><a class="header" href="#binary-message-support-1">Binary Message Support</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNkYPhfDwAChwGA60e6kgAAAABJRU5ErkJggg==","binary":true}
{"ts":1000,"dir":"out","text":"Image sent successfully"}
</code></pre>
<h3 id="error-simulation-1"><a class="header" href="#error-simulation-1">Error Simulation</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"Connection established"}
{"ts":5000,"dir":"out","text":"Internal server error","error":true}
{"ts":1000,"dir":"out","text":"Attempting reconnection..."}
{"ts":2000,"dir":"out","text":"Reconnection failed","close":true}
</code></pre>
<h2 id="creating-replay-files-1"><a class="header" href="#creating-replay-files-1">Creating Replay Files</a></h2>
<h3 id="manual-creation"><a class="header" href="#manual-creation">Manual Creation</a></h3>
<pre><code class="language-bash"># Create a new replay file
cat &gt; chat-replay.jsonl &lt;&lt; 'EOF'
{"ts":0,"dir":"out","text":"Welcome to support chat!"}
{"ts":1000,"dir":"out","text":"How can I help you today?","waitFor":".*"}
{"ts":500,"dir":"out","text":"Thanks for your question. Let me check..."}
{"ts":2000,"dir":"out","text":"I found the solution! Here's what you need to do:"}
{"ts":1000,"dir":"out","text":"1. Go to settings\n2. Click preferences\n3. Enable feature X"}
{"ts":3000,"dir":"out","text":"Does this solve your issue?","waitFor":"^(yes|no)$"}
{"ts":500,"dir":"out","text":"Great! Glad I could help. Have a nice day!"}
EOF
</code></pre>
<h3 id="from-application-logs"><a class="header" href="#from-application-logs">From Application Logs</a></h3>
<pre><code class="language-bash">#!/bin/bash
# extract-websocket-logs.sh

# Extract WebSocket messages from application logs
grep "WEBSOCKET_MSG" app.log | \
  # Parse log entries and convert to JSONL
  awk '{
    # Extract timestamp, direction, and message
    match($0, /([0-9]+).*dir=([^ ]*).*msg=(.*)/, arr)
    printf "{\"ts\":%d,\"dir\":\"%s\",\"text\":\"%s\"}\n", arr[1], arr[2], arr[3]
  }' &gt; replay-from-logs.jsonl
</code></pre>
<h3 id="programmatic-generation"><a class="header" href="#programmatic-generation">Programmatic Generation</a></h3>
<pre><code class="language-javascript">// generate-replay.js
const fs = require('fs');

function generateHeartbeatReplay(interval = 30000, duration = 300000) {
  const messages = [];
  const messageCount = duration / interval;

  for (let i = 0; i &lt; messageCount; i++) {
    messages.push({
      ts: i * interval,
      dir: "out",
      text: JSON.stringify({
        type: "heartbeat",
        timestamp: `{{now+${i * interval}ms}}`,
        sequence: i + 1
      })
    });
  }

  fs.writeFileSync('heartbeat-replay.jsonl',
    messages.map(JSON.stringify).join('\n'));
}

generateHeartbeatReplay();
</code></pre>
<pre><code class="language-python"># generate-replay.py
import json
import random

def generate_data_stream(count=100, interval=1000):
    messages = []
    for i in range(count):
        messages.append({
            "ts": i * interval,
            "dir": "out",
            "text": json.dumps({
                "type": "data_point",
                "id": f"{{{{uuid}}}}",
                "value": random.randint(1, 100),
                "timestamp": f"{{{{now+{i * interval}ms}}}}}"
            })
        })
    return messages

# Write to file
with open('data-stream-replay.jsonl', 'w') as f:
    for msg in generate_data_stream():
        f.write(json.dumps(msg) + '\n')
</code></pre>
<h2 id="validation-and-testing"><a class="header" href="#validation-and-testing">Validation and Testing</a></h2>
<h3 id="replay-file-validation"><a class="header" href="#replay-file-validation">Replay File Validation</a></h3>
<pre><code class="language-bash"># Validate JSONL syntax
node -e "
const fs = require('fs');
const lines = fs.readFileSync('replay.jsonl', 'utf8').split('\n');
let valid = true;

lines.forEach((line, i) =&gt; {
  if (line.trim()) {
    try {
      const msg = JSON.parse(line);
      if (!msg.ts || !msg.dir || !msg.text) {
        console.log(\`Line \${i+1}: Missing required fields\`);
        valid = false;
      }
      if (typeof msg.ts !== 'number' || msg.ts &lt; 0) {
        console.log(\`Line \${i+1}: Invalid timestamp\`);
        valid = false;
      }
      if (!['in', 'out'].includes(msg.dir)) {
        console.log(\`Line \${i+1}: Invalid direction\`);
        valid = false;
      }
    } catch (e) {
      console.log(\`Line \${i+1}: Invalid JSON - \${e.message}\`);
      valid = false;
    }
  }
});

console.log(valid ? '✓ Replay file is valid' : '✗ Replay file has errors');
"
</code></pre>
<h3 id="timing-analysis"><a class="header" href="#timing-analysis">Timing Analysis</a></h3>
<pre><code class="language-bash"># Analyze replay timing
node -e "
const fs = require('fs');
const messages = fs.readFileSync('replay.jsonl', 'utf8')
  .split('\n')
  .filter(line =&gt; line.trim())
  .map(line =&gt; JSON.parse(line));

const timings = messages.map((msg, i) =&gt; ({
  index: i + 1,
  ts: msg.ts,
  interval: i &gt; 0 ? msg.ts - messages[i-1].ts : 0
}));

console.log('Timing Analysis:');
timings.forEach(t =&gt; {
  console.log(\`Message \${t.index}: \${t.ts}ms (interval: \${t.interval}ms)\`);
});

const totalDuration = Math.max(...messages.map(m =&gt; m.ts));
console.log(\`Total duration: \${totalDuration}ms (\${(totalDuration/1000).toFixed(1)}s)\`);
"
</code></pre>
<h3 id="functional-testing"><a class="header" href="#functional-testing">Functional Testing</a></h3>
<pre><code class="language-bash">#!/bin/bash
# test-replay.sh

REPLAY_FILE=$1
WS_URL="ws://localhost:3001/ws"

echo "Testing replay file: $REPLAY_FILE"

# Validate file exists and is readable
if [ ! -f "$REPLAY_FILE" ]; then
  echo "✗ Replay file not found"
  exit 1
fi

# Basic syntax check
if ! node -e "
  const fs = require('fs');
  const content = fs.readFileSync('$REPLAY_FILE', 'utf8');
  const lines = content.split('\n').filter(l =&gt; l.trim());
  lines.forEach((line, i) =&gt; {
    try {
      JSON.parse(line);
    } catch (e) {
      console.error(\`Line \${i+1}: \${e.message}\`);
      process.exit(1);
    }
  });
  console.log(\`✓ Valid JSONL: \${lines.length} messages\`);
"; then
  echo "✗ Syntax validation failed"
  exit 1
fi

echo "✓ Replay file validation passed"
echo "Ready to test with: mockforge serve --ws-replay-file $REPLAY_FILE"
</code></pre>
<h2 id="best-practices-6"><a class="header" href="#best-practices-6">Best Practices</a></h2>
<h3 id="file-organization"><a class="header" href="#file-organization">File Organization</a></h3>
<ol>
<li>
<p><strong>Descriptive Names</strong>: Use clear, descriptive filenames</p>
<pre><code>user-authentication-flow.jsonl
real-time-data-stream.jsonl
error-handling-scenarios.jsonl
</code></pre>
</li>
<li>
<p><strong>Modular Scenarios</strong>: Break complex interactions into focused files</p>
<pre><code>login-flow.jsonl
main-interaction.jsonl
logout-flow.jsonl
</code></pre>
</li>
<li>
<p><strong>Version Control</strong>: Keep replay files in Git with meaningful commit messages</p>
</li>
</ol>
<h3 id="performance-optimization-2"><a class="header" href="#performance-optimization-2">Performance Optimization</a></h3>
<ol>
<li><strong>Message Batching</strong>: Group related messages with minimal intervals</li>
<li><strong>Memory Management</strong>: Monitor memory usage with large replay files</li>
<li><strong>Connection Limits</strong>: Consider concurrent connection impact</li>
</ol>
<h3 id="maintenance"><a class="header" href="#maintenance">Maintenance</a></h3>
<ol>
<li><strong>Regular Updates</strong>: Keep replay files synchronized with application changes</li>
<li><strong>Documentation</strong>: Comment complex scenarios inline</li>
<li><strong>Versioning</strong>: Tag replay files with application versions</li>
</ol>
<h3 id="debugging"><a class="header" href="#debugging">Debugging</a></h3>
<ol>
<li><strong>Verbose Logging</strong>: Enable detailed WebSocket logging during development</li>
<li><strong>Step-through Testing</strong>: Test replay files incrementally</li>
<li><strong>Timing Verification</strong>: Validate message timing against expectations</li>
</ol>
<h2 id="common-patterns"><a class="header" href="#common-patterns">Common Patterns</a></h2>
<h3 id="authentication-flow"><a class="header" href="#authentication-flow">Authentication Flow</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"Please authenticate","waitFor":"^AUTH .+$"}
{"ts":100,"dir":"out","text":"Authenticating..."}
{"ts":500,"dir":"out","text":"Authentication successful"}
{"ts":200,"dir":"out","text":"Welcome back, user!"}
</code></pre>
<h3 id="streaming-data"><a class="header" href="#streaming-data">Streaming Data</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"{\"type\":\"stream_start\",\"stream_id\":\"{{uuid}}\"}"}
{"ts":100,"dir":"out","text":"{\"type\":\"data\",\"value\":{{randInt 1 100}}}"}
{"ts":100,"dir":"out","text":"{\"type\":\"data\",\"value\":{{randInt 1 100}}}"}
{"ts":100,"dir":"out","text":"{\"type\":\"data\",\"value\":{{randInt 1 100}}}"}
{"ts":5000,"dir":"out","text":"{\"type\":\"stream_end\",\"total_messages\":3}"}
</code></pre>
<h3 id="error-recovery"><a class="header" href="#error-recovery">Error Recovery</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"System operational"}
{"ts":30000,"dir":"out","text":"Warning: High load detected"}
{"ts":10000,"dir":"out","text":"Error: Service unavailable","error":true}
{"ts":5000,"dir":"out","text":"Attempting recovery..."}
{"ts":10000,"dir":"out","text":"Recovery successful"}
{"ts":1000,"dir":"out","text":"System back to normal"}
</code></pre>
<h2 id="integration-with-cicd"><a class="header" href="#integration-with-cicd">Integration with CI/CD</a></h2>
<h3 id="automated-testing-2"><a class="header" href="#automated-testing-2">Automated Testing</a></h3>
<pre><code class="language-yaml"># .github/workflows/test.yml
name: WebSocket Tests
on: [push, pull_request]

jobs:
  websocket-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
      - name: Install dependencies
        run: npm install ws
      - name: Start MockForge
        run: |
          cargo install mockforge-cli
          mockforge serve --ws-replay-file examples/ws-demo.jsonl &amp;
          sleep 2
      - name: Run WebSocket tests
        run: node test-websocket.js
</code></pre>
<h3 id="performance-benchmarking"><a class="header" href="#performance-benchmarking">Performance Benchmarking</a></h3>
<pre><code class="language-bash">#!/bin/bash
# benchmark-replay.sh

CONCURRENT_CONNECTIONS=100
DURATION=60

echo "Benchmarking WebSocket replay with $CONCURRENT_CONNECTIONS connections for ${DURATION}s"

# Start MockForge
mockforge serve --ws-replay-file benchmark-replay.jsonl &amp;
SERVER_PID=$!
sleep 2

# Run benchmark
node benchmark-websocket.js $CONCURRENT_CONNECTIONS $DURATION

# Cleanup
kill $SERVER_PID
</code></pre>
<p>This comprehensive approach to replay mode ensures reliable, deterministic WebSocket testing scenarios that can be easily created, validated, and maintained as part of your testing infrastructure.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="interactive-mode-1"><a class="header" href="#interactive-mode-1">Interactive Mode</a></h1>
<p>Interactive mode enables dynamic, real-time WebSocket communication where MockForge responds intelligently to client messages. Unlike replay mode’s predetermined sequences, interactive mode supports complex conversational patterns, state management, and adaptive responses based on client input.</p>
<h2 id="core-concepts-1"><a class="header" href="#core-concepts-1">Core Concepts</a></h2>
<h3 id="dynamic-response-logic"><a class="header" href="#dynamic-response-logic">Dynamic Response Logic</a></h3>
<p>Interactive mode evaluates client messages and generates contextually appropriate responses using conditional logic, pattern matching, and state tracking.</p>
<h3 id="state-management-2"><a class="header" href="#state-management-2">State Management</a></h3>
<p>Connections maintain state across messages, enabling complex interactions like authentication flows, game mechanics, and multi-step processes.</p>
<h3 id="message-processing-pipeline"><a class="header" href="#message-processing-pipeline">Message Processing Pipeline</a></h3>
<ol>
<li><strong>Receive</strong> client message</li>
<li><strong>Parse</strong> and validate input</li>
<li><strong>Evaluate</strong> conditions and state</li>
<li><strong>Generate</strong> appropriate response</li>
<li><strong>Update</strong> connection state</li>
</ol>
<h2 id="basic-interactive-setup-1"><a class="header" href="#basic-interactive-setup-1">Basic Interactive Setup</a></h2>
<h3 id="simple-echo-server"><a class="header" href="#simple-echo-server">Simple Echo Server</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"Echo server ready. Send me a message!"}
{"ts":0,"dir":"in","text":".*","response":"You said: {{request.ws.message}}"}
</code></pre>
<h3 id="command-processor"><a class="header" href="#command-processor">Command Processor</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"Available commands: HELP, TIME, ECHO &lt;message&gt;, QUIT"}
{"ts":0,"dir":"in","text":"^HELP$","response":"Commands: HELP, TIME, ECHO &lt;msg&gt;, QUIT"}
{"ts":0,"dir":"in","text":"^TIME$","response":"Current time: {{now}}"}
{"ts":0,"dir":"in","text":"^ECHO (.+)$","response":"Echo: {{request.ws.message.match(/^ECHO (.+)$/)[1]}}"}
{"ts":0,"dir":"in","text":"^QUIT$","response":"Goodbye!","close":true}
</code></pre>
<h2 id="advanced-interactive-patterns"><a class="header" href="#advanced-interactive-patterns">Advanced Interactive Patterns</a></h2>
<h3 id="authentication-flow-1"><a class="header" href="#authentication-flow-1">Authentication Flow</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"Welcome! Please login with: LOGIN &lt;username&gt; &lt;password&gt;"}
{"ts":0,"dir":"in","text":"^LOGIN (\\w+) (\\w+)$","response":"Authenticating {{request.ws.message.match(/^LOGIN (\\w+) (\\w+)$/)[1]}}...","state":"authenticating"}
{"ts":1000,"dir":"out","text":"Login successful! Welcome, {{request.ws.state.username}}!","condition":"{{request.ws.state.authenticating}}"}
{"ts":0,"dir":"out","text":"Login failed. Try again.","condition":"{{!request.ws.state.authenticating}}"}
</code></pre>
<h3 id="state-based-conversations"><a class="header" href="#state-based-conversations">State-Based Conversations</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"Welcome to the survey bot. What's your name?","state":"awaiting_name"}
{"ts":0,"dir":"in","text":".+","response":"Nice to meet you, {{request.ws.message}}! How old are you?","state":"awaiting_age","condition":"{{request.ws.state.awaiting_name}}"}
{"ts":0,"dir":"in","text":"^\\d+$","response":"Thanks! You're {{request.ws.message}} years old. Survey complete!","state":"complete","condition":"{{request.ws.state.awaiting_age}}"}
{"ts":0,"dir":"in","text":".*","response":"Please enter a valid age (numbers only).","condition":"{{request.ws.state.awaiting_age}}"}
</code></pre>
<h3 id="game-mechanics"><a class="header" href="#game-mechanics">Game Mechanics</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"Welcome to Number Guessing Game! I'm thinking of a number between 1-100.","state":"playing","game":{"target":42,"attempts":0}}
{"ts":0,"dir":"in","text":"^GUESS (\\d+)$","condition":"{{request.ws.state.playing}}","response":"{{#if (eq (parseInt request.ws.message.match(/^GUESS (\\d+)$/) [1]) request.ws.state.game.target)}}You won in {{request.ws.state.game.attempts + 1}} attempts!{{else}}{{#if (gt (parseInt request.ws.message.match(/^GUESS (\\d+)$/) [1]) request.ws.state.game.target)}}Too high!{{else}}Too low!{{/if}} Try again.{{/if}}","state":"{{#if (eq (parseInt request.ws.message.match(/^GUESS (\\d+)$/) [1]) request.ws.state.game.target)}}won{{else}}playing{{/if}}","game":{"target":"{{request.ws.state.game.target}}","attempts":"{{request.ws.state.game.attempts + 1}}"}}
</code></pre>
<h2 id="message-processing-syntax"><a class="header" href="#message-processing-syntax">Message Processing Syntax</a></h2>
<h3 id="input-patterns"><a class="header" href="#input-patterns">Input Patterns</a></h3>
<p>Interactive mode uses regex patterns to match client messages:</p>
<pre><code class="language-jsonl">// Exact match
{"dir":"in","text":"hello","response":"Hi there!"}

// Case-insensitive match
{"dir":"in","text":"(?i)hello","response":"Hi there!"}

// Pattern with capture groups
{"dir":"in","text":"^NAME (.+)$","response":"Hello, {{request.ws.message.match(/^NAME (.+)$/)[1]}}!"}

// Optional elements
{"dir":"in","text":"^(HELP|help|\\?)$","response":"Available commands: ..."}
</code></pre>
<h3 id="response-templates"><a class="header" href="#response-templates">Response Templates</a></h3>
<p>Responses support the full MockForge template system:</p>
<pre><code class="language-jsonl">{"dir":"in","text":".*","response":"Message received at {{now}}: {{request.ws.message}} (length: {{request.ws.message.length}})"}
</code></pre>
<h3 id="conditions"><a class="header" href="#conditions">Conditions</a></h3>
<p>Use template conditions to control when rules apply:</p>
<pre><code class="language-jsonl">{"dir":"in","text":".*","condition":"{{request.ws.state.authenticated}}","response":"Welcome back!"}
{"dir":"in","text":".*","condition":"{{!request.ws.state.authenticated}}","response":"Please authenticate first."}
</code></pre>
<h3 id="state-updates"><a class="header" href="#state-updates">State Updates</a></h3>
<p>Modify connection state based on interactions:</p>
<pre><code class="language-jsonl">// Set simple state
{"dir":"in","text":"START","response":"Starting...","state":"active"}

// Update complex state
{"dir":"in","text":"SCORE","response":"Current score: {{request.ws.state.score}}","state":"playing","score":"{{request.ws.state.score + 10}}"}
</code></pre>
<h2 id="advanced-features-2"><a class="header" href="#advanced-features-2">Advanced Features</a></h2>
<h3 id="multi-message-conversations"><a class="header" href="#multi-message-conversations">Multi-Message Conversations</a></h3>
<pre><code class="language-jsonl">// Step 1: Greeting
{"ts":0,"dir":"out","text":"Hello! What's your favorite color?"}
{"ts":0,"dir":"in","text":".+","response":"{{request.ws.message}} is a great choice! What's your favorite food?","state":"asked_color","color":"{{request.ws.message}}","next":"food"}

// Step 2: Follow-up
{"ts":0,"dir":"out","text":"Based on your preferences, I recommend: ...","condition":"{{request.ws.state.next === 'complete'}}"}
{"ts":0,"dir":"in","text":".+","condition":"{{request.ws.state.next === 'food'}}","response":"Perfect! You like {{request.ws.state.color}} and {{request.ws.message}}. Here's a recommendation...","state":"complete"}
</code></pre>
<h3 id="error-handling-1"><a class="header" href="#error-handling-1">Error Handling</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"Enter a command:"}
{"ts":0,"dir":"in","text":"","response":"Empty input not allowed. Try again."}
{"ts":0,"dir":"in","text":"^.{100,}$","response":"Input too long (max 99 characters). Please shorten."}
{"ts":0,"dir":"in","text":"^INVALID.*","response":"Unknown command. Type HELP for available commands."}
{"ts":0,"dir":"in","text":".*","response":"Processing: {{request.ws.message}}"}
</code></pre>
<h3 id="rate-limiting"><a class="header" href="#rate-limiting">Rate Limiting</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"in","text":".*","condition":"{{request.ws.state.messageCount &lt; 10}}","response":"Message {{request.ws.state.messageCount + 1}}: {{request.ws.message}}","messageCount":"{{request.ws.state.messageCount + 1}}"}
{"ts":0,"dir":"in","text":".*","condition":"{{request.ws.state.messageCount &gt;= 10}}","response":"Rate limit exceeded. Please wait."}
</code></pre>
<h3 id="session-management"><a class="header" href="#session-management">Session Management</a></h3>
<pre><code class="language-jsonl">// Initialize session
{"ts":0,"dir":"out","text":"Session started: {{uuid}}","sessionId":"{{uuid}}","startTime":"{{now}}","messageCount":0}

// Track activity
{"ts":0,"dir":"in","text":".*","response":"Received","messageCount":"{{request.ws.state.messageCount + 1}}","lastActivity":"{{now}}","condition":"{{request.ws.state.active}}"}
</code></pre>
<h2 id="template-functions-for-interactive-mode"><a class="header" href="#template-functions-for-interactive-mode">Template Functions for Interactive Mode</a></h2>
<h3 id="message-analysis"><a class="header" href="#message-analysis">Message Analysis</a></h3>
<pre><code class="language-jsonl">// Message properties
{"dir":"in","text":".*","response":"Length: {{request.ws.message.length}}, Uppercase: {{request.ws.message.toUpperCase()}}"}
</code></pre>
<h3 id="state-queries"><a class="header" href="#state-queries">State Queries</a></h3>
<pre><code class="language-jsonl">// Check state existence
{"condition":"{{request.ws.state.userId}}","response":"Logged in as: {{request.ws.state.userId}}"}
{"condition":"{{!request.ws.state.userId}}","response":"Please log in first."}

// State comparisons
{"condition":"{{request.ws.state.score &gt; 100}}","response":"High score achieved!"}
{"condition":"{{request.ws.state.level === 'expert'}}","response":"Expert mode enabled."}
</code></pre>
<h3 id="time-based-logic"><a class="header" href="#time-based-logic">Time-based Logic</a></h3>
<pre><code class="language-jsonl">// Session timeout
{"condition":"{{request.ws.state.lastActivity &amp;&amp; (now - request.ws.state.lastActivity) &gt; 300000}}","response":"Session expired. Please reconnect.","close":true}

// Time-based greetings
{"response":"{{#if (gte (now.getHours()) 18)}}Good evening!{{else if (gte (now.getHours()) 12)}}Good afternoon!{{else}}Good morning!{{/if}}"}
</code></pre>
<h2 id="creating-interactive-scenarios"><a class="header" href="#creating-interactive-scenarios">Creating Interactive Scenarios</a></h2>
<h3 id="from-scratch"><a class="header" href="#from-scratch">From Scratch</a></h3>
<pre><code class="language-bash"># Create a new interactive scenario
cat &gt; interactive-chat.jsonl &lt;&lt; 'EOF'
{"ts":0,"dir":"out","text":"ChatBot: Hello! How can I help you today?"}
{"ts":0,"dir":"in","text":"(?i).*help.*","response":"ChatBot: I can answer questions, tell jokes, or just chat. What would you like?"}
{"ts":0,"dir":"in","text":"(?i).*joke.*","response":"ChatBot: Why did the computer go to the doctor? It had a virus! 😂"}
{"ts":0,"dir":"in","text":"(?i).*bye.*","response":"ChatBot: Goodbye! Have a great day! 👋","close":true}
{"ts":0,"dir":"in","text":".*","response":"ChatBot: I'm not sure how to respond to that. Try asking for help!"}
EOF
</code></pre>
<h3 id="from-existing-logs"><a class="header" href="#from-existing-logs">From Existing Logs</a></h3>
<pre><code class="language-bash">#!/bin/bash
# convert-logs-to-interactive.sh

# Extract conversation patterns from logs
grep "USER:" chat.log | sed 's/.*USER: //' | sort | uniq &gt; user_patterns.txt
grep "BOT:" chat.log | sed 's/.*BOT: //' | sort | uniq &gt; bot_responses.txt

# Generate interactive rules
paste user_patterns.txt bot_responses.txt | while IFS=$'\t' read -r user bot; do
  echo "{\"dir\":\"in\",\"text\":\"$(echo "$user" | sed 's/[^a-zA-Z0-9]/\\&amp;/g')\",\"response\":\"$bot\"}"
done &gt; interactive-from-logs.jsonl
</code></pre>
<h3 id="testing-interactive-scenarios"><a class="header" href="#testing-interactive-scenarios">Testing Interactive Scenarios</a></h3>
<pre><code class="language-bash">#!/bin/bash
# test-interactive.sh

echo "Testing interactive WebSocket scenario..."

# Start MockForge with interactive file
mockforge serve --ws-replay-file interactive-test.jsonl &amp;
SERVER_PID=$!
sleep 2

# Test conversation flow
node -e "
const WebSocket = require('ws');
const ws = new WebSocket('ws://localhost:3001/ws');

const conversation = [
  'Hello',
  'Tell me a joke',
  'What can you do?',
  'Goodbye'
];

let step = 0;

ws.on('open', () =&gt; {
  console.log('Connected, starting conversation...');
  ws.send(conversation[step++]);
});

ws.on('message', (data) =&gt; {
  const response = data.toString();
  console.log('Bot:', response);

  if (step &lt; conversation.length) {
    setTimeout(() =&gt; {
      ws.send(conversation[step++]);
    }, 1000);
  } else {
    ws.close();
  }
});

ws.on('close', () =&gt; {
  console.log('Conversation complete');
  process.exit(0);
});

ws.on('error', (err) =&gt; {
  console.error('Error:', err);
  process.exit(1);
});
"

# Cleanup
kill $SERVER_PID
</code></pre>
<h2 id="best-practices-7"><a class="header" href="#best-practices-7">Best Practices</a></h2>
<h3 id="design-principles"><a class="header" href="#design-principles">Design Principles</a></h3>
<ol>
<li><strong>Clear Conversation Flow</strong>: Design conversations with clear paths and expectations</li>
<li><strong>Graceful Error Handling</strong>: Provide helpful responses for unexpected input</li>
<li><strong>State Consistency</strong>: Keep state updates predictable and logical</li>
<li><strong>Performance Awareness</strong>: Avoid complex regex or template processing</li>
</ol>
<h3 id="pattern-guidelines"><a class="header" href="#pattern-guidelines">Pattern Guidelines</a></h3>
<ol>
<li><strong>Specific to General</strong>: Order patterns from most specific to most general</li>
<li><strong>Anchored Regex</strong>: Use <code>^</code> and <code>$</code> to avoid partial matches</li>
<li><strong>Case Handling</strong>: Consider case sensitivity in user input</li>
<li><strong>Input Validation</strong>: Validate and sanitize user input</li>
</ol>
<h3 id="state-management-3"><a class="header" href="#state-management-3">State Management</a></h3>
<ol>
<li><strong>Minimal State</strong>: Store only necessary information in connection state</li>
<li><strong>State Validation</strong>: Verify state consistency across interactions</li>
<li><strong>State Cleanup</strong>: Clear state when conversations end</li>
<li><strong>State Persistence</strong>: Consider state requirements for reconnection scenarios</li>
</ol>
<h3 id="debugging-interactive-scenarios"><a class="header" href="#debugging-interactive-scenarios">Debugging Interactive Scenarios</a></h3>
<ol>
<li><strong>Verbose Logging</strong>: Enable detailed WebSocket logging</li>
<li><strong>State Inspection</strong>: Log state changes during conversations</li>
<li><strong>Pattern Testing</strong>: Test regex patterns independently</li>
<li><strong>Flow Tracing</strong>: Track conversation paths through state changes</li>
</ol>
<h2 id="common-patterns-1"><a class="header" href="#common-patterns-1">Common Patterns</a></h2>
<h3 id="customer-support-chat"><a class="header" href="#customer-support-chat">Customer Support Chat</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"Welcome to support! How can I help you? (Type your question or 'menu' for options)"}
{"ts":0,"dir":"in","text":"(?i)menu","response":"Options: 1) Password reset 2) Billing 3) Technical issue 4) Other","state":"menu"}
{"ts":0,"dir":"in","text":"(?i).*password.*","response":"I'll help you reset your password. What's your email address?","state":"password_reset","issue":"password"}
{"ts":0,"dir":"in","text":"(?i).*billing.*","response":"For billing questions, please visit our billing portal at billing.example.com","state":"billing"}
{"ts":0,"dir":"in","text":".*","response":"Thanks for your question: '{{request.ws.message}}'. A support agent will respond shortly. Your ticket ID is: {{uuid}}"}
</code></pre>
<h3 id="e-commerce-assistant"><a class="header" href="#e-commerce-assistant">E-commerce Assistant</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"Welcome to our store! What are you looking for?","state":"browsing"}
{"ts":0,"dir":"in","text":"(?i).*shirt.*","response":"We have various shirts: casual, formal, graphic. Which style interests you?","state":"shirt_selection","category":"shirts"}
{"ts":0,"dir":"in","text":"(?i).*size.*","response":"Available sizes: S, M, L, XL. Which size would you like?","state":"size_selection","condition":"{{request.ws.state.category}}"}
{"ts":0,"dir":"in","text":"(?i)(S|M|L|XL)","condition":"{{request.ws.state.size_selection}}","response":"Great! Adding {{request.ws.state.category}} in size {{request.ws.message.toUpperCase()}} to cart. Would you like to checkout or continue shopping?","state":"checkout_ready"}
</code></pre>
<h3 id="game-server"><a class="header" href="#game-server">Game Server</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"Welcome to the game server! Choose your character: WARRIOR, MAGE, ROGUE","state":"character_select"}
{"ts":0,"dir":"in","text":"(?i)^(warrior|mage|rogue)$","response":"Excellent choice! You selected {{request.ws.message.toUpperCase()}}. Your adventure begins now...","state":"playing","character":"{{request.ws.message.toLowerCase()}}","health":100,"level":1}
{"ts":0,"dir":"in","text":"(?i)stats","condition":"{{request.ws.state.playing}}","response":"Character: {{request.ws.state.character}}, Level: {{request.ws.state.level}}, Health: {{request.ws.state.health}}"}
{"ts":0,"dir":"in","text":"(?i)fight","condition":"{{request.ws.state.playing}}","response":"You encounter a monster! Roll for attack... {{randInt 1 20}}! {{#if (gte (randInt 1 20) 10)}}Victory!{{else}}Defeat!{{/if}}"}
</code></pre>
<h2 id="integration-examples"><a class="header" href="#integration-examples">Integration Examples</a></h2>
<h3 id="with-testing-frameworks"><a class="header" href="#with-testing-frameworks">With Testing Frameworks</a></h3>
<pre><code class="language-javascript">// test-interactive.js
const WebSocket = require('ws');

class InteractiveWebSocketTester {
  constructor(url) {
    this.url = url;
    this.ws = null;
  }

  async connect() {
    return new Promise((resolve, reject) =&gt; {
      this.ws = new WebSocket(this.url);
      this.ws.on('open', () =&gt; resolve());
      this.ws.on('error', reject);
    });
  }

  async sendAndExpect(message, expectedResponse) {
    return new Promise((resolve, reject) =&gt; {
      const timeout = setTimeout(() =&gt; reject(new Error('Timeout')), 5000);

      this.ws.send(message);
      this.ws.once('message', (data) =&gt; {
        clearTimeout(timeout);
        const response = data.toString();
        if (response === expectedResponse) {
          resolve(response);
        } else {
          reject(new Error(`Expected "${expectedResponse}", got "${response}"`));
        }
      });
    });
  }

  close() {
    if (this.ws) this.ws.close();
  }
}

module.exports = InteractiveWebSocketTester;
</code></pre>
<h3 id="load-testing-interactive-scenarios"><a class="header" href="#load-testing-interactive-scenarios">Load Testing Interactive Scenarios</a></h3>
<pre><code class="language-bash">#!/bin/bash
# load-test-interactive.sh

CONCURRENT_USERS=50
DURATION=300

echo "Load testing interactive WebSocket with $CONCURRENT_USERS concurrent users for ${DURATION}s"

# Start MockForge
mockforge serve --ws-replay-file interactive-load-test.jsonl &amp;
SERVER_PID=$!
sleep 2

# Run load test
node load-test-interactive.js $CONCURRENT_USERS $DURATION

# Generate report
echo "Generating performance report..."
node analyze-results.js

# Cleanup
kill $SERVER_PID
</code></pre>
<p>Interactive mode transforms MockForge from a simple message player into an intelligent conversation partner, enabling sophisticated testing scenarios that adapt to client behavior and maintain complex interaction state.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="admin-ui"><a class="header" href="#admin-ui">Admin UI</a></h1>
<p>MockForge provides a comprehensive web-based Admin UI for managing and monitoring your mock servers. The Admin UI offers real-time insights, configuration management, and debugging tools to make mock server management effortless.</p>
<h2 id="accessing-the-admin-ui"><a class="header" href="#accessing-the-admin-ui">Accessing the Admin UI</a></h2>
<p>The Admin UI is automatically available when you start MockForge with the <code>--admin</code> flag:</p>
<pre><code class="language-bash"># Start with Admin UI enabled
mockforge serve --spec api-spec.json --admin --admin-port 8080 --http-port 3000
</code></pre>
<p>The Admin UI will be available at: <strong>http://localhost:8080</strong> (default port)</p>
<h3 id="configuration-options"><a class="header" href="#configuration-options">Configuration Options</a></h3>
<pre><code class="language-bash"># Custom admin port
mockforge serve --admin --admin-port 9090

# Disable admin UI (default)
mockforge serve --spec api-spec.json --no-admin
</code></pre>
<h3 id="environment-variables-4"><a class="header" href="#environment-variables-4">Environment Variables</a></h3>
<pre><code class="language-bash"># Enable/disable admin UI
MOCKFORGE_ADMIN_ENABLED=true

# Set admin UI port
MOCKFORGE_ADMIN_PORT=8080

# Set admin UI bind address (default: 0.0.0.0)
MOCKFORGE_ADMIN_BIND=127.0.0.1
</code></pre>
<h2 id="interface-overview"><a class="header" href="#interface-overview">Interface Overview</a></h2>
<p>The Admin UI features a clean, modern interface with the following main sections:</p>
<h3 id="navigation-tabs"><a class="header" href="#navigation-tabs">Navigation Tabs</a></h3>
<ul>
<li><strong>Dashboard</strong> - System overview and real-time metrics</li>
<li><strong>Routes</strong> - API endpoint management and testing</li>
<li><strong>Fixtures</strong> - Recorded request/response management</li>
<li><strong>Logs</strong> - Request/response logging and debugging</li>
<li><strong>Configuration</strong> - Runtime configuration management</li>
<li><strong>Metrics</strong> - Performance monitoring and analytics</li>
<li><strong>Files</strong> - File system access for configuration files</li>
</ul>
<h3 id="status-indicators"><a class="header" href="#status-indicators">Status Indicators</a></h3>
<p>The header displays real-time system status:</p>
<ul>
<li><strong>● Healthy</strong> - All systems operational</li>
<li><strong>● Warning</strong> - Minor issues detected</li>
<li><strong>● Error</strong> - Critical issues requiring attention</li>
</ul>
<h2 id="dashboard"><a class="header" href="#dashboard">Dashboard</a></h2>
<p>The Dashboard provides a comprehensive overview of your MockForge instance:</p>
<h3 id="system-status"><a class="header" href="#system-status">System Status</a></h3>
<ul>
<li><strong>Uptime</strong> - How long the server has been running</li>
<li><strong>Memory Usage</strong> - Current memory consumption</li>
<li><strong>CPU Usage</strong> - Current CPU utilization</li>
<li><strong>Active Connections</strong> - Number of open connections</li>
</ul>
<h3 id="recent-activity"><a class="header" href="#recent-activity">Recent Activity</a></h3>
<ul>
<li><strong>Latest Requests</strong> - Most recent API calls with timestamps</li>
<li><strong>Response Times</strong> - Average response latency</li>
<li><strong>Error Rate</strong> - Percentage of failed requests</li>
</ul>
<h3 id="quick-actions"><a class="header" href="#quick-actions">Quick Actions</a></h3>
<ul>
<li><strong>Restart Server</strong> - Gracefully restart the mock server</li>
<li><strong>Clear Logs</strong> - Remove all accumulated logs</li>
<li><strong>Export Configuration</strong> - Download current config as YAML</li>
</ul>
<h2 id="routes-management"><a class="header" href="#routes-management">Routes Management</a></h2>
<p>The Routes tab provides detailed API endpoint management:</p>
<h3 id="route-listing"><a class="header" href="#route-listing">Route Listing</a></h3>
<ul>
<li>View all configured API routes</li>
<li>Filter by HTTP method, path pattern, or response status</li>
<li>Sort by request count, response time, or error rate</li>
</ul>
<h3 id="route-details"><a class="header" href="#route-details">Route Details</a></h3>
<p>For each route, view:</p>
<ul>
<li><strong>Request Count</strong> - Total requests served</li>
<li><strong>Average Response Time</strong> - Performance metrics</li>
<li><strong>Success/Error Rates</strong> - Reliability statistics</li>
<li><strong>Recent Requests</strong> - Last 10 requests with details</li>
</ul>
<h3 id="route-testing"><a class="header" href="#route-testing">Route Testing</a></h3>
<ul>
<li><strong>Interactive Tester</strong> - Send test requests directly from the UI</li>
<li><strong>Request Builder</strong> - Construct complex requests with headers, query params, and body</li>
<li><strong>Response Preview</strong> - See exactly what would be returned</li>
</ul>
<h3 id="route-overrides"><a class="header" href="#route-overrides">Route Overrides</a></h3>
<ul>
<li><strong>Temporary Overrides</strong> - Modify responses without changing configuration</li>
<li><strong>Conditional Responses</strong> - Set up A/B testing scenarios</li>
<li><strong>Failure Injection</strong> - Simulate errors for testing resilience</li>
</ul>
<h2 id="fixtures-management"><a class="header" href="#fixtures-management">Fixtures Management</a></h2>
<p>The Fixtures tab manages recorded request/response pairs:</p>
<h3 id="fixture-browser"><a class="header" href="#fixture-browser">Fixture Browser</a></h3>
<ul>
<li><strong>Search and Filter</strong> - Find fixtures by endpoint, method, or content</li>
<li><strong>Categorization</strong> - Group fixtures by API version or feature</li>
<li><strong>Tagging</strong> - Add custom tags for organization</li>
</ul>
<h3 id="fixture-operations"><a class="header" href="#fixture-operations">Fixture Operations</a></h3>
<ul>
<li><strong>View Details</strong> - Inspect request/response pairs in detail</li>
<li><strong>Edit Responses</strong> - Modify recorded responses</li>
<li><strong>Export/Import</strong> - Backup and restore fixture collections</li>
<li><strong>Bulk Operations</strong> - Apply changes to multiple fixtures</li>
</ul>
<h3 id="recording-controls"><a class="header" href="#recording-controls">Recording Controls</a></h3>
<ul>
<li><strong>Start/Stop Recording</strong> - Control when new fixtures are captured</li>
<li><strong>Recording Filters</strong> - Only record specific endpoints or request types</li>
<li><strong>Storage Management</strong> - Configure fixture retention and cleanup</li>
</ul>
<h2 id="logging-and-debugging"><a class="header" href="#logging-and-debugging">Logging and Debugging</a></h2>
<p>The Logs tab provides comprehensive request/response monitoring:</p>
<h3 id="log-viewer"><a class="header" href="#log-viewer">Log Viewer</a></h3>
<ul>
<li><strong>Real-time Updates</strong> - See requests as they happen</li>
<li><strong>Filtering Options</strong> - Filter by endpoint, status code, or time range</li>
<li><strong>Search Functionality</strong> - Find specific requests or responses</li>
</ul>
<h3 id="log-details"><a class="header" href="#log-details">Log Details</a></h3>
<p>For each log entry:</p>
<ul>
<li><strong>Full Request</strong> - Headers, body, and metadata</li>
<li><strong>Full Response</strong> - Status, headers, and body</li>
<li><strong>Timing Information</strong> - Request/response duration</li>
<li><strong>Error Details</strong> - Stack traces and error context</li>
</ul>
<h3 id="log-management"><a class="header" href="#log-management">Log Management</a></h3>
<ul>
<li><strong>Export Logs</strong> - Download logs in various formats</li>
<li><strong>Log Rotation</strong> - Automatic cleanup of old logs</li>
<li><strong>Log Levels</strong> - Adjust verbosity for debugging</li>
</ul>
<h2 id="configuration-management"><a class="header" href="#configuration-management">Configuration Management</a></h2>
<p>The Configuration tab allows runtime configuration changes:</p>
<h3 id="current-configuration"><a class="header" href="#current-configuration">Current Configuration</a></h3>
<ul>
<li><strong>View Active Config</strong> - See all current settings</li>
<li><strong>Configuration Sources</strong> - Understand precedence (CLI &gt; Env &gt; File)</li>
<li><strong>Validation Status</strong> - Check configuration validity</li>
</ul>
<h3 id="configuration-editor"><a class="header" href="#configuration-editor">Configuration Editor</a></h3>
<ul>
<li><strong>Live Editing</strong> - Modify settings without restart</li>
<li><strong>Validation</strong> - Real-time syntax and semantic validation</li>
<li><strong>Change History</strong> - Track configuration modifications</li>
</ul>
<h3 id="configuration-templates"><a class="header" href="#configuration-templates">Configuration Templates</a></h3>
<ul>
<li><strong>Save/Load Templates</strong> - Reuse common configurations</li>
<li><strong>Environment Profiles</strong> - Different configs for dev/staging/prod</li>
<li><strong>Backup/Restore</strong> - Version control for configurations</li>
</ul>
<h2 id="metrics-and-analytics"><a class="header" href="#metrics-and-analytics">Metrics and Analytics</a></h2>
<p>The Metrics tab provides detailed performance analytics:</p>
<h3 id="performance-metrics"><a class="header" href="#performance-metrics">Performance Metrics</a></h3>
<ul>
<li><strong>Response Time Distribution</strong> - P50, P95, P99 latencies</li>
<li><strong>Throughput</strong> - Requests per second over time</li>
<li><strong>Error Rate Trends</strong> - Track reliability over time</li>
</ul>
<h3 id="endpoint-analytics"><a class="header" href="#endpoint-analytics">Endpoint Analytics</a></h3>
<ul>
<li><strong>Top Endpoints</strong> - Most frequently called routes</li>
<li><strong>Slowest Endpoints</strong> - Performance bottlenecks</li>
<li><strong>Error-prone Endpoints</strong> - Routes with high failure rates</li>
</ul>
<h3 id="system-metrics"><a class="header" href="#system-metrics">System Metrics</a></h3>
<ul>
<li><strong>Resource Usage</strong> - CPU, memory, disk over time</li>
<li><strong>Connection Pool</strong> - Database connection utilization</li>
<li><strong>Cache Hit Rates</strong> - Effectiveness of response caching</li>
</ul>
<h2 id="file-system-access"><a class="header" href="#file-system-access">File System Access</a></h2>
<p>The Files tab provides access to configuration and data files:</p>
<h3 id="file-browser"><a class="header" href="#file-browser">File Browser</a></h3>
<ul>
<li><strong>Navigate Directory Structure</strong> - Browse the file system</li>
<li><strong>File Type Detection</strong> - Syntax highlighting for different file types</li>
<li><strong>Quick Access</strong> - Bookmarks for frequently used directories</li>
</ul>
<h3 id="file-editor"><a class="header" href="#file-editor">File Editor</a></h3>
<ul>
<li><strong>In-browser Editing</strong> - Edit configuration files directly</li>
<li><strong>Syntax Validation</strong> - Catch errors before saving</li>
<li><strong>Version Control Integration</strong> - Commit changes with Git</li>
</ul>
<h3 id="file-operations"><a class="header" href="#file-operations">File Operations</a></h3>
<ul>
<li><strong>Upload/Download</strong> - Transfer files to/from the server</li>
<li><strong>Backup Operations</strong> - Create and restore backups</li>
<li><strong>Permission Management</strong> - Control file access</li>
</ul>
<h2 id="advanced-features-3"><a class="header" href="#advanced-features-3">Advanced Features</a></h2>
<h3 id="auto-refresh"><a class="header" href="#auto-refresh">Auto-Refresh</a></h3>
<ul>
<li><strong>Configurable Intervals</strong> - Set refresh rates from 1 second to 5 minutes</li>
<li><strong>Smart Updates</strong> - Only refresh when data has changed</li>
<li><strong>Background Updates</strong> - Continue working while data refreshes</li>
</ul>
<h3 id="keyboard-shortcuts"><a class="header" href="#keyboard-shortcuts">Keyboard Shortcuts</a></h3>
<ul>
<li><strong>Navigation</strong> - Tab switching with keyboard shortcuts</li>
<li><strong>Actions</strong> - Quick access to common operations</li>
<li><strong>Search</strong> - Global search across all tabs</li>
</ul>
<h3 id="themes-and-customization"><a class="header" href="#themes-and-customization">Themes and Customization</a></h3>
<ul>
<li><strong>Light/Dark Mode</strong> - Choose your preferred theme</li>
<li><strong>Layout Options</strong> - Customize dashboard layout</li>
<li><strong>Color Schemes</strong> - Personalize the interface</li>
</ul>
<h2 id="security-considerations-2"><a class="header" href="#security-considerations-2">Security Considerations</a></h2>
<h3 id="access-control-1"><a class="header" href="#access-control-1">Access Control</a></h3>
<ul>
<li><strong>Authentication</strong> - Optional login requirements</li>
<li><strong>Authorization</strong> - Role-based access control</li>
<li><strong>IP Restrictions</strong> - Limit access to specific networks</li>
</ul>
<h3 id="data-protection"><a class="header" href="#data-protection">Data Protection</a></h3>
<ul>
<li><strong>Sensitive Data Masking</strong> - Hide passwords and tokens in logs</li>
<li><strong>Encryption</strong> - Secure data transmission</li>
<li><strong>Audit Logging</strong> - Track all administrative actions</li>
</ul>
<h2 id="troubleshooting-7"><a class="header" href="#troubleshooting-7">Troubleshooting</a></h2>
<h3 id="common-issues-4"><a class="header" href="#common-issues-4">Common Issues</a></h3>
<p><strong>Admin UI not loading</strong>: Check that <code>--admin</code> flag is used and port 8080 is accessible</p>
<p><strong>Slow performance</strong>: Reduce auto-refresh interval or disable real-time updates</p>
<p><strong>Missing data</strong>: Ensure proper permissions for file system access</p>
<p><strong>Configuration not applying</strong>: Some changes may require server restart</p>
<h3 id="debug-tools"><a class="header" href="#debug-tools">Debug Tools</a></h3>
<ul>
<li><strong>Network Inspector</strong> - Monitor all HTTP requests</li>
<li><strong>Console Logs</strong> - JavaScript debugging information</li>
<li><strong>Performance Profiler</strong> - Identify UI performance bottlenecks</li>
</ul>
<h3 id="getting-help"><a class="header" href="#getting-help">Getting Help</a></h3>
<ul>
<li><strong>Built-in Help</strong> - Press <code>?</code> for keyboard shortcuts</li>
<li><strong>Tooltips</strong> - Hover over UI elements for explanations</li>
<li><strong>Context Help</strong> - Right-click for contextual help menus</li>
</ul>
<p>The Admin UI transforms MockForge from a simple mock server into a powerful development and testing platform, providing the visibility and control needed for professional API mocking workflows.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="environment-variables-5"><a class="header" href="#environment-variables-5">Environment Variables</a></h1>
<p>MockForge supports extensive configuration through environment variables. This page documents all available environment variables, their purposes, and usage examples.</p>
<h2 id="core-functionality"><a class="header" href="#core-functionality">Core Functionality</a></h2>
<h3 id="server-control"><a class="header" href="#server-control">Server Control</a></h3>
<ul>
<li>
<p><code>MOCKFORGE_LATENCY_ENABLED=true|false</code> (default: <code>true</code>)</p>
<ul>
<li>Enable/disable response latency simulation</li>
<li>When disabled, responses are immediate</li>
</ul>
</li>
<li>
<p><code>MOCKFORGE_FAILURES_ENABLED=true|false</code> (default: <code>false</code>)</p>
<ul>
<li>Enable/disable failure injection</li>
<li>When enabled, can simulate HTTP errors and timeouts</li>
</ul>
</li>
<li>
<p><code>MOCKFORGE_LOG_LEVEL=debug|info|warn|error</code> (default: <code>info</code>)</p>
<ul>
<li>Set the logging verbosity level</li>
<li>Available: <code>debug</code>, <code>info</code>, <code>warn</code>, <code>error</code></li>
</ul>
</li>
</ul>
<h3 id="recording-and-replay"><a class="header" href="#recording-and-replay">Recording and Replay</a></h3>
<ul>
<li>
<p><code>MOCKFORGE_RECORD_ENABLED=true|false</code> (default: <code>false</code>)</p>
<ul>
<li>Enable recording of HTTP requests as fixtures</li>
<li>Recorded fixtures can be replayed later</li>
</ul>
</li>
<li>
<p><code>MOCKFORGE_REPLAY_ENABLED=true|false</code> (default: <code>false</code>)</p>
<ul>
<li>Enable replay of recorded fixtures</li>
<li>When enabled, serves recorded responses instead of generating new ones</li>
</ul>
</li>
<li>
<p><code>MOCKFORGE_PROXY_ENABLED=true|false</code> (default: <code>false</code>)</p>
<ul>
<li>Enable proxy mode for forwarding requests</li>
<li>Useful for testing against real APIs</li>
</ul>
</li>
</ul>
<h2 id="http-server-configuration"><a class="header" href="#http-server-configuration">HTTP Server Configuration</a></h2>
<h3 id="server-settings"><a class="header" href="#server-settings">Server Settings</a></h3>
<ul>
<li>
<p><code>MOCKFORGE_HTTP_PORT=3000</code> (default: <code>3000</code>)</p>
<ul>
<li>Port for the HTTP server to listen on</li>
</ul>
</li>
<li>
<p><code>MOCKFORGE_HTTP_HOST=127.0.0.1</code> (default: <code>0.0.0.0</code>)</p>
<ul>
<li>Host address for the HTTP server to bind to</li>
</ul>
</li>
<li>
<p><code>MOCKFORGE_CORS_ENABLED=true|false</code> (default: <code>true</code>)</p>
<ul>
<li>Enable/disable CORS headers in responses</li>
</ul>
</li>
<li>
<p><code>MOCKFORGE_REQUEST_TIMEOUT_SECS=30</code> (default: <code>30</code>)</p>
<ul>
<li>Timeout for HTTP requests in seconds</li>
</ul>
</li>
</ul>
<h3 id="openapi-integration-2"><a class="header" href="#openapi-integration-2">OpenAPI Integration</a></h3>
<ul>
<li><code>MOCKFORGE_HTTP_OPENAPI_SPEC=path/to/spec.json</code>
<ul>
<li>Path to OpenAPI specification file</li>
<li>Enables automatic endpoint generation from OpenAPI spec</li>
</ul>
</li>
</ul>
<h3 id="validation-and-templating"><a class="header" href="#validation-and-templating">Validation and Templating</a></h3>
<ul>
<li>
<p><code>MOCKFORGE_REQUEST_VALIDATION=enforce|warn|off</code> (default: <code>enforce</code>)</p>
<ul>
<li>Level of request validation</li>
<li><code>enforce</code>: Reject invalid requests with error</li>
<li><code>warn</code>: Log warnings but allow requests</li>
<li><code>off</code>: Skip validation entirely</li>
</ul>
</li>
<li>
<p><code>MOCKFORGE_RESPONSE_VALIDATION=true|false</code> (default: <code>false</code>)</p>
<ul>
<li>Enable validation of generated responses</li>
<li>Useful for ensuring response format compliance</li>
</ul>
</li>
<li>
<p><code>MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true|false</code> (default: <code>false</code>)</p>
<ul>
<li>Enable template expansion in responses</li>
<li>Allows use of <code>{{uuid}}</code>, <code>{{now}}</code>, etc. in responses</li>
</ul>
</li>
<li>
<p><code>MOCKFORGE_AGGREGATE_ERRORS=true|false</code> (default: <code>true</code>)</p>
<ul>
<li>Aggregate multiple validation errors into a single response</li>
<li>When enabled, returns all validation errors at once</li>
</ul>
</li>
<li>
<p><code>MOCKFORGE_VALIDATION_STATUS=400|422</code> (default: <code>400</code>)</p>
<ul>
<li>HTTP status code for validation errors</li>
<li><code>400</code>: Bad Request (general)</li>
<li><code>422</code>: Unprocessable Entity (validation-specific)</li>
</ul>
</li>
</ul>
<h2 id="websocket-server-configuration"><a class="header" href="#websocket-server-configuration">WebSocket Server Configuration</a></h2>
<h3 id="server-settings-1"><a class="header" href="#server-settings-1">Server Settings</a></h3>
<ul>
<li>
<p><code>MOCKFORGE_WS_PORT=3001</code> (default: <code>3001</code>)</p>
<ul>
<li>Port for the WebSocket server to listen on</li>
</ul>
</li>
<li>
<p><code>MOCKFORGE_WS_HOST=127.0.0.1</code> (default: <code>0.0.0.0</code>)</p>
<ul>
<li>Host address for the WebSocket server to bind to</li>
</ul>
</li>
<li>
<p><code>MOCKFORGE_WS_CONNECTION_TIMEOUT_SECS=300</code> (default: <code>300</code>)</p>
<ul>
<li>WebSocket connection timeout in seconds</li>
</ul>
</li>
</ul>
<h3 id="replay-configuration"><a class="header" href="#replay-configuration">Replay Configuration</a></h3>
<ul>
<li><code>MOCKFORGE_WS_REPLAY_FILE=path/to/replay.jsonl</code>
<ul>
<li>Path to WebSocket replay file</li>
<li>Enables scripted WebSocket message sequences</li>
</ul>
</li>
</ul>
<h2 id="grpc-server-configuration"><a class="header" href="#grpc-server-configuration">gRPC Server Configuration</a></h2>
<h3 id="server-settings-2"><a class="header" href="#server-settings-2">Server Settings</a></h3>
<ul>
<li>
<p><code>MOCKFORGE_GRPC_PORT=50051</code> (default: <code>50051</code>)</p>
<ul>
<li>Port for the gRPC server to listen on</li>
</ul>
</li>
<li>
<p><code>MOCKFORGE_GRPC_HOST=127.0.0.1</code> (default: <code>0.0.0.0</code>)</p>
<ul>
<li>Host address for the gRPC server to bind to</li>
</ul>
</li>
</ul>
<h2 id="admin-ui-configuration"><a class="header" href="#admin-ui-configuration">Admin UI Configuration</a></h2>
<h3 id="server-settings-3"><a class="header" href="#server-settings-3">Server Settings</a></h3>
<ul>
<li>
<p><code>MOCKFORGE_ADMIN_ENABLED=true|false</code> (default: <code>false</code>)</p>
<ul>
<li>Enable/disable the Admin UI</li>
<li>When enabled, provides web interface for management</li>
</ul>
</li>
<li>
<p><code>MOCKFORGE_ADMIN_PORT=8080</code> (default: <code>8080</code>)</p>
<ul>
<li>Port for the Admin UI server to listen on</li>
</ul>
</li>
<li>
<p><code>MOCKFORGE_ADMIN_HOST=127.0.0.1</code> (default: <code>127.0.0.1</code>)</p>
<ul>
<li>Host address for the Admin UI server to bind to</li>
</ul>
</li>
</ul>
<h3 id="ui-configuration"><a class="header" href="#ui-configuration">UI Configuration</a></h3>
<ul>
<li>
<p><code>MOCKFORGE_ADMIN_MOUNT_PATH=/admin</code> (default: none)</p>
<ul>
<li>Mount path for embedded Admin UI</li>
<li>When set, Admin UI is available under HTTP server</li>
</ul>
</li>
<li>
<p><code>MOCKFORGE_ADMIN_API_ENABLED=true|false</code> (default: <code>true</code>)</p>
<ul>
<li>Enable/disable Admin UI API endpoints</li>
<li>Controls whether <code>/__mockforge/*</code> endpoints are available</li>
</ul>
</li>
</ul>
<h2 id="data-generation-configuration"><a class="header" href="#data-generation-configuration">Data Generation Configuration</a></h2>
<h3 id="faker-control"><a class="header" href="#faker-control">Faker Control</a></h3>
<ul>
<li>
<p><code>MOCKFORGE_RAG_ENABLED=true|false</code> (default: <code>false</code>)</p>
<ul>
<li>Enable Retrieval-Augmented Generation for data</li>
<li>Requires additional setup for LLM integration</li>
</ul>
</li>
<li>
<p><code>MOCKFORGE_FAKE_TOKENS=true|false</code> (default: <code>true</code>)</p>
<ul>
<li>Enable/disable faker token expansion</li>
<li>Controls whether <code>{{faker.email}}</code> etc. work</li>
</ul>
</li>
</ul>
<h2 id="fixtures-and-testing"><a class="header" href="#fixtures-and-testing">Fixtures and Testing</a></h2>
<h3 id="fixtures-configuration"><a class="header" href="#fixtures-configuration">Fixtures Configuration</a></h3>
<ul>
<li>
<p><code>MOCKFORGE_FIXTURES_DIR=path/to/fixtures</code> (default: <code>./fixtures</code>)</p>
<ul>
<li>Directory where fixtures are stored</li>
<li>Used for recording and replaying HTTP requests</li>
</ul>
</li>
<li>
<p><code>MOCKFORGE_RECORD_GET_ONLY=true|false</code> (default: <code>false</code>)</p>
<ul>
<li>When recording, only record GET requests</li>
<li>Reduces fixture file size for read-only APIs</li>
</ul>
</li>
</ul>
<h2 id="configuration-files"><a class="header" href="#configuration-files">Configuration Files</a></h2>
<h3 id="configuration-loading"><a class="header" href="#configuration-loading">Configuration Loading</a></h3>
<ul>
<li><code>MOCKFORGE_CONFIG_FILE=path/to/config.yaml</code>
<ul>
<li>Path to YAML configuration file</li>
<li>Alternative to environment variables</li>
</ul>
</li>
</ul>
<h2 id="usage-examples"><a class="header" href="#usage-examples">Usage Examples</a></h2>
<h3 id="basic-http-server-with-openapi"><a class="header" href="#basic-http-server-with-openapi">Basic HTTP Server with OpenAPI</a></h3>
<pre><code class="language-bash">export MOCKFORGE_HTTP_OPENAPI_SPEC=examples/openapi-demo.json
export MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true
export MOCKFORGE_ADMIN_ENABLED=true
cargo run -p mockforge-cli -- serve --http-port 3000 --admin-port 8080
</code></pre>
<h3 id="full-websocket-support"><a class="header" href="#full-websocket-support">Full WebSocket Support</a></h3>
<pre><code class="language-bash">export MOCKFORGE_WS_REPLAY_FILE=examples/ws-demo.jsonl
export MOCKFORGE_WS_PORT=3001
export MOCKFORGE_HTTP_OPENAPI_SPEC=examples/openapi-demo.json
export MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true
cargo run -p mockforge-cli -- serve --admin
</code></pre>
<h3 id="development-setup"><a class="header" href="#development-setup">Development Setup</a></h3>
<pre><code class="language-bash">export MOCKFORGE_LOG_LEVEL=debug
export MOCKFORGE_LATENCY_ENABLED=false
export MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true
export MOCKFORGE_ADMIN_ENABLED=true
export MOCKFORGE_HTTP_OPENAPI_SPEC=examples/openapi-demo.json
cargo run -p mockforge-cli -- serve
</code></pre>
<h3 id="production-setup"><a class="header" href="#production-setup">Production Setup</a></h3>
<pre><code class="language-bash">export MOCKFORGE_LOG_LEVEL=warn
export MOCKFORGE_LATENCY_ENABLED=true
export MOCKFORGE_FAILURES_ENABLED=false
export MOCKFORGE_REQUEST_VALIDATION=enforce
export MOCKFORGE_ADMIN_ENABLED=false
export MOCKFORGE_HTTP_OPENAPI_SPEC=path/to/production-spec.json
cargo run -p mockforge-cli -- serve --http-port 80
</code></pre>
<h2 id="environment-variable-priority"><a class="header" href="#environment-variable-priority">Environment Variable Priority</a></h2>
<p>Environment variables override configuration file settings. CLI flags take precedence over both. The priority order is:</p>
<ol>
<li>CLI flags (highest priority)</li>
<li>Environment variables</li>
<li>Configuration file settings</li>
<li>Default values (lowest priority)</li>
</ol>
<h2 id="security-considerations-3"><a class="header" href="#security-considerations-3">Security Considerations</a></h2>
<ul>
<li>Be careful with <code>MOCKFORGE_ADMIN_ENABLED=true</code> in production</li>
<li>Consider setting restrictive host bindings (<code>127.0.0.1</code>) for internal use</li>
<li>Use <code>MOCKFORGE_FAKE_TOKENS=false</code> for deterministic testing</li>
<li>Review <code>MOCKFORGE_CORS_ENABLED</code> settings for cross-origin requests</li>
</ul>
<h2 id="troubleshooting-8"><a class="header" href="#troubleshooting-8">Troubleshooting</a></h2>
<h3 id="common-issues-5"><a class="header" href="#common-issues-5">Common Issues</a></h3>
<ol>
<li>
<p><strong>Environment variables not taking effect</strong></p>
<ul>
<li>Check variable names for typos</li>
<li>Ensure variables are exported before running the command</li>
<li>Use <code>env | grep MOCKFORGE</code> to verify variables are set</li>
</ul>
</li>
<li>
<p><strong>Port conflicts</strong></p>
<ul>
<li>Use different ports via <code>MOCKFORGE_HTTP_PORT</code>, <code>MOCKFORGE_WS_PORT</code>, etc.</li>
<li>Check what processes are using ports with <code>netstat -tlnp</code></li>
</ul>
</li>
<li>
<p><strong>OpenAPI spec not loading</strong></p>
<ul>
<li>Verify file path in <code>MOCKFORGE_HTTP_OPENAPI_SPEC</code></li>
<li>Ensure JSON/YAML syntax is valid</li>
<li>Check file permissions</li>
</ul>
</li>
<li>
<p><strong>Template expansion not working</strong></p>
<ul>
<li>Set <code>MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true</code></li>
<li>Verify token syntax (e.g., <code>{{uuid}}</code> not <code>{uuid}</code>)</li>
</ul>
</li>
</ol>
<p>For more detailed configuration options, see the <a href="configuration/files.html">Configuration Files</a> documentation.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="configuration-files-1"><a class="header" href="#configuration-files-1">Configuration Files</a></h1>
<p>MockForge supports comprehensive configuration through YAML files as an alternative to environment variables. This page documents the configuration file format, options, and usage.</p>
<h2 id="configuration-file-location"><a class="header" href="#configuration-file-location">Configuration File Location</a></h2>
<p>MockForge looks for configuration files in the following order:</p>
<ol>
<li>Path specified by <code>--config</code> CLI flag</li>
<li>Path specified by <code>MOCKFORGE_CONFIG_FILE</code> environment variable</li>
<li>Default location: <code>./mockforge.yaml</code> or <code>./mockforge.yml</code></li>
<li>No configuration file (uses defaults)</li>
</ol>
<h2 id="basic-configuration-structure"><a class="header" href="#basic-configuration-structure">Basic Configuration Structure</a></h2>
<pre><code class="language-yaml"># MockForge Configuration Example
# This file demonstrates all available configuration options

# HTTP server configuration
http:
  port: 3000
  host: "0.0.0.0"
  openapi_spec: "examples/openapi-demo.json"
  cors_enabled: true
  request_timeout_secs: 30
  request_validation: "enforce"
  aggregate_validation_errors: true
  validate_responses: false
  response_template_expand: true
  skip_admin_validation: true

# WebSocket server configuration
websocket:
  port: 3001
  host: "0.0.0.0"
  replay_file: "examples/ws-demo.jsonl"
  connection_timeout_secs: 300

# gRPC server configuration
grpc:
  port: 50051
  host: "0.0.0.0"

# Admin UI configuration
admin:
  enabled: true
  port: 8080
  host: "127.0.0.1"
  mount_path: null
  api_enabled: true

# Core MockForge configuration
core:
  latency_enabled: true
  failures_enabled: false

# Logging configuration
logging:
  level: "info"
  json_format: false
  file_path: null
  max_file_size_mb: 10
  max_files: 5

# Data generation configuration
data:
  default_rows: 100
  default_format: "json"
  locale: "en"
</code></pre>
<h2 id="http-server-configuration-1"><a class="header" href="#http-server-configuration-1">HTTP Server Configuration</a></h2>
<h3 id="basic-settings"><a class="header" href="#basic-settings">Basic Settings</a></h3>
<pre><code class="language-yaml">http:
  port: 3000                    # Server port
  host: "0.0.0.0"              # Bind address (0.0.0.0 for all interfaces)
  cors_enabled: true           # Enable CORS headers
  request_timeout_secs: 30     # Request timeout in seconds
</code></pre>
<h3 id="openapi-integration-3"><a class="header" href="#openapi-integration-3">OpenAPI Integration</a></h3>
<pre><code class="language-yaml">http:
  openapi_spec: "path/to/spec.json"  # Path to OpenAPI specification
  # Alternative: use URL
  openapi_spec: "https://example.com/api-spec.yaml"
</code></pre>
<h3 id="validation-and-response-handling"><a class="header" href="#validation-and-response-handling">Validation and Response Handling</a></h3>
<pre><code class="language-yaml">http:
  request_validation: "enforce"      # off|warn|enforce
  aggregate_validation_errors: true  # Combine multiple errors
  validate_responses: false          # Validate generated responses
  response_template_expand: true     # Enable {{uuid}}, {{now}} etc.
  skip_admin_validation: true        # Skip validation for admin endpoints
</code></pre>
<h3 id="validation-overrides"><a class="header" href="#validation-overrides">Validation Overrides</a></h3>
<pre><code class="language-yaml">http:
  validation_overrides:
    "POST /users/{id}": "warn"      # Override validation level per endpoint
    "GET /internal/health": "off"  # Skip validation for specific endpoints
</code></pre>
<h2 id="websocket-server-configuration-1"><a class="header" href="#websocket-server-configuration-1">WebSocket Server Configuration</a></h2>
<pre><code class="language-yaml">websocket:
  port: 3001                          # Server port
  host: "0.0.0.0"                    # Bind address
  replay_file: "path/to/replay.jsonl" # WebSocket replay file
  connection_timeout_secs: 300       # Connection timeout in seconds
</code></pre>
<h2 id="grpc-server-configuration-1"><a class="header" href="#grpc-server-configuration-1">gRPC Server Configuration</a></h2>
<pre><code class="language-yaml">grpc:
  port: 50051       # Server port
  host: "0.0.0.0"  # Bind address
  proto_dir: null  # Directory containing .proto files
  tls: null        # TLS configuration (optional)
</code></pre>
<h2 id="admin-ui-configuration-1"><a class="header" href="#admin-ui-configuration-1">Admin UI Configuration</a></h2>
<h3 id="standalone-mode-default"><a class="header" href="#standalone-mode-default">Standalone Mode (Default)</a></h3>
<pre><code class="language-yaml">admin:
  enabled: true
  port: 8080
  host: "127.0.0.1"
  api_enabled: true
</code></pre>
<h3 id="embedded-mode"><a class="header" href="#embedded-mode">Embedded Mode</a></h3>
<pre><code class="language-yaml">admin:
  enabled: true
  mount_path: "/admin"  # Mount under HTTP server
  api_enabled: true     # Enable API endpoints
  # Note: port/host ignored when mount_path is set
</code></pre>
<h2 id="core-configuration"><a class="header" href="#core-configuration">Core Configuration</a></h2>
<h3 id="latency-simulation"><a class="header" href="#latency-simulation">Latency Simulation</a></h3>
<pre><code class="language-yaml">core:
  latency_enabled: true
  default_latency:
    base_ms: 50
    jitter_ms: 20
    distribution: "fixed"  # fixed, normal, or pareto

  # For normal distribution
  # std_dev_ms: 10.0

  # For pareto distribution
  # pareto_shape: 2.0

  min_ms: 10      # Minimum latency
  max_ms: 5000    # Maximum latency (optional)

  # Per-operation overrides
  tag_overrides:
    auth: 100
    payments: 200
</code></pre>
<h3 id="failure-injection-1"><a class="header" href="#failure-injection-1">Failure Injection</a></h3>
<pre><code class="language-yaml">core:
  failures_enabled: true
  failure_config:
    global_error_rate: 0.05  # 5% global error rate

    # Default status codes for failures
    default_status_codes: [500, 502, 503, 504]

    # Per-tag error rates and status codes
    tag_configs:
      auth:
        error_rate: 0.1      # 10% error rate for auth operations
        status_codes: [401, 403]
        error_message: "Authentication failed"
      payments:
        error_rate: 0.02     # 2% error rate for payments
        status_codes: [402, 503]
        error_message: "Payment processing failed"

    # Tag filtering
    include_tags: []         # Empty means all tags included
    exclude_tags: ["health", "metrics"]  # Exclude these tags
</code></pre>
<h3 id="proxy-configuration"><a class="header" href="#proxy-configuration">Proxy Configuration</a></h3>
<pre><code class="language-yaml">core:
  proxy:
    upstream_url: "http://api.example.com"
    timeout_seconds: 30
</code></pre>
<h2 id="logging-configuration"><a class="header" href="#logging-configuration">Logging Configuration</a></h2>
<pre><code class="language-yaml">logging:
  level: "info"           # debug|info|warn|error
  json_format: false      # Use JSON format for logs
  file_path: "logs/mockforge.log"  # Optional log file
  max_file_size_mb: 10    # Rotate when file reaches this size
  max_files: 5           # Keep this many rotated log files
</code></pre>
<h2 id="data-generation-configuration-1"><a class="header" href="#data-generation-configuration-1">Data Generation Configuration</a></h2>
<pre><code class="language-yaml">data:
  default_rows: 100       # Default number of rows to generate
  default_format: "json"  # Default output format
  locale: "en"           # Locale for generated data

  # Custom faker templates
  templates:
    custom_user:
      name: "{{faker.name}}"
      email: "{{faker.email}}"
      department: "{{faker.word}}"

  # RAG (Retrieval-Augmented Generation) configuration
  rag:
    enabled: false
    api_endpoint: null
    api_key: null
    model: null
    context_window: 4000
</code></pre>
<h2 id="advanced-configuration-1"><a class="header" href="#advanced-configuration-1">Advanced Configuration</a></h2>
<h3 id="requestresponse-overrides"><a class="header" href="#requestresponse-overrides">Request/Response Overrides</a></h3>
<pre><code class="language-yaml"># YAML patch overrides for requests/responses
overrides:
  - targets: ["operation:getUser"]     # Target specific operations
    patch:
      - op: add
        path: /metadata/requestId
        value: "{{uuid}}"
      - op: replace
        path: /user/createdAt
        value: "{{now}}"
      - op: add
        path: /user/score
        value: "{{rand.float}}"

  - targets: ["tag:Payments"]          # Target by tags
    patch:
      - op: replace
        path: /payment/status
        value: "FAILED"
</code></pre>
<h3 id="latency-profiles"><a class="header" href="#latency-profiles">Latency Profiles</a></h3>
<pre><code class="language-yaml"># External latency profiles file
latency_profiles: "config/latency.yaml"

# Example latency configuration:
# operation:getUser:
#   fixed_ms: 120
#   jitter_ms: 80
#   fail_p: 0.0
#
# tag:Payments:
#   fixed_ms: 200
#   jitter_ms: 300
#   fail_p: 0.05
#   fail_status: 503
</code></pre>
<h2 id="configuration-examples"><a class="header" href="#configuration-examples">Configuration Examples</a></h2>
<h3 id="development-configuration"><a class="header" href="#development-configuration">Development Configuration</a></h3>
<pre><code class="language-yaml"># Development setup with debugging and fast responses
http:
  port: 3000
  response_template_expand: true
  request_validation: "warn"

admin:
  enabled: true
  port: 8080

core:
  latency_enabled: false  # Disable latency for faster development

logging:
  level: "debug"
  json_format: false
</code></pre>
<h3 id="testing-configuration"><a class="header" href="#testing-configuration">Testing Configuration</a></h3>
<pre><code class="language-yaml"># Testing setup with deterministic responses
http:
  port: 3000
  response_template_expand: false  # Disable random tokens for determinism

core:
  latency_enabled: false

data:
  rag:
    enabled: false  # Disable RAG for consistent test data
</code></pre>
<h3 id="production-configuration"><a class="header" href="#production-configuration">Production Configuration</a></h3>
<pre><code class="language-yaml"># Production setup with monitoring and reliability
http:
  port: 80
  host: "0.0.0.0"
  request_validation: "enforce"
  cors_enabled: false

admin:
  enabled: false  # Disable admin UI in production

core:
  latency_enabled: true
  failures_enabled: false

logging:
  level: "warn"
  json_format: true
  file_path: "/var/log/mockforge.log"
</code></pre>
<h2 id="configuration-file-validation"><a class="header" href="#configuration-file-validation">Configuration File Validation</a></h2>
<p>MockForge validates configuration files at startup. Common issues:</p>
<ol>
<li><strong>Invalid YAML syntax</strong> - Check indentation and quotes</li>
<li><strong>Missing required fields</strong> - Some fields like <code>request_timeout_secs</code> are required</li>
<li><strong>Invalid file paths</strong> - Ensure OpenAPI spec and replay files exist</li>
<li><strong>Port conflicts</strong> - Choose unique ports for each service</li>
</ol>
<h2 id="configuration-precedence"><a class="header" href="#configuration-precedence">Configuration Precedence</a></h2>
<p>Configuration values are resolved in this priority order:</p>
<ol>
<li><strong>CLI flags</strong> (highest priority)</li>
<li><strong>Environment variables</strong></li>
<li><strong>Configuration file</strong></li>
<li><strong>Default values</strong> (lowest priority)</li>
</ol>
<p>This allows you to override specific values without changing your configuration file.</p>
<h2 id="hot-reloading"><a class="header" href="#hot-reloading">Hot Reloading</a></h2>
<p>Configuration changes require a server restart to take effect. For development, you can use:</p>
<pre><code class="language-bash"># Watch for changes and auto-restart
cargo watch -x "run -p mockforge-cli -- serve --config config.yaml"
</code></pre>
<p>For more information on environment variables, see the <a href="configuration/environment.html">Environment Variables</a> documentation.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="advanced-options"><a class="header" href="#advanced-options">Advanced Options</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="building-from-source"><a class="header" href="#building-from-source">Building from Source</a></h1>
<p>This guide covers building MockForge from source code, including prerequisites, build processes, and troubleshooting common build issues.</p>
<h2 id="prerequisites-2"><a class="header" href="#prerequisites-2">Prerequisites</a></h2>
<p>Before building MockForge, ensure you have the required development tools installed.</p>
<h3 id="system-requirements"><a class="header" href="#system-requirements">System Requirements</a></h3>
<ul>
<li><strong>Rust</strong>: Version 1.70.0 or later</li>
<li><strong>Cargo</strong>: Included with Rust</li>
<li><strong>Git</strong>: For cloning the repository</li>
<li><strong>C/C++ Compiler</strong>: For native dependencies</li>
</ul>
<h3 id="platform-specific-requirements"><a class="header" href="#platform-specific-requirements">Platform-Specific Requirements</a></h3>
<h4 id="linux-ubuntudebian"><a class="header" href="#linux-ubuntudebian">Linux (Ubuntu/Debian)</a></h4>
<pre><code class="language-bash"># Install build essentials
sudo apt update
sudo apt install build-essential pkg-config libssl-dev

# Install Rust (if not already installed)
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
source $HOME/.cargo/env
</code></pre>
<h4 id="macos"><a class="header" href="#macos">macOS</a></h4>
<pre><code class="language-bash"># Install Xcode command line tools
xcode-select --install

# Install Homebrew (optional, for additional tools)
# /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

# Install Rust
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
source $HOME/.cargo/env
</code></pre>
<h4 id="windows"><a class="header" href="#windows">Windows</a></h4>
<pre><code class="language-powershell"># Install Visual Studio Build Tools
# Download from: https://visualstudio.microsoft.com/visual-cpp-build-tools/

# Install Rust
# Download from: https://rustup.rs/
# Or use winget: winget install --id Rustlang.Rustup
</code></pre>
<h3 id="rust-setup-verification"><a class="header" href="#rust-setup-verification">Rust Setup Verification</a></h3>
<pre><code class="language-bash"># Verify Rust installation
rustc --version
cargo --version

# Update to latest stable
rustup update stable
</code></pre>
<h2 id="cloning-the-repository"><a class="header" href="#cloning-the-repository">Cloning the Repository</a></h2>
<pre><code class="language-bash"># Clone the repository
git clone https://github.com/SaaSy-Solutions/mockforge.git
cd mockforge

# Initialize submodules (if any)
git submodule update --init --recursive
</code></pre>
<h2 id="build-process"><a class="header" href="#build-process">Build Process</a></h2>
<h3 id="basic-build"><a class="header" href="#basic-build">Basic Build</a></h3>
<pre><code class="language-bash"># Build all crates in debug mode (default)
cargo build

# Build in release mode for production
cargo build --release

# Build specific crate
cargo build -p mockforge-cli
</code></pre>
<h3 id="build-outputs"><a class="header" href="#build-outputs">Build Outputs</a></h3>
<p>After building, binaries are available in:</p>
<pre><code class="language-bash"># Debug builds
target/debug/mockforge-cli

# Release builds
target/release/mockforge-cli
</code></pre>
<h3 id="build-features"><a class="header" href="#build-features">Build Features</a></h3>
<p>MockForge supports conditional compilation features:</p>
<pre><code class="language-bash"># Build with all features enabled
cargo build --all-features

# Build with specific features
cargo build --features "grpc,websocket"

# List available features
cargo metadata --format-version 1 | jq '.packages[] | select(.name == "mockforge-cli") | .features'
</code></pre>
<h2 id="development-workflow"><a class="header" href="#development-workflow">Development Workflow</a></h2>
<h3 id="development-builds"><a class="header" href="#development-builds">Development Builds</a></h3>
<pre><code class="language-bash"># Quick development builds
cargo build

# Run tests during development
cargo test

# Run specific tests
cargo test --package mockforge-core --lib
</code></pre>
<h3 id="watch-mode-development"><a class="header" href="#watch-mode-development">Watch Mode Development</a></h3>
<pre><code class="language-bash"># Install cargo-watch for automatic rebuilds
cargo install cargo-watch

# Watch for changes and rebuild
cargo watch -x build

# Watch and run tests
cargo watch -x test

# Watch and run specific binary
cargo watch -x "run --bin mockforge-cli -- --help"
</code></pre>
<h3 id="ide-setup"><a class="header" href="#ide-setup">IDE Setup</a></h3>
<h4 id="vs-code"><a class="header" href="#vs-code">VS Code</a></h4>
<p>Install recommended extensions:</p>
<ul>
<li><code>rust-lang.rust-analyzer</code></li>
<li><code>ms-vscode.vscode-json</code></li>
<li><code>redhat.vscode-yaml</code></li>
</ul>
<h4 id="intellijclion"><a class="header" href="#intellijclion">IntelliJ/CLion</a></h4>
<p>Install Rust plugin through marketplace.</p>
<h3 id="debugging-1"><a class="header" href="#debugging-1">Debugging</a></h3>
<pre><code class="language-bash"># Build with debug symbols
cargo build

# Run with debugger
rust-gdb target/debug/mockforge-cli

# Or use lldb on macOS
rust-lldb target/debug/mockforge-cli
</code></pre>
<h2 id="advanced-build-options"><a class="header" href="#advanced-build-options">Advanced Build Options</a></h2>
<h3 id="cross-compilation"><a class="header" href="#cross-compilation">Cross-Compilation</a></h3>
<pre><code class="language-bash"># Install cross-compilation targets
rustup target add x86_64-unknown-linux-musl
rustup target add aarch64-unknown-linux-gnu

# Build for different architectures
cargo build --target x86_64-unknown-linux-musl
cargo build --target aarch64-unknown-linux-gnu
</code></pre>
<h3 id="custom-linker"><a class="header" href="#custom-linker">Custom Linker</a></h3>
<pre><code class="language-bash"># Use mold linker for faster linking (Linux)
sudo apt install mold
export RUSTFLAGS="-C link-arg=-fuse-ld=mold"
cargo build
</code></pre>
<h3 id="build-caching"><a class="header" href="#build-caching">Build Caching</a></h3>
<pre><code class="language-bash"># Use sccache for faster rebuilds
cargo install sccache
export RUSTC_WRAPPER=sccache
cargo build
</code></pre>
<h2 id="testing"><a class="header" href="#testing">Testing</a></h2>
<h3 id="running-tests"><a class="header" href="#running-tests">Running Tests</a></h3>
<pre><code class="language-bash"># Run all tests
cargo test

# Run tests with output
cargo test -- --nocapture

# Run specific test
cargo test test_name

# Run tests for specific package
cargo test -p mockforge-core

# Run integration tests
cargo test --test integration

# Run with release optimizations
cargo test --release
</code></pre>
<h3 id="test-coverage"><a class="header" href="#test-coverage">Test Coverage</a></h3>
<pre><code class="language-bash"># Install cargo-tarpaulin
cargo install cargo-tarpaulin

# Generate coverage report
cargo tarpaulin --out Html

# Open coverage report
open tarpaulin-report.html
</code></pre>
<h3 id="benchmarking"><a class="header" href="#benchmarking">Benchmarking</a></h3>
<pre><code class="language-bash"># Run benchmarks
cargo bench

# Run specific benchmark
cargo bench benchmark_name
</code></pre>
<h2 id="code-quality"><a class="header" href="#code-quality">Code Quality</a></h2>
<h3 id="linting"><a class="header" href="#linting">Linting</a></h3>
<pre><code class="language-bash"># Run clippy lints
cargo clippy

# Run with pedantic mode
cargo clippy -- -W clippy::pedantic

# Auto-fix some issues
cargo clippy --fix
</code></pre>
<h3 id="formatting"><a class="header" href="#formatting">Formatting</a></h3>
<pre><code class="language-bash"># Check code formatting
cargo fmt --check

# Auto-format code
cargo fmt
</code></pre>
<h3 id="security-auditing"><a class="header" href="#security-auditing">Security Auditing</a></h3>
<pre><code class="language-bash"># Install cargo-audit
cargo install cargo-audit

# Audit dependencies for security vulnerabilities
cargo audit
</code></pre>
<h2 id="documentation-1"><a class="header" href="#documentation-1">Documentation</a></h2>
<h3 id="building-documentation"><a class="header" href="#building-documentation">Building Documentation</a></h3>
<pre><code class="language-bash"># Build API documentation
cargo doc

# Open documentation in browser
cargo doc --open

# Build documentation with private items
cargo doc --document-private-items

# Build for specific package
cargo doc -p mockforge-core
</code></pre>
<h3 id="building-mdbook"><a class="header" href="#building-mdbook">Building mdBook</a></h3>
<pre><code class="language-bash"># Install mdbook
cargo install mdbook

# Build the documentation
mdbook build

# Serve documentation locally
mdbook serve
</code></pre>
<h2 id="packaging-and-distribution"><a class="header" href="#packaging-and-distribution">Packaging and Distribution</a></h2>
<h3 id="creating-releases"><a class="header" href="#creating-releases">Creating Releases</a></h3>
<pre><code class="language-bash"># Create a release build
cargo build --release

# Strip debug symbols (Linux/macOS)
strip target/release/mockforge-cli

# Create distribution archive
tar -czf mockforge-v0.1.0-x86_64-linux.tar.gz \
  -C target/release mockforge-cli

# Create Debian package
cargo install cargo-deb
cargo deb
</code></pre>
<h3 id="docker-builds"><a class="header" href="#docker-builds">Docker Builds</a></h3>
<pre><code class="language-bash"># Build Docker image
docker build -t mockforge .

# Build with buildkit for faster builds
DOCKER_BUILDKIT=1 docker build -t mockforge .

# Multi-stage build for smaller images
docker build -f Dockerfile.multi-stage -t mockforge .
</code></pre>
<h2 id="troubleshooting-build-issues"><a class="header" href="#troubleshooting-build-issues">Troubleshooting Build Issues</a></h2>
<h3 id="common-problems"><a class="header" href="#common-problems">Common Problems</a></h3>
<h4 id="compilation-errors"><a class="header" href="#compilation-errors">Compilation Errors</a></h4>
<p><strong>Problem</strong>: <code>error[E0432]: unresolved import</code></p>
<p><strong>Solution</strong>: Check that dependencies are properly specified in <code>Cargo.toml</code></p>
<pre><code class="language-bash"># Update dependencies
cargo update

# Clean and rebuild
cargo clean
cargo build
</code></pre>
<h4 id="linker-errors"><a class="header" href="#linker-errors">Linker Errors</a></h4>
<p><strong>Problem</strong>: <code>undefined reference to...</code></p>
<p><strong>Solution</strong>: Install system dependencies</p>
<pre><code class="language-bash"># Ubuntu/Debian
sudo apt install libssl-dev pkg-config

# macOS
brew install openssl pkg-config
</code></pre>
<h4 id="out-of-memory"><a class="header" href="#out-of-memory">Out of Memory</a></h4>
<p><strong>Problem</strong>: <code>fatal error: Killed signal terminated program cc1</code></p>
<p><strong>Solution</strong>: Increase available memory or reduce parallelism</p>
<pre><code class="language-bash"># Reduce parallel jobs
cargo build --jobs 1

# Or set memory limits
export CARGO_BUILD_JOBS=2
</code></pre>
<h4 id="slow-builds"><a class="header" href="#slow-builds">Slow Builds</a></h4>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Use incremental compilation
export CARGO_INCREMENTAL=1

# Use faster linker
export RUSTFLAGS="-C link-arg=-fuse-ld=mold"

# Use build cache
cargo install sccache
export RUSTC_WRAPPER=sccache
</code></pre>
<h3 id="platform-specific-issues"><a class="header" href="#platform-specific-issues">Platform-Specific Issues</a></h3>
<h4 id="windows-1"><a class="header" href="#windows-1">Windows</a></h4>
<pre><code class="language-powershell"># Install Windows SDK if missing
# Download from: https://developer.microsoft.com/en-us/windows/downloads/windows-sdk/

# Use different target for static linking
cargo build --target x86_64-pc-windows-msvc
</code></pre>
<h4 id="macos-1"><a class="header" href="#macos-1">macOS</a></h4>
<pre><code class="language-bash"># Install missing headers
open /Library/Developer/CommandLineTools/Packages/macOS_SDK_headers_for_macOS_10.14.pkg

# Or reinstall command line tools
sudo rm -rf /Library/Developer/CommandLineTools
xcode-select --install
</code></pre>
<h4 id="linux"><a class="header" href="#linux">Linux</a></h4>
<pre><code class="language-bash"># Install additional development libraries
sudo apt install libclang-dev llvm-dev

# For cross-compilation
sudo apt install gcc-aarch64-linux-gnu
</code></pre>
<h3 id="network-issues"><a class="header" href="#network-issues">Network Issues</a></h3>
<pre><code class="language-bash"># Clear cargo cache
cargo clean
rm -rf ~/.cargo/registry/cache
rm -rf ~/.cargo/git/checkouts

# Use different registry
export CARGO_REGISTRIES_CRATES_IO_PROTOCOL=sparse
</code></pre>
<h3 id="dependency-conflicts"><a class="header" href="#dependency-conflicts">Dependency Conflicts</a></h3>
<pre><code class="language-bash"># Update Cargo.lock
cargo update

# Resolve conflicts
cargo update -p package-name

# Use cargo-tree to visualize dependencies
cargo install cargo-tree
cargo tree
</code></pre>
<h2 id="performance-optimization-3"><a class="header" href="#performance-optimization-3">Performance Optimization</a></h2>
<h3 id="release-builds"><a class="header" href="#release-builds">Release Builds</a></h3>
<pre><code class="language-bash"># Optimized release build
cargo build --release

# With Link-Time Optimization (LTO)
export RUSTFLAGS="-C opt-level=3 -C lto=fat -C codegen-units=1"
cargo build --release
</code></pre>
<h3 id="profile-guided-optimization-pgo"><a class="header" href="#profile-guided-optimization-pgo">Profile-Guided Optimization (PGO)</a></h3>
<pre><code class="language-bash"># Build with instrumentation
export RUSTFLAGS="-Cprofile-generate=/tmp/pgo-data"
cargo build --release

# Run instrumented binary with representative workload
./target/release/mockforge-cli serve --spec examples/openapi-demo.json &amp;
sleep 10
curl -s http://localhost:3000/users &gt; /dev/null
pkill mockforge-cli

# Build optimized version
export RUSTFLAGS="-Cprofile-use=/tmp/pgo-data"
cargo build --release
</code></pre>
<h2 id="contributing-to-the-build-system"><a class="header" href="#contributing-to-the-build-system">Contributing to the Build System</a></h2>
<h3 id="adding-new-dependencies"><a class="header" href="#adding-new-dependencies">Adding New Dependencies</a></h3>
<pre><code class="language-toml"># Add to workspace Cargo.toml
[workspace.dependencies]
new-dependency = "1.0"

# Use in crate Cargo.toml
[dependencies]
new-dependency = { workspace = true }
</code></pre>
<h3 id="adding-build-scripts"><a class="header" href="#adding-build-scripts">Adding Build Scripts</a></h3>
<pre><pre class="playground"><code class="language-rust">// build.rs
fn main() {
    // Generate code or check dependencies
    println!("cargo:rerun-if-changed=proto/");
    tonic_build::compile_protos("proto/service.proto").unwrap();
}</code></pre></pre>
<h3 id="custom-build-profiles"><a class="header" href="#custom-build-profiles">Custom Build Profiles</a></h3>
<pre><code class="language-toml"># In Cargo.toml
[profile.release]
opt-level = 3
lto = true
codegen-units = 1
panic = "abort"

[profile.dev]
opt-level = 0
debug = true
overflow-checks = true
</code></pre>
<p>This comprehensive build guide ensures developers can successfully compile, test, and contribute to MockForge across different platforms and development environments.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="testing-guide"><a class="header" href="#testing-guide">Testing Guide</a></h1>
<p>This guide covers MockForge’s comprehensive testing strategy, including unit tests, integration tests, end-to-end tests, and testing best practices.</p>
<h2 id="testing-overview"><a class="header" href="#testing-overview">Testing Overview</a></h2>
<p>MockForge employs a multi-layered testing approach to ensure code quality and prevent regressions:</p>
<ul>
<li><strong>Unit Tests</strong>: Individual functions and modules</li>
<li><strong>Integration Tests</strong>: Component interactions</li>
<li><strong>End-to-End Tests</strong>: Full system workflows</li>
<li><strong>Performance Tests</strong>: Load and performance validation</li>
<li><strong>Security Tests</strong>: Vulnerability and access control testing</li>
</ul>
<h2 id="unit-testing"><a class="header" href="#unit-testing">Unit Testing</a></h2>
<h3 id="running-unit-tests"><a class="header" href="#running-unit-tests">Running Unit Tests</a></h3>
<pre><code class="language-bash"># Run all unit tests
cargo test --lib

# Run tests for specific crate
cargo test -p mockforge-core

# Run specific test function
cargo test test_template_rendering

# Run tests matching pattern
cargo test template

# Run tests with output
cargo test -- --nocapture
</code></pre>
<h3 id="writing-unit-tests"><a class="header" href="#writing-unit-tests">Writing Unit Tests</a></h3>
<h4 id="basic-test-structure"><a class="header" href="#basic-test-structure">Basic Test Structure</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_basic_functionality() {
        // Arrange
        let input = "test input";
        let expected = "expected output";

        // Act
        let result = process_input(input);

        // Assert
        assert_eq!(result, expected);
    }

    #[test]
    fn test_error_conditions() {
        // Test error cases
        let result = process_input("");
        assert!(result.is_err());
    }
}
<span class="boring">}</span></code></pre></pre>
<h4 id="async-tests"><a class="header" href="#async-tests">Async Tests</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod async_tests {
    use tokio::test;

    #[tokio::test]
    async fn test_async_operation() {
        let result = async_operation().await;
        assert!(result.is_ok());
    }

    #[tokio::test]
    async fn test_concurrent_operations() {
        let (result1, result2) = tokio::join(
            async_operation(),
            another_async_operation()
        );

        assert!(result1.is_ok());
        assert!(result2.is_ok());
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="integration-testing"><a class="header" href="#integration-testing">Integration Testing</a></h2>
<h3 id="component-integration-tests"><a class="header" href="#component-integration-tests">Component Integration Tests</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod integration_tests {
    use mockforge_core::config::MockForgeConfig;
    use mockforge_http::HttpServer;

    #[tokio::test]
    async fn test_http_server_integration() {
        // Start test server
        let config = test_config();
        let server = HttpServer::new(config);
        let addr = server.local_addr();

        tokio::spawn(async move {
            server.serve().await.unwrap();
        });

        // Wait for server to start
        tokio::time::sleep(tokio::time::Duration::from_millis(100)).await;

        // Test HTTP request
        let client = reqwest::Client::new();
        let response = client
            .get(&amp;format!("http://{}/health", addr))
            .send()
            .await
            .unwrap();

        assert_eq!(response.status(), 200);
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="end-to-end-testing"><a class="header" href="#end-to-end-testing">End-to-End Testing</a></h2>
<h3 id="full-system-tests"><a class="header" href="#full-system-tests">Full System Tests</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod e2e_tests {
    use std::process::Command;
    use std::thread;
    use std::time::Duration;

    #[test]
    fn test_full_openapi_workflow() {
        // Start MockForge server
        let mut server = Command::new("cargo")
            .args(&amp;["run", "--bin", "mockforge-cli", "serve",
                   "--spec", "examples/openapi-demo.json",
                   "--http-port", "3000"])
            .spawn()
            .unwrap();

        // Wait for server to start
        thread::sleep(Duration::from_secs(2));

        // Test API endpoints
        test_user_endpoints();
        test_product_endpoints();

        // Stop server
        server.kill().unwrap();
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="performance-testing"><a class="header" href="#performance-testing">Performance Testing</a></h2>
<h3 id="load-testing-2"><a class="header" href="#load-testing-2">Load Testing</a></h3>
<pre><code class="language-bash"># Using hey for HTTP load testing
hey -n 1000 -c 10 http://localhost:3000/users

# Using wrk for more detailed benchmarking
wrk -t 4 -c 100 -d 30s http://localhost:3000/users
</code></pre>
<h3 id="benchmarking-1"><a class="header" href="#benchmarking-1">Benchmarking</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// In benches/benchmark.rs
use criterion::{black_box, criterion_group, criterion_main, Criterion};

fn benchmark_template_rendering(c: &amp;mut Criterion) {
    let engine = TemplateEngine::new();

    c.bench_function("template_render_simple", |b| {
        b.iter(|| {
            engine.render("Hello {{name}}", &amp;Context::from_value("name", "World"))
        })
    });
}

criterion_group!(benches, benchmark_template_rendering);
criterion_main!(benches);
<span class="boring">}</span></code></pre></pre>
<p>Run benchmarks:</p>
<pre><code class="language-bash">cargo bench
</code></pre>
<h2 id="security-testing"><a class="header" href="#security-testing">Security Testing</a></h2>
<h3 id="input-validation-tests"><a class="header" href="#input-validation-tests">Input Validation Tests</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod security_tests {
    #[test]
    fn test_sql_injection_prevention() {
        let input = "'; DROP TABLE users; --";
        let result = sanitize_input(input);

        // Ensure dangerous characters are escaped
        assert!(!result.contains("DROP"));
    }

    #[test]
    fn test_template_injection() {
        let engine = TemplateEngine::new();
        let malicious = "{{#exec}}rm -rf /{{/exec}}";

        // Should not execute dangerous commands
        let result = engine.render(malicious, &amp;Context::new());
        assert!(!result.contains("exec"));
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="continuous-integration"><a class="header" href="#continuous-integration">Continuous Integration</a></h2>
<h3 id="github-actions-testing"><a class="header" href="#github-actions-testing">GitHub Actions Testing</a></h3>
<pre><code class="language-yaml"># .github/workflows/test.yml
name: Test

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - uses: actions-rs/toolchain@v1
      with:
        toolchain: stable
        override: true

    - name: Cache dependencies
      uses: actions/cache@v2
      with:
        path: |
          ~/.cargo/registry
          ~/.cargo/git
          target
        key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}

    - name: Run tests
      run: cargo test --verbose

    - name: Run clippy
      run: cargo clippy -- -D warnings

    - name: Check formatting
      run: cargo fmt --check

    - name: Run security audit
      run: cargo audit
</code></pre>
<p>This comprehensive testing guide ensures MockForge maintains high code quality and prevents regressions across all components and integration points.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="architecture-overview"><a class="header" href="#architecture-overview">Architecture Overview</a></h1>
<p>MockForge is a modular, Rust-based platform for mocking APIs across HTTP, WebSocket, and gRPC protocols. This document provides a comprehensive overview of the system architecture, design principles, and component interactions.</p>
<h2 id="system-overview"><a class="header" href="#system-overview">System Overview</a></h2>
<p>MockForge enables frontend and integration development without live backends by providing realistic API mocking with configurable latency, failure injection, and dynamic response generation. The system is built as a modular workspace of Rust crates that share a core engine for request routing, validation, and data generation.</p>
<h3 id="key-design-principles"><a class="header" href="#key-design-principles">Key Design Principles</a></h3>
<ul>
<li><strong>Modularity</strong>: Separated concerns across focused crates</li>
<li><strong>Extensibility</strong>: Plugin architecture for custom functionality</li>
<li><strong>Performance</strong>: Async-first design with efficient resource usage</li>
<li><strong>Developer Experience</strong>: Comprehensive tooling and clear APIs</li>
<li><strong>Protocol Agnostic</strong>: Unified approach across different protocols</li>
</ul>
<h2 id="high-level-architecture"><a class="header" href="#high-level-architecture">High-Level Architecture</a></h2>
<pre><code class="language-text">             +------------------+
             |     CLI / UI     |
             +--------+---------+
                      |
         +------------+------------+
         |    Core Engine (axum)   |
         +------------+------------+
                      |
   +----------+-------+---------+-----------+
   |          |                 |           |
 HTTP Mock  WS Mock          gRPC Mock   Data Gen
(axum)    (tokio-ws)         (tonic)     (faker+RAG)
</code></pre>
<h2 id="crate-structure"><a class="header" href="#crate-structure">Crate Structure</a></h2>
<p>MockForge is organized as a Cargo workspace with the following crates:</p>
<pre><code>mockforge/
  crates/
    mockforge-cli/     # Command-line interface
    mockforge-core/    # Shared functionality
    mockforge-http/    # HTTP REST API mocking
    mockforge-ws/      # WebSocket connection mocking
    mockforge-grpc/    # gRPC service mocking
    mockforge-data/   # Synthetic data generation
    mockforge-ui/      # Web-based admin interface
</code></pre>
<h3 id="crate-responsibilities"><a class="header" href="#crate-responsibilities">Crate Responsibilities</a></h3>
<h4 id="mockforge-core---shared-core-engine"><a class="header" href="#mockforge-core---shared-core-engine"><code>mockforge-core</code> - Shared Core Engine</a></h4>
<p>The foundation crate providing common functionality used across all protocols:</p>
<ul>
<li><strong>Request Routing</strong>: Unified route registry and matching logic</li>
<li><strong>Validation Engine</strong>: OpenAPI and schema validation</li>
<li><strong>Template System</strong>: Handlebars-based dynamic content generation</li>
<li><strong>Latency Injection</strong>: Configurable response delays</li>
<li><strong>Failure Injection</strong>: Simulated error conditions</li>
<li><strong>Record/Replay</strong>: Request/response capture and replay</li>
<li><strong>Logging</strong>: Structured request/response logging</li>
<li><strong>Configuration</strong>: Unified configuration management</li>
</ul>
<h4 id="mockforge-http---http-rest-api-mocking"><a class="header" href="#mockforge-http---http-rest-api-mocking"><code>mockforge-http</code> - HTTP REST API Mocking</a></h4>
<p>HTTP-specific implementation built on axum:</p>
<ul>
<li><strong>OpenAPI Integration</strong>: Automatic route generation from specifications</li>
<li><strong>Request Matching</strong>: Method, path, query, header, and body matching</li>
<li><strong>Response Generation</strong>: Schema-driven and template-based responses</li>
<li><strong>Middleware Support</strong>: Custom request/response processing</li>
</ul>
<h4 id="mockforge-ws---websocket-connection-mocking"><a class="header" href="#mockforge-ws---websocket-connection-mocking"><code>mockforge-ws</code> - WebSocket Connection Mocking</a></h4>
<p>Real-time communication mocking:</p>
<ul>
<li><strong>Replay Mode</strong>: Scripted message sequences with timing control</li>
<li><strong>Interactive Mode</strong>: Dynamic responses based on client messages</li>
<li><strong>State Management</strong>: Connection-specific state tracking</li>
<li><strong>Template Support</strong>: Dynamic message content generation</li>
</ul>
<h4 id="mockforge-grpc---grpc-service-mocking"><a class="header" href="#mockforge-grpc---grpc-service-mocking"><code>mockforge-grpc</code> - gRPC Service Mocking</a></h4>
<p>Protocol buffer-based service mocking:</p>
<ul>
<li><strong>Dynamic Proto Discovery</strong>: Automatic compilation of <code>.proto</code> files</li>
<li><strong>Service Reflection</strong>: Runtime service discovery and inspection</li>
<li><strong>Streaming Support</strong>: Unary, server, client, and bidirectional streaming</li>
<li><strong>Schema Validation</strong>: Message validation against proto definitions</li>
</ul>
<h4 id="mockforge-data---synthetic-data-generation"><a class="header" href="#mockforge-data---synthetic-data-generation"><code>mockforge-data</code> - Synthetic Data Generation</a></h4>
<p>Advanced data generation capabilities:</p>
<ul>
<li><strong>Faker Integration</strong>: Realistic fake data generation</li>
<li><strong>RAG Enhancement</strong>: Retrieval-augmented generation for contextual data</li>
<li><strong>Schema-Driven Generation</strong>: Data conforming to JSON Schema/OpenAPI specs</li>
<li><strong>Template Helpers</strong>: Integration with core templating system</li>
</ul>
<h4 id="mockforge-cli---command-line-interface"><a class="header" href="#mockforge-cli---command-line-interface"><code>mockforge-cli</code> - Command-Line Interface</a></h4>
<p>User-facing command-line tool:</p>
<ul>
<li><strong>Server Management</strong>: Start/stop mock servers</li>
<li><strong>Configuration</strong>: Load and validate configuration files</li>
<li><strong>Data Generation</strong>: Command-line data generation utilities</li>
<li><strong>Development Tools</strong>: Testing and debugging utilities</li>
</ul>
<h4 id="mockforge-ui---admin-web-interface"><a class="header" href="#mockforge-ui---admin-web-interface"><code>mockforge-ui</code> - Admin Web Interface</a></h4>
<p>Browser-based management interface:</p>
<ul>
<li><strong>Real-time Monitoring</strong>: Live request/response viewing</li>
<li><strong>Configuration Management</strong>: Runtime configuration changes</li>
<li><strong>Fixture Management</strong>: Recorded interaction management</li>
<li><strong>Performance Metrics</strong>: Response times and error rates</li>
</ul>
<h2 id="core-engine-architecture"><a class="header" href="#core-engine-architecture">Core Engine Architecture</a></h2>
<h3 id="request-processing-pipeline"><a class="header" href="#request-processing-pipeline">Request Processing Pipeline</a></h3>
<p>All requests follow a unified processing pipeline regardless of protocol:</p>
<ol>
<li><strong>Request Reception</strong>: Protocol-specific server receives request</li>
<li><strong>Route Matching</strong>: Core routing engine matches request to handler</li>
<li><strong>Validation</strong>: Schema validation if enabled</li>
<li><strong>Template Processing</strong>: Dynamic content generation</li>
<li><strong>Latency Injection</strong>: Artificial delays if configured</li>
<li><strong>Failure Injection</strong>: Error simulation if enabled</li>
<li><strong>Response Generation</strong>: Handler generates response</li>
<li><strong>Logging</strong>: Request/response logging</li>
<li><strong>Response Delivery</strong>: Protocol-specific response sending</li>
</ol>
<h3 id="route-registry-system"><a class="header" href="#route-registry-system">Route Registry System</a></h3>
<p>The core routing system provides unified route management:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct RouteRegistry {
    routes: HashMap&lt;RouteKey, Vec&lt;RouteHandler&gt;&gt;,
    overrides: Overrides,
    validation_mode: ValidationMode,
}

impl RouteRegistry {
    pub fn register(&amp;mut self, key: RouteKey, handler: RouteHandler);
    pub fn match_route(&amp;self, request: &amp;Request) -&gt; Option&lt;&amp;RouteHandler&gt;;
    pub fn apply_overrides(&amp;mut self, overrides: &amp;Overrides);
}
<span class="boring">}</span></code></pre></pre>
<h3 id="template-engine"><a class="header" href="#template-engine">Template Engine</a></h3>
<p>Handlebars-based templating with custom helpers:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct TemplateEngine {
    registry: handlebars::Handlebars&lt;'static&gt;,
}

impl TemplateEngine {
    pub fn render(&amp;self, template: &amp;str, context: &amp;Context) -&gt; Result&lt;String&gt;;
    pub fn register_helper(&amp;mut self, name: &amp;str, helper: Box&lt;dyn HelperDef&gt;);
}
<span class="boring">}</span></code></pre></pre>
<p>Built-in helpers include:</p>
<ul>
<li><code>uuid</code>: Generate unique identifiers</li>
<li><code>now</code>: Current timestamp</li>
<li><code>randInt</code>: Random integers</li>
<li><code>request</code>: Access request data</li>
<li><code>faker</code>: Synthetic data generation</li>
</ul>
<p>This architecture provides a solid foundation for API mocking while maintaining extensibility, performance, and developer experience. The modular design allows for independent evolution of each protocol implementation while sharing common infrastructure.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="cli-crate"><a class="header" href="#cli-crate">CLI Crate</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="http-crate"><a class="header" href="#http-crate">HTTP Crate</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="grpc-crate"><a class="header" href="#grpc-crate">gRPC Crate</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="websocket-crate"><a class="header" href="#websocket-crate">WebSocket Crate</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="cli-reference"><a class="header" href="#cli-reference">CLI Reference</a></h1>
<p>MockForge provides a comprehensive command-line interface for managing mock servers and generating test data. This reference covers all available commands, options, and usage patterns.</p>
<h2 id="global-options"><a class="header" href="#global-options">Global Options</a></h2>
<p>All MockForge commands support the following global options:</p>
<pre><code class="language-bash">mockforge-cli [OPTIONS] &lt;COMMAND&gt;
</code></pre>
<h3 id="global-options-1"><a class="header" href="#global-options-1">Global Options</a></h3>
<ul>
<li><code>-h, --help</code>: Display help information</li>
</ul>
<h2 id="commands"><a class="header" href="#commands">Commands</a></h2>
<h3 id="serve---start-mock-servers"><a class="header" href="#serve---start-mock-servers"><code>serve</code> - Start Mock Servers</a></h3>
<p>The primary command for starting MockForge’s mock servers with support for HTTP, WebSocket, and gRPC protocols.</p>
<pre><code class="language-bash">mockforge-cli serve [OPTIONS]
</code></pre>
<h4 id="server-options"><a class="header" href="#server-options">Server Options</a></h4>
<p><strong>Port Configuration:</strong></p>
<ul>
<li><code>--http-port &lt;PORT&gt;</code>: HTTP server port (default: 3000)</li>
<li><code>--ws-port &lt;PORT&gt;</code>: WebSocket server port (default: 3001)</li>
<li><code>--grpc-port &lt;PORT&gt;</code>: gRPC server port (default: 50051)</li>
</ul>
<p><strong>API Specification:</strong></p>
<ul>
<li><code>--spec &lt;PATH&gt;</code>: Path to OpenAPI specification file (JSON or YAML format)</li>
</ul>
<p><strong>Configuration:</strong></p>
<ul>
<li><code>-c, --config &lt;PATH&gt;</code>: Path to configuration file</li>
</ul>
<h4 id="admin-ui-options"><a class="header" href="#admin-ui-options">Admin UI Options</a></h4>
<p><strong>Admin UI Control:</strong></p>
<ul>
<li><code>--admin</code>: Enable admin UI</li>
<li><code>--admin-port &lt;PORT&gt;</code>: Admin UI port (default: 8080)</li>
<li><code>--admin-embed</code>: Force embedding Admin UI under HTTP server</li>
<li><code>--admin-mount-path &lt;PATH&gt;</code>: Explicit mount path for embedded Admin UI (implies <code>--admin-embed</code>)</li>
<li><code>--admin-standalone</code>: Force standalone Admin UI on separate port (overrides embed)</li>
<li><code>--disable-admin-api</code>: Disable Admin API endpoints (UI loads but API routes are absent)</li>
</ul>
<h4 id="validation-options"><a class="header" href="#validation-options">Validation Options</a></h4>
<p><strong>Request Validation:</strong></p>
<ul>
<li><code>--validation &lt;MODE&gt;</code>: Request validation mode (default: enforce)
<ul>
<li><code>off</code>: Disable validation</li>
<li><code>warn</code>: Log warnings but allow requests</li>
<li><code>enforce</code>: Reject invalid requests</li>
</ul>
</li>
<li><code>--aggregate-errors</code>: Aggregate request validation errors into JSON array</li>
<li><code>--validate-responses</code>: Validate responses (warn-only)</li>
<li><code>--validation-status &lt;CODE&gt;</code>: Validation error HTTP status code (default: 400)</li>
</ul>
<h4 id="response-processing"><a class="header" href="#response-processing">Response Processing</a></h4>
<p><strong>Template Expansion:</strong></p>
<ul>
<li><code>--response-template-expand</code>: Expand templating tokens in responses/examples</li>
</ul>
<h4 id="chaos-engineering"><a class="header" href="#chaos-engineering">Chaos Engineering</a></h4>
<p><strong>Latency Simulation:</strong></p>
<ul>
<li><code>--latency-enabled</code>: Enable latency simulation</li>
</ul>
<p><strong>Failure Injection:</strong></p>
<ul>
<li><code>--failures-enabled</code>: Enable failure injection</li>
</ul>
<h4 id="examples-1"><a class="header" href="#examples-1">Examples</a></h4>
<p><strong>Basic HTTP Server:</strong></p>
<pre><code class="language-bash">mockforge-cli serve --spec examples/openapi-demo.json --http-port 3000
</code></pre>
<p><strong>Full Multi-Protocol Setup:</strong></p>
<pre><code class="language-bash">mockforge-cli serve \
  --spec examples/openapi-demo.json \
  --http-port 3000 \
  --ws-port 3001 \
  --grpc-port 50051 \
  --admin \
  --admin-port 8080 \
  --response-template-expand
</code></pre>
<p><strong>Development Configuration:</strong></p>
<pre><code class="language-bash">mockforge-cli serve \
  --config demo-config.yaml \
  --validation warn \
  --response-template-expand \
  --latency-enabled
</code></pre>
<p><strong>Production Configuration:</strong></p>
<pre><code class="language-bash">mockforge-cli serve \
  --config production-config.yaml \
  --validation enforce \
  --admin-standalone
</code></pre>
<h3 id="data---generate-synthetic-data"><a class="header" href="#data---generate-synthetic-data"><code>data</code> - Generate Synthetic Data</a></h3>
<p>Generate synthetic test data using various templates and schemas.</p>
<pre><code class="language-bash">mockforge-cli data &lt;SUBCOMMAND&gt;
</code></pre>
<h4 id="subcommands"><a class="header" href="#subcommands">Subcommands</a></h4>
<h5 id="template---generate-from-built-in-templates"><a class="header" href="#template---generate-from-built-in-templates"><code>template</code> - Generate from Built-in Templates</a></h5>
<p>Generate data using MockForge’s built-in data generation templates.</p>
<pre><code class="language-bash">mockforge-cli data template [OPTIONS]
</code></pre>
<p><strong>Options:</strong></p>
<ul>
<li><code>--count &lt;N&gt;</code>: Number of items to generate (default: 1)</li>
<li><code>--format &lt;FORMAT&gt;</code>: Output format (json, yaml, csv)</li>
<li><code>--template &lt;NAME&gt;</code>: Template name (user, product, order, etc.)</li>
<li><code>--output &lt;PATH&gt;</code>: Output file path</li>
</ul>
<p><strong>Examples:</strong></p>
<pre><code class="language-bash"># Generate 10 user records as JSON
mockforge-cli data template --template user --count 10 --format json

# Generate product data to file
mockforge-cli data template --template product --count 50 --output products.json
</code></pre>
<h5 id="schema---generate-from-json-schema"><a class="header" href="#schema---generate-from-json-schema"><code>schema</code> - Generate from JSON Schema</a></h5>
<p>Generate data conforming to a JSON Schema specification.</p>
<pre><code class="language-bash">mockforge-cli data schema [OPTIONS] &lt;SCHEMA&gt;
</code></pre>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>&lt;SCHEMA&gt;</code>: Path to JSON Schema file</li>
</ul>
<p><strong>Options:</strong></p>
<ul>
<li><code>--count &lt;N&gt;</code>: Number of items to generate (default: 1)</li>
<li><code>--format &lt;FORMAT&gt;</code>: Output format (json, yaml)</li>
<li><code>--output &lt;PATH&gt;</code>: Output file path</li>
</ul>
<p><strong>Examples:</strong></p>
<pre><code class="language-bash"># Generate data from user schema
mockforge-cli data schema --count 5 user-schema.json

# Generate and save to file
mockforge-cli data schema --count 100 --output generated-data.json api-schema.json
</code></pre>
<h5 id="open-api---generate-from-openapi-spec"><a class="header" href="#open-api---generate-from-openapi-spec"><code>open-api</code> - Generate from OpenAPI Spec</a></h5>
<p>Generate mock data based on OpenAPI specification schemas.</p>
<pre><code class="language-bash">mockforge-cli data open-api [OPTIONS] &lt;SPEC&gt;
</code></pre>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>&lt;SPEC&gt;</code>: Path to OpenAPI specification file</li>
</ul>
<p><strong>Options:</strong></p>
<ul>
<li><code>--endpoint &lt;PATH&gt;</code>: Specific endpoint to generate data for</li>
<li><code>--method &lt;METHOD&gt;</code>: HTTP method (get, post, put, delete)</li>
<li><code>--count &lt;N&gt;</code>: Number of items to generate (default: 1)</li>
<li><code>--format &lt;FORMAT&gt;</code>: Output format (json, yaml)</li>
<li><code>--output &lt;PATH&gt;</code>: Output file path</li>
</ul>
<p><strong>Examples:</strong></p>
<pre><code class="language-bash"># Generate data for all endpoints in OpenAPI spec
mockforge-cli data open-api api-spec.yaml

# Generate data for specific endpoint
mockforge-cli data open-api --endpoint /users --method get --count 20 api-spec.yaml

# Generate POST request body data
mockforge-cli data open-api --endpoint /users --method post api-spec.yaml
</code></pre>
<h3 id="admin---admin-ui-server"><a class="header" href="#admin---admin-ui-server"><code>admin</code> - Admin UI Server</a></h3>
<p>Start the Admin UI as a standalone server without the main mock servers.</p>
<pre><code class="language-bash">mockforge-cli admin [OPTIONS]
</code></pre>
<h4 id="options"><a class="header" href="#options">Options</a></h4>
<ul>
<li><code>--port &lt;PORT&gt;</code>: Server port (default: 8080)</li>
</ul>
<h4 id="examples-2"><a class="header" href="#examples-2">Examples</a></h4>
<pre><code class="language-bash"># Start admin UI on default port
mockforge-cli admin

# Start admin UI on custom port
mockforge-cli admin --port 9090
</code></pre>
<h2 id="configuration-file-format"><a class="header" href="#configuration-file-format">Configuration File Format</a></h2>
<p>MockForge supports YAML configuration files that can be used instead of command-line options.</p>
<h3 id="basic-configuration-structure-1"><a class="header" href="#basic-configuration-structure-1">Basic Configuration Structure</a></h3>
<pre><code class="language-yaml"># Server configuration
server:
  http_port: 3000
  ws_port: 3001
  grpc_port: 50051

# API specification
spec: examples/openapi-demo.json

# Admin UI configuration
admin:
  enabled: true
  port: 8080
  embedded: false
  mount_path: "/admin"
  standalone: true
  disable_api: false

# Validation settings
validation:
  mode: enforce
  aggregate_errors: false
  validate_responses: false
  status_code: 400

# Response processing
response:
  template_expand: true

# Chaos engineering
chaos:
  latency_enabled: false
  failures_enabled: false

# Protocol-specific settings
grpc:
  proto_dir: "proto/"
  enable_reflection: true

websocket:
  replay_file: "examples/ws-demo.jsonl"
</code></pre>
<h3 id="configuration-precedence-1"><a class="header" href="#configuration-precedence-1">Configuration Precedence</a></h3>
<p>Configuration values are applied in the following order (later sources override earlier ones):</p>
<ol>
<li><strong>Default values</strong> (compiled into the binary)</li>
<li><strong>Configuration file</strong> (<code>-c/--config</code> option)</li>
<li><strong>Environment variables</strong></li>
<li><strong>Command-line arguments</strong> (highest priority)</li>
</ol>
<h3 id="environment-variables-6"><a class="header" href="#environment-variables-6">Environment Variables</a></h3>
<p>All configuration options can be set via environment variables using the <code>MOCKFORGE_</code> prefix:</p>
<pre><code class="language-bash"># Server ports
export MOCKFORGE_HTTP_PORT=3000
export MOCKFORGE_WS_PORT=3001
export MOCKFORGE_GRPC_PORT=50051

# Admin UI
export MOCKFORGE_ADMIN_ENABLED=true
export MOCKFORGE_ADMIN_PORT=8080

# Validation
export MOCKFORGE_VALIDATION_MODE=enforce
export MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true

# gRPC settings
export MOCKFORGE_PROTO_DIR=proto/
export MOCKFORGE_GRPC_REFLECTION_ENABLED=true

# WebSocket settings
export MOCKFORGE_WS_REPLAY_FILE=examples/ws-demo.jsonl
</code></pre>
<h2 id="exit-codes"><a class="header" href="#exit-codes">Exit Codes</a></h2>
<p>MockForge uses standard exit codes:</p>
<ul>
<li><strong>0</strong>: Success</li>
<li><strong>1</strong>: General error</li>
<li><strong>2</strong>: Configuration error</li>
<li><strong>3</strong>: Validation error</li>
<li><strong>4</strong>: File I/O error</li>
<li><strong>5</strong>: Network error</li>
</ul>
<h2 id="logging"><a class="header" href="#logging">Logging</a></h2>
<p>MockForge provides configurable logging output to help with debugging and monitoring.</p>
<h3 id="log-levels"><a class="header" href="#log-levels">Log Levels</a></h3>
<ul>
<li><code>error</code>: Only error messages</li>
<li><code>warn</code>: Warnings and errors</li>
<li><code>info</code>: General information (default)</li>
<li><code>debug</code>: Detailed debugging information</li>
<li><code>trace</code>: Very verbose tracing information</li>
</ul>
<h3 id="log-configuration"><a class="header" href="#log-configuration">Log Configuration</a></h3>
<pre><code class="language-bash"># Set log level via environment variable
export RUST_LOG=mockforge=debug

# Or via configuration file
logging:
  level: debug
  format: json
</code></pre>
<h3 id="log-output"><a class="header" href="#log-output">Log Output</a></h3>
<p>Logs include structured information about:</p>
<ul>
<li>HTTP requests/responses</li>
<li>WebSocket connections and messages</li>
<li>gRPC calls and streaming</li>
<li>Configuration loading</li>
<li>Template expansion</li>
<li>Validation errors</li>
</ul>
<h2 id="examples-3"><a class="header" href="#examples-3">Examples</a></h2>
<h3 id="complete-development-setup"><a class="header" href="#complete-development-setup">Complete Development Setup</a></h3>
<pre><code class="language-bash"># Start all servers with admin UI
mockforge-cli serve \
  --spec examples/openapi-demo.json \
  --http-port 3000 \
  --ws-port 3001 \
  --grpc-port 50051 \
  --admin \
  --admin-port 8080 \
  --response-template-expand \
  --validation warn
</code></pre>
<h3 id="cicd-testing-pipeline"><a class="header" href="#cicd-testing-pipeline">CI/CD Testing Pipeline</a></h3>
<pre><code class="language-bash">#!/bin/bash
# test-mockforge.sh

# Start MockForge in background
mockforge-cli serve --spec api-spec.yaml --http-port 3000 &amp;
MOCKFORGE_PID=$!

# Wait for server to start
sleep 5

# Run API tests
npm test

# Generate test data
mockforge-cli data open-api --endpoint /users --count 100 api-spec.yaml &gt; test-users.json

# Stop MockForge
kill $MOCKFORGE_PID
</code></pre>
<h3 id="load-testing-setup"><a class="header" href="#load-testing-setup">Load Testing Setup</a></h3>
<pre><code class="language-bash">#!/bin/bash
# load-test-setup.sh

# Start MockForge with minimal validation for performance
MOCKFORGE_VALIDATION_MODE=off \
MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=false \
mockforge-cli serve \
  --spec load-test-spec.yaml \
  --http-port 3000 \
  --validation off

# Now run your load testing tool against localhost:3000
# Example: hey -n 10000 -c 100 http://localhost:3000/api/test
</code></pre>
<h3 id="docker-integration"><a class="header" href="#docker-integration">Docker Integration</a></h3>
<pre><code class="language-bash"># Run MockForge in Docker with CLI commands
docker run --rm -v $(pwd)/examples:/examples \
  mockforge \
  serve --spec /examples/openapi-demo.json --http-port 3000
</code></pre>
<h2 id="troubleshooting-9"><a class="header" href="#troubleshooting-9">Troubleshooting</a></h2>
<h3 id="common-issues-6"><a class="header" href="#common-issues-6">Common Issues</a></h3>
<p><strong>Server won’t start:</strong></p>
<pre><code class="language-bash"># Check if ports are available
lsof -i :3000
lsof -i :3001

# Try different ports
mockforge-cli serve --http-port 3001 --ws-port 3002
</code></pre>
<p><strong>Configuration not loading:</strong></p>
<pre><code class="language-bash"># Validate YAML syntax
yamllint config.yaml

# Check file permissions
ls -la config.yaml
</code></pre>
<p><strong>OpenAPI spec not found:</strong></p>
<pre><code class="language-bash"># Verify file exists and path is correct
ls -la examples/openapi-demo.json

# Use absolute path
mockforge-cli serve --spec /full/path/to/examples/openapi-demo.json
</code></pre>
<p><strong>Template expansion not working:</strong></p>
<pre><code class="language-bash"># Ensure template expansion is enabled
mockforge-cli serve --response-template-expand --spec api-spec.yaml
</code></pre>
<h3 id="debug-mode"><a class="header" href="#debug-mode">Debug Mode</a></h3>
<p>Run with debug logging for detailed information:</p>
<pre><code class="language-bash">RUST_LOG=mockforge=debug mockforge-cli serve --spec api-spec.yaml
</code></pre>
<h3 id="health-checks"><a class="header" href="#health-checks">Health Checks</a></h3>
<p>Test basic functionality:</p>
<pre><code class="language-bash"># HTTP health check
curl http://localhost:3000/health

# WebSocket connection test
websocat ws://localhost:3001/ws

# gRPC service discovery
grpcurl -plaintext localhost:50051 list
</code></pre>
<p>This CLI reference provides comprehensive coverage of MockForge’s command-line interface. For programmatic usage, see the <a href="api/rust.html">Rust API Reference</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rust-api-reference"><a class="header" href="#rust-api-reference">Rust API Reference</a></h1>
<p>MockForge provides comprehensive Rust libraries for programmatic usage and extension. This reference covers the main crates and their APIs.</p>
<h2 id="crate-overview"><a class="header" href="#crate-overview">Crate Overview</a></h2>
<p>MockForge consists of several interconnected crates:</p>
<ul>
<li><strong><code>mockforge-cli</code></strong>: Command-line interface and main executable</li>
<li><strong><code>mockforge-core</code></strong>: Core functionality shared across protocols</li>
<li><strong><code>mockforge-http</code></strong>: HTTP REST API mocking</li>
<li><strong><code>mockforge-grpc</code></strong>: gRPC service mocking</li>
<li><strong><code>mockforge-ui</code></strong>: Web-based admin interface</li>
</ul>
<h2 id="getting-started"><a class="header" href="#getting-started">Getting Started</a></h2>
<p>Add MockForge to your <code>Cargo.toml</code>:</p>
<pre><code class="language-toml">[dependencies]
mockforge-core = "0.1"
mockforge-http = "0.1"
mockforge-grpc = "0.1"
</code></pre>
<p>For development or testing, you might want to use path dependencies:</p>
<pre><code class="language-toml">[dependencies]
mockforge-core = { path = "../mockforge/crates/mockforge-core" }
mockforge-http = { path = "../mockforge/crates/mockforge-http" }
mockforge-grpc = { path = "../mockforge/crates/mockforge-grpc" }
</code></pre>
<h2 id="core-concepts-2"><a class="header" href="#core-concepts-2">Core Concepts</a></h2>
<h3 id="configuration-system"><a class="header" href="#configuration-system">Configuration System</a></h3>
<p>MockForge uses a hierarchical configuration system that can be built programmatically:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_core::config::MockForgeConfig;

let config = MockForgeConfig {
    server: ServerConfig {
        http_port: Some(3000),
        ws_port: Some(3001),
        grpc_port: Some(50051),
    },
    validation: ValidationConfig {
        mode: ValidationMode::Enforce,
        aggregate_errors: false,
    },
    response: ResponseConfig {
        template_expand: true,
    },
    ..Default::default()
};
<span class="boring">}</span></code></pre></pre>
<h3 id="template-system-1"><a class="header" href="#template-system-1">Template System</a></h3>
<p>MockForge includes a powerful template engine for dynamic content generation:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_core::template::{TemplateEngine, Context};

let engine = TemplateEngine::new();
let context = Context::new()
    .with_value("user_id", "12345")
    .with_value("timestamp", "2025-09-12T10:00:00Z");

let result = engine.render("User {{user_id}} logged in at {{timestamp}}", &amp;context)?;
assert_eq!(result, "User 12345 logged in at 2025-09-12T10:00:00Z");
<span class="boring">}</span></code></pre></pre>
<h3 id="error-handling-2"><a class="header" href="#error-handling-2">Error Handling</a></h3>
<p>MockForge uses the <code>anyhow</code> crate for error handling:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use anyhow::{Result, Context};

fn start_server(config: &amp;Config) -&gt; Result&lt;()&gt; {
    let server = HttpServer::new(config)
        .context("Failed to create HTTP server")?;

    server.start()
        .context("Failed to start server")?;

    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<h2 id="http-api"><a class="header" href="#http-api">HTTP API</a></h2>
<h3 id="basic-http-server"><a class="header" href="#basic-http-server">Basic HTTP Server</a></h3>
<pre><pre class="playground"><code class="language-rust">use mockforge_http::{HttpServer, HttpConfig};
use mockforge_core::config::ServerConfig;

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    // Create HTTP configuration
    let http_config = HttpConfig {
        spec_path: Some("api-spec.yaml".to_string()),
        validation_mode: ValidationMode::Warn,
        template_expand: true,
    };

    // Start HTTP server
    let mut server = HttpServer::new(http_config);
    server.start(([127, 0, 0, 1], 3000)).await?;

    println!("HTTP server running on http://localhost:3000");
    Ok(())
}</code></pre></pre>
<h3 id="custom-route-handlers"><a class="header" href="#custom-route-handlers">Custom Route Handlers</a></h3>
<pre><pre class="playground"><code class="language-rust">use mockforge_http::{HttpServer, RouteHandler};
use warp::{Filter, Reply};

struct CustomHandler;

impl RouteHandler for CustomHandler {
    fn handle(&amp;self, path: &amp;str, method: &amp;str) -&gt; Option&lt;Box&lt;dyn Reply&gt;&gt; {
        if path == "/custom" &amp;&amp; method == "GET" {
            Some(Box::new(warp::reply::json(&amp;serde_json::json!({
                "message": "Custom response",
                "timestamp": chrono::Utc::now()
            }))))
        } else {
            None
        }
    }
}

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    let handler = CustomHandler;
    let server = HttpServer::with_handler(handler);
    server.start(([127, 0, 0, 1], 3000)).await?;
    Ok(())
}</code></pre></pre>
<h2 id="grpc-api"><a class="header" href="#grpc-api">gRPC API</a></h2>
<h3 id="basic-grpc-server-1"><a class="header" href="#basic-grpc-server-1">Basic gRPC Server</a></h3>
<pre><pre class="playground"><code class="language-rust">use mockforge_grpc::{GrpcServer, GrpcConfig};
use std::path::Path;

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    // Configure proto discovery
    let config = GrpcConfig {
        proto_dir: Path::new("proto/"),
        enable_reflection: true,
        ..Default::default()
    };

    // Start gRPC server
    let server = GrpcServer::new(config);
    server.start("127.0.0.1:50051").await?;

    println!("gRPC server running on 127.0.0.1:50051");
    Ok(())
}</code></pre></pre>
<h3 id="custom-service-implementation"><a class="header" href="#custom-service-implementation">Custom Service Implementation</a></h3>
<pre><pre class="playground"><code class="language-rust">use mockforge_grpc::{ServiceRegistry, ServiceImplementation};
use prost::Message;
use tonic::{Request, Response, Status};

// Generated from proto file
mod greeter {
    include!("generated/greeter.rs");
}

pub struct GreeterService;

#[tonic::async_trait]
impl greeter::greeter_server::Greeter for GreeterService {
    async fn say_hello(
        &amp;self,
        request: Request&lt;greeter::HelloRequest&gt;,
    ) -&gt; Result&lt;Response&lt;greeter::HelloReply&gt;, Status&gt; {
        let name = request.into_inner().name;

        let reply = greeter::HelloReply {
            message: format!("Hello, {}!", name),
            timestamp: Some(prost_types::Timestamp::from(std::time::SystemTime::now())),
        };

        Ok(Response::new(reply))
    }
}

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    let service = GreeterService {};
    let server = GrpcServer::with_service(service);
    server.start("127.0.0.1:50051").await?;
    Ok(())
}</code></pre></pre>
<h2 id="websocket-api"><a class="header" href="#websocket-api">WebSocket API</a></h2>
<h3 id="basic-websocket-server"><a class="header" href="#basic-websocket-server">Basic WebSocket Server</a></h3>
<pre><pre class="playground"><code class="language-rust">use mockforge_ws::{WebSocketServer, WebSocketConfig};

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    let config = WebSocketConfig {
        port: 3001,
        replay_file: Some("ws-replay.jsonl".to_string()),
        ..Default::default()
    };

    let server = WebSocketServer::new(config);
    server.start().await?;

    println!("WebSocket server running on ws://localhost:3001");
    Ok(())
}</code></pre></pre>
<h3 id="custom-message-handler"><a class="header" href="#custom-message-handler">Custom Message Handler</a></h3>
<pre><pre class="playground"><code class="language-rust">use mockforge_ws::{WebSocketServer, MessageHandler};
use futures_util::{SinkExt, StreamExt};

struct EchoHandler;

impl MessageHandler for EchoHandler {
    async fn handle_message(&amp;self, message: String) -&gt; String {
        format!("Echo: {}", message)
    }
}

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    let handler = EchoHandler {};
    let server = WebSocketServer::with_handler(handler);
    server.start().await?;
    Ok(())
}</code></pre></pre>
<p>This Rust API reference provides the foundation for programmatic usage of MockForge. For protocol-specific details, see the <a href="api/rust/http.html">HTTP</a>, <a href="api/rust/grpc.html">gRPC</a>, and <a href="api/rust/ws.html">WebSocket</a> API documentation.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="http-module"><a class="header" href="#http-module">HTTP Module</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="grpc-module"><a class="header" href="#grpc-module">gRPC Module</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="websocket-module"><a class="header" href="#websocket-module">WebSocket Module</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="development-setup-1"><a class="header" href="#development-setup-1">Development Setup</a></h1>
<p>This guide helps contributors get started with MockForge development, including environment setup, development workflow, and project structure.</p>
<h2 id="prerequisites-3"><a class="header" href="#prerequisites-3">Prerequisites</a></h2>
<p>Before contributing to MockForge, ensure you have the following installed:</p>
<h3 id="required-tools"><a class="header" href="#required-tools">Required Tools</a></h3>
<ul>
<li><strong>Rust</strong>: Version 1.70.0 or later</li>
<li><strong>Cargo</strong>: Included with Rust</li>
<li><strong>Git</strong>: For version control</li>
<li><strong>C/C++ Compiler</strong>: For native dependencies</li>
<li><strong>Docker</strong>: For containerized development and testing</li>
</ul>
<h3 id="recommended-tools"><a class="header" href="#recommended-tools">Recommended Tools</a></h3>
<ul>
<li><strong>Visual Studio Code</strong> or <strong>IntelliJ/CLion</strong> with Rust plugins</li>
<li><strong>cargo-watch</strong> for automatic rebuilds</li>
<li><strong>cargo-edit</strong> for dependency management</li>
<li><strong>cargo-audit</strong> for security scanning</li>
<li><strong>mdbook</strong> for documentation development</li>
</ul>
<h2 id="environment-setup"><a class="header" href="#environment-setup">Environment Setup</a></h2>
<h3 id="1-install-rust"><a class="header" href="#1-install-rust">1. Install Rust</a></h3>
<pre><code class="language-bash"># Install Rust using rustup
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh

# Add Cargo to PATH
source $HOME/.cargo/env

# Verify installation
rustc --version
cargo --version
</code></pre>
<h3 id="2-clone-the-repository"><a class="header" href="#2-clone-the-repository">2. Clone the Repository</a></h3>
<pre><code class="language-bash"># Clone with SSH (recommended for contributors)
git clone git@github.com:SaaSy-Solutions/mockforge.git

# Or with HTTPS
git clone https://github.com/SaaSy-Solutions/mockforge.git

cd mockforge

# Initialize submodules if any
git submodule update --init --recursive
</code></pre>
<h3 id="3-install-development-tools"><a class="header" href="#3-install-development-tools">3. Install Development Tools</a></h3>
<pre><code class="language-bash"># Install cargo-watch for automatic rebuilds
cargo install cargo-watch

# Install cargo-edit for dependency management
cargo install cargo-edit

# Install cargo-audit for security scanning
cargo install cargo-audit

# Install mdbook for documentation
cargo install mdbook mdbook-linkcheck mdbook-toc

# Install additional development tools
cargo install cargo-tarpaulin cargo-udeps cargo-outdated
</code></pre>
<h3 id="4-verify-setup"><a class="header" href="#4-verify-setup">4. Verify Setup</a></h3>
<pre><code class="language-bash"># Build the project
cargo build

# Run tests
cargo test

# Check code quality
cargo clippy
cargo fmt --check
</code></pre>
<h2 id="development-workflow-1"><a class="header" href="#development-workflow-1">Development Workflow</a></h2>
<h3 id="daily-development"><a class="header" href="#daily-development">Daily Development</a></h3>
<ol>
<li>
<p><strong>Create a feature branch</strong>:</p>
<pre><code class="language-bash">git checkout -b feature/your-feature-name
</code></pre>
</li>
<li>
<p><strong>Make changes</strong> with frequent testing:</p>
<pre><code class="language-bash"># Run tests automatically on changes
cargo watch -x test

# Or build automatically
cargo watch -x build
</code></pre>
</li>
<li>
<p><strong>Follow code quality standards</strong>:</p>
<pre><code class="language-bash"># Format code
cargo fmt

# Lint code
cargo clippy -- -W clippy::pedantic

# Run security audit
cargo audit
</code></pre>
</li>
<li>
<p><strong>Write tests</strong> for new functionality:</p>
<pre><code class="language-bash"># Add unit tests
cargo test --lib

# Add integration tests
cargo test --test integration
</code></pre>
</li>
</ol>
<h3 id="ide-configuration"><a class="header" href="#ide-configuration">IDE Configuration</a></h3>
<h4 id="visual-studio-code"><a class="header" href="#visual-studio-code">Visual Studio Code</a></h4>
<ol>
<li>
<p>Install extensions:</p>
<ul>
<li><code>rust-lang.rust-analyzer</code> - Rust language support</li>
<li><code>ms-vscode.vscode-json</code> - JSON support</li>
<li><code>redhat.vscode-yaml</code> - YAML support</li>
<li><code>ms-vscode.vscode-docker</code> - Docker support</li>
</ul>
</li>
<li>
<p>Recommended settings in <code>.vscode/settings.json</code>:</p>
<pre><code class="language-json">{
  "rust-analyzer.checkOnSave.command": "clippy",
  "rust-analyzer.cargo.allFeatures": true,
  "editor.formatOnSave": true,
  "editor.codeActionsOnSave": {
    "source.fixAll": "explicit"
  }
}
</code></pre>
</li>
</ol>
<h4 id="intellijclion-1"><a class="header" href="#intellijclion-1">IntelliJ/CLion</a></h4>
<ol>
<li>Install Rust plugin from marketplace</li>
<li>Enable external linter (clippy)</li>
<li>Configure code style to match project standards</li>
</ol>
<h3 id="pre-commit-setup"><a class="header" href="#pre-commit-setup">Pre-commit Setup</a></h3>
<p>Install pre-commit hooks to ensure code quality:</p>
<pre><code class="language-bash"># Install pre-commit if not already installed
pip install pre-commit

# Install hooks
pre-commit install

# Run on all files
pre-commit run --all-files
</code></pre>
<h2 id="project-structure"><a class="header" href="#project-structure">Project Structure</a></h2>
<pre><code>mockforge/
├── crates/                    # Rust crates
│   ├── mockforge-cli/        # Command-line interface
│   ├── mockforge-core/       # Shared core functionality
│   ├── mockforge-http/       # HTTP REST API mocking
│   ├── mockforge-ws/         # WebSocket connection mocking
│   ├── mockforge-grpc/       # gRPC service mocking
│   ├── mockforge-data/       # Synthetic data generation
│   └── mockforge-ui/         # Web-based admin interface
├── docs/                     # Technical documentation
├── examples/                 # Usage examples
├── book/                     # User documentation (mdBook)
│   └── src/
├── fixtures/                 # Test fixtures
├── scripts/                  # Development scripts
├── tools/                    # Development tools
├── Cargo.toml               # Workspace configuration
├── Cargo.lock               # Dependency lock file
├── Makefile                # Development tasks
├── docker-compose.yml      # Development environment
└── README.md               # Project overview
</code></pre>
<h2 id="development-tasks"><a class="header" href="#development-tasks">Development Tasks</a></h2>
<h3 id="common-make-targets"><a class="header" href="#common-make-targets">Common Make Targets</a></h3>
<pre><code class="language-bash"># Build all crates
make build

# Run tests
make test

# Run integration tests
make test-integration

# Build documentation
make docs

# Serve documentation locally
make docs-serve

# Run linter
make lint

# Format code
make format

# Clean build artifacts
make clean
</code></pre>
<h3 id="custom-development-scripts"><a class="header" href="#custom-development-scripts">Custom Development Scripts</a></h3>
<p>Several development scripts are available in the <code>scripts/</code> directory:</p>
<pre><code class="language-bash"># Update dependencies
./scripts/update-deps.sh

# Generate API documentation
./scripts/gen-docs.sh

# Run performance benchmarks
./scripts/benchmark.sh

# Check for unused dependencies
./scripts/check-deps.sh
</code></pre>
<h2 id="testing-strategy"><a class="header" href="#testing-strategy">Testing Strategy</a></h2>
<h3 id="unit-tests"><a class="header" href="#unit-tests">Unit Tests</a></h3>
<pre><code class="language-bash"># Run unit tests for all crates
cargo test --lib

# Run unit tests for specific crate
cargo test -p mockforge-core

# Run with coverage
cargo tarpaulin --out Html
</code></pre>
<h3 id="integration-tests"><a class="header" href="#integration-tests">Integration Tests</a></h3>
<pre><code class="language-bash"># Run integration tests
cargo test --test integration

# Run with verbose output
cargo test --test integration -- --nocapture
</code></pre>
<h3 id="end-to-end-tests"><a class="header" href="#end-to-end-tests">End-to-End Tests</a></h3>
<pre><code class="language-bash"># Run E2E tests (requires Docker)
make test-e2e

# Or run manually
./scripts/test-e2e.sh
</code></pre>
<h2 id="docker-development"><a class="header" href="#docker-development">Docker Development</a></h2>
<h3 id="development-container"><a class="header" href="#development-container">Development Container</a></h3>
<pre><code class="language-bash"># Build development container
docker build -f Dockerfile.dev -t mockforge-dev .

# Run development environment
docker run -it --rm \
  -v $(pwd):/app \
  -p 3000:3000 \
  -p 3001:3001 \
  -p 50051:50051 \
  -p 8080:8080 \
  mockforge-dev
</code></pre>
<h3 id="testing-with-docker"><a class="header" href="#testing-with-docker">Testing with Docker</a></h3>
<pre><code class="language-bash"># Run tests in container
docker run --rm -v $(pwd):/app mockforge-dev cargo test

# Build release binaries
docker run --rm -v $(pwd):/app mockforge-dev cargo build --release
</code></pre>
<h2 id="contributing-workflow"><a class="header" href="#contributing-workflow">Contributing Workflow</a></h2>
<h3 id="1-choose-an-issue"><a class="header" href="#1-choose-an-issue">1. Choose an Issue</a></h3>
<ul>
<li>Check <a href="https://github.com/SaaSy-Solutions/mockforge/issues">GitHub Issues</a> for open tasks</li>
<li>Look for issues labeled <code>good first issue</code> or <code>help wanted</code></li>
<li>Comment on the issue to indicate you’re working on it</li>
</ul>
<h3 id="2-create-a-branch"><a class="header" href="#2-create-a-branch">2. Create a Branch</a></h3>
<pre><code class="language-bash"># Create feature branch
git checkout -b feature/issue-number-description

# Or create bugfix branch
git checkout -b bugfix/issue-number-description
</code></pre>
<h3 id="3-make-changes"><a class="header" href="#3-make-changes">3. Make Changes</a></h3>
<ul>
<li>Write clear, focused commits</li>
<li>Follow the <a href="contributing/style.html">code style guide</a></li>
<li>Add tests for new functionality</li>
<li>Update documentation as needed</li>
</ul>
<h3 id="4-test-your-changes"><a class="header" href="#4-test-your-changes">4. Test Your Changes</a></h3>
<pre><code class="language-bash"># Run full test suite
make test

# Run integration tests
make test-integration

# Test manually if applicable
cargo run -- serve --spec examples/openapi-demo.json
</code></pre>
<h3 id="5-update-documentation"><a class="header" href="#5-update-documentation">5. Update Documentation</a></h3>
<pre><code class="language-bash"># Update user-facing docs if needed
mdbook build

# Update API docs
cargo doc

# Test documentation links
mdbook test
</code></pre>
<h3 id="6-submit-a-pull-request"><a class="header" href="#6-submit-a-pull-request">6. Submit a Pull Request</a></h3>
<pre><code class="language-bash"># Ensure branch is up to date
git fetch origin
git rebase origin/main

# Push your branch
git push origin feature/your-feature

# Create PR on GitHub with:
# - Clear title and description
# - Reference to issue number
# - Screenshots/videos for UI changes
# - Test results
</code></pre>
<h2 id="getting-help-1"><a class="header" href="#getting-help-1">Getting Help</a></h2>
<h3 id="communication-channels"><a class="header" href="#communication-channels">Communication Channels</a></h3>
<ul>
<li><strong>GitHub Issues</strong>: For bugs, features, and general discussion</li>
<li><strong>GitHub Discussions</strong>: For questions and longer-form discussion</li>
<li><strong>Discord/Slack</strong>: For real-time chat (if available)</li>
</ul>
<h3 id="when-to-ask-for-help"><a class="header" href="#when-to-ask-for-help">When to Ask for Help</a></h3>
<ul>
<li>Stuck on a technical problem for more than 2 hours</li>
<li>Unsure about design decisions</li>
<li>Need clarification on requirements</li>
<li>Found a potential security issue</li>
</ul>
<h3 id="code-review-process"><a class="header" href="#code-review-process">Code Review Process</a></h3>
<ul>
<li>All PRs require review from at least one maintainer</li>
<li>CI must pass all checks</li>
<li>Code coverage should not decrease significantly</li>
<li>Documentation must be updated for user-facing changes</li>
</ul>
<p>This setup guide ensures you have everything needed to contribute effectively to MockForge. Happy coding! 🚀</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="code-style-guide"><a class="header" href="#code-style-guide">Code Style Guide</a></h1>
<p>This guide outlines the coding standards and style guidelines for MockForge development. Consistent code style improves readability, maintainability, and collaboration.</p>
<h2 id="rust-code-style"><a class="header" href="#rust-code-style">Rust Code Style</a></h2>
<p>MockForge follows the official Rust style guidelines with some project-specific conventions.</p>
<h3 id="formatting-1"><a class="header" href="#formatting-1">Formatting</a></h3>
<p>Use <code>rustfmt</code> for automatic code formatting:</p>
<pre><code class="language-bash"># Format all code
cargo fmt

# Check formatting without modifying files
cargo fmt --check
</code></pre>
<h3 id="linting-1"><a class="header" href="#linting-1">Linting</a></h3>
<p>Use <code>clippy</code> for additional code quality checks:</p>
<pre><code class="language-bash"># Run clippy with project settings
cargo clippy

# Run with pedantic mode for stricter checks
cargo clippy -- -W clippy::pedantic
</code></pre>
<h3 id="naming-conventions-1"><a class="header" href="#naming-conventions-1">Naming Conventions</a></h3>
<h4 id="functions-and-variables"><a class="header" href="#functions-and-variables">Functions and Variables</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good: snake_case for functions and variables
fn process_user_data(user_id: i32, data: &amp;str) -&gt; Result&lt;User, Error&gt; {
    let processed_data = validate_and_clean(data)?;
    let user_record = create_user_record(user_id, &amp;processed_data)?;
    Ok(user_record)
}

// Bad: camelCase or PascalCase
fn processUserData(userId: i32, data: &amp;str) -&gt; Result&lt;User, Error&gt; {
    let ProcessedData = validate_and_clean(data)?;
    let userRecord = create_user_record(userId, &amp;ProcessedData)?;
    Ok(userRecord)
}
<span class="boring">}</span></code></pre></pre>
<h4 id="types-and-traits"><a class="header" href="#types-and-traits">Types and Traits</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good: PascalCase for types
pub struct HttpServer {
    config: ServerConfig,
    router: Router,
}

pub trait RequestHandler {
    fn handle_request(&amp;self, request: Request) -&gt; Response;
}

// Bad: snake_case for types
pub struct http_server {
    config: ServerConfig,
    router: Router,
}
<span class="boring">}</span></code></pre></pre>
<h4 id="constants"><a class="header" href="#constants">Constants</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good: SCREAMING_SNAKE_CASE for constants
const MAX_CONNECTIONS: usize = 1000;
const DEFAULT_TIMEOUT_SECS: u64 = 30;

// Bad: camelCase or PascalCase
const maxConnections: usize = 1000;
const DefaultTimeoutSecs: u64 = 30;
<span class="boring">}</span></code></pre></pre>
<h4 id="modules-and-files"><a class="header" href="#modules-and-files">Modules and Files</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good: snake_case for module names
pub mod request_handler;
pub mod template_engine;

// File: request_handler.rs
// Module: request_handler
<span class="boring">}</span></code></pre></pre>
<h3 id="documentation-2"><a class="header" href="#documentation-2">Documentation</a></h3>
<h4 id="function-documentation"><a class="header" href="#function-documentation">Function Documentation</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// Processes a user request and returns a response.
///
/// This function handles the complete request processing pipeline:
/// 1. Validates the request data
/// 2. Applies business logic
/// 3. Returns appropriate response
///
/// # Arguments
///
/// * `user_id` - The ID of the user making the request
/// * `request_data` - The request payload as JSON
///
/// # Returns
///
/// Returns a `Result&lt;Response, Error&gt;` where:
/// - `Ok(response)` contains the successful response
/// - `Err(error)` contains details about what went wrong
///
/// # Errors
///
/// This function will return an error if:
/// - The user ID is invalid
/// - The request data is malformed
/// - Database operations fail
///
/// # Examples
///
/// ```rust
/// let user_id = 123;
/// let request_data = r#"{"action": "update_profile"}"#;
/// let response = process_user_request(user_id, request_data)?;
/// assert_eq!(response.status(), 200);
/// ```
pub fn process_user_request(user_id: i32, request_data: &amp;str) -&gt; Result&lt;Response, Error&gt; {
    // Implementation
}
<span class="boring">}</span></code></pre></pre>
<h4 id="module-documentation"><a class="header" href="#module-documentation">Module Documentation</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>//! # HTTP Server Module
//!
//! This module provides HTTP server functionality for MockForge,
//! including request routing, middleware support, and response handling.
//!
//! ## Architecture
//!
//! The HTTP server uses axum as the underlying web framework and provides:
//! - OpenAPI specification integration
//! - Template-based response generation
//! - Middleware for logging and validation
//!
//! ## Example
//!
//! ```rust
//! use mockforge_http::HttpServer;
//!
//! let server = HttpServer::new(config);
//! server.serve("127.0.0.1:3000").await?;
//! ```
<span class="boring">}</span></code></pre></pre>
<h3 id="error-handling-3"><a class="header" href="#error-handling-3">Error Handling</a></h3>
<h4 id="custom-error-types"><a class="header" href="#custom-error-types">Custom Error Types</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use thiserror::Error;

#[derive(Error, Debug)]
pub enum MockForgeError {
    #[error("Configuration error: {message}")]
    Config { message: String },

    #[error("I/O error: {source}")]
    Io {
        #[from]
        source: std::io::Error,
    },

    #[error("Template rendering error: {message}")]
    Template { message: String },

    #[error("HTTP error: {status} - {message}")]
    Http { status: u16, message: String },
}
<span class="boring">}</span></code></pre></pre>
<h4 id="result-types"><a class="header" href="#result-types">Result Types</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good: Use Result&lt;T, MockForgeError&gt; for fallible operations
pub fn load_config(path: &amp;Path) -&gt; Result&lt;Config, MockForgeError&gt; {
    let content = fs::read_to_string(path)
        .map_err(|e| MockForgeError::Io { source: e })?;

    let config: Config = serde_yaml::from_str(&amp;content)
        .map_err(|e| MockForgeError::Config {
            message: format!("Failed to parse YAML: {}", e),
        })?;

    Ok(config)
}

// Bad: Using Option when you should use Result
pub fn load_config_bad(path: &amp;Path) -&gt; Option&lt;Config&gt; {
    // This loses error information
    None
}
<span class="boring">}</span></code></pre></pre>
<h3 id="async-code"><a class="header" href="#async-code">Async Code</a></h3>
<h4 id="async-function-signatures"><a class="header" href="#async-function-signatures">Async Function Signatures</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good: Clear async function signatures
pub async fn process_request(request: Request) -&gt; Result&lt;Response, Error&gt; {
    let data = validate_request(&amp;request).await?;
    let result = process_data(data).await?;
    Ok(create_response(result))
}

// Bad: Unclear async boundaries
pub fn process_request(request: Request) -&gt; impl Future&lt;Output = Result&lt;Response, Error&gt;&gt; {
    async move {
        // Implementation
    }
}
<span class="boring">}</span></code></pre></pre>
<h4 id="tokio-usage"><a class="header" href="#tokio-usage">Tokio Usage</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tokio::sync::{Mutex, RwLock};

// Good: Use appropriate synchronization primitives
pub struct SharedState {
    data: RwLock&lt;HashMap&lt;String, String&gt;&gt;,
    counter: Mutex&lt;i64&gt;,
}

impl SharedState {
    pub async fn get_data(&amp;self, key: &amp;str) -&gt; Option&lt;String&gt; {
        let data = self.data.read().await;
        data.get(key).cloned()
    }

    pub async fn increment_counter(&amp;self) -&gt; i64 {
        let mut counter = self.counter.lock().await;
        *counter += 1;
        *counter
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="testing-1"><a class="header" href="#testing-1">Testing</a></h3>
<h4 id="unit-test-structure"><a class="header" href="#unit-test-structure">Unit Test Structure</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_function_basic_case() {
        // Given
        let input = "test input";
        let expected = "expected output";

        // When
        let result = process_input(input);

        // Then
        assert_eq!(result, expected);
    }

    #[test]
    fn test_function_error_case() {
        // Given
        let input = "";

        // When
        let result = process_input(input);

        // Then
        assert!(result.is_err());
        assert!(matches!(result.unwrap_err(), Error::InvalidInput(_)));
    }

    #[tokio::test]
    async fn test_async_function() {
        // Given
        let client = create_test_client().await;

        // When
        let response = client.make_request().await.unwrap();

        // Then
        assert_eq!(response.status(), 200);
    }
}
<span class="boring">}</span></code></pre></pre>
<h4 id="test-organization"><a class="header" href="#test-organization">Test Organization</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// tests/integration_tests.rs
#[cfg(test)]
mod integration_tests {
    use mockforge_core::config::MockForgeConfig;

    #[tokio::test]
    async fn test_full_http_flow() {
        // Test complete request/response cycle
        let server = TestServer::new().await;
        let client = TestClient::new(server.url());

        let response = client.get("/api/users").await;
        assert_eq!(response.status(), 200);
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="performance-considerations-3"><a class="header" href="#performance-considerations-3">Performance Considerations</a></h3>
<h4 id="memory-management-1"><a class="header" href="#memory-management-1">Memory Management</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good: Use references when possible
pub fn process_data(data: &amp;str) -&gt; Result&lt;String, Error&gt; {
    // Avoid cloning unless necessary
    if data.is_empty() {
        return Err(Error::EmptyInput);
    }
    Ok(data.to_uppercase())
}

// Good: Use Cow for flexible ownership
use std::borrow::Cow;

pub fn normalize_string&lt;'a&gt;(input: &amp;'a str) -&gt; Cow&lt;'a, str&gt; {
    if input.chars().all(|c| c.is_lowercase()) {
        Cow::Borrowed(input)
    } else {
        Cow::Owned(input.to_lowercase())
    }
}
<span class="boring">}</span></code></pre></pre>
<h4 id="zero-cost-abstractions"><a class="header" href="#zero-cost-abstractions">Zero-Cost Abstractions</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good: Use iterators for memory efficiency
pub fn find_active_users(users: &amp;[User]) -&gt; impl Iterator&lt;Item = &amp;User&gt; {
    users.iter().filter(|user| user.is_active)
}

// Bad: Collect into Vec unnecessarily
pub fn find_active_users_bad(users: &amp;[User]) -&gt; Vec&lt;&amp;User&gt; {
    users.iter().filter(|user| user.is_active).collect()
}
<span class="boring">}</span></code></pre></pre>
<h2 id="project-specific-conventions"><a class="header" href="#project-specific-conventions">Project-Specific Conventions</a></h2>
<h3 id="configuration-handling"><a class="header" href="#configuration-handling">Configuration Handling</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good: Use builder pattern for complex configuration
#[derive(Debug, Clone)]
pub struct ServerConfig {
    pub host: String,
    pub port: u16,
    pub tls: Option&lt;TlsConfig&gt;,
}

impl Default for ServerConfig {
    fn default() -&gt; Self {
        Self {
            host: "127.0.0.1".to_string(),
            port: 3000,
            tls: None,
        }
    }
}

impl ServerConfig {
    pub fn builder() -&gt; ServerConfigBuilder {
        ServerConfigBuilder::default()
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="logging-1"><a class="header" href="#logging-1">Logging</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tracing::{info, warn, error, debug, instrument};

// Good: Use structured logging
#[instrument(skip(config))]
pub async fn start_server(config: &amp;ServerConfig) -&gt; Result&lt;(), Error&gt; {
    info!("Starting server", host = %config.host, port = config.port);

    if let Err(e) = setup_server(config).await {
        error!("Failed to start server", error = %e);
        return Err(e);
    }

    info!("Server started successfully");
    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<h3 id="feature-flags"><a class="header" href="#feature-flags">Feature Flags</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good: Use feature flags for optional functionality
#[cfg(feature = "grpc")]
pub mod grpc {
    // gRPC-specific code
}

#[cfg(feature = "websocket")]
pub mod websocket {
    // WebSocket-specific code
}
<span class="boring">}</span></code></pre></pre>
<h2 id="code-review-checklist"><a class="header" href="#code-review-checklist">Code Review Checklist</a></h2>
<p>Before submitting code for review, ensure:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Code is formatted with <code>cargo fmt</code></li>
<li><input disabled="" type="checkbox"/>
No clippy warnings remain</li>
<li><input disabled="" type="checkbox"/>
All tests pass</li>
<li><input disabled="" type="checkbox"/>
Documentation is updated</li>
<li><input disabled="" type="checkbox"/>
No TODO comments left in production code</li>
<li><input disabled="" type="checkbox"/>
Error messages are user-friendly</li>
<li><input disabled="" type="checkbox"/>
Performance considerations are addressed</li>
<li><input disabled="" type="checkbox"/>
Security implications are reviewed</li>
</ul>
<h2 id="tools-and-automation"><a class="header" href="#tools-and-automation">Tools and Automation</a></h2>
<h3 id="pre-commit-hooks"><a class="header" href="#pre-commit-hooks">Pre-commit Hooks</a></h3>
<pre><code class="language-bash">#!/bin/bash
# .git/hooks/pre-commit

# Format code
cargo fmt --check
if [ $? -ne 0 ]; then
    echo "Code is not formatted. Run 'cargo fmt' to fix."
    exit 1
fi

# Run clippy
cargo clippy -- -D warnings
if [ $? -ne 0 ]; then
    echo "Clippy found issues. Fix them before committing."
    exit 1
fi

# Run tests
cargo test
if [ $? -ne 0 ]; then
    echo "Tests are failing. Fix them before committing."
    exit 1
fi
</code></pre>
<h3 id="ci-configuration"><a class="header" href="#ci-configuration">CI Configuration</a></h3>
<pre><code class="language-yaml"># .github/workflows/ci.yml
name: CI

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - uses: actions-rs/toolchain@v1
      with:
        toolchain: stable

    - name: Check formatting
      run: cargo fmt --check

    - name: Run clippy
      run: cargo clippy -- -D warnings

    - name: Run tests
      run: cargo test --verbose

    - name: Run security audit
      run: cargo audit
</code></pre>
<p>This style guide ensures MockForge maintains high code quality and consistency across the entire codebase. Following these guidelines makes the code more readable, maintainable, and collaborative.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="testing-guidelines"><a class="header" href="#testing-guidelines">Testing Guidelines</a></h1>
<p>This guide outlines the testing standards and practices for MockForge contributions. Quality testing ensures code reliability, prevents regressions, and maintains system stability.</p>
<h2 id="testing-philosophy"><a class="header" href="#testing-philosophy">Testing Philosophy</a></h2>
<h3 id="testing-pyramid"><a class="header" href="#testing-pyramid">Testing Pyramid</a></h3>
<p>MockForge follows a testing pyramid approach with different types of tests serving different purposes:</p>
<pre><code>End-to-End Tests (E2E)
        ↑
Integration Tests
        ↑
Unit Tests
       Base
</code></pre>
<ul>
<li><strong>Unit Tests</strong>: Test individual functions and modules in isolation</li>
<li><strong>Integration Tests</strong>: Test component interactions and data flow</li>
<li><strong>End-to-End Tests</strong>: Test complete user workflows and system behavior</li>
</ul>
<h3 id="testing-principles"><a class="header" href="#testing-principles">Testing Principles</a></h3>
<ol>
<li><strong>Test First</strong>: Write tests before implementation when possible</li>
<li><strong>Test Behavior</strong>: Test what the code does, not how it does it</li>
<li><strong>Test Boundaries</strong>: Focus on edge cases and error conditions</li>
<li><strong>Keep Tests Fast</strong>: Tests should run quickly to encourage frequent execution</li>
<li><strong>Make Tests Reliable</strong>: Tests should be deterministic and not flaky</li>
</ol>
<h2 id="unit-testing-requirements"><a class="header" href="#unit-testing-requirements">Unit Testing Requirements</a></h2>
<h3 id="test-coverage-1"><a class="header" href="#test-coverage-1">Test Coverage</a></h3>
<p>All new code must include unit tests with the following minimum coverage:</p>
<ul>
<li><strong>Functions</strong>: Test all public functions with valid inputs</li>
<li><strong>Error Cases</strong>: Test all error conditions and edge cases</li>
<li><strong>Branches</strong>: Test all conditional branches (if/else, match arms)</li>
<li><strong>Loops</strong>: Test loop boundaries (empty, single item, multiple items)</li>
</ul>
<h3 id="test-structure"><a class="header" href="#test-structure">Test Structure</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_function_name_description() {
        // Given: Set up test data and preconditions
        let input = create_test_input();
        let expected = create_expected_output();

        // When: Execute the function under test
        let result = function_under_test(input);

        // Then: Verify the result matches expectations
        assert_eq!(result, expected);
    }

    #[test]
    fn test_function_name_error_case() {
        // Given: Set up error condition
        let invalid_input = create_invalid_input();

        // When: Execute the function
        let result = function_under_test(invalid_input);

        // Then: Verify error handling
        assert!(result.is_err());
        let error = result.unwrap_err();
        assert!(matches!(error, ExpectedError::Variant));
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="test-naming-conventions"><a class="header" href="#test-naming-conventions">Test Naming Conventions</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good: Descriptive test names
#[test]
fn test_parse_openapi_spec_validates_required_fields() { ... }
#[test]
fn test_template_engine_handles_missing_variables() { ... }
#[test]
fn test_http_server_rejects_invalid_content_type() { ... }

// Bad: Non-descriptive names
#[test]
fn test_function() { ... }
#[test]
fn test_case_1() { ... }
#[test]
fn test_error() { ... }
<span class="boring">}</span></code></pre></pre>
<h3 id="test-data-management"><a class="header" href="#test-data-management">Test Data Management</a></h3>
<h4 id="test-fixtures"><a class="header" href="#test-fixtures">Test Fixtures</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Use shared test fixtures for common data
pub fn sample_openapi_spec() -&gt; &amp;'static str {
    r#"
    openapi: 3.0.3
    info:
      title: Test API
      version: 1.0.0
    paths:
      /users:
        get:
          responses:
            '200':
              description: Success
    "#
}

pub fn sample_user_data() -&gt; User {
    User {
        id: "123".to_string(),
        name: "John Doe".to_string(),
        email: "john@example.com".to_string(),
    }
}
<span class="boring">}</span></code></pre></pre>
<h4 id="test-utilities"><a class="header" href="#test-utilities">Test Utilities</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Create test utilities for common setup
pub struct TestServer {
    server_handle: Option&lt;JoinHandle&lt;()&gt;&gt;,
    base_url: String,
}

impl TestServer {
    pub async fn new() -&gt; Self {
        // Start test server
        // Return configured instance
    }

    pub fn url(&amp;self) -&gt; &amp;str {
        &amp;self.base_url
    }
}

impl Drop for TestServer {
    fn drop(&amp;mut self) {
        // Clean up server
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="integration-testing-standards"><a class="header" href="#integration-testing-standards">Integration Testing Standards</a></h2>
<h3 id="when-to-write-integration-tests"><a class="header" href="#when-to-write-integration-tests">When to Write Integration Tests</a></h3>
<p>Integration tests are required for:</p>
<ul>
<li><strong>API Boundaries</strong>: HTTP endpoints, gRPC services, WebSocket connections</li>
<li><strong>Database Operations</strong>: Data persistence and retrieval</li>
<li><strong>External Services</strong>: Third-party API integrations</li>
<li><strong>File I/O</strong>: Configuration loading, fixture management</li>
<li><strong>Component Communication</strong>: Cross-crate interactions</li>
</ul>
<h3 id="integration-test-structure"><a class="header" href="#integration-test-structure">Integration Test Structure</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod integration_tests {
    use mockforge_core::config::MockForgeConfig;

    #[tokio::test]
    async fn test_http_server_startup() {
        // Given: Configure test server
        let config = create_test_config();
        let server = HttpServer::new(config);

        // When: Start the server
        let addr = server.local_addr();
        tokio::spawn(async move {
            server.serve().await.unwrap();
        });

        // Wait for startup
        tokio::time::sleep(Duration::from_millis(100)).await;

        // Then: Verify server is responding
        let client = reqwest::Client::new();
        let response = client
            .get(format!("http://{}/health", addr))
            .send()
            .await
            .unwrap();

        assert_eq!(response.status(), 200);
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="database-testing"><a class="header" href="#database-testing">Database Testing</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod database_tests {
    use sqlx::PgPool;

    #[sqlx::test]
    async fn test_user_creation(pool: PgPool) {
        // Given: Clean database state
        sqlx::query!("DELETE FROM users").execute(&amp;pool).await.unwrap();

        // When: Create a user
        let user_id = create_user(&amp;pool, "test@example.com").await.unwrap();

        // Then: Verify user exists
        let user = sqlx::query!("SELECT * FROM users WHERE id = $1", user_id)
            .fetch_one(&amp;pool)
            .await
            .unwrap();

        assert_eq!(user.email, "test@example.com");
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="end-to-end-testing-requirements"><a class="header" href="#end-to-end-testing-requirements">End-to-End Testing Requirements</a></h2>
<h3 id="e2e-test-scenarios"><a class="header" href="#e2e-test-scenarios">E2E Test Scenarios</a></h3>
<p>E2E tests must cover:</p>
<ul>
<li><strong>Happy Path</strong>: Complete successful user workflows</li>
<li><strong>Error Recovery</strong>: System behavior under failure conditions</li>
<li><strong>Data Persistence</strong>: State changes across operations</li>
<li><strong>Performance</strong>: Response times and resource usage</li>
<li><strong>Security</strong>: Authentication and authorization flows</li>
</ul>
<h3 id="e2e-test-implementation"><a class="header" href="#e2e-test-implementation">E2E Test Implementation</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod e2e_tests {
    use std::process::Command;
    use std::time::Duration;

    #[test]
    fn test_complete_api_workflow() {
        // Start MockForge server
        let mut server = Command::new("cargo")
            .args(&amp;["run", "--release", "--", "serve", "--spec", "test-api.yaml"])
            .spawn()
            .unwrap();

        // Wait for server startup
        std::thread::sleep(Duration::from_secs(3));

        // Execute complete workflow
        let result = run_workflow_test();
        assert!(result.is_ok());

        // Cleanup
        server.kill().unwrap();
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="test-quality-standards"><a class="header" href="#test-quality-standards">Test Quality Standards</a></h2>
<h3 id="code-coverage-requirements"><a class="header" href="#code-coverage-requirements">Code Coverage Requirements</a></h3>
<ul>
<li><strong>Minimum Coverage</strong>: 80% overall, 90% for critical paths</li>
<li><strong>Branch Coverage</strong>: All conditional branches must be tested</li>
<li><strong>Error Path Coverage</strong>: All error conditions must be tested</li>
</ul>
<h3 id="performance-testing-1"><a class="header" href="#performance-testing-1">Performance Testing</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod performance_tests {
    use criterion::Criterion;

    fn benchmark_template_rendering(c: &amp;mut Criterion) {
        let engine = TemplateEngine::new();

        c.bench_function("render_simple_template", |b| {
            b.iter(|| {
                engine.render("Hello {{name}}", &amp;[("name", "World")]);
            })
        });
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="load-testing-3"><a class="header" href="#load-testing-3">Load Testing</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod load_tests {
    use tokio::time::{Duration, Instant};

    #[tokio::test]
    async fn test_concurrent_requests() {
        let client = reqwest::Client::new();
        let start = Instant::now();

        // Spawn 100 concurrent requests
        let handles: Vec&lt;_&gt; = (0..100).map(|_| {
            let client = client.clone();
            tokio::spawn(async move {
                client.get("http://localhost:3000/api/users")
                    .send()
                    .await
                    .unwrap()
            })
        }).collect();

        // Wait for all requests to complete
        for handle in handles {
            let response = handle.await.unwrap();
            assert_eq!(response.status(), 200);
        }

        let duration = start.elapsed();
        assert!(duration &lt; Duration::from_secs(5), "Load test took too long: {:?}", duration);
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="testing-tools-and-frameworks"><a class="header" href="#testing-tools-and-frameworks">Testing Tools and Frameworks</a></h2>
<h3 id="required-testing-dependencies"><a class="header" href="#required-testing-dependencies">Required Testing Dependencies</a></h3>
<pre><code class="language-toml">[dev-dependencies]
tokio-test = "0.4"
proptest = "1.0"          # Property-based testing
criterion = "0.4"         # Benchmarking
assert_cmd = "2.0"        # CLI testing
predicates = "2.1"        # Value assertions
tempfile = "3.0"          # Temporary files
</code></pre>
<h3 id="mocking-and-stubbing"><a class="header" href="#mocking-and-stubbing">Mocking and Stubbing</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod mock_tests {
    use mockall::mock;

    #[mockall::mock]
    trait Database {
        async fn get_user(&amp;self, id: i32) -&gt; Result&lt;User, Error&gt;;
        async fn save_user(&amp;self, user: User) -&gt; Result&lt;(), Error&gt;;
    }

    #[tokio::test]
    async fn test_service_with_mocks() {
        let mut mock_db = MockDatabase::new();

        mock_db
            .expect_get_user()
            .with(eq(123))
            .returning(|_| Ok(User { id: 123, name: "Test".to_string() }));

        let service = UserService::new(mock_db);
        let user = service.get_user(123).await.unwrap();

        assert_eq!(user.name, "Test");
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="property-based-testing"><a class="header" href="#property-based-testing">Property-Based Testing</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod property_tests {
    use proptest::prelude::*;

    proptest! {
        #[test]
        fn test_template_rendering_with_random_input(
            input in "\\PC*",  // Any printable character except control chars
            name in "[a-zA-Z]{1,10}"
        ) {
            let engine = TemplateEngine::new();
            let context = &amp;[("name", &amp;name)];

            // Should not panic regardless of input
            let _result = engine.render(&amp;input, context);
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="test-organization-and-naming"><a class="header" href="#test-organization-and-naming">Test Organization and Naming</a></h2>
<h3 id="file-structure"><a class="header" href="#file-structure">File Structure</a></h3>
<pre><code>src/
├── lib.rs
├── module.rs
└── module/
    ├── mod.rs
    └── submodule.rs

tests/
├── unit/
│   ├── module_tests.rs
│   └── submodule_tests.rs
├── integration/
│   ├── api_tests.rs
│   └── database_tests.rs
└── e2e/
    ├── workflow_tests.rs
    └── performance_tests.rs
</code></pre>
<h3 id="test-module-organization"><a class="header" href="#test-module-organization">Test Module Organization</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// tests/unit/template_tests.rs
#[cfg(test)]
mod template_tests {
    use mockforge_core::templating::TemplateEngine;

    // Unit tests for template functionality
}

// tests/integration/http_tests.rs
#[cfg(test)]
mod http_integration_tests {
    use mockforge_http::HttpServer;

    // Integration tests for HTTP server
}

// tests/e2e/api_workflow_tests.rs
#[cfg(test)]
mod e2e_tests {
    // End-to-end workflow tests
}
<span class="boring">}</span></code></pre></pre>
<h2 id="cicd-integration-1"><a class="header" href="#cicd-integration-1">CI/CD Integration</a></h2>
<h3 id="github-actions-testing-1"><a class="header" href="#github-actions-testing-1">GitHub Actions Testing</a></h3>
<pre><code class="language-yaml">name: Test

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v3
    - uses: dtolnay/rust-toolchain@stable

    - name: Cache dependencies
      uses: Swatinem/rust-cache@v2

    - name: Check formatting
      run: cargo fmt --check

    - name: Run clippy
      run: cargo clippy -- -D warnings

    - name: Run tests
      run: cargo test --verbose

    - name: Run integration tests
      run: cargo test --test integration

    - name: Generate coverage
      run: |
        cargo install cargo-tarpaulin
        cargo tarpaulin --out Xml --output-dir coverage

    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        file: coverage/cobertura.xml
</code></pre>
<h3 id="test-result-reporting"><a class="header" href="#test-result-reporting">Test Result Reporting</a></h3>
<pre><code class="language-yaml">- name: Run tests with JUnit output
  run: |
    cargo install cargo2junit
    cargo test -- -Z unstable-options --format json | cargo2junit &gt; test-results.xml

- name: Publish test results
  uses: EnricoMi/publish-unit-test-result-action@v2
  with:
    files: test-results.xml
</code></pre>
<h2 id="best-practices-8"><a class="header" href="#best-practices-8">Best Practices</a></h2>
<h3 id="test-isolation"><a class="header" href="#test-isolation">Test Isolation</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod isolated_tests {
    use tempfile::TempDir;

    #[test]
    fn test_file_operations() {
        // Use temporary directory for isolation
        let temp_dir = TempDir::new().unwrap();
        let file_path = temp_dir.path().join("test.txt");

        // Test file operations
        write_test_file(&amp;file_path);
        assert!(file_path.exists());

        // Cleanup happens automatically
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="test-data-management-1"><a class="header" href="#test-data-management-1">Test Data Management</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod test_data {
    use once_cell::sync::Lazy;

    static TEST_USERS: Lazy&lt;Vec&lt;User&gt;&gt; = Lazy::new(|| {
        vec![
            User { id: 1, name: "Alice".to_string() },
            User { id: 2, name: "Bob".to_string() },
        ]
    });

    #[test]
    fn test_user_operations() {
        let users = TEST_USERS.clone();
        // Use shared test data
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="asynchronous-testing"><a class="header" href="#asynchronous-testing">Asynchronous Testing</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod async_tests {
    use tokio::time::{timeout, Duration};

    #[tokio::test]
    async fn test_async_operation_with_timeout() {
        let result = timeout(Duration::from_secs(5), async_operation()).await;

        match result {
            Ok(Ok(data)) =&gt; assert!(data.is_valid()),
            Ok(Err(e)) =&gt; panic!("Operation failed: {}", e),
            Err(_) =&gt; panic!("Operation timed out"),
        }
    }

    #[tokio::test]
    async fn test_concurrent_operations() {
        let (result1, result2) = tokio::join(
            operation1(),
            operation2()
        );

        assert!(result1.is_ok());
        assert!(result2.is_ok());
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="test-flakiness-prevention"><a class="header" href="#test-flakiness-prevention">Test Flakiness Prevention</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod reliable_tests {
    #[test]
    fn test_with_retries() {
        let mut attempts = 0;
        let max_attempts = 3;

        loop {
            attempts += 1;

            match potentially_flaky_operation() {
                Ok(result) =&gt; {
                    assert!(result.is_valid());
                    break;
                }
                Err(e) if attempts &lt; max_attempts =&gt; {
                    eprintln!("Attempt {} failed: {}, retrying...", attempts, e);
                    std::thread::sleep(Duration::from_millis(100));
                    continue;
                }
                Err(e) =&gt; panic!("Operation failed after {} attempts: {}", max_attempts, e),
            }
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="security-testing-1"><a class="header" href="#security-testing-1">Security Testing</a></h2>
<h3 id="input-validation-testing"><a class="header" href="#input-validation-testing">Input Validation Testing</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod security_tests {
    #[test]
    fn test_sql_injection_prevention() {
        let malicious_input = "'; DROP TABLE users; --";
        let result = sanitize_sql_input(malicious_input);

        assert!(!result.contains("DROP"));
        assert!(!result.contains(";"));
    }

    #[test]
    fn test_xss_prevention() {
        let malicious_input = "&lt;script&gt;alert('xss')&lt;/script&gt;";
        let result = sanitize_html_input(malicious_input);

        assert!(!result.contains("&lt;script&gt;"));
        assert!(result.contains("&amp;lt;script&amp;gt;"));
    }

    #[test]
    fn test_path_traversal_prevention() {
        let malicious_input = "../../../etc/passwd";
        let result = validate_file_path(malicious_input);

        assert!(result.is_err());
        assert!(matches!(result.unwrap_err(), ValidationError::PathTraversal));
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="authentication-testing"><a class="header" href="#authentication-testing">Authentication Testing</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod auth_tests {
    #[tokio::test]
    async fn test_unauthorized_access() {
        let client = create_test_client();

        let response = client
            .get("/admin/users")
            .send()
            .await
            .unwrap();

        assert_eq!(response.status(), 401);
    }

    #[tokio::test]
    async fn test_authorized_access() {
        let client = create_authenticated_client();

        let response = client
            .get("/admin/users")
            .send()
            .await
            .unwrap();

        assert_eq!(response.status(), 200);
    }
}
<span class="boring">}</span></code></pre></pre>
<p>This comprehensive testing guide ensures MockForge maintains high quality and reliability through thorough automated testing at all levels.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="release-process"><a class="header" href="#release-process">Release Process</a></h1>
<p>This guide outlines the complete process for releasing new versions of MockForge, from planning through deployment and post-release activities.</p>
<h2 id="release-planning"><a class="header" href="#release-planning">Release Planning</a></h2>
<h3 id="version-numbering"><a class="header" href="#version-numbering">Version Numbering</a></h3>
<p>MockForge follows <a href="https://semver.org/">Semantic Versioning</a> (SemVer):</p>
<pre><code>MAJOR.MINOR.PATCH[-PRERELEASE][+BUILD]

Examples:
- 1.0.0 (stable release)
- 1.1.0 (minor release with new features)
- 1.1.1 (patch release with bug fixes)
- 2.0.0-alpha.1 (pre-release)
- 1.0.0+20230912 (build metadata)
</code></pre>
<h4 id="when-to-increment"><a class="header" href="#when-to-increment">When to Increment</a></h4>
<ul>
<li><strong>MAJOR</strong> (X.0.0): Breaking changes to public API</li>
<li><strong>MINOR</strong> (X.Y.0): New features, backward compatible</li>
<li><strong>PATCH</strong> (X.Y.Z): Bug fixes, backward compatible</li>
</ul>
<h3 id="release-types"><a class="header" href="#release-types">Release Types</a></h3>
<h4 id="major-releases"><a class="header" href="#major-releases">Major Releases</a></h4>
<ul>
<li>Breaking API changes</li>
<li>Major feature additions</li>
<li>Architectural changes</li>
<li>Extended testing period (2-4 weeks beta)</li>
</ul>
<h4 id="minor-releases"><a class="header" href="#minor-releases">Minor Releases</a></h4>
<ul>
<li>New features and enhancements</li>
<li>Backward compatible API changes</li>
<li>Standard testing period (1-2 weeks)</li>
</ul>
<h4 id="patch-releases"><a class="header" href="#patch-releases">Patch Releases</a></h4>
<ul>
<li>Critical bug fixes</li>
<li>Security patches</li>
<li>Documentation updates</li>
<li>Minimal testing period (3-5 days)</li>
</ul>
<h4 id="pre-releases"><a class="header" href="#pre-releases">Pre-releases</a></h4>
<ul>
<li>Alpha/Beta/RC versions</li>
<li>Feature previews</li>
<li>Breaking change previews</li>
<li>Limited distribution</li>
</ul>
<h2 id="pre-release-checklist"><a class="header" href="#pre-release-checklist">Pre-Release Checklist</a></h2>
<h3 id="1-code-quality-verification"><a class="header" href="#1-code-quality-verification">1. Code Quality Verification</a></h3>
<pre><code class="language-bash"># Run complete test suite
make test

# Run integration tests
make test-integration

# Run E2E tests
make test-e2e

# Check code quality
make lint
make format-check

# Security audit
cargo audit

# Check for unused dependencies
cargo +nightly udeps

# Performance benchmarks
make benchmark
</code></pre>
<h3 id="2-documentation-updates"><a class="header" href="#2-documentation-updates">2. Documentation Updates</a></h3>
<pre><code class="language-bash"># Update CHANGELOG.md with release notes
# Update version numbers in documentation
# Build and test documentation
make docs
make docs-serve

# Test documentation links
mdbook test
</code></pre>
<h3 id="3-version-bump"><a class="header" href="#3-version-bump">3. Version Bump</a></h3>
<pre><code class="language-bash"># Update version in Cargo.toml files
# Update version in package metadata
# Update version in documentation

# Example version bump script
#!/bin/bash
NEW_VERSION=$1

# Update workspace Cargo.toml
sed -i "s/^version = .*/version = \"$NEW_VERSION\"/" Cargo.toml

# Update all crate Cargo.toml files
find crates -name "Cargo.toml" -exec sed -i "s/^version = .*/version = \"$NEW_VERSION\"/" {} \;

# Update README and documentation version references
sed -i "s/mockforge [0-9]\+\.[0-9]\+\.[0-9]\+/mockforge $NEW_VERSION/g" README.md
</code></pre>
<h3 id="4-branch-management"><a class="header" href="#4-branch-management">4. Branch Management</a></h3>
<pre><code class="language-bash"># Create release branch
git checkout -b release/v$NEW_VERSION

# Cherry-pick approved commits
# Or merge from develop/main

# Tag the release
git tag -a v$NEW_VERSION -m "Release version $NEW_VERSION"

# Push branch and tag
git push origin release/v$NEW_VERSION
git push origin v$NEW_VERSION
</code></pre>
<h2 id="release-build-process"><a class="header" href="#release-build-process">Release Build Process</a></h2>
<h3 id="1-build-verification"><a class="header" href="#1-build-verification">1. Build Verification</a></h3>
<pre><code class="language-bash"># Clean build
cargo clean

# Build all targets
cargo build --release --all-targets

# Build specific platforms if needed
cargo build --release --target x86_64-unknown-linux-gnu
cargo build --release --target x86_64-apple-darwin
cargo build --release --target x86_64-pc-windows-msvc

# Test release build
./target/release/mockforge-cli --version
</code></pre>
<h3 id="2-binary-distribution"><a class="header" href="#2-binary-distribution">2. Binary Distribution</a></h3>
<h4 id="linuxmacos-packages"><a class="header" href="#linuxmacos-packages">Linux/macOS Packages</a></h4>
<pre><code class="language-bash"># Strip debug symbols
strip target/release/mockforge-cli

# Create distribution archives
VERSION=1.0.0
tar -czf mockforge-v${VERSION}-x86_64-linux.tar.gz \
  -C target/release mockforge-cli

tar -czf mockforge-v${VERSION}-x86_64-macos.tar.gz \
  -C target/release mockforge-cli
</code></pre>
<h4 id="debian-packages"><a class="header" href="#debian-packages">Debian Packages</a></h4>
<pre><code class="language-bash"># Install cargo-deb
cargo install cargo-deb

# Build .deb package
cargo deb

# Test package installation
sudo dpkg -i target/debian/mockforge_*.deb
</code></pre>
<h4 id="docker-images"><a class="header" href="#docker-images">Docker Images</a></h4>
<pre><code class="language-dockerfile"># Dockerfile.release
FROM rust:1.70-slim AS builder
WORKDIR /app
COPY . .
RUN cargo build --release

FROM debian:bookworm-slim
RUN apt-get update &amp;&amp; apt-get install -y ca-certificates &amp;&amp; rm -rf /var/lib/apt/lists/*
COPY --from=builder /app/target/release/mockforge-cli /usr/local/bin/mockforge-cli
EXPOSE 3000 3001 50051 8080
CMD ["mockforge-cli", "serve"]
</code></pre>
<pre><code class="language-bash"># Build and push Docker image
docker build -f Dockerfile.release -t mockforge:$VERSION .
docker tag mockforge:$VERSION mockforge:latest
docker push mockforge:$VERSION
docker push mockforge:latest
</code></pre>
<h3 id="3-cross-platform-builds"><a class="header" href="#3-cross-platform-builds">3. Cross-Platform Builds</a></h3>
<pre><code class="language-bash"># Use cross for cross-compilation
cargo install cross

# Build for different architectures
cross build --release --target aarch64-unknown-linux-gnu
cross build --release --target x86_64-unknown-linux-musl

# Create release archives for each platform
for target in x86_64-unknown-linux-gnu aarch64-unknown-linux-gnu x86_64-apple-darwin x86_64-pc-windows-msvc; do
  cross build --release --target $target
  if [[ $target == *"windows"* ]]; then
    zip -j mockforge-$VERSION-$target.zip target/$target/release/mockforge-cli.exe
  else
    tar -czf mockforge-$VERSION-$target.tar.gz -C target/$target/release mockforge-cli
  fi
done
</code></pre>
<h2 id="release-deployment"><a class="header" href="#release-deployment">Release Deployment</a></h2>
<h3 id="1-github-release"><a class="header" href="#1-github-release">1. GitHub Release</a></h3>
<pre><code class="language-bash"># Create GitHub release (manual or automated)
gh release create v$VERSION \
  --title "MockForge v$VERSION" \
  --notes-file release-notes.md \
  --draft

# Upload release assets
gh release upload v$VERSION \
  mockforge-v$VERSION-x86_64-linux.tar.gz \
  mockforge-v$VERSION-x86_64-macos.tar.gz \
  mockforge-v$VERSION-x86_64-windows.zip \
  mockforge_$VERSION_amd64.deb

# Publish release
gh release edit v$VERSION --draft=false
</code></pre>
<h3 id="2-package-registries"><a class="header" href="#2-package-registries">2. Package Registries</a></h3>
<h4 id="cratesio-publication"><a class="header" href="#cratesio-publication">Crates.io Publication</a></h4>
<pre><code class="language-bash"># Publish all crates to crates.io
# Note: Must be done in dependency order

# Publish core first
cd crates/mockforge-core
cargo publish

# Then other crates
cd ../mockforge-http
cargo publish

cd ../mockforge-ws
cargo publish

cd ../mockforge-grpc
cargo publish

cd ../mockforge-data
cargo publish

cd ../mockforge-ui
cargo publish

# Finally CLI
cd ../mockforge-cli
cargo publish
</code></pre>
<h4 id="docker-hub"><a class="header" href="#docker-hub">Docker Hub</a></h4>
<pre><code class="language-bash"># Tag and push Docker images
docker tag mockforge:$VERSION mockforge/mockforge:$VERSION
docker tag mockforge:$VERSION mockforge/mockforge:latest

docker push mockforge/mockforge:$VERSION
docker push mockforge/mockforge:latest
</code></pre>
<h3 id="3-homebrew-macos"><a class="header" href="#3-homebrew-macos">3. Homebrew (macOS)</a></h3>
<pre><code class="language-ruby"># Formula/mockforge.rb
class Mockforge &lt; Formula
  desc "Advanced API Mocking Platform"
  homepage "https://github.com/SaaSy-Solutions/mockforge"
  url "https://github.com/SaaSy-Solutions/mockforge/releases/download/v#{version}/mockforge-v#{version}-x86_64-macos.tar.gz"
  sha256 "..."

  def install
    bin.install "mockforge-cli"
  end

  test do
    system "#{bin}/mockforge-cli", "--version"
  end
end
</code></pre>
<h3 id="4-package-managers"><a class="header" href="#4-package-managers">4. Package Managers</a></h3>
<h4 id="apt-repository-ubuntudebian"><a class="header" href="#apt-repository-ubuntudebian">APT Repository (Ubuntu/Debian)</a></h4>
<pre><code class="language-bash"># Set up PPA or repository
# Upload .deb packages
# Update package indices
</code></pre>
<h4 id="snapcraft"><a class="header" href="#snapcraft">Snapcraft</a></h4>
<pre><code class="language-yaml"># snapcraft.yaml
name: mockforge
version: '1.0.0'
summary: Advanced API Mocking Platform
description: |
  MockForge is a comprehensive API mocking platform supporting HTTP, WebSocket, and gRPC protocols.

grade: stable
confinement: strict

apps:
  mockforge:
    command: mockforge-cli
    plugs: [network, network-bind]

parts:
  mockforge:
    plugin: rust
    source: .
    build-packages: [pkg-config, libssl-dev]
</code></pre>
<h2 id="post-release-activities"><a class="header" href="#post-release-activities">Post-Release Activities</a></h2>
<h3 id="1-announcement"><a class="header" href="#1-announcement">1. Announcement</a></h3>
<h4 id="github-release-notes"><a class="header" href="#github-release-notes">GitHub Release Notes</a></h4>
<pre><code class="language-markdown">## What's New in MockForge v1.0.0

### 🚀 Major Features
- Multi-protocol support (HTTP, WebSocket, gRPC)
- Advanced templating system
- Web-based admin UI
- Comprehensive testing framework

### 🐛 Bug Fixes
- Fixed template rendering performance
- Resolved WebSocket connection stability
- Improved error messages

### 📚 Documentation
- Complete API reference
- Getting started guides
- Troubleshooting documentation

### 🤝 Contributors
Special thanks to all contributors!

### 🔗 Links
- [Documentation](https://docs.mockforge.dev)
- [GitHub Repository](https://github.com/SaaSy-Solutions/mockforge)
- [Issue Tracker](https://github.com/SaaSy-Solutions/mockforge/issues)
</code></pre>
<h4 id="social-media--community"><a class="header" href="#social-media--community">Social Media &amp; Community</a></h4>
<pre><code class="language-bash"># Post to social media
# Update Discord/Slack channels
# Send email newsletter
# Update website/blog
</code></pre>
<h3 id="2-monitoring--support"><a class="header" href="#2-monitoring--support">2. Monitoring &amp; Support</a></h3>
<h4 id="release-health-checks"><a class="header" href="#release-health-checks">Release Health Checks</a></h4>
<pre><code class="language-bash"># Monitor installation success
# Check for immediate bug reports
# Monitor CI/CD pipelines
# Track adoption metrics

# Example monitoring script
#!/bin/bash
VERSION=$1

# Check GitHub release downloads
gh release view v$VERSION --json assets -q '.assets[].downloadCount'

# Check crates.io download stats
curl -s "https://crates.io/api/v1/crates/mockforge-cli/downloads" | jq '.versions[0].downloads'

# Monitor error reports
gh issue list --label bug --state open --limit 10
</code></pre>
<h4 id="support-channels"><a class="header" href="#support-channels">Support Channels</a></h4>
<ul>
<li><strong>GitHub Issues</strong>: Bug reports and feature requests</li>
<li><strong>GitHub Discussions</strong>: General questions and support</li>
<li><strong>Discord/Slack</strong>: Real-time community support</li>
<li><strong>Documentation</strong>: Self-service troubleshooting</li>
</ul>
<h3 id="3-follow-up-releases"><a class="header" href="#3-follow-up-releases">3. Follow-up Releases</a></h3>
<h4 id="hotfix-process"><a class="header" href="#hotfix-process">Hotfix Process</a></h4>
<p>For critical issues discovered post-release:</p>
<pre><code class="language-bash"># Create hotfix branch from release tag
git checkout -b hotfix/critical-bug-fix v1.0.0

# Apply fix
# Write test
# Update CHANGELOG

# Create patch release
NEW_VERSION=1.0.1
git tag -a v$NEW_VERSION
git push origin v$NEW_VERSION

# Deploy hotfix
</code></pre>
<h3 id="4-analytics--metrics"><a class="header" href="#4-analytics--metrics">4. Analytics &amp; Metrics</a></h3>
<h4 id="release-metrics"><a class="header" href="#release-metrics">Release Metrics</a></h4>
<ul>
<li>Download counts across platforms</li>
<li>Installation success rates</li>
<li>User adoption and usage patterns</li>
<li>Performance benchmarks vs previous versions</li>
<li>Community feedback and sentiment</li>
</ul>
<h4 id="continuous-improvement"><a class="header" href="#continuous-improvement">Continuous Improvement</a></h4>
<pre><code class="language-yaml"># Post-release retrospective template
## Release Summary
- Version: v1.0.0
- Release Date: YYYY-MM-DD
- Duration: X weeks

## What Went Well
- [ ] Smooth release process
- [ ] No critical bugs found
- [ ] Good community reception

## Areas for Improvement
- [ ] Documentation could be clearer
- [ ] Testing took longer than expected
- [ ] More platform support needed

## Action Items
- [ ] Improve release documentation
- [ ] Automate more of the process
- [ ] Add more platform builds
</code></pre>
<h2 id="release-automation"><a class="header" href="#release-automation">Release Automation</a></h2>
<h3 id="github-actions-release-workflow"><a class="header" href="#github-actions-release-workflow">GitHub Actions Release Workflow</a></h3>
<pre><code class="language-yaml"># .github/workflows/release.yml
name: Release

on:
  push:
    tags:
      - 'v*'

jobs:
  release:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v3

    - name: Set version
      run: echo "VERSION=${GITHUB_REF#refs/tags/v}" &gt;&gt; $GITHUB_ENV

    - name: Build release binaries
      run: |
        cargo build --release
        strip target/release/mockforge-cli

    - name: Create release archives
      run: |
        tar -czf mockforge-${VERSION}-linux-x64.tar.gz -C target/release mockforge-cli
        zip mockforge-${VERSION}-linux-x64.zip target/release/mockforge-cli

    - name: Create GitHub release
      uses: actions/create-release@v1
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      with:
        tag_name: ${{ github.ref }}
        release_name: MockForge ${{ env.VERSION }}
        body: |
          ## What's New

          See [CHANGELOG.md](CHANGELOG.md) for details.

          ## Downloads

          - Linux x64: [mockforge-${{ env.VERSION }}-linux-x64.tar.gz](mockforge-${{ env.VERSION }}-linux-x64.tar.gz)
        draft: false
        prerelease: false

    - name: Upload release assets
      uses: actions/upload-release-asset@v1
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      with:
        upload_url: ${{ steps.create_release.outputs.upload_url }}
        asset_path: ./mockforge-${{ env.VERSION }}-linux-x64.tar.gz
        asset_name: mockforge-${{ env.VERSION }}-linux-x64.tar.gz
        asset_content_type: application/gzip
</code></pre>
<h3 id="automated-publishing"><a class="header" href="#automated-publishing">Automated Publishing</a></h3>
<pre><code class="language-yaml"># Publish to crates.io on release
- name: Publish to crates.io
  run: cargo publish --token ${{ secrets.CRATES_IO_TOKEN }}
  if: startsWith(github.ref, 'refs/tags/')

# Build and push Docker image
- name: Build and push Docker image
  uses: docker/build-push-action@v3
  with:
    context: .
    push: true
    tags: mockforge/mockforge:${{ env.VERSION }},mockforge/mockforge:latest
</code></pre>
<h2 id="emergency-releases"><a class="header" href="#emergency-releases">Emergency Releases</a></h2>
<h3 id="security-vulnerabilities"><a class="header" href="#security-vulnerabilities">Security Vulnerabilities</a></h3>
<p>For security issues requiring immediate release:</p>
<ol>
<li><strong>Assess Severity</strong>: Determine CVSS score and impact</li>
<li><strong>Develop Fix</strong>: Create minimal fix with comprehensive tests</li>
<li><strong>Bypass Normal Process</strong>: Skip extended testing for critical security fixes</li>
<li><strong>Accelerated Release</strong>: 24-48 hour release cycle</li>
<li><strong>Public Disclosure</strong>: Coordinate with security community</li>
</ol>
<h3 id="critical-bug-fixes"><a class="header" href="#critical-bug-fixes">Critical Bug Fixes</a></h3>
<p>For show-stopping bugs affecting production:</p>
<ol>
<li><strong>Immediate Assessment</strong>: Evaluate user impact and severity</li>
<li><strong>Rapid Development</strong>: 1-2 day fix development</li>
<li><strong>Limited Testing</strong>: Focus on regression and critical path tests</li>
<li><strong>Fast-Track Release</strong>: 3-5 day release cycle</li>
</ol>
<p>This comprehensive release process ensures MockForge releases are reliable, well-tested, and properly distributed across all supported platforms and package managers.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="configuration-schema"><a class="header" href="#configuration-schema">Configuration Schema</a></h1>
<p>MockForge supports comprehensive configuration through YAML files. This schema reference documents all available configuration options, their types, defaults, and usage examples.</p>
<h2 id="file-format"><a class="header" href="#file-format">File Format</a></h2>
<p>Configuration files use YAML format with the following structure:</p>
<pre><code class="language-yaml"># Top-level configuration sections
server:        # Server port and binding configuration
admin:         # Admin UI settings
validation:    # Request validation settings
response:      # Response processing options
chaos:         # Chaos engineering features
grpc:          # gRPC-specific settings
websocket:     # WebSocket-specific settings
logging:       # Logging configuration
</code></pre>
<h2 id="server-configuration"><a class="header" href="#server-configuration">Server Configuration</a></h2>
<h3 id="serverhttp_port-integer-default-3000"><a class="header" href="#serverhttp_port-integer-default-3000"><code>server.http_port</code> (integer, default: 3000)</a></h3>
<p>HTTP server port for REST API endpoints.</p>
<pre><code class="language-yaml">server:
  http_port: 8080
</code></pre>
<h3 id="serverws_port-integer-default-3001"><a class="header" href="#serverws_port-integer-default-3001"><code>server.ws_port</code> (integer, default: 3001)</a></h3>
<p>WebSocket server port for real-time connections.</p>
<pre><code class="language-yaml">server:
  ws_port: 8081
</code></pre>
<h3 id="servergrpc_port-integer-default-50051"><a class="header" href="#servergrpc_port-integer-default-50051"><code>server.grpc_port</code> (integer, default: 50051)</a></h3>
<p>gRPC server port for protocol buffer services.</p>
<pre><code class="language-yaml">server:
  grpc_port: 9090
</code></pre>
<h3 id="serverbind-string-default-0000"><a class="header" href="#serverbind-string-default-0000"><code>server.bind</code> (string, default: “0.0.0.0”)</a></h3>
<p>Network interface to bind servers to.</p>
<pre><code class="language-yaml">server:
  bind: "127.0.0.1"  # Bind to localhost only
</code></pre>
<h2 id="admin-ui-configuration-2"><a class="header" href="#admin-ui-configuration-2">Admin UI Configuration</a></h2>
<h3 id="adminenabled-boolean-default-false"><a class="header" href="#adminenabled-boolean-default-false"><code>admin.enabled</code> (boolean, default: false)</a></h3>
<p>Enable the web-based admin interface.</p>
<pre><code class="language-yaml">admin:
  enabled: true
</code></pre>
<h3 id="adminport-integer-default-8080"><a class="header" href="#adminport-integer-default-8080"><code>admin.port</code> (integer, default: 8080)</a></h3>
<p>Port for the admin UI server.</p>
<pre><code class="language-yaml">admin:
  port: 9090
</code></pre>
<h3 id="adminembedded-boolean-default-false"><a class="header" href="#adminembedded-boolean-default-false"><code>admin.embedded</code> (boolean, default: false)</a></h3>
<p>Embed admin UI under the main HTTP server instead of running standalone.</p>
<pre><code class="language-yaml">admin:
  embedded: true
</code></pre>
<h3 id="adminmount_path-string-default-admin"><a class="header" href="#adminmount_path-string-default-admin"><code>admin.mount_path</code> (string, default: “/admin”)</a></h3>
<p>URL path where embedded admin UI is accessible.</p>
<pre><code class="language-yaml">admin:
  embedded: true
  mount_path: "/mockforge-admin"
</code></pre>
<h3 id="adminstandalone-boolean-default-true"><a class="header" href="#adminstandalone-boolean-default-true"><code>admin.standalone</code> (boolean, default: true)</a></h3>
<p>Force standalone admin UI server (overrides embedded setting).</p>
<pre><code class="language-yaml">admin:
  standalone: true
</code></pre>
<h3 id="admindisable_api-boolean-default-false"><a class="header" href="#admindisable_api-boolean-default-false"><code>admin.disable_api</code> (boolean, default: false)</a></h3>
<p>Disable admin API endpoints while keeping the UI interface.</p>
<pre><code class="language-yaml">admin:
  disable_api: false
</code></pre>
<h2 id="validation-configuration"><a class="header" href="#validation-configuration">Validation Configuration</a></h2>
<h3 id="validationmode-string-default-enforce"><a class="header" href="#validationmode-string-default-enforce"><code>validation.mode</code> (string, default: “enforce”)</a></h3>
<p>Request validation mode. Options: “off”, “warn”, “enforce”</p>
<pre><code class="language-yaml">validation:
  mode: warn  # Log warnings but allow invalid requests
</code></pre>
<h3 id="validationaggregate_errors-boolean-default-false"><a class="header" href="#validationaggregate_errors-boolean-default-false"><code>validation.aggregate_errors</code> (boolean, default: false)</a></h3>
<p>Combine multiple validation errors into a single JSON array response.</p>
<pre><code class="language-yaml">validation:
  aggregate_errors: true
</code></pre>
<h3 id="validationvalidate_responses-boolean-default-false"><a class="header" href="#validationvalidate_responses-boolean-default-false"><code>validation.validate_responses</code> (boolean, default: false)</a></h3>
<p>Validate response payloads against OpenAPI schemas (warn-only).</p>
<pre><code class="language-yaml">validation:
  validate_responses: true
</code></pre>
<h3 id="validationstatus_code-integer-default-400"><a class="header" href="#validationstatus_code-integer-default-400"><code>validation.status_code</code> (integer, default: 400)</a></h3>
<p>HTTP status code to return for validation errors.</p>
<pre><code class="language-yaml">validation:
  status_code: 422  # Use 422 Unprocessable Entity
</code></pre>
<h3 id="validationskip_admin_validation-boolean-default-true"><a class="header" href="#validationskip_admin_validation-boolean-default-true"><code>validation.skip_admin_validation</code> (boolean, default: true)</a></h3>
<p>Skip validation for admin UI routes.</p>
<pre><code class="language-yaml">validation:
  skip_admin_validation: true
</code></pre>
<h3 id="validationoverrides-object"><a class="header" href="#validationoverrides-object"><code>validation.overrides</code> (object)</a></h3>
<p>Per-route validation overrides.</p>
<pre><code class="language-yaml">validation:
  overrides:
    "/api/users": "off"      # Disable validation for this route
    "/api/admin/**": "warn"  # Warning mode for admin routes
</code></pre>
<h2 id="response-configuration"><a class="header" href="#response-configuration">Response Configuration</a></h2>
<h3 id="responsetemplate_expand-boolean-default-false"><a class="header" href="#responsetemplate_expand-boolean-default-false"><code>response.template_expand</code> (boolean, default: false)</a></h3>
<p>Enable template variable expansion in responses.</p>
<pre><code class="language-yaml">response:
  template_expand: true
</code></pre>
<h3 id="responsecaching-object"><a class="header" href="#responsecaching-object"><code>response.caching</code> (object)</a></h3>
<p>Response caching configuration.</p>
<pre><code class="language-yaml">response:
  caching:
    enabled: true
    ttl_seconds: 300
    max_size_mb: 100
</code></pre>
<h2 id="chaos-engineering-1"><a class="header" href="#chaos-engineering-1">Chaos Engineering</a></h2>
<h3 id="chaoslatency_enabled-boolean-default-false"><a class="header" href="#chaoslatency_enabled-boolean-default-false"><code>chaos.latency_enabled</code> (boolean, default: false)</a></h3>
<p>Enable response latency simulation.</p>
<pre><code class="language-yaml">chaos:
  latency_enabled: true
</code></pre>
<h3 id="chaoslatency_min_ms-integer-default-0"><a class="header" href="#chaoslatency_min_ms-integer-default-0"><code>chaos.latency_min_ms</code> (integer, default: 0)</a></h3>
<p>Minimum response latency in milliseconds.</p>
<pre><code class="language-yaml">chaos:
  latency_min_ms: 100
</code></pre>
<h3 id="chaoslatency_max_ms-integer-default-1000"><a class="header" href="#chaoslatency_max_ms-integer-default-1000"><code>chaos.latency_max_ms</code> (integer, default: 1000)</a></h3>
<p>Maximum response latency in milliseconds.</p>
<pre><code class="language-yaml">chaos:
  latency_max_ms: 2000
</code></pre>
<h3 id="chaosfailures_enabled-boolean-default-false"><a class="header" href="#chaosfailures_enabled-boolean-default-false"><code>chaos.failures_enabled</code> (boolean, default: false)</a></h3>
<p>Enable random failure injection.</p>
<pre><code class="language-yaml">chaos:
  failures_enabled: true
</code></pre>
<h3 id="chaosfailure_rate-float-default-00"><a class="header" href="#chaosfailure_rate-float-default-00"><code>chaos.failure_rate</code> (float, default: 0.0)</a></h3>
<p>Probability of random failures (0.0 to 1.0).</p>
<pre><code class="language-yaml">chaos:
  failure_rate: 0.05  # 5% failure rate
</code></pre>
<h3 id="chaosfailure_status_codes-array-of-integers"><a class="header" href="#chaosfailure_status_codes-array-of-integers"><code>chaos.failure_status_codes</code> (array of integers)</a></h3>
<p>HTTP status codes to return for injected failures.</p>
<pre><code class="language-yaml">chaos:
  failure_status_codes: [500, 502, 503, 504]
</code></pre>
<h2 id="grpc-configuration"><a class="header" href="#grpc-configuration">gRPC Configuration</a></h2>
<h3 id="grpcproto_dir-string-default-proto"><a class="header" href="#grpcproto_dir-string-default-proto"><code>grpc.proto_dir</code> (string, default: “proto/”)</a></h3>
<p>Directory containing Protocol Buffer files.</p>
<pre><code class="language-yaml">grpc:
  proto_dir: "my-protos/"
</code></pre>
<h3 id="grpcenable_reflection-boolean-default-true"><a class="header" href="#grpcenable_reflection-boolean-default-true"><code>grpc.enable_reflection</code> (boolean, default: true)</a></h3>
<p>Enable gRPC server reflection for service discovery.</p>
<pre><code class="language-yaml">grpc:
  enable_reflection: true
</code></pre>
<h3 id="grpcexcluded_services-array-of-strings"><a class="header" href="#grpcexcluded_services-array-of-strings"><code>grpc.excluded_services</code> (array of strings)</a></h3>
<p>gRPC services to exclude from automatic registration.</p>
<pre><code class="language-yaml">grpc:
  excluded_services:
    - "grpc.reflection.v1alpha.ServerReflection"
</code></pre>
<h3 id="grpcmax_message_size-integer-default-4194304"><a class="header" href="#grpcmax_message_size-integer-default-4194304"><code>grpc.max_message_size</code> (integer, default: 4194304)</a></h3>
<p>Maximum message size in bytes (4MB default).</p>
<pre><code class="language-yaml">grpc:
  max_message_size: 8388608  # 8MB
</code></pre>
<h3 id="grpcconcurrency_limit-integer-default-32"><a class="header" href="#grpcconcurrency_limit-integer-default-32"><code>grpc.concurrency_limit</code> (integer, default: 32)</a></h3>
<p>Maximum concurrent requests per connection.</p>
<pre><code class="language-yaml">grpc:
  concurrency_limit: 64
</code></pre>
<h2 id="websocket-configuration"><a class="header" href="#websocket-configuration">WebSocket Configuration</a></h2>
<h3 id="websocketreplay_file-string"><a class="header" href="#websocketreplay_file-string"><code>websocket.replay_file</code> (string)</a></h3>
<p>Path to WebSocket replay file for scripted interactions.</p>
<pre><code class="language-yaml">websocket:
  replay_file: "examples/ws-demo.jsonl"
</code></pre>
<h3 id="websocketmax_connections-integer-default-1000"><a class="header" href="#websocketmax_connections-integer-default-1000"><code>websocket.max_connections</code> (integer, default: 1000)</a></h3>
<p>Maximum concurrent WebSocket connections.</p>
<pre><code class="language-yaml">websocket:
  max_connections: 500
</code></pre>
<h3 id="websocketmessage_timeout-integer-default-30000"><a class="header" href="#websocketmessage_timeout-integer-default-30000"><code>websocket.message_timeout</code> (integer, default: 30000)</a></h3>
<p>Timeout for WebSocket messages in milliseconds.</p>
<pre><code class="language-yaml">websocket:
  message_timeout: 60000
</code></pre>
<h3 id="websocketheartbeat_interval-integer-default-30000"><a class="header" href="#websocketheartbeat_interval-integer-default-30000"><code>websocket.heartbeat_interval</code> (integer, default: 30000)</a></h3>
<p>Heartbeat interval for long-running connections.</p>
<pre><code class="language-yaml">websocket:
  heartbeat_interval: 45000
</code></pre>
<h2 id="logging-configuration-1"><a class="header" href="#logging-configuration-1">Logging Configuration</a></h2>
<h3 id="logginglevel-string-default-info"><a class="header" href="#logginglevel-string-default-info"><code>logging.level</code> (string, default: “info”)</a></h3>
<p>Log level. Options: “error”, “warn”, “info”, “debug”, “trace”</p>
<pre><code class="language-yaml">logging:
  level: debug
</code></pre>
<h3 id="loggingformat-string-default-text"><a class="header" href="#loggingformat-string-default-text"><code>logging.format</code> (string, default: “text”)</a></h3>
<p>Log output format. Options: “text”, “json”</p>
<pre><code class="language-yaml">logging:
  format: json
</code></pre>
<h3 id="loggingfile-string"><a class="header" href="#loggingfile-string"><code>logging.file</code> (string)</a></h3>
<p>Path to log file (if not specified, logs to stdout).</p>
<pre><code class="language-yaml">logging:
  file: "/var/log/mockforge.log"
</code></pre>
<h3 id="loggingmax_size_mb-integer-default-10"><a class="header" href="#loggingmax_size_mb-integer-default-10"><code>logging.max_size_mb</code> (integer, default: 10)</a></h3>
<p>Maximum log file size in megabytes before rotation.</p>
<pre><code class="language-yaml">logging:
  max_size_mb: 50
</code></pre>
<h3 id="loggingmax_files-integer-default-5"><a class="header" href="#loggingmax_files-integer-default-5"><code>logging.max_files</code> (integer, default: 5)</a></h3>
<p>Maximum number of rotated log files to keep.</p>
<pre><code class="language-yaml">logging:
  max_files: 10
</code></pre>
<h2 id="complete-configuration-example"><a class="header" href="#complete-configuration-example">Complete Configuration Example</a></h2>
<pre><code class="language-yaml"># Complete MockForge configuration example
server:
  http_port: 3000
  ws_port: 3001
  grpc_port: 50051
  bind: "0.0.0.0"

admin:
  enabled: true
  port: 8080
  embedded: false
  standalone: true

validation:
  mode: enforce
  aggregate_errors: false
  validate_responses: false
  status_code: 400

response:
  template_expand: true

chaos:
  latency_enabled: false
  failures_enabled: false

grpc:
  proto_dir: "proto/"
  enable_reflection: true
  max_message_size: 4194304

websocket:
  replay_file: "examples/ws-demo.jsonl"
  max_connections: 1000

logging:
  level: info
  format: text
</code></pre>
<h2 id="configuration-precedence-2"><a class="header" href="#configuration-precedence-2">Configuration Precedence</a></h2>
<p>Configuration values are applied in order of priority (highest to lowest):</p>
<ol>
<li><strong>Command-line arguments</strong> - Override all other settings</li>
<li><strong>Environment variables</strong> - Override config file settings</li>
<li><strong>Configuration file</strong> - Default values from YAML file</li>
<li><strong>Compiled defaults</strong> - Built-in fallback values</li>
</ol>
<h2 id="environment-variable-mapping"><a class="header" href="#environment-variable-mapping">Environment Variable Mapping</a></h2>
<p>All configuration options can be set via environment variables using the <code>MOCKFORGE_</code> prefix with underscore-separated paths:</p>
<pre><code class="language-bash"># Server configuration
export MOCKFORGE_SERVER_HTTP_PORT=8080
export MOCKFORGE_SERVER_BIND="127.0.0.1"

# Admin UI
export MOCKFORGE_ADMIN_ENABLED=true
export MOCKFORGE_ADMIN_PORT=9090

# Validation
export MOCKFORGE_VALIDATION_MODE=warn
export MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true

# Protocol-specific
export MOCKFORGE_GRPC_PROTO_DIR="my-protos/"
export MOCKFORGE_WEBSOCKET_REPLAY_FILE="replay.jsonl"
</code></pre>
<h2 id="validation-2"><a class="header" href="#validation-2">Validation</a></h2>
<p>MockForge validates configuration files at startup and reports errors clearly:</p>
<pre><code class="language-bash"># Validate configuration without starting server
mockforge-cli validate-config config.yaml

# Check for deprecated options
mockforge-cli validate-config --check-deprecated config.yaml
</code></pre>
<h2 id="hot-reloading-1"><a class="header" href="#hot-reloading-1">Hot Reloading</a></h2>
<p>Some configuration options support runtime updates without restart:</p>
<ul>
<li>Validation mode changes</li>
<li>Template expansion toggle</li>
<li>Admin UI settings</li>
<li>Logging level adjustments</li>
</ul>
<pre><code class="language-bash"># Update validation mode at runtime
curl -X POST http://localhost:8080/__mockforge/config \
  -H "Content-Type: application/json" \
  -d '{"validation": {"mode": "warn"}}'
</code></pre>
<h2 id="best-practices-9"><a class="header" href="#best-practices-9">Best Practices</a></h2>
<h3 id="development-configuration-1"><a class="header" href="#development-configuration-1">Development Configuration</a></h3>
<pre><code class="language-yaml"># development.yaml
server:
  http_port: 3000
  ws_port: 3001

admin:
  enabled: true
  embedded: true

validation:
  mode: warn

response:
  template_expand: true

logging:
  level: debug
</code></pre>
<h3 id="production-configuration-1"><a class="header" href="#production-configuration-1">Production Configuration</a></h3>
<pre><code class="language-yaml"># production.yaml
server:
  http_port: 8080
  bind: "127.0.0.1"

admin:
  enabled: true
  standalone: true
  port: 9090

validation:
  mode: enforce

chaos:
  latency_enabled: false
  failures_enabled: false

logging:
  level: warn
  file: "/var/log/mockforge.log"
</code></pre>
<h3 id="testing-configuration-1"><a class="header" href="#testing-configuration-1">Testing Configuration</a></h3>
<pre><code class="language-yaml"># test.yaml
server:
  http_port: 3000

validation:
  mode: off

response:
  template_expand: true

logging:
  level: debug
</code></pre>
<h2 id="migration-guide"><a class="header" href="#migration-guide">Migration Guide</a></h2>
<h3 id="upgrading-from-cli-only-configuration"><a class="header" href="#upgrading-from-cli-only-configuration">Upgrading from CLI-only Configuration</a></h3>
<p>If migrating from command-line only configuration:</p>
<ol>
<li>Create a <code>config.yaml</code> file with your current settings</li>
<li>Test the configuration with <code>mockforge-cli validate-config</code></li>
<li>Gradually move settings from environment variables to the config file</li>
<li>Update deployment scripts to use the config file</li>
</ol>
<h3 id="version-compatibility"><a class="header" href="#version-compatibility">Version Compatibility</a></h3>
<p>Configuration options may change between versions. Check the changelog for breaking changes and use the validation command to identify deprecated options:</p>
<pre><code class="language-bash">mockforge-cli validate-config --check-deprecated config.yaml
</code></pre>
<p>This schema provides comprehensive control over MockForge’s behavior across all protocols and features.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="supported-formats"><a class="header" href="#supported-formats">Supported Formats</a></h1>
<p>MockForge supports various data formats for configuration, specifications, and data exchange. This reference documents all supported formats, their usage, and conversion utilities.</p>
<h2 id="openapi-specifications"><a class="header" href="#openapi-specifications">OpenAPI Specifications</a></h2>
<h3 id="json-format-primary"><a class="header" href="#json-format-primary">JSON Format (Primary)</a></h3>
<p>MockForge primarily supports OpenAPI 3.0+ specifications in JSON format:</p>
<pre><code class="language-json">{
  "openapi": "3.0.3",
  "info": {
    "title": "User API",
    "version": "1.0.0"
  },
  "paths": {
    "/users": {
      "get": {
        "summary": "List users",
        "responses": {
          "200": {
            "description": "Success",
            "content": {
              "application/json": {
                "schema": {
                  "type": "array",
                  "items": {
                    "$ref": "#/components/schemas/User"
                  }
                }
              }
            }
          }
        }
      }
    }
  },
  "components": {
    "schemas": {
      "User": {
        "type": "object",
        "properties": {
          "id": {"type": "string"},
          "name": {"type": "string"},
          "email": {"type": "string"}
        }
      }
    }
  }
}
</code></pre>
<h3 id="yaml-format-alternative"><a class="header" href="#yaml-format-alternative">YAML Format (Alternative)</a></h3>
<p>OpenAPI specifications can also be provided in YAML format:</p>
<pre><code class="language-yaml">openapi: 3.0.3
info:
  title: User API
  version: 1.0.0
paths:
  /users:
    get:
      summary: List users
      responses:
        '200':
          description: Success
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: '#/components/schemas/User'
components:
  schemas:
    User:
      type: object
      properties:
        id:
          type: string
        name:
          type: string
        email:
          type: string
</code></pre>
<h3 id="conversion-between-formats"><a class="header" href="#conversion-between-formats">Conversion Between Formats</a></h3>
<pre><code class="language-bash"># Convert JSON to YAML
node -e "
const fs = require('fs');
const yaml = require('js-yaml');
const spec = JSON.parse(fs.readFileSync('api.json', 'utf8'));
fs.writeFileSync('api.yaml', yaml.dump(spec));
"

# Convert YAML to JSON
node -e "
const fs = require('fs');
const yaml = require('js-yaml');
const spec = yaml.load(fs.readFileSync('api.yaml', 'utf8'));
fs.writeFileSync('api.json', JSON.stringify(spec, null, 2));
"
</code></pre>
<h2 id="protocol-buffers-1"><a class="header" href="#protocol-buffers-1">Protocol Buffers</a></h2>
<h3 id="proto-files"><a class="header" href="#proto-files">.proto Files</a></h3>
<p>gRPC services use Protocol Buffer definitions:</p>
<pre><code class="language-protobuf">syntax = "proto3";

package myapp.user;

service UserService {
  rpc GetUser(GetUserRequest) returns (User);
  rpc ListUsers(ListUsersRequest) returns (stream User);
  rpc CreateUser(CreateUserRequest) returns (User);
}

message GetUserRequest {
  string user_id = 1;
}

message User {
  string user_id = 1;
  string name = 2;
  string email = 3;
  google.protobuf.Timestamp created_at = 4;
}

message ListUsersRequest {
  int32 page_size = 1;
  string page_token = 2;
}

message CreateUserRequest {
  string name = 1;
  string email = 2;
}
</code></pre>
<h3 id="generated-code"><a class="header" href="#generated-code">Generated Code</a></h3>
<p>MockForge automatically generates Rust code from <code>.proto</code> files:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Generated code structure
pub mod myapp {
    pub mod user {
        tonic::include_proto!("myapp.user");

        // Generated service trait
        #[tonic::async_trait]
        pub trait UserService: Send + Sync + 'static {
            async fn get_user(
                &amp;self,
                request: tonic::Request&lt;GetUserRequest&gt;,
            ) -&gt; Result&lt;tonic::Response&lt;User&gt;, tonic::Status&gt;;

            async fn list_users(
                &amp;self,
                request: tonic::Request&lt;ListUsersRequest&gt;,
            ) -&gt; Result&lt;tonic::Response&lt;Self::ListUsersStream&gt;, tonic::Status&gt;;
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="websocket-replay-files"><a class="header" href="#websocket-replay-files">WebSocket Replay Files</a></h2>
<h3 id="jsonl-format-1"><a class="header" href="#jsonl-format-1">JSONL Format</a></h3>
<p>WebSocket interactions use JSON Lines format:</p>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"Welcome to chat!","waitFor":"^HELLO$"}
{"ts":1000,"dir":"out","text":"How can I help you?"}
{"ts":2000,"dir":"out","text":"Please wait while I process your request..."}
{"ts":5000,"dir":"out","text":"Here's your response: ..."}
</code></pre>
<h3 id="extended-jsonl-with-templates"><a class="header" href="#extended-jsonl-with-templates">Extended JSONL with Templates</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"Session {{uuid}} started at {{now}}"}
{"ts":1000,"dir":"out","text":"Connected to server {{server_id}}"}
{"ts":2000,"dir":"out","text":"{{#if authenticated}}Welcome back!{{else}}Please authenticate{{/if}}"}
</code></pre>
<h3 id="binary-message-support-2"><a class="header" href="#binary-message-support-2">Binary Message Support</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNkYPhfDwAChwGA60e6kgAAAABJRU5ErkJggg==","binary":true}
{"ts":1000,"dir":"out","text":"Image data sent"}
</code></pre>
<h2 id="configuration-files-2"><a class="header" href="#configuration-files-2">Configuration Files</a></h2>
<h3 id="yaml-configuration"><a class="header" href="#yaml-configuration">YAML Configuration</a></h3>
<p>MockForge uses YAML for configuration files:</p>
<pre><code class="language-yaml"># Server configuration
server:
  http_port: 3000
  ws_port: 3001
  grpc_port: 50051

# Validation settings
validation:
  mode: enforce
  aggregate_errors: false

# Response processing
response:
  template_expand: true

# Protocol-specific settings
grpc:
  proto_dir: "proto/"
  enable_reflection: true

websocket:
  replay_file: "examples/demo.jsonl"
</code></pre>
<h3 id="json-configuration-alternative"><a class="header" href="#json-configuration-alternative">JSON Configuration (Alternative)</a></h3>
<p>Configuration can also be provided as JSON:</p>
<pre><code class="language-json">{
  "server": {
    "http_port": 3000,
    "ws_port": 3001,
    "grpc_port": 50051
  },
  "validation": {
    "mode": "enforce",
    "aggregate_errors": false
  },
  "response": {
    "template_expand": true
  },
  "grpc": {
    "proto_dir": "proto/",
    "enable_reflection": true
  },
  "websocket": {
    "replay_file": "examples/demo.jsonl"
  }
}
</code></pre>
<h2 id="data-generation-formats"><a class="header" href="#data-generation-formats">Data Generation Formats</a></h2>
<h3 id="json-output"><a class="header" href="#json-output">JSON Output</a></h3>
<p>Generated test data in JSON format:</p>
<pre><code class="language-json">[
  {
    "id": "550e8400-e29b-41d4-a716-446655440000",
    "name": "John Doe",
    "email": "john.doe@example.com",
    "created_at": "2025-09-12T10:00:00Z"
  },
  {
    "id": "550e8400-e29b-41d4-a716-446655440001",
    "name": "Jane Smith",
    "email": "jane.smith@example.com",
    "created_at": "2025-09-12T11:00:00Z"
  }
]
</code></pre>
<h3 id="yaml-output"><a class="header" href="#yaml-output">YAML Output</a></h3>
<p>Same data in YAML format:</p>
<pre><code class="language-yaml">- id: 550e8400-e29b-41d4-a716-446655440000
  name: John Doe
  email: john.doe@example.com
  created_at: '2025-09-12T10:00:00Z'
- id: 550e8400-e29b-41d4-a716-446655440001
  name: Jane Smith
  email: jane.smith@example.com
  created_at: '2025-09-12T11:00:00Z'
</code></pre>
<h3 id="csv-output"><a class="header" href="#csv-output">CSV Output</a></h3>
<p>Tabular data in CSV format:</p>
<pre><code class="language-csv">id,name,email,created_at
550e8400-e29b-41d4-a716-446655440000,John Doe,john.doe@example.com,2025-09-12T10:00:00Z
550e8400-e29b-41d4-a716-446655440001,Jane Smith,jane.smith@example.com,2025-09-12T11:00:00Z
</code></pre>
<h2 id="log-formats"><a class="header" href="#log-formats">Log Formats</a></h2>
<h3 id="text-format-default"><a class="header" href="#text-format-default">Text Format (Default)</a></h3>
<p>Human-readable log output:</p>
<pre><code>2025-09-12T10:00:00Z INFO mockforge::http: Server started on 0.0.0.0:3000
2025-09-12T10:00:01Z INFO mockforge::http: Request: GET /users
2025-09-12T10:00:01Z DEBUG mockforge::template: Template expanded: {{uuid}} -&gt; 550e8400-e29b-41d4-a716-446655440000
2025-09-12T10:00:01Z INFO mockforge::http: Response: 200 OK
</code></pre>
<h3 id="json-format"><a class="header" href="#json-format">JSON Format</a></h3>
<p>Structured JSON logging:</p>
<pre><code class="language-json">{"timestamp":"2025-09-12T10:00:00Z","level":"INFO","module":"mockforge::http","message":"Server started on 0.0.0.0:3000"}
{"timestamp":"2025-09-12T10:00:01Z","level":"INFO","module":"mockforge::http","message":"Request: GET /users","method":"GET","path":"/users","user_agent":"curl/7.68.0"}
{"timestamp":"2025-09-12T10:00:01Z","level":"DEBUG","module":"mockforge::template","message":"Template expanded","template":"{{uuid}}","result":"550e8400-e29b-41d4-a716-446655440000"}
{"timestamp":"2025-09-12T10:00:01Z","level":"INFO","module":"mockforge::http","message":"Response: 200 OK","status":200,"duration_ms":15}
</code></pre>
<h2 id="template-syntax"><a class="header" href="#template-syntax">Template Syntax</a></h2>
<h3 id="handlebars-templates"><a class="header" href="#handlebars-templates">Handlebars Templates</a></h3>
<p>MockForge uses Handlebars-style templates:</p>
<pre><code class="language-handlebars">{{variable}}
{{object.property}}
{{array.[0]}}
{{#if condition}}content{{/if}}
{{#each items}}{{this}}{{/each}}
{{helper arg1 arg2}}
</code></pre>
<h3 id="built-in-helpers"><a class="header" href="#built-in-helpers">Built-in Helpers</a></h3>
<pre><code class="language-handlebars">&lt;!-- Data generation --&gt;
{{uuid}}                    &lt;!-- Random UUID --&gt;
{{now}}                     &lt;!-- Current timestamp --&gt;
{{now+1h}}                  &lt;!-- Future timestamp --&gt;
{{randInt 1 100}}          &lt;!-- Random integer --&gt;
{{randFloat 0.0 1.0}}      &lt;!-- Random float --&gt;
{{randWord}}               &lt;!-- Random word --&gt;
{{randSentence}}           &lt;!-- Random sentence --&gt;
{{randParagraph}}          &lt;!-- Random paragraph --&gt;

&lt;!-- Request context --&gt;
{{request.path.id}}        &lt;!-- URL path parameter --&gt;
{{request.query.limit}}    &lt;!-- Query parameter --&gt;
{{request.header.auth}}    &lt;!-- HTTP header --&gt;
{{request.body.name}}      &lt;!-- Request body field --&gt;

&lt;!-- Logic helpers --&gt;
{{#if user.authenticated}}
  Welcome back, {{user.name}}!
{{else}}
  Please log in.
{{/if}}

{{#each users}}
  &lt;li&gt;{{name}} - {{email}}&lt;/li&gt;
{{/each}}
</code></pre>
<h2 id="conversion-utilities"><a class="header" href="#conversion-utilities">Conversion Utilities</a></h2>
<h3 id="format-conversion-scripts"><a class="header" href="#format-conversion-scripts">Format Conversion Scripts</a></h3>
<pre><code class="language-bash">#!/bin/bash
# convert-format.sh - Convert between supported formats

input_file=$1
output_format=$2

case $output_format in
    "yaml")
        python3 -c "
import sys, yaml, json
data = json.load(sys.stdin)
yaml.dump(data, sys.stdout, default_flow_style=False)
" &lt; "$input_file"
        ;;
    "json")
        python3 -c "
import sys, yaml, json
data = yaml.safe_load(sys.stdin)
json.dump(data, sys.stdout, indent=2)
" &lt; "$input_file"
        ;;
    "xml")
        python3 -c "
import sys, json, dicttoxml
data = json.load(sys.stdin)
xml = dicttoxml.dicttoxml(data, custom_root='root', attr_type=False)
print(xml.decode())
" &lt; "$input_file"
        ;;
    *)
        echo "Unsupported format: $output_format"
        echo "Supported: yaml, json, xml"
        exit 1
        ;;
esac
</code></pre>
<h3 id="validation-scripts"><a class="header" href="#validation-scripts">Validation Scripts</a></h3>
<pre><code class="language-bash">#!/bin/bash
# validate-format.sh - Validate file formats

file=$1
format=$(basename "$file" | sed 's/.*\.//')

case $format in
    "json")
        python3 -c "
import sys, json
try:
    json.load(sys.stdin)
    print('✓ Valid JSON')
except Exception as e:
    print('✗ Invalid JSON:', e)
    sys.exit(1)
" &lt; "$file"
        ;;
    "yaml")
        python3 -c "
import sys, yaml
try:
    yaml.safe_load(sys.stdin)
    print('✓ Valid YAML')
except Exception as e:
    print('✗ Invalid YAML:', e)
    sys.exit(1)
" &lt; "$file"
        ;;
    "xml")
        python3 -c "
import sys, xml.etree.ElementTree as ET
try:
    ET.parse(sys.stdin)
    print('✓ Valid XML')
except Exception as e:
    print('✗ Invalid XML:', e)
    sys.exit(1)
" &lt; "$file"
        ;;
    *)
        echo "Unsupported format: $format"
        exit 1
        ;;
esac
</code></pre>
<h2 id="best-practices-10"><a class="header" href="#best-practices-10">Best Practices</a></h2>
<h3 id="choosing-the-right-format"><a class="header" href="#choosing-the-right-format">Choosing the Right Format</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Use Case</th><th>Recommended Format</th><th>Reason</th></tr></thead><tbody>
<tr><td>API Specifications</td><td>OpenAPI YAML</td><td>More readable, better for version control</td></tr>
<tr><td>Configuration</td><td>YAML</td><td>Human-readable, supports comments</td></tr>
<tr><td>Data Exchange</td><td>JSON</td><td>Universally supported, compact</td></tr>
<tr><td>Logs</td><td>JSON</td><td>Structured, searchable</td></tr>
<tr><td>Templates</td><td>Handlebars</td><td>Expressive, logic support</td></tr>
</tbody></table>
</div>
<h3 id="format-conversion-workflow"><a class="header" href="#format-conversion-workflow">Format Conversion Workflow</a></h3>
<pre><code class="language-bash"># API development workflow
# 1. Design API in YAML (readable)
swagger-editor

# 2. Convert to JSON for tools that require it
./convert-format.sh api.yaml json &gt; api.json

# 3. Validate both formats
./validate-format.sh api.yaml
./validate-format.sh api.json

# 4. Generate documentation
swagger-codegen generate -i api.yaml -l html -o docs/

# 5. Commit YAML version (better diff)
git add api.yaml
</code></pre>
<h3 id="performance-considerations-4"><a class="header" href="#performance-considerations-4">Performance Considerations</a></h3>
<ul>
<li><strong>JSON</strong>: Fastest parsing, smallest size</li>
<li><strong>YAML</strong>: Slower parsing, larger size, better readability</li>
<li><strong>XML</strong>: Slowest parsing, largest size, most verbose</li>
<li><strong>Binary formats</strong>: Fastest for large data, not human-readable</li>
</ul>
<h3 id="compatibility-matrix"><a class="header" href="#compatibility-matrix">Compatibility Matrix</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Format</th><th>MockForge Support</th><th>Readability</th><th>Tool Support</th><th>Size</th></tr></thead><tbody>
<tr><td>JSON</td><td>✅ Full</td><td>Medium</td><td>Excellent</td><td>Small</td></tr>
<tr><td>YAML</td><td>✅ Full</td><td>High</td><td>Good</td><td>Medium</td></tr>
<tr><td>XML</td><td>❌ None</td><td>Low</td><td>Good</td><td>Large</td></tr>
<tr><td>Protocol Buffers</td><td>✅ gRPC only</td><td>Low</td><td>Limited</td><td>Small</td></tr>
<tr><td>JSONL</td><td>✅ WebSocket</td><td>Medium</td><td>Basic</td><td>Medium</td></tr>
</tbody></table>
</div>
<p>This format reference ensures you can work effectively with all data formats supported by MockForge across different use cases and workflows.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="templating-reference"><a class="header" href="#templating-reference">Templating Reference</a></h1>
<p>MockForge supports lightweight templating across HTTP responses, overrides, and (soon) WS/gRPC). This page documents all supported tokens and controls.</p>
<h2 id="enabling"><a class="header" href="#enabling">Enabling</a></h2>
<ul>
<li>Environment: <code>MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true|false</code> (default: false)</li>
<li>Config: <code>http.response_template_expand: true|false</code></li>
<li>CLI: <code>--response-template-expand</code></li>
<li>Determinism: <code>MOCKFORGE_FAKE_TOKENS=false</code> disables faker token expansion.</li>
</ul>
<h2 id="time-tokens"><a class="header" href="#time-tokens">Time Tokens</a></h2>
<ul>
<li><code>{{now}}</code> — RFC3339 timestamp.</li>
<li><code>{{now±Nd|Nh|Nm|Ns}}</code> — Offset from now by Days/Hours/Minutes/Seconds.
<ul>
<li>Examples: <code>{{now+2h}}</code>, <code>{{now-30m}}</code>, <code>{{now+10s}}</code>, <code>{{now-1d}}</code>.</li>
</ul>
</li>
</ul>
<h2 id="random-tokens"><a class="header" href="#random-tokens">Random Tokens</a></h2>
<ul>
<li><code>{{rand.int}}</code> — random integer in [0, 1_000_000].</li>
<li><code>{{rand.float}}</code> — random float in [0,1).</li>
<li><code>{{randInt a b}}</code> / <code>{{rand.int a b}}</code> — random integer between a and b (order-agnostic, negatives allowed).
<ul>
<li>Examples: <code>{{randInt 10 99}}</code>, <code>{{randInt -5 5}}</code>.</li>
</ul>
</li>
</ul>
<h2 id="uuid"><a class="header" href="#uuid">UUID</a></h2>
<ul>
<li><code>{{uuid}}</code> — UUID v4.</li>
</ul>
<h2 id="request-data-access-1"><a class="header" href="#request-data-access-1">Request Data Access</a></h2>
<ul>
<li><code>{{request.body.field}}</code> — Access fields from request body JSON.
<ul>
<li>Example: <code>{{request.body.name}}</code> extracts the <code>name</code> field from request body.</li>
</ul>
</li>
<li><code>{{request.path.param}}</code> — Access path parameters.
<ul>
<li>Example: <code>{{request.path.id}}</code> extracts the <code>id</code> path parameter.</li>
</ul>
</li>
<li><code>{{request.query.param}}</code> — Access query parameters.
<ul>
<li>Example: <code>{{request.query.limit}}</code> extracts the <code>limit</code> query parameter.</li>
</ul>
</li>
</ul>
<h2 id="faker-tokens"><a class="header" href="#faker-tokens">Faker Tokens</a></h2>
<p>Faker expansions can be disabled via <code>MOCKFORGE_FAKE_TOKENS=false</code>.</p>
<ul>
<li>Minimal (always available): <code>{{faker.uuid}}</code>, <code>{{faker.email}}</code>, <code>{{faker.name}}</code>.</li>
<li>Extended (when feature <code>data-faker</code> is enabled):
<ul>
<li><code>{{faker.address}}</code>, <code>{{faker.phone}}</code>, <code>{{faker.company}}</code>, <code>{{faker.url}}</code>, <code>{{faker.ip}}</code></li>
<li><code>{{faker.color}}</code>, <code>{{faker.word}}</code>, <code>{{faker.sentence}}</code>, <code>{{faker.paragraph}}</code></li>
</ul>
</li>
</ul>
<h2 id="where-templating-applies"><a class="header" href="#where-templating-applies">Where Templating Applies</a></h2>
<ul>
<li>HTTP (OpenAPI): media-level <code>example</code> bodies and synthesized responses.</li>
<li>HTTP Overrides: YAML patches loaded via <code>validation_overrides</code>.</li>
<li>WS/gRPC: provider is registered now; expansion hooks will be added as features land.</li>
</ul>
<h2 id="status-codes-for-validation-errors"><a class="header" href="#status-codes-for-validation-errors">Status Codes for Validation Errors</a></h2>
<ul>
<li><code>MOCKFORGE_VALIDATION_STATUS=400|422</code> (default 400). Affects HTTP request validation failures in enforce mode.</li>
</ul>
<h2 id="security--determinism-notes"><a class="header" href="#security--determinism-notes">Security &amp; Determinism Notes</a></h2>
<ul>
<li>Tokens inject random/time-based values; disable faker to reduce variability.</li>
<li>For deterministic integration tests, set <code>MOCKFORGE_FAKE_TOKENS=false</code> and prefer explicit literals.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="request-chaining"><a class="header" href="#request-chaining">Request Chaining</a></h1>
<p>MockForge supports request chaining, which allows you to create complex workflows where requests can depend on responses from previous requests in the chain. This is particularly useful for testing API workflows that require authentication, data flow between endpoints, or multi-step operations.</p>
<h2 id="overview-2"><a class="header" href="#overview-2">Overview</a></h2>
<p>Request chaining enables you to:</p>
<ul>
<li>Execute requests in a predefined sequence with dependencies</li>
<li>Reference data from previous responses using template variables</li>
<li>Extract and store specific values from responses for reuse</li>
<li>Validate response status codes and content</li>
<li>Implement parallel execution for independent requests</li>
<li>Handle complex authentication and authorization flows</li>
</ul>
<h2 id="chain-definition"><a class="header" href="#chain-definition">Chain Definition</a></h2>
<p>Chains are defined using YAML or JSON configuration files with the following structure:</p>
<pre><code class="language-yaml">id: my-chain
name: My Chain
description: A description of what this chain does
config:
  enabled: true
  maxChainLength: 20
  globalTimeoutSecs: 300
  enableParallelExecution: false
links:
  # Define your requests here
  - request:
      id: step1
      method: POST
      url: https://api.example.com/auth/login
      headers:
        Content-Type: application/json
      body:
        username: "testuser"
        password: "password123"
    extract:
      token: body.access_token
    storeAs: login_response
    dependsOn: []
variables:
  base_url: https://api.example.com
tags:
  - authentication
  - workflow
</code></pre>
<h2 id="chain-configuration"><a class="header" href="#chain-configuration">Chain Configuration</a></h2>
<p>The <code>config</code> section controls how the chain behaves:</p>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>enabled</code></td><td>boolean</td><td><code>false</code></td><td>Whether this chain is enabled</td></tr>
<tr><td><code>maxChainLength</code></td><td>integer</td><td><code>20</code></td><td>Maximum number of requests in the chain</td></tr>
<tr><td><code>globalTimeoutSecs</code></td><td>integer</td><td><code>300</code></td><td>Total timeout for chain execution</td></tr>
<tr><td><code>enableParallelExecution</code></td><td>boolean</td><td><code>false</code></td><td>Enable parallel execution of independent requests</td></tr>
</tbody></table>
</div>
<h2 id="request-links"><a class="header" href="#request-links">Request Links</a></h2>
<p>Each link in the chain defines a single HTTP request and its behavior:</p>
<h3 id="request-definition"><a class="header" href="#request-definition">Request Definition</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Required</th><th>Description</th></tr></thead><tbody>
<tr><td><code>id</code></td><td>string</td><td>Yes</td><td>Unique identifier for this request</td></tr>
<tr><td><code>method</code></td><td>string</td><td>Yes</td><td>HTTP method (GET, POST, PUT, DELETE, etc.)</td></tr>
<tr><td><code>url</code></td><td>string</td><td>Yes</td><td>Request URL (supports template variables)</td></tr>
<tr><td><code>headers</code></td><td>object</td><td>No</td><td>Request headers</td></tr>
<tr><td><code>body</code></td><td>any</td><td>No</td><td>Request body (supports template variables)</td></tr>
<tr><td><code>dependsOn</code></td><td>array</td><td>No</td><td>List of request IDs this request depends on</td></tr>
<tr><td><code>timeoutSecs</code></td><td>number</td><td>No</td><td>Individual request timeout</td></tr>
<tr><td><code>expectedStatus</code></td><td>array</td><td>No</td><td>Expected status codes for validation</td></tr>
</tbody></table>
</div>
<h3 id="response-processing-1"><a class="header" href="#response-processing-1">Response Processing</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Required</th><th>Description</th></tr></thead><tbody>
<tr><td><code>extract</code></td><td>object</td><td>No</td><td>Extract values from response into variables</td></tr>
<tr><td><code>storeAs</code></td><td>string</td><td>No</td><td>Store entire response with this name</td></tr>
</tbody></table>
</div>
<h2 id="template-variables"><a class="header" href="#template-variables">Template Variables</a></h2>
<p>Chain requests support powerful templating that can reference:</p>
<h3 id="previous-response-data"><a class="header" href="#previous-response-data">Previous Response Data</a></h3>
<p>Use <code>{{chain.&lt;response_name&gt;.&lt;path&gt;}}</code> to reference data from previous responses:</p>
<pre><code class="language-yaml">url: https://api.example.com/users/{{chain.login_response.body.user_id}}/posts
headers:
  Authorization: "Bearer {{chain.auth_response.body.access_token}}"
</code></pre>
<h3 id="variable-extraction"><a class="header" href="#variable-extraction">Variable Extraction</a></h3>
<p>Extract values from responses into reusable variables:</p>
<pre><code class="language-yaml">extract:
  user_id: body.user.id
  token: body.access_token
storeAs: user_response
</code></pre>
<h3 id="built-in-template-functions-1"><a class="header" href="#built-in-template-functions-1">Built-in Template Functions</a></h3>
<p>All standard MockForge templating functions are available:</p>
<ul>
<li><code>{{uuid}}</code> - Random UUID</li>
<li><code>{{faker.email}}</code> - Fake email address</li>
<li><code>{{faker.name}}</code> - Fake name</li>
<li><code>{{rand.int}}</code> - Random integer</li>
<li><code>{{now}}</code> - Current timestamp</li>
</ul>
<h2 id="advanced-features-4"><a class="header" href="#advanced-features-4">Advanced Features</a></h2>
<h3 id="dependency-resolution"><a class="header" href="#dependency-resolution">Dependency Resolution</a></h3>
<p>Requests can depend on other requests using the <code>dependsOn</code> field. MockForge automatically resolves dependencies using topological sorting:</p>
<pre><code class="language-yaml">links:
  - request:
      id: login
      method: POST
      url: https://api.example.com/auth/login
      body:
        username: "user"
        password: "pass"
    storeAs: auth

  - request:
      id: get_profile
      method: GET
      url: https://api.example.com/user/profile
      headers:
        Authorization: "Bearer {{chain.auth.body.token}}"
    dependsOn:
      - login
</code></pre>
<h3 id="parallel-execution"><a class="header" href="#parallel-execution">Parallel Execution</a></h3>
<p>Enable <code>enableParallelExecution: true</code> to allow independent requests to run simultaneously:</p>
<pre><code class="language-yaml">config:
  enableParallelExecution: true
links:
  - request:
      id: get_profile
      method: GET
      url: https://api.example.com/profile
    dependsOn:
      - login

  - request:
      id: get_preferences
      method: GET
      url: https://api.example.com/preferences
    dependsOn:
      - login
  # These two requests will run in parallel
</code></pre>
<h3 id="response-validation"><a class="header" href="#response-validation">Response Validation</a></h3>
<p>Validate response status codes and content:</p>
<pre><code class="language-yaml">links:
  - request:
      id: create_user
      method: POST
      url: https://api.example.com/users
      body:
        name: "John Doe"
    expectedStatus: [201, 202]  # Expect 201 or 202 status codes
</code></pre>
<h2 id="json-path-support"><a class="header" href="#json-path-support">JSON Path Support</a></h2>
<p>Chain templating supports JSON path syntax for accessing nested data:</p>
<h3 id="simple-properties"><a class="header" href="#simple-properties">Simple Properties</a></h3>
<pre><code class="language-yaml">extract:
  user_id: body.id
  name: body.profile.name
</code></pre>
<h3 id="array-access"><a class="header" href="#array-access">Array Access</a></h3>
<pre><code class="language-yaml">extract:
  first_user: body.users.[0].name
  user_count: body.users.[*]  # Get array length
</code></pre>
<h3 id="complex-nesting"><a class="header" href="#complex-nesting">Complex Nesting</a></h3>
<pre><code class="language-yaml">url: https://api.example.com/users/{{chain.login_response.body.user.id}}/projects/{{chain.project_response.body.data.[0].id}}
</code></pre>
<h2 id="response-function-new-ui-feature"><a class="header" href="#response-function-new-ui-feature">Response Function (New UI Feature)</a></h2>
<p>MockForge also supports a <code>response()</code> function for use in the Admin UI and other editing contexts:</p>
<h3 id="syntax"><a class="header" href="#syntax">Syntax</a></h3>
<pre><code class="language-javascript">response('request_name', 'json_path')
</code></pre>
<h3 id="examples-4"><a class="header" href="#examples-4">Examples</a></h3>
<pre><code class="language-javascript">// Simple usage
response('login', 'body.user_id')

// Complex JSON path
response('user_profile', 'body.data.employee.name')

// Environment variable usage
let userId = response('login', 'body.user_id');
let updateUrl = `/users/${userId}/profile`;
</code></pre>
<h3 id="ui-integration"><a class="header" href="#ui-integration">UI Integration</a></h3>
<ol>
<li><strong>Autocomplete</strong>: Type <code>response(</code> in any input field in the UI and use Ctrl+Space for autocomplete</li>
<li><strong>Configuration Dialog</strong>: Click the blue template tag next to the function to open the configuration dialog</li>
<li><strong>Request Selection</strong>: Choose from available requests in the current chain</li>
<li><strong>Path Specification</strong>: Enter the JSONPath to extract the desired value</li>
</ol>
<h2 id="prepost-request-scripting"><a class="header" href="#prepost-request-scripting">Pre/Post Request Scripting</a></h2>
<p>MockForge supports JavaScript scripting for complex request processing and data manipulation in request chains.</p>
<h3 id="enable-scripting"><a class="header" href="#enable-scripting">Enable Scripting</a></h3>
<p>Add scripting configuration to any request in your chain:</p>
<pre><code class="language-yaml">links:
  - request:
      id: process_data
      method: POST
      url: https://api.example.com/process
      scripting:
        pre_script: |
          // Execute before request
          console.log('Processing request with mockforge context');
          console.log('Request URL:', mockforge.request.url);

          if (mockforge.variables.skip_processing) {
            request.body.skip_processing = true;
          }
        post_script: |
          // Execute after request
          console.log('Request completed in', mockforge.response.duration_ms, 'ms');

          if (mockforge.response.status === 429) {
            throw new Error('Rate limited - retry needed');
          }

          // Store custom data for next request
          setVariable('processed_user_id', mockforge.response.body.user_id);
        runtime: javascript
        timeout_ms: 5000
</code></pre>
<h3 id="pre-scripts"><a class="header" href="#pre-scripts">Pre-Scripts</a></h3>
<p>Executed before the HTTP request:</p>
<pre><code class="language-javascript">// Available context in mockforge object:
mockforge.request     // Current request (id, method, url, headers)
mockforge.chain       // Previous responses: mockforge.chain.login.body.user_id
mockforge.variables   // Chain variables
mockforge.env         // Environment variables

// Direct access to functions:
console.log('Starting request processing');

// Modify request before it goes out
if (mockforge.variables.enable_debug) {
  request.headers['X-Debug'] = 'true';
  request.body.debug_mode = true;
}

// Set variables for this request
setVariable('request_start_time', Date.now());

// Example: Add authentication from previous response
request.headers['Authorization'] = 'Bearer ' + mockforge.chain.login.body.token;
</code></pre>
<h3 id="post-scripts"><a class="header" href="#post-scripts">Post-Scripts</a></h3>
<p>Executed after the HTTP response:</p>
<pre><code class="language-javascript">// Available context in mockforge object:
mockforge.response    // Current response (status, headers, body, duration_ms)
mockforge.request     // Original request
mockforge.chain       // Previous responses
mockforge.variables   // Chain variables
mockforge.env         // Environment variables

// Example: Validate response and extract data
if (mockforge.response.status !== 200) {
  throw new Error('Request failed with status ' + mockforge.response.status);
}

// Extract and store data for next requests
setVariable('user_profile', mockforge.response.body);
setVariable('session_cookie', mockforge.response.headers['Set-Cookie']);

// Example: Transform response data
if (mockforge.response.body &amp;&amp; mockforge.response.body.user) {
  mockforge.response.body.processed_user = {
    fullName: mockforge.response.body.user.first_name + ' ' + mockforge.response.body.user.last_name,
    age: mockforge.response.body.user.age,
    isActive: mockforge.response.body.user.status === 'active'
  };
}
</code></pre>
<h3 id="built-in-functions"><a class="header" href="#built-in-functions">Built-in Functions</a></h3>
<h4 id="logging-and-diagnostics"><a class="header" href="#logging-and-diagnostics">Logging and Diagnostics</a></h4>
<pre><code class="language-javascript">console.log('Debug message:', mockforge.request.url);
console.warn('Warning:', mockforge.response.status);
console.error('Error occurred');
</code></pre>
<h4 id="variable-management"><a class="header" href="#variable-management">Variable Management</a></h4>
<pre><code class="language-javascript">// Set a variable for use in next requests
setVariable('api_token', mockforge.response.body.token);

// Access environment variables
const configUrl = mockforge.env['API_CONFIG_URL'];
</code></pre>
<h4 id="data-validation"><a class="header" href="#data-validation">Data Validation</a></h4>
<pre><code class="language-javascript">// Simple assertions
assert(mockforge.response.status === 200, 'Expected status 200');

// Complex validation
if (!mockforge.response.body || !mockforge.response.body.items) {
  throw new Error('Response missing required "items" field');
}

if (mockforge.response.body.items.length === 0) {
  console.warn('Response contains empty items array');
}
</code></pre>
<h3 id="error-handling-4"><a class="header" href="#error-handling-4">Error Handling</a></h3>
<p>Scripts can throw errors to fail the chain:</p>
<pre><code class="language-javascript">if (mockforge.response.status &gt;= 400) {
  throw new Error('HTTP ' + mockforge.response.status + ': ' + mockforge.response.body.error);
}

if (mockforge.response.duration_ms &gt; 30000) {
  throw new Error('Request took too long: ' + mockforge.response.duration_ms + 'ms');
}
</code></pre>
<h3 id="security-and-isolation"><a class="header" href="#security-and-isolation">Security and Isolation</a></h3>
<ul>
<li><strong>Timeout Protection</strong>: Scripts are limited by <code>timeout_ms</code> (default: 5 seconds)</li>
<li><strong>Sandboxing</strong>: Scripts run in isolated JavaScript contexts</li>
<li><strong>Resource Limits</strong>: CPU and memory usage is monitored and limited</li>
<li><strong>Network Restrictions</strong>: Scripts cannot make outbound network calls</li>
<li><strong>File System Access</strong>: Read-only file access through <code>fs.readFile()</code> function</li>
</ul>
<h3 id="best-practices-11"><a class="header" href="#best-practices-11">Best Practices</a></h3>
<ol>
<li><strong>Keep Scripts Simple</strong>: Break complex logic into smaller, focused scripts</li>
<li><strong>Validate Inputs</strong>: Always check that expected data exists before processing</li>
<li><strong>Set Appropriate Timeouts</strong>: Use shorter timeouts for simple scripts</li>
<li><strong>Use Environment Variables</strong>: Store configuration in environment variables</li>
<li><strong>Error Handling</strong>: Always check for error conditions and fail fast when needed</li>
<li><strong>Documentation</strong>: Comment complex business logic in your scripts</li>
<li><strong>Testing</strong>: Test scripts with various response scenarios</li>
</ol>
<h3 id="environment-variables-7"><a class="header" href="#environment-variables-7">Environment Variables</a></h3>
<p>For multiple uses of the same response value, store it in an environment variable:</p>
<pre><code class="language-javascript">// In environment variables
RESPONSE_USER_ID = response('login', 'body.user_id')

// Then use in multiple places
let url1 = `/users/${RESPONSE_USER_ID}`;
let url2 = `/profile/${RESPONSE_USER_ID}`;
</code></pre>
<h3 id="benefits-over-traditional-templates"><a class="header" href="#benefits-over-traditional-templates">Benefits Over Traditional Templates</a></h3>
<ul>
<li><strong>Cleaner Syntax</strong>: More readable than <code>{{chain.request_name.body.path}}</code></li>
<li><strong>Type Safety</strong>: JSONPath validation in the UI</li>
<li><strong>Better UX</strong>: Visual configuration through dialogs</li>
<li><strong>Autocomplete</strong>: Intelligent suggestions for request names and paths</li>
</ul>
<h2 id="error-handling-5"><a class="header" href="#error-handling-5">Error Handling</a></h2>
<p>Chains provide comprehensive error handling:</p>
<ul>
<li><strong>Dependency errors</strong>: Missing or invalid dependencies</li>
<li><strong>Circular dependencies</strong>: Automatic detection and prevention</li>
<li><strong>Timeout errors</strong>: Individual and global timeouts</li>
<li><strong>Status validation</strong>: Expected status code validation</li>
<li><strong>Network errors</strong>: Connection and HTTP errors</li>
</ul>
<h2 id="chain-management"><a class="header" href="#chain-management">Chain Management</a></h2>
<p>Chains can be managed programmatically or via configuration files:</p>
<h3 id="loading-chains"><a class="header" href="#loading-chains">Loading Chains</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_core::RequestChainRegistry;

let registry = RequestChainRegistry::new(chain_config);
// Load from YAML
registry.register_from_yaml(yaml_content).await?;
// Load from JSON
registry.register_from_json(json_content).await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="executing-chains"><a class="header" href="#executing-chains">Executing Chains</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_core::ChainExecutionEngine;

let engine = ChainExecutionEngine::new(registry, config);
// Execute a chain
let result = engine.execute_chain("my-chain").await?;
println!("Chain executed in {}ms", result.total_duration_ms);
<span class="boring">}</span></code></pre></pre>
<h2 id="complete-example-1"><a class="header" href="#complete-example-1">Complete Example</a></h2>
<p>See the provided examples in the <code>examples/</code> directory:</p>
<ul>
<li><code>examples/chain-example.yaml</code> - Comprehensive user management workflow</li>
<li><code>examples/simple-chain.json</code> - Simple authentication chain</li>
</ul>
<h2 id="working-with-large-values"><a class="header" href="#working-with-large-values">Working With Large Values</a></h2>
<p>MockForge provides several strategies to handle large values efficiently without affecting performance or crashing the user interface. The system automatically hides large text values by default, but extremely large values can still impact performance.</p>
<h3 id="file-system-template-functions"><a class="header" href="#file-system-template-functions">File System Template Functions</a></h3>
<p>MockForge supports the <code>fs.readFile()</code> template function for reading file contents directly into templates. This is particularly useful for including large text content within structured data.</p>
<p><strong>Syntax:</strong></p>
<pre><code class="language-yaml">{{fs.readFile "path/to/file.txt"}}
{{fs.readFile('path/to/file.txt')}}
</code></pre>
<p><strong>Example usage in request chaining:</strong></p>
<pre><code class="language-yaml">links:
  - request:
      id: upload_large_data
      method: POST
      url: https://api.example.com/upload
      headers:
        Content-Type: application/json
      body:
        metadata:
          filename: "large_document.txt"
          size: 1048576
        content: "{{fs.readFile('/path/to/large/file.txt')}}"
</code></pre>
<p><strong>Error handling:</strong></p>
<ul>
<li>If the file doesn’t exist: <code>&lt;fs.readFile error: No such file or directory (os error 2)&gt;</code></li>
<li>If the path is empty: <code>&lt;fs.readFile: empty path&gt;</code></li>
</ul>
<h3 id="binary-file-request-bodies"><a class="header" href="#binary-file-request-bodies">Binary File Request Bodies</a></h3>
<p>For truly large binary files (images, videos, documents), MockForge supports binary file request bodies that reference files on disk rather than loading them into memory.</p>
<p><strong>YAML Configuration:</strong></p>
<pre><code class="language-yaml">links:
  - request:
      id: upload_image
      method: POST
      url: https://api.example.com/upload
      body:
        type: binary_file
        data:
          path: "/path/to/image.jpg"
          content_type: "image/jpeg"
</code></pre>
<p><strong>JSON Configuration:</strong></p>
<pre><code class="language-json">{
  "id": "upload_image",
  "method": "POST",
  "url": "https://api.example.com/upload",
  "body": {
    "type": "binary_file",
    "data": {
      "path": "/path/to/image.jpg",
      "content_type": "image/jpeg"
    }
  }
}
</code></pre>
<p><strong>Key Features:</strong></p>
<ul>
<li><strong>Path templating</strong>: File paths support template expansion (e.g., <code>"{{chain.previous_response.body.file_path}}"</code>)</li>
<li><strong>Content type</strong>: Optional content-type header (defaults to none for binary files)</li>
<li><strong>Memory efficient</strong>: Files are read only when the request is executed</li>
<li><strong>Error handling</strong>: Clear error messages for missing files</li>
</ul>
<h3 id="performance-best-practices"><a class="header" href="#performance-best-practices">Performance Best Practices</a></h3>
<ol>
<li><strong>Use binary_file for large binary content</strong> (images, videos, large documents)</li>
<li><strong>Use fs.readFile for large text content</strong> within structured JSON/XML bodies</li>
<li><strong>Template file paths</strong> to make configurations dynamic</li>
<li><strong>Validate file paths</strong> before running chains to avoid runtime errors</li>
<li><strong>Consider file size limits</strong> based on your system’s memory constraints</li>
</ol>
<h2 id="best-practices-12"><a class="header" href="#best-practices-12">Best Practices</a></h2>
<ol>
<li><strong>Keep chains focused</strong>: Each chain should have a single, clear purpose</li>
<li><strong>Use meaningful IDs</strong>: Choose descriptive names for requests and chains</li>
<li><strong>Handle dependencies carefully</strong>: Ensure dependency chains are logical and avoid cycles</li>
<li><strong>Validate responses</strong>: Use <code>expectedStatus</code> and <code>extract</code> for critical paths</li>
<li><strong>Use parallel execution</strong>: Enable for independent requests to improve performance</li>
<li><strong>Template effectively</strong>: Leverage chain context variables for dynamic content</li>
<li><strong>Error handling</strong>: Plan for failure scenarios in your chains</li>
<li><strong>Handle large values efficiently</strong>: Use <code>fs.readFile()</code> for large text content and <code>binary_file</code> request bodies for large binary files to maintain performance</li>
</ol>
<h2 id="limitations"><a class="header" href="#limitations">Limitations</a></h2>
<ul>
<li>Maximum chain length is configurable (default: 20 requests)</li>
<li>Global execution timeout applies to entire chain</li>
<li>Circular dependencies are automatically prevented</li>
<li>Parallel execution requires careful dependency management</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="fixtures-and-smoke-testing"><a class="header" href="#fixtures-and-smoke-testing">Fixtures and Smoke Testing</a></h1>
<p>MockForge supports recording and replaying HTTP requests and responses as fixtures, which can be used for smoke testing your APIs.</p>
<h2 id="recording-fixtures"><a class="header" href="#recording-fixtures">Recording Fixtures</a></h2>
<p>To record fixtures, enable recording by setting the environment variable:</p>
<pre><code>MOCKFORGE_RECORD_ENABLED=true
</code></pre>
<p>By default, all HTTP requests will be recorded. To record only GET requests, set:</p>
<pre><code>MOCKFORGE_RECORD_GET_ONLY=true
</code></pre>
<p>Fixtures are saved in the <code>fixtures</code> directory by default. You can change this location with:</p>
<pre><code>MOCKFORGE_FIXTURES_DIR=/path/to/fixtures
</code></pre>
<h2 id="replay-fixtures"><a class="header" href="#replay-fixtures">Replay Fixtures</a></h2>
<p>To replay recorded fixtures, enable replay by setting the environment variable:</p>
<pre><code>MOCKFORGE_REPLAY_ENABLED=true
</code></pre>
<p>When replay is enabled, MockForge will serve recorded responses for matching requests instead of generating new ones.</p>
<h2 id="ready-to-run-fixtures"><a class="header" href="#ready-to-run-fixtures">Ready-to-Run Fixtures</a></h2>
<p>Fixtures can be marked as “ready-to-run” for smoke testing by adding a metadata field <code>smoke_test</code> with the value <code>true</code>. These fixtures will be listed in the smoke test endpoints.</p>
<p>Example fixture with smoke test metadata:</p>
<pre><code class="language-json">{
  "fingerprint": {
    "method": "GET",
    "path": "/api/users",
    "query_params": {},
    "headers": {}
  },
  "timestamp": "2024-01-15T10:30:00Z",
  "status_code": 200,
  "response_headers": {
    "content-type": "application/json"
  },
  "response_body": "{\"users\": []}",
  "metadata": {
    "smoke_test": "true",
    "name": "Get Users Endpoint"
  }
}
</code></pre>
<h2 id="smoke-testing"><a class="header" href="#smoke-testing">Smoke Testing</a></h2>
<p>MockForge provides endpoints to list and run smoke tests:</p>
<ul>
<li><code>GET /__mockforge/smoke</code> - List available smoke test endpoints</li>
<li><code>GET /__mockforge/smoke/run</code> - Run all smoke tests</li>
</ul>
<p>These endpoints are also available in the Admin UI under the “Smoke Tests” tab.</p>
<h2 id="admin-ui-integration"><a class="header" href="#admin-ui-integration">Admin UI Integration</a></h2>
<p>The Admin UI provides a graphical interface for managing fixtures and running smoke tests:</p>
<ol>
<li>View all recorded fixtures in the “Fixtures” tab</li>
<li>Mark fixtures as ready-to-run for smoke testing</li>
<li>Run smoke tests with a single click</li>
<li>View smoke test results and status</li>
</ol>
<h2 id="configuration-3"><a class="header" href="#configuration-3">Configuration</a></h2>
<p>The following environment variables control fixture and smoke test behavior:</p>
<h3 id="core-settings"><a class="header" href="#core-settings">Core Settings</a></h3>
<ul>
<li><code>MOCKFORGE_FIXTURES_DIR</code> - Directory where fixtures are stored (default: <code>./fixtures</code>)</li>
<li><code>MOCKFORGE_RECORD_ENABLED</code> - Enable recording of requests (default: <code>false</code>)</li>
<li><code>MOCKFORGE_REPLAY_ENABLED</code> - Enable replay of recorded requests (default: <code>false</code>)</li>
</ul>
<h3 id="recording-options"><a class="header" href="#recording-options">Recording Options</a></h3>
<ul>
<li><code>MOCKFORGE_RECORD_GET_ONLY</code> - Record only GET requests (default: <code>false</code>)</li>
<li><code>MOCKFORGE_LATENCY_ENABLED</code> - Include latency in recorded fixtures (default: <code>true</code>)</li>
<li><code>MOCKFORGE_RESPONSE_TEMPLATE_EXPAND</code> - Expand templates when recording (default: <code>false</code>)</li>
</ul>
<h3 id="validation-and-testing-1"><a class="header" href="#validation-and-testing-1">Validation and Testing</a></h3>
<ul>
<li><code>MOCKFORGE_REQUEST_VALIDATION</code> - Validation level during recording (default: <code>enforce</code>)</li>
<li><code>MOCKFORGE_RESPONSE_VALIDATION</code> - Validate responses during replay (default: <code>false</code>)</li>
</ul>
<h3 id="configuration-file-support"><a class="header" href="#configuration-file-support">Configuration File Support</a></h3>
<p>You can also configure fixtures through YAML:</p>
<pre><code class="language-yaml"># In your configuration file
core:
  fixtures:
    dir: "./fixtures"
    record_enabled: false
    replay_enabled: false
    record_get_only: false
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="troubleshooting-10"><a class="header" href="#troubleshooting-10">Troubleshooting</a></h1>
<p>This guide helps you diagnose and resolve common issues with MockForge. If you’re experiencing problems, follow the steps below to identify and fix the issue.</p>
<h2 id="quick-diagnosis"><a class="header" href="#quick-diagnosis">Quick Diagnosis</a></h2>
<h3 id="check-server-status"><a class="header" href="#check-server-status">Check Server Status</a></h3>
<p>First, verify that MockForge is running and accessible:</p>
<pre><code class="language-bash"># Check if processes are running
ps aux | grep mockforge

# Check listening ports
netstat -tlnp | grep -E ":(3000|3001|50051|8080)"

# Test basic connectivity
curl -I http://localhost:3000/health 2&gt;/dev/null || echo "HTTP server not responding"
curl -I http://localhost:8080/health 2&gt;/dev/null || echo "Admin UI not responding"
</code></pre>
<h3 id="check-logs"><a class="header" href="#check-logs">Check Logs</a></h3>
<p>Enable verbose logging to see detailed information:</p>
<pre><code class="language-bash"># Run with debug logging
RUST_LOG=mockforge=debug mockforge serve --spec api-spec.yaml

# View recent logs
tail -f mockforge.log

# Filter logs by component
grep "ERROR" mockforge.log
grep "WARN" mockforge.log
</code></pre>
<h2 id="http-api-issues"><a class="header" href="#http-api-issues">HTTP API Issues</a></h2>
<h3 id="server-wont-start-1"><a class="header" href="#server-wont-start-1">Server Won’t Start</a></h3>
<p><strong>Symptoms</strong>: <code>mockforge serve</code> exits immediately with error</p>
<p><strong>Common causes and solutions</strong>:</p>
<ol>
<li>
<p><strong>Port already in use</strong>:</p>
<pre><code class="language-bash"># Find what's using the port
lsof -i :3000

# Kill conflicting process
kill -9 &lt;PID&gt;

# Or use different port
mockforge serve --http-port 3001
</code></pre>
</li>
<li>
<p><strong>Invalid OpenAPI specification</strong>:</p>
<pre><code class="language-bash"># Validate YAML syntax
yamllint api-spec.yaml

# Validate OpenAPI structure
swagger-cli validate api-spec.yaml

# Test with minimal spec
mockforge serve --spec examples/openapi-demo.json
</code></pre>
</li>
<li>
<p><strong>File permissions</strong>:</p>
<pre><code class="language-bash"># Check file access
ls -la api-spec.yaml

# Fix permissions if needed
chmod 644 api-spec.yaml
</code></pre>
</li>
</ol>
<h3 id="404-errors-for-valid-routes"><a class="header" href="#404-errors-for-valid-routes">404 Errors for Valid Routes</a></h3>
<p><strong>Symptoms</strong>: API returns 404 for endpoints that should exist</p>
<p><strong>Possible causes</strong>:</p>
<ol>
<li>
<p><strong>OpenAPI spec not loaded correctly</strong>:</p>
<pre><code class="language-bash"># Check if spec was loaded
grep "OpenAPI spec loaded" mockforge.log

# Verify file path
ls -la api-spec.yaml
</code></pre>
</li>
<li>
<p><strong>Path matching issues</strong>:</p>
<ul>
<li>Ensure paths in spec match request URLs</li>
<li>Check for trailing slashes</li>
<li>Verify HTTP methods match</li>
</ul>
</li>
<li>
<p><strong>Template expansion disabled</strong>:</p>
<pre><code class="language-bash"># Enable template expansion
mockforge serve --response-template-expand --spec api-spec.yaml
</code></pre>
</li>
</ol>
<h3 id="template-variables-not-working-1"><a class="header" href="#template-variables-not-working-1">Template Variables Not Working</a></h3>
<p><strong>Symptoms</strong>: <code>{{variable}}</code> appears literally in responses</p>
<p><strong>Solutions</strong>:</p>
<ol>
<li>
<p><strong>Enable template expansion</strong>:</p>
<pre><code class="language-bash"># Via command line
mockforge serve --response-template-expand --spec api-spec.yaml

# Via environment variable
MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true mockforge serve --spec api-spec.yaml

# Via config file
echo "response:\n  template_expand: true" &gt; config.yaml
mockforge serve --config config.yaml --spec api-spec.yaml
</code></pre>
</li>
<li>
<p><strong>Check template syntax</strong>:</p>
<ul>
<li>Use <code>{{variable}}</code> not <code>${variable}</code></li>
<li>Ensure variables are defined in spec examples</li>
<li>Check for typos in variable names</li>
</ul>
</li>
</ol>
<h3 id="validation-errors"><a class="header" href="#validation-errors">Validation Errors</a></h3>
<p><strong>Symptoms</strong>: Requests return 400/422 with validation errors</p>
<p><strong>Solutions</strong>:</p>
<ol>
<li>
<p><strong>Adjust validation mode</strong>:</p>
<pre><code class="language-bash"># Disable validation
mockforge serve --validation off --spec api-spec.yaml

# Use warning mode
mockforge serve --validation warn --spec api-spec.yaml
</code></pre>
</li>
<li>
<p><strong>Fix request format</strong>:</p>
<ul>
<li>Ensure Content-Type header matches request body format</li>
<li>Verify required fields are present</li>
<li>Check parameter formats match OpenAPI spec</li>
</ul>
</li>
</ol>
<h2 id="websocket-issues"><a class="header" href="#websocket-issues">WebSocket Issues</a></h2>
<h3 id="connection-fails"><a class="header" href="#connection-fails">Connection Fails</a></h3>
<p><strong>Symptoms</strong>: WebSocket client cannot connect</p>
<p><strong>Common causes</strong>:</p>
<ol>
<li>
<p><strong>Wrong port or path</strong>:</p>
<pre><code class="language-bash"># Check WebSocket port
netstat -tlnp | grep :3001

# Test connection
websocat ws://localhost:3001/ws
</code></pre>
</li>
<li>
<p><strong>Replay file not found</strong>:</p>
<pre><code class="language-bash"># Check file exists
ls -la ws-replay.jsonl

# Run without replay file
mockforge serve --ws-port 3001  # No replay file specified
</code></pre>
</li>
</ol>
<h3 id="messages-not-received"><a class="header" href="#messages-not-received">Messages Not Received</a></h3>
<p><strong>Symptoms</strong>: WebSocket connection established but no messages</p>
<p><strong>Solutions</strong>:</p>
<ol>
<li>
<p><strong>Check replay file format</strong>:</p>
<pre><code class="language-bash"># Validate JSONL syntax
node -e "
const fs = require('fs');
const lines = fs.readFileSync('ws-replay.jsonl', 'utf8').split('\n');
lines.forEach((line, i) =&gt; {
  if (line.trim()) {
    try { JSON.parse(line); }
    catch (e) { console.log(\`Line \${i+1}: \${e.message}\`); }
  }
});
"
</code></pre>
</li>
<li>
<p><strong>Verify message timing</strong>:</p>
<ul>
<li>Check <code>ts</code> values are in milliseconds</li>
<li>Ensure messages have required fields (<code>ts</code>, <code>dir</code>, <code>text</code>)</li>
</ul>
</li>
</ol>
<h3 id="interactive-mode-issues"><a class="header" href="#interactive-mode-issues">Interactive Mode Issues</a></h3>
<p><strong>Symptoms</strong>: Client messages not triggering responses</p>
<p><strong>Debug steps</strong>:</p>
<ol>
<li>
<p><strong>Check regex patterns</strong>:</p>
<pre><code class="language-bash"># Test regex patterns
node -e "
const pattern = '^HELLO';
const test = 'HELLO world';
console.log('Match:', test.match(new RegExp(pattern)));
"
</code></pre>
</li>
<li>
<p><strong>Verify state management</strong>:</p>
<ul>
<li>Check that state variables are properly set</li>
<li>Ensure conditional logic is correct</li>
</ul>
</li>
</ol>
<h2 id="grpc-issues"><a class="header" href="#grpc-issues">gRPC Issues</a></h2>
<h3 id="service-not-found"><a class="header" href="#service-not-found">Service Not Found</a></h3>
<p><strong>Symptoms</strong>: <code>grpcurl list</code> shows no services</p>
<p><strong>Solutions</strong>:</p>
<ol>
<li>
<p><strong>Check proto directory</strong>:</p>
<pre><code class="language-bash"># Verify proto files exist
find proto/ -name "*.proto"

# Check directory path
MOCKFORGE_PROTO_DIR=proto/ mockforge serve --grpc-port 50051
</code></pre>
</li>
<li>
<p><strong>Compilation errors</strong>:</p>
<pre><code class="language-bash"># Check for proto compilation errors
cargo build --verbose 2&gt;&amp;1 | grep -i proto
</code></pre>
</li>
<li>
<p><strong>Reflection disabled</strong>:</p>
<pre><code class="language-bash"># Enable gRPC reflection
MOCKFORGE_GRPC_REFLECTION_ENABLED=true mockforge serve --grpc-port 50051
</code></pre>
</li>
</ol>
<h3 id="method-calls-fail"><a class="header" href="#method-calls-fail">Method Calls Fail</a></h3>
<p><strong>Symptoms</strong>: gRPC calls return errors</p>
<p><strong>Debug steps</strong>:</p>
<ol>
<li>
<p><strong>Check service definition</strong>:</p>
<pre><code class="language-bash"># List service methods
grpcurl -plaintext localhost:50051 describe mockforge.user.UserService
</code></pre>
</li>
<li>
<p><strong>Validate request format</strong>:</p>
<pre><code class="language-bash"># Test with verbose output
grpcurl -plaintext -v -d '{"user_id": "123"}' localhost:50051 mockforge.user.UserService/GetUser
</code></pre>
</li>
<li>
<p><strong>Check proto compatibility</strong>:</p>
<ul>
<li>Ensure client and server use same proto definitions</li>
<li>Verify message field names and types match</li>
</ul>
</li>
</ol>
<h2 id="admin-ui-issues"><a class="header" href="#admin-ui-issues">Admin UI Issues</a></h2>
<h3 id="ui-not-loading"><a class="header" href="#ui-not-loading">UI Not Loading</a></h3>
<p><strong>Symptoms</strong>: Browser shows connection error</p>
<p><strong>Solutions</strong>:</p>
<ol>
<li>
<p><strong>Check admin port</strong>:</p>
<pre><code class="language-bash"># Verify port is listening
curl -I http://localhost:8080 2&gt;/dev/null || echo "Admin UI not accessible"

# Try different port
mockforge serve --admin --admin-port 9090
</code></pre>
</li>
<li>
<p><strong>CORS issues</strong>:</p>
<ul>
<li>Admin UI should work from any origin by default</li>
<li>Check browser console for CORS errors</li>
</ul>
</li>
<li>
<p><strong>Embedded vs standalone</strong>:</p>
<pre><code class="language-bash"># Force standalone mode
mockforge serve --admin --admin-standalone

# Or embedded mode
mockforge serve --admin --admin-embed
</code></pre>
</li>
</ol>
<h3 id="api-endpoints-not-working"><a class="header" href="#api-endpoints-not-working">API Endpoints Not Working</a></h3>
<p><strong>Symptoms</strong>: UI loads but API calls fail</p>
<p><strong>Solutions</strong>:</p>
<ol>
<li>
<p><strong>Check admin API</strong>:</p>
<pre><code class="language-bash"># Test admin API directly
curl http://localhost:8080/__mockforge/status
</code></pre>
</li>
<li>
<p><strong>Enable admin API</strong>:</p>
<pre><code class="language-bash"># Ensure admin API is not disabled
mockforge serve --admin  # Don't use --disable-admin-api
</code></pre>
</li>
</ol>
<h2 id="configuration-issues"><a class="header" href="#configuration-issues">Configuration Issues</a></h2>
<h3 id="config-file-not-loading"><a class="header" href="#config-file-not-loading">Config File Not Loading</a></h3>
<p><strong>Symptoms</strong>: Settings from config file are ignored</p>
<p><strong>Solutions</strong>:</p>
<ol>
<li>
<p><strong>Validate YAML syntax</strong>:</p>
<pre><code class="language-bash"># Check YAML format
python3 -c "import yaml; yaml.safe_load(open('config.yaml'))"

# Or use yamllint
yamllint config.yaml
</code></pre>
</li>
<li>
<p><strong>Check file path</strong>:</p>
<pre><code class="language-bash"># Use absolute path
mockforge serve --config /full/path/to/config.yaml

# Verify file permissions
ls -la config.yaml
</code></pre>
</li>
<li>
<p><strong>Environment variable override</strong>:</p>
<ul>
<li>Remember that environment variables override config file settings</li>
<li>Command-line arguments override both</li>
</ul>
</li>
</ol>
<h3 id="environment-variables-not-working"><a class="header" href="#environment-variables-not-working">Environment Variables Not Working</a></h3>
<p><strong>Symptoms</strong>: Environment variables are ignored</p>
<p><strong>Common issues</strong>:</p>
<ol>
<li>
<p><strong>Shell not reloaded</strong>:</p>
<pre><code class="language-bash"># Export variable and reload shell
export MOCKFORGE_HTTP_PORT=3001
exec $SHELL
</code></pre>
</li>
<li>
<p><strong>Variable name typos</strong>:</p>
<pre><code class="language-bash"># Check variable is set
echo $MOCKFORGE_HTTP_PORT

# List all MockForge variables
env | grep MOCKFORGE
</code></pre>
</li>
</ol>
<h2 id="performance-issues"><a class="header" href="#performance-issues">Performance Issues</a></h2>
<h3 id="high-memory-usage"><a class="header" href="#high-memory-usage">High Memory Usage</a></h3>
<p><strong>Symptoms</strong>: MockForge consumes excessive memory</p>
<p><strong>Solutions</strong>:</p>
<ol>
<li>
<p><strong>Reduce concurrent connections</strong>:</p>
<pre><code class="language-bash"># Limit connection pool
MOCKFORGE_MAX_CONNECTIONS=100 mockforge serve
</code></pre>
</li>
<li>
<p><strong>Disable unnecessary features</strong>:</p>
<pre><code class="language-bash"># Run with minimal features
mockforge serve --validation off --response-template-expand false
</code></pre>
</li>
<li>
<p><strong>Monitor resource usage</strong>:</p>
<pre><code class="language-bash"># Check memory usage
ps aux | grep mockforge

# Monitor over time
htop -p $(pgrep mockforge)
</code></pre>
</li>
</ol>
<h3 id="slow-response-times"><a class="header" href="#slow-response-times">Slow Response Times</a></h3>
<p><strong>Symptoms</strong>: API responses are slow</p>
<p><strong>Debug steps</strong>:</p>
<ol>
<li>
<p><strong>Enable latency logging</strong>:</p>
<pre><code class="language-bash">RUST_LOG=mockforge=debug mockforge serve --spec api-spec.yaml 2&gt;&amp;1 | grep -i latency
</code></pre>
</li>
<li>
<p><strong>Check template complexity</strong>:</p>
<ul>
<li>Complex templates can slow response generation</li>
<li>Consider caching for frequently used templates</li>
</ul>
</li>
<li>
<p><strong>Profile performance</strong>:</p>
<pre><code class="language-bash"># Use cargo flamegraph for profiling
cargo flamegraph --bin mockforge-cli -- serve --spec api-spec.yaml
</code></pre>
</li>
</ol>
<h2 id="docker-issues"><a class="header" href="#docker-issues">Docker Issues</a></h2>
<h3 id="container-wont-start"><a class="header" href="#container-wont-start">Container Won’t Start</a></h3>
<p><strong>Symptoms</strong>: Docker container exits immediately</p>
<p><strong>Solutions</strong>:</p>
<ol>
<li>
<p><strong>Check container logs</strong>:</p>
<pre><code class="language-bash">docker logs &lt;container-id&gt;

# Run with verbose output
docker run --rm mockforge mockforge serve --spec api-spec.yaml
</code></pre>
</li>
<li>
<p><strong>Volume mounting issues</strong>:</p>
<pre><code class="language-bash"># Ensure spec file is accessible
docker run -v $(pwd)/api-spec.yaml:/app/api-spec.yaml \
  mockforge mockforge serve --spec /app/api-spec.yaml
</code></pre>
</li>
<li>
<p><strong>Port conflicts</strong>:</p>
<pre><code class="language-bash"># Use different ports
docker run -p 3001:3000 -p 3002:3001 mockforge
</code></pre>
</li>
</ol>
<h2 id="getting-help-2"><a class="header" href="#getting-help-2">Getting Help</a></h2>
<h3 id="log-analysis-2"><a class="header" href="#log-analysis-2">Log Analysis</a></h3>
<pre><code class="language-bash"># Extract error patterns
grep "ERROR" mockforge.log | head -10

# Find recent issues
tail -100 mockforge.log | grep -E "(ERROR|WARN)"

# Count error types
grep "ERROR" mockforge.log | sed 's/.*ERROR //' | sort | uniq -c | sort -nr
</code></pre>
<h3 id="debug-commands-5"><a class="header" href="#debug-commands-5">Debug Commands</a></h3>
<pre><code class="language-bash"># Full system information
echo "=== System Info ==="
uname -a
echo "=== Rust Version ==="
rustc --version
echo "=== Cargo Version ==="
cargo --version
echo "=== Running Processes ==="
ps aux | grep mockforge
echo "=== Listening Ports ==="
netstat -tlnp | grep -E ":(3000|3001|50051|8080)"
echo "=== Disk Space ==="
df -h
echo "=== Memory Usage ==="
free -h
</code></pre>
<h3 id="community-support"><a class="header" href="#community-support">Community Support</a></h3>
<p>If you can’t resolve the issue:</p>
<ol>
<li><strong>Check existing issues</strong>: Search GitHub issues for similar problems</li>
<li><strong>Create a minimal reproduction</strong>: Isolate the issue with minimal configuration</li>
<li><strong>Include debug information</strong>: Attach logs, configuration, and system details</li>
<li><strong>Use descriptive titles</strong>: Clearly describe the problem in issue titles</li>
</ol>
<h3 id="emergency-stop"><a class="header" href="#emergency-stop">Emergency Stop</a></h3>
<p>If MockForge is causing issues:</p>
<pre><code class="language-bash"># Kill all MockForge processes
pkill -f mockforge

# Kill specific process
kill -9 &lt;mockforge-pid&gt;

# Clean up any leftover files
rm -f mockforge.log
</code></pre>
<p>This troubleshooting guide covers the most common issues. For more specific problems, check the logs and consider creating an issue on GitHub with detailed information about your setup and the problem you’re experiencing.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="faq"><a class="header" href="#faq">FAQ</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="changelog"><a class="header" href="#changelog">Changelog</a></h1>
<p>All notable changes to this project will be documented in this file.</p>
<p>The format is based on <a href="https://keepachangelog.com/en/1.0.0/">Keep a Changelog</a>,
and this project adheres to <a href="https://semver.org/spec/v2.0.0.html">Semantic Versioning</a>.</p>
<h2 id="unreleased"><a class="header" href="#unreleased">[Unreleased]</a></h2>
<h3 id="added"><a class="header" href="#added">Added</a></h3>
<ul>
<li>
<p>OpenAPI request validation (path/query/header/cookie/body) with deep $ref resolution and composite schemas (oneOf/anyOf/allOf).</p>
</li>
<li>
<p>Validation modes: <code>disabled</code>, <code>warn</code>, <code>enforce</code>, with aggregate error reporting and detailed error objects.</p>
</li>
<li>
<p>Runtime Admin UI panel to view/toggle validation mode and per-route overrides; Admin API endpoint <code>/__mockforge/validation</code>.</p>
</li>
<li>
<p>CLI flags and config options to control validation (including <code>skip_admin_validation</code> and per-route <code>validation_overrides</code>).</p>
</li>
<li>
<p>New e2e tests for 2xx/422 request validation and response example expansion across HTTP routes.</p>
</li>
<li>
<p>Templating reference docs and examples; WS templating tests and demo update.</p>
</li>
<li>
<p>Initial release of MockForge</p>
</li>
<li>
<p>HTTP API mocking with OpenAPI support</p>
</li>
<li>
<p>gRPC service mocking with Protocol Buffers</p>
</li>
<li>
<p>WebSocket connection mocking with replay functionality</p>
</li>
<li>
<p>CLI tool for easy local development</p>
</li>
<li>
<p>Admin UI for managing mock servers</p>
</li>
<li>
<p>Comprehensive documentation with mdBook</p>
</li>
<li>
<p>GitHub Actions CI/CD pipeline</p>
</li>
<li>
<p>Security audit integration</p>
</li>
<li>
<p>Pre-commit hooks for code quality</p>
</li>
</ul>
<h3 id="changed"><a class="header" href="#changed">Changed</a></h3>
<ul>
<li>HTTP handlers now perform request validation before routing; invalid requests return 400 with structured details (when <code>enforce</code>).</li>
<li>Bump <code>jsonschema</code> to 0.33 and adapt validator API; enable draft selection and format checks internally.</li>
<li>Improve route registry and OpenAPI parameter parsing, including styles/explode and array coercion for query/header/cookie parameters.</li>
</ul>
<h3 id="deprecated"><a class="header" href="#deprecated">Deprecated</a></h3>
<ul>
<li>N/A</li>
</ul>
<h3 id="removed"><a class="header" href="#removed">Removed</a></h3>
<ul>
<li>N/A</li>
</ul>
<h3 id="fixed"><a class="header" href="#fixed">Fixed</a></h3>
<ul>
<li>Resolve admin mount prefix from config and exclude admin routes from validation when configured.</li>
<li>Various small correctness fixes in OpenAPI schema mapping and parameter handling; clearer error messages.</li>
</ul>
<h3 id="security"><a class="header" href="#security">Security</a></h3>
<ul>
<li>N/A</li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>



        <script>
            window.playground_line_numbers = true;
        </script>

        <script>
            window.playground_copyable = true;
        </script>

        <script src="ace.js"></script>
        <script src="mode-rust.js"></script>
        <script src="editor.js"></script>
        <script src="theme-dawn.js"></script>
        <script src="theme-tomorrow_night.js"></script>

        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->
        <script src="custom.js"></script>

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>


    </div>
    </body>
</html>
