<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>MockForge Documentation</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="A comprehensive mocking framework for APIs, gRPC, and WebSockets">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="custom.css">


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "light";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "searchindex.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>‚Üê</kbd> or <kbd>‚Üí</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">MockForge Documentation</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/SaaSy-Solutions/mockforge" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <i class="fa fa-spinner fa-spin"></i>
                            </div>
                        </div>
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="mockforge"><a class="header" href="#mockforge">MockForge</a></h1>
<p><a href="https://crates.io/crates/mockforge"><img src="https://img.shields.io/crates/v/mockforge.svg" alt="Crates.io" /></a>
<a href="https://docs.rs/mockforge"><img src="https://docs.rs/mockforge/badge.svg" alt="Documentation" /></a>
<a href="https://github.com/SaaSy-Solutions/mockforge/actions"><img src="https://github.com/SaaSy-Solutions/mockforge/workflows/CI/badge.svg" alt="CI" /></a>
<a href="https://github.com/SaaSy-Solutions/mockforge/blob/main/LICENSE"><img src="https://img.shields.io/badge/license-MIT%20OR%20Apache--2.0-blue.svg" alt="License" /></a></p>
<p>MockForge is a comprehensive mocking framework for APIs, gRPC services, and WebSockets. It provides a unified interface for creating, managing, and deploying mock servers across different protocols.</p>
<h2 id="the-five-pillars"><a class="header" href="#the-five-pillars">The Five Pillars</a></h2>
<p>MockForge is built on five foundational pillars: <strong>[Reality]</strong>, <strong>[Contracts]</strong>, <strong>[DevX]</strong>, <strong>[Cloud]</strong>, and <strong>[AI]</strong>. These pillars guide every feature we build and help you understand how MockForge delivers value. See the <a href="../../docs/PILLARS.html">complete Pillars documentation</a> for detailed information.</p>
<h2 id="features"><a class="header" href="#features">Features</a></h2>
<ul>
<li><strong>Multi-Protocol Support</strong>: HTTP REST APIs, gRPC services, and WebSocket connections</li>
<li><strong>Dynamic Response Generation</strong>: Create realistic mock responses with configurable latency and failure rates</li>
<li><strong>Scenario Management</strong>: Define complex interaction scenarios with state management</li>
<li><strong>CLI Tool</strong>: Easy-to-use command-line interface for local development</li>
<li><strong>Admin UI</strong>: Web-based interface for managing mock servers</li>
<li><strong>Extensible Architecture</strong>: Plugin system for custom response generators</li>
</ul>
<h2 id="quick-start"><a class="header" href="#quick-start">Quick Start</a></h2>
<h3 id="installation"><a class="header" href="#installation">Installation</a></h3>
<pre><code class="language-bash">cargo install mockforge-cli
</code></pre>
<h3 id="basic-usage"><a class="header" href="#basic-usage">Basic Usage</a></h3>
<pre><code class="language-bash"># Start a mock server with an OpenAPI spec
cargo run -p mockforge-cli -- serve --spec examples/openapi-demo.json --http-port 3000

# Add WebSocket support with replay file
MOCKFORGE_WS_REPLAY_FILE=examples/ws-demo.jsonl cargo run -p mockforge-cli -- serve --ws-port 3001

# Full configuration with Admin UI
MOCKFORGE_WS_REPLAY_FILE=examples/ws-demo.jsonl \
MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true \
cargo run -p mockforge-cli -- serve --spec examples/openapi-demo.json --admin --admin-port 9080

# Use configuration file
cargo run -p mockforge-cli -- serve --config demo-config.yaml
</code></pre>
<h3 id="docker"><a class="header" href="#docker">Docker</a></h3>
<pre><code class="language-bash">docker run -p 3000:3000 -p 3001:3001 -p 50051:50051 SaaSy-Solutions/mockforge
</code></pre>
<h2 id="documentation-structure"><a class="header" href="#documentation-structure">Documentation Structure</a></h2>
<ul>
<li><a href="getting-started.html">Getting Started</a> - Installation and basic setup</li>
<li><a href="http-mocking.html">HTTP Mocking</a> - REST API mocking guide</li>
<li><a href="grpc-mocking.html">gRPC Mocking</a> - gRPC service mocking</li>
<li><a href="websocket-mocking.html">WebSocket Mocking</a> - WebSocket connection mocking</li>
<li><a href="configuration.html">Configuration</a> - Advanced configuration options</li>
<li><a href="api-reference.html">API Reference</a> - Complete API documentation</li>
<li><a href="contributing.html">Contributing</a> - How to contribute to MockForge</li>
<li><a href="faq.html">FAQ</a> - Frequently asked questions</li>
</ul>
<h2 id="examples"><a class="header" href="#examples">Examples</a></h2>
<p>Check out the <a href="../examples/"><code>examples/</code></a> directory for sample configurations and use cases.</p>
<h2 id="community"><a class="header" href="#community">Community</a></h2>
<ul>
<li><a href="https://github.com/SaaSy-Solutions/mockforge/issues">GitHub Issues</a> - Report bugs and request features</li>
<li><a href="https://github.com/SaaSy-Solutions/mockforge/discussions">GitHub Discussions</a> - Ask questions and share ideas</li>
<li><a href="https://discord.gg/2FxXqKpa">Discord</a> - Join our community chat</li>
</ul>
<h2 id="license"><a class="header" href="#license">License</a></h2>
<p>Licensed under either of:</p>
<ul>
<li>Apache License, Version 2.0 (<a href="https://github.com/SaaSy-Solutions/mockforge/blob/main/LICENSE-APACHE">LICENSE-APACHE</a>)</li>
<li>MIT License (<a href="https://github.com/SaaSy-Solutions/mockforge/blob/main/LICENSE-MIT">LICENSE-MIT</a>)</li>
</ul>
<p>at your option.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="getting-started-with-mockforge"><a class="header" href="#getting-started-with-mockforge">Getting Started with MockForge</a></h1>
<p><strong>Welcome to MockForge!</strong> This guide will get you up and running in minutes. MockForge is a powerful, multi-protocol mocking framework that helps frontend and backend teams work in parallel by providing realistic API mocks.</p>
<h2 id="table-of-contents"><a class="header" href="#table-of-contents">Table of Contents</a></h2>
<ul>
<li><a href="getting-started/getting-started.html#what-is-mockforge">What is MockForge?</a></li>
<li><a href="getting-started/getting-started.html#installation">Installation</a></li>
<li><a href="getting-started/getting-started.html#quick-start-your-first-mock-api">Quick Start: Your First Mock API</a></li>
<li><a href="getting-started/getting-started.html#basic-configuration">Basic Configuration</a></li>
<li><a href="getting-started/getting-started.html#next-steps">Next Steps</a></li>
</ul>
<h2 id="what-is-mockforge"><a class="header" href="#what-is-mockforge">What is MockForge?</a></h2>
<p>MockForge is a comprehensive mocking framework that supports multiple protocols:</p>
<ul>
<li><strong>HTTP/REST APIs</strong> - Mock REST endpoints from OpenAPI/Swagger specs</li>
<li><strong>WebSocket</strong> - Simulate real-time connections with replay and interactive modes</li>
<li><strong>gRPC</strong> - Mock gRPC services from <code>.proto</code> files</li>
<li><strong>GraphQL</strong> - Generate mock resolvers from GraphQL schemas</li>
</ul>
<h3 id="why-mockforge"><a class="header" href="#why-mockforge">Why MockForge?</a></h3>
<ul>
<li>üöÄ <strong>Fast Setup</strong>: Go from OpenAPI spec to running mock server in seconds</li>
<li>üîÑ <strong>Multi-Protocol</strong>: Mock HTTP, WebSocket, gRPC, and GraphQL in one tool</li>
<li>üéØ <strong>Realistic Data</strong>: Generate intelligent mock data with faker functions and templates</li>
<li>üîå <strong>Extensible</strong>: Plugin system for custom authentication, templates, and data sources</li>
<li>üìä <strong>Admin UI</strong>: Visual interface for monitoring and managing mock servers</li>
</ul>
<h2 id="the-five-pillars-of-mockforge"><a class="header" href="#the-five-pillars-of-mockforge">The Five Pillars of MockForge</a></h2>
<p>MockForge is built on five foundational pillars that guide every feature we build. Understanding these pillars helps you see how MockForge delivers value across different aspects of API mocking:</p>
<h3 id="reality--everything-that-makes-mocks-feel-like-a-real-evolving-backend"><a class="header" href="#reality--everything-that-makes-mocks-feel-like-a-real-evolving-backend">[Reality] ‚Äì Everything that makes mocks feel like a real, evolving backend</a></h3>
<p>Make mocks indistinguishable from production backends through realistic behavior, state management, and dynamic data generation. Features like Reality Continuum, Smart Personas, Chaos Lab, and Temporal Simulation ensure your mocks behave like real systems.</p>
<p><strong>Key Features:</strong></p>
<ul>
<li>Reality Continuum and Reality Slider for configurable realism levels</li>
<li>Smart Personas for consistent cross-endpoint data generation</li>
<li>Generative Schema Mode for dynamic mock data without seed data</li>
<li>Chaos Lab for network condition simulation</li>
<li>Multi-protocol support (HTTP, gRPC, WebSocket, Kafka, MQTT, AMQP, SMTP, FTP, TCP)</li>
</ul>
<h3 id="contracts--schema-drift-validation-and-safety-nets"><a class="header" href="#contracts--schema-drift-validation-and-safety-nets">[Contracts] ‚Äì Schema, drift, validation, and safety nets</a></h3>
<p>Ensure API contracts are correct, validated, and stay in sync with real backends. Features like AI Contract Diff, automatic API sync, and comprehensive validation help catch breaking changes before they reach production.</p>
<p><strong>Key Features:</strong></p>
<ul>
<li>OpenAPI/GraphQL schema validation</li>
<li>AI Contract Diff for contract comparison and visualization</li>
<li>Automatic API Sync &amp; Change Detection</li>
<li>Request/response validation with detailed error reporting</li>
<li>Contract drift detection and monitoring</li>
</ul>
<h3 id="devx--sdks-generators-playgrounds-ergonomics"><a class="header" href="#devx--sdks-generators-playgrounds-ergonomics">[DevX] ‚Äì SDKs, generators, playgrounds, ergonomics</a></h3>
<p>Make MockForge effortless to use, integrate, and extend for developers. Native SDKs for 6 languages, client code generators, interactive playgrounds, and comprehensive tooling ensure a smooth developer experience.</p>
<p><strong>Key Features:</strong></p>
<ul>
<li>Multi-language SDKs (Rust, Node.js, Python, Go, Java, .NET)</li>
<li>Client code generators (React, Vue, Angular, Svelte)</li>
<li>GraphQL + REST Playground</li>
<li>CLI tool and Admin UI</li>
<li>Plugin system for extensibility</li>
</ul>
<h3 id="cloud--registry-orgs-governance-monetization-marketplace"><a class="header" href="#cloud--registry-orgs-governance-monetization-marketplace">[Cloud] ‚Äì Registry, orgs, governance, monetization, marketplace</a></h3>
<p>Enable team collaboration, sharing, and scaling from solo developers to enterprise organizations. Cloud workspaces, scenario marketplace, registry server, and organization management help teams work together effectively.</p>
<p><strong>Key Features:</strong></p>
<ul>
<li>Cloud Workspaces for team collaboration</li>
<li>Scenario Marketplace for sharing mock scenarios</li>
<li>Registry Server for centralized distribution</li>
<li>Organization Management for enterprise teams</li>
<li>Security controls and governance</li>
</ul>
<h3 id="ai--llmvoice-flows-ai-diffassist-generative-behaviors"><a class="header" href="#ai--llmvoice-flows-ai-diffassist-generative-behaviors">[AI] ‚Äì LLM/voice flows, AI diff/assist, generative behaviors</a></h3>
<p>Leverage artificial intelligence to automate mock generation, enhance data realism, and assist developers. AI-powered features like MockAI, voice interface, and intelligent contract analysis make mock creation effortless.</p>
<p><strong>Key Features:</strong></p>
<ul>
<li>MockAI for intelligent mock generation from natural language</li>
<li>Voice + LLM Interface for voice-driven mock creation</li>
<li>AI Contract Diff for intelligent contract analysis</li>
<li>AI Event Streams for narrative-driven WebSocket events</li>
<li>Generative data behaviors with RAG-powered synthesis</li>
</ul>
<p><strong>Learn More:</strong> See the <a href="getting-started/../../docs/PILLARS.html">complete Pillars documentation</a> for detailed information about each pillar, feature mappings, and examples.</p>
<h2 id="choose-your-path"><a class="header" href="#choose-your-path">Choose Your Path</a></h2>
<p>Depending on your role, team, or use case, you may want to start with a specific pillar:</p>
<ul>
<li><strong><a href="getting-started/reality-first.html">Reality-First Onboarding</a></strong> - Start here if you care about realism. Perfect for frontend teams needing realistic data that evolves over time.</li>
<li><strong><a href="getting-started/contracts-first.html">Contracts-First Onboarding</a></strong> - Start here if you‚Äôre a Platform/API team. Perfect for teams needing contract validation and drift detection.</li>
<li><strong><a href="getting-started/ai-first.html">AI-First Onboarding</a></strong> - Start here if you want natural-language-driven mocks. Perfect for rapid prototyping and AI-powered mock generation.</li>
</ul>
<p>See <a href="getting-started/../../docs/JOURNEYS_BY_PILLAR.html">Journeys by Pillar</a> for a complete overview of all pillar-first onboarding journeys.</p>
<h2 id="installation-1"><a class="header" href="#installation-1">Installation</a></h2>
<h3 id="prerequisites"><a class="header" href="#prerequisites">Prerequisites</a></h3>
<p>MockForge requires one of:</p>
<ul>
<li>Rust toolchain (for <code>cargo install</code>)</li>
<li>Docker (for containerized deployment)</li>
</ul>
<h3 id="method-1-cargo-install-recommended"><a class="header" href="#method-1-cargo-install-recommended">Method 1: Cargo Install (Recommended)</a></h3>
<pre><code class="language-bash">cargo install mockforge-cli
</code></pre>
<p>Verify installation:</p>
<pre><code class="language-bash">mockforge --version
</code></pre>
<h3 id="method-2-docker"><a class="header" href="#method-2-docker">Method 2: Docker</a></h3>
<pre><code class="language-bash"># Build the Docker image
git clone https://github.com/SaaSy-Solutions/mockforge.git
cd mockforge
docker build -t mockforge .

# Run with default ports
docker run -p 3000:3000 -p 3001:3001 -p 9080:9080 mockforge
</code></pre>
<h3 id="method-3-build-from-source"><a class="header" href="#method-3-build-from-source">Method 3: Build from Source</a></h3>
<pre><code class="language-bash">git clone https://github.com/SaaSy-Solutions/mockforge.git
cd mockforge
cargo build --release

# Install globally
cargo install --path crates/mockforge-cli
</code></pre>
<p><strong>See <a href="getting-started/installation.html">Installation Guide</a> for detailed instructions and troubleshooting.</strong></p>
<h2 id="quick-start-your-first-mock-api"><a class="header" href="#quick-start-your-first-mock-api">Quick Start: Your First Mock API</a></h2>
<p>Let‚Äôs create a simple mock API in 3 steps:</p>
<h3 id="step-1-create-an-openapi-specification"><a class="header" href="#step-1-create-an-openapi-specification">Step 1: Create an OpenAPI Specification</a></h3>
<p>Create a file <code>my-api.yaml</code>:</p>
<pre><code class="language-yaml">openapi: 3.0.3
info:
  title: My First API
  version: 1.0.0
paths:
  /users:
    get:
      summary: List users
      responses:
        '200':
          description: Success
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: '#/components/schemas/User'
    post:
      summary: Create user
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/User'
      responses:
        '201':
          description: Created
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/User'
  /users/{id}:
    get:
      summary: Get user by ID
      parameters:
        - name: id
          in: path
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Success
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/User'
components:
  schemas:
    User:
      type: object
      required:
        - id
        - name
        - email
      properties:
        id:
          type: string
          example: "{{uuid}}"
        name:
          type: string
          example: "John Doe"
        email:
          type: string
          format: email
          example: "john@example.com"
        createdAt:
          type: string
          format: date-time
          example: "{{now}}"
</code></pre>
<h3 id="step-2-start-mockforge-with-your-spec"><a class="header" href="#step-2-start-mockforge-with-your-spec">Step 2: Start MockForge with Your Spec</a></h3>
<pre><code class="language-bash">mockforge serve --spec my-api.yaml --http-port 3000
</code></pre>
<p>You should see:</p>
<pre><code>üöÄ MockForge v1.0.0 starting...
üì° HTTP server listening on 0.0.0.0:3000
üìã OpenAPI spec loaded from my-api.yaml
‚úÖ Ready to serve requests at http://localhost:3000
</code></pre>
<h3 id="step-3-test-your-mock-api"><a class="header" href="#step-3-test-your-mock-api">Step 3: Test Your Mock API</a></h3>
<p>Open a new terminal and test your endpoints:</p>
<pre><code class="language-bash"># List users
curl http://localhost:3000/users

# Get a specific user
curl http://localhost:3000/users/123

# Create a user
curl -X POST http://localhost:3000/users \
  -H "Content-Type: application/json" \
  -d '{"name": "Jane Smith", "email": "jane@example.com"}'
</code></pre>
<p><strong>Congratulations!</strong> You have a working mock API! üéâ</p>
<h3 id="enable-dynamic-data-optional"><a class="header" href="#enable-dynamic-data-optional">Enable Dynamic Data (Optional)</a></h3>
<p>To get unique data on each request, enable template expansion:</p>
<pre><code class="language-bash"># Stop the server (Ctrl+C), then restart with templates enabled
MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true \
  mockforge serve --spec my-api.yaml --http-port 3000
</code></pre>
<p>Now <code>{{uuid}}</code> and <code>{{now}}</code> in your spec will generate unique values!</p>
<h2 id="basic-configuration"><a class="header" href="#basic-configuration">Basic Configuration</a></h2>
<h3 id="using-a-configuration-file"><a class="header" href="#using-a-configuration-file">Using a Configuration File</a></h3>
<p>Create <code>mockforge.yaml</code> for better control:</p>
<pre><code class="language-yaml">http:
  port: 3000
  openapi_spec: my-api.yaml
  response_template_expand: true
  cors:
    enabled: true
    allowed_origins: ["http://localhost:3000"]

admin:
  enabled: true
  port: 9080

logging:
  level: info
</code></pre>
<p>Start with the config file:</p>
<pre><code class="language-bash">mockforge serve --config mockforge.yaml
</code></pre>
<h3 id="environment-variables"><a class="header" href="#environment-variables">Environment Variables</a></h3>
<p>All settings can be set via environment variables:</p>
<pre><code class="language-bash">export MOCKFORGE_HTTP_PORT=3000
export MOCKFORGE_ADMIN_ENABLED=true
export MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true
export MOCKFORGE_LOG_LEVEL=debug

mockforge serve --spec my-api.yaml
</code></pre>
<p><strong>See <a href="getting-started/../configuration/files.html">Configuration Reference</a> for all options.</strong></p>
<h2 id="common-use-cases"><a class="header" href="#common-use-cases">Common Use Cases</a></h2>
<h3 id="frontend-development"><a class="header" href="#frontend-development">Frontend Development</a></h3>
<p>Start a mock server and point your frontend to it:</p>
<pre><code class="language-bash"># Terminal 1: Start mock server
mockforge serve --spec api.json --http-port 3000 --admin

# Terminal 2: Point frontend to mock server
export REACT_APP_API_URL=http://localhost:3000
npm start
</code></pre>
<h3 id="api-contract-testing"><a class="header" href="#api-contract-testing">API Contract Testing</a></h3>
<p>Test that your API matches the OpenAPI specification:</p>
<pre><code class="language-bash">mockforge serve --spec api.json \
  --validation enforce \
  --http-port 3000
</code></pre>
<h3 id="team-collaboration"><a class="header" href="#team-collaboration">Team Collaboration</a></h3>
<p>Share mock configurations via Git:</p>
<pre><code class="language-bash"># Commit your mock config
git add mockforge.yaml
git commit -m "Add user API mocks"

# Team members can use the same mocks
git pull
mockforge serve --config mockforge.yaml
</code></pre>
<h2 id="next-steps"><a class="header" href="#next-steps">Next Steps</a></h2>
<p>Now that you have MockForge running, explore these resources:</p>
<h3 id="tutorials"><a class="header" href="#tutorials">Tutorials</a></h3>
<ul>
<li><a href="getting-started/five-minute-api.html">5-Minute API Tutorial</a> - Build a complete mock API quickly</li>
<li><a href="getting-started/../tutorials/mock-openapi-spec.html">Mock from OpenAPI Spec</a> - Detailed OpenAPI workflow</li>
<li><a href="getting-started/../tutorials/react-workflow.html">React + MockForge Workflow</a> - Use MockForge with React apps</li>
<li><a href="getting-started/../tutorials/vue-workflow.html">Vue + MockForge Workflow</a> - Use MockForge with Vue apps</li>
</ul>
<h3 id="user-guides"><a class="header" href="#user-guides">User Guides</a></h3>
<ul>
<li><a href="getting-started/../user-guide/http-mocking.html">HTTP Mocking</a> - REST API mocking features</li>
<li><a href="getting-started/../user-guide/websocket-mocking.html">WebSocket Mocking</a> - Real-time connection mocking</li>
<li><a href="getting-started/../user-guide/grpc-mocking.html">gRPC Mocking</a> - gRPC service mocking</li>
<li><a href="getting-started/../user-guide/plugins.html">Plugin System</a> - Extend MockForge with plugins</li>
</ul>
<h3 id="reference"><a class="header" href="#reference">Reference</a></h3>
<ul>
<li><a href="getting-started/../configuration/files.html">Configuration Guide</a> - Complete configuration options</li>
<li><a href="getting-started/../reference/faq.html">FAQ</a> - Common questions and answers</li>
<li><a href="getting-started/../reference/troubleshooting.html">Troubleshooting</a> - Solve common issues</li>
</ul>
<h3 id="examples-1"><a class="header" href="#examples-1">Examples</a></h3>
<ul>
<li><a href="getting-started/../../examples/react-demo/">React Demo</a> - Complete React application</li>
<li><a href="getting-started/../../examples/vue-demo/">Vue Demo</a> - Complete Vue 3 application</li>
<li><a href="getting-started/../../examples/README.html">Example Projects</a> - All available examples</li>
</ul>
<h2 id="troubleshooting"><a class="header" href="#troubleshooting">Troubleshooting</a></h2>
<h3 id="server-wont-start"><a class="header" href="#server-wont-start">Server Won‚Äôt Start</a></h3>
<pre><code class="language-bash"># Check if port is in use
lsof -i :3000

# Use a different port
mockforge serve --spec my-api.yaml --http-port 3001
</code></pre>
<h3 id="templates-not-working"><a class="header" href="#templates-not-working">Templates Not Working</a></h3>
<p>Enable template expansion:</p>
<pre><code class="language-bash">MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true mockforge serve --spec my-api.yaml
</code></pre>
<h3 id="need-more-help"><a class="header" href="#need-more-help">Need More Help?</a></h3>
<ul>
<li>Check the <a href="getting-started/../reference/faq.html">FAQ</a></li>
<li>Review <a href="getting-started/../reference/troubleshooting.html">Troubleshooting Guide</a></li>
<li><a href="https://github.com/SaaSy-Solutions/mockforge/issues">Open a GitHub Issue</a></li>
</ul>
<hr />
<p><strong>Ready to dive deeper?</strong> Continue to the <a href="getting-started/five-minute-api.html">5-Minute Tutorial</a> or explore <a href="getting-started/../../examples/README.html">all available examples</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="installation-2"><a class="header" href="#installation-2">Installation</a></h1>
<p>MockForge can be installed through multiple methods depending on your needs and environment. Choose the installation method that best fits your workflow.</p>
<h2 id="prerequisites-1"><a class="header" href="#prerequisites-1">Prerequisites</a></h2>
<p>Before installing MockForge, ensure you have one of the following:</p>
<ul>
<li><strong>Rust toolchain</strong> (for cargo installation or building from source)</li>
<li><strong>Docker</strong> (for containerized deployment)</li>
<li><strong>Pre-built binaries</strong> (when available)</li>
</ul>
<h2 id="method-1-cargo-install-recommended-1"><a class="header" href="#method-1-cargo-install-recommended-1">Method 1: Cargo Install (Recommended)</a></h2>
<p>The easiest way to install MockForge is through Cargo, Rust‚Äôs package manager:</p>
<pre><code class="language-bash">cargo install mockforge-cli
</code></pre>
<p>This installs the MockForge CLI globally on your system. After installation, you can verify it‚Äôs working:</p>
<pre><code class="language-bash">mockforge --version
</code></pre>
<h3 id="updating"><a class="header" href="#updating">Updating</a></h3>
<p>To update to the latest version:</p>
<pre><code class="language-bash">cargo install mockforge-cli --force
</code></pre>
<h2 id="method-2-docker-containerized"><a class="header" href="#method-2-docker-containerized">Method 2: Docker (Containerized)</a></h2>
<p>MockForge is also available as a Docker image, which is ideal for:</p>
<ul>
<li>Isolated environments</li>
<li>CI/CD pipelines</li>
<li>Systems without Rust installed</li>
</ul>
<h3 id="build-docker-image"><a class="header" href="#build-docker-image">Build Docker image</a></h3>
<p>Since pre-built images are not yet published to Docker Hub, build the image locally:</p>
<pre><code class="language-bash"># Clone and build
git clone https://github.com/SaaSy-Solutions/mockforge.git
cd mockforge
docker build -t mockforge .
</code></pre>
<h3 id="run-with-basic-configuration"><a class="header" href="#run-with-basic-configuration">Run with basic configuration</a></h3>
<pre><code class="language-bash">docker run -p 3000:3000 -p 3001:3001 -p 50051:50051 -p 9080:9080 \
  -e MOCKFORGE_ADMIN_ENABLED=true \
  -e MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true \
  mockforge
</code></pre>
<h3 id="alternative-docker-compose"><a class="header" href="#alternative-docker-compose">Alternative: Docker Compose</a></h3>
<p>For a complete setup with all services:</p>
<pre><code class="language-bash">git clone https://github.com/SaaSy-Solutions/mockforge.git
cd mockforge
docker-compose up
</code></pre>
<h3 id="build-from-source-without-docker"><a class="header" href="#build-from-source-without-docker">Build from source (without Docker)</a></h3>
<pre><code class="language-bash">git clone https://github.com/SaaSy-Solutions/mockforge.git
cd mockforge
docker build -t mockforge .
</code></pre>
<h2 id="method-3-building-from-source"><a class="header" href="#method-3-building-from-source">Method 3: Building from Source</a></h2>
<p>For development or custom builds, you can build MockForge from source:</p>
<pre><code class="language-bash">git clone https://github.com/SaaSy-Solutions/mockforge.git
cd mockforge
cargo build --release
</code></pre>
<p>The binary will be available at <code>target/release/mockforge</code>.</p>
<p>To install it system-wide after building:</p>
<pre><code class="language-bash">cargo install --path crates/mockforge-cli
</code></pre>
<h2 id="verification"><a class="header" href="#verification">Verification</a></h2>
<p>After installation, verify MockForge is working:</p>
<pre><code class="language-bash"># Check version
mockforge --version

# View help
mockforge --help

# Start with example configuration
mockforge serve --spec examples/openapi-demo.json --http-port 3000
</code></pre>
<h2 id="platform-support"><a class="header" href="#platform-support">Platform Support</a></h2>
<p>MockForge supports:</p>
<ul>
<li><strong>Linux</strong> (x86_64, aarch64)</li>
<li><strong>macOS</strong> (x86_64, aarch64)</li>
<li><strong>Windows</strong> (x86_64)</li>
<li><strong>Docker</strong> (any platform with Docker support)</li>
</ul>
<h2 id="troubleshooting-installation"><a class="header" href="#troubleshooting-installation">Troubleshooting Installation</a></h2>
<h3 id="cargo-installation-fails"><a class="header" href="#cargo-installation-fails">Cargo installation fails</a></h3>
<p>If <code>cargo install</code> fails, ensure you have Rust installed:</p>
<pre><code class="language-bash">curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
source $HOME/.cargo/env
</code></pre>
<h3 id="docker-permission-issues"><a class="header" href="#docker-permission-issues">Docker permission issues</a></h3>
<p>If Docker commands fail with permission errors:</p>
<pre><code class="language-bash"># Add user to docker group (Linux)
sudo usermod -aG docker $USER
# Log out and back in for changes to take effect
</code></pre>
<h3 id="port-conflicts"><a class="header" href="#port-conflicts">Port conflicts</a></h3>
<p>If default ports (3000, 3001, 9080, 50051) are in use:</p>
<pre><code class="language-bash"># Check what's using the ports
lsof -i :3000
lsof -i :3001

# Kill conflicting processes or use different ports
mockforge serve --http-port 3001 --ws-port 3002 --admin-port 8081
</code></pre>
<h2 id="next-steps-1"><a class="header" href="#next-steps-1">Next Steps</a></h2>
<p>Once installed, proceed to the <a href="getting-started/quick-start.html">Quick Start</a> guide to create your first mock server, or read about <a href="getting-started/concepts.html">Basic Concepts</a> to understand how MockForge works.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="your-first-mock-api-in-5-minutes"><a class="header" href="#your-first-mock-api-in-5-minutes">Your First Mock API in 5 Minutes</a></h1>
<p><strong>Scenario</strong>: Your frontend team needs a <code>/users</code> API to continue development, but the backend isn‚Äôt ready. Let‚Äôs create a working mock in 5 minutes.</p>
<h2 id="step-1-install-mockforge-30-seconds"><a class="header" href="#step-1-install-mockforge-30-seconds">Step 1: Install MockForge (30 seconds)</a></h2>
<pre><code class="language-bash">cargo install mockforge-cli
</code></pre>
<p>Or use the pre-built binary from the <a href="https://github.com/SaaSy-Solutions/mockforge/releases">releases page</a>.</p>
<h2 id="step-2-create-a-simple-config-1-minute"><a class="header" href="#step-2-create-a-simple-config-1-minute">Step 2: Create a Simple Config (1 minute)</a></h2>
<p>You can either create a config manually or use the <code>init</code> command:</p>
<pre><code class="language-bash"># Option A: Use the init command (recommended)
mockforge init .

# This creates mockforge.yaml with sensible defaults
# Then edit it to match the config below

# Option B: Create manually
</code></pre>
<p>Create a file called <code>my-api.yaml</code> (or edit the generated <code>mockforge.yaml</code>):</p>
<pre><code class="language-yaml">http:
  port: 3000
  routes:
    - path: /users
      method: GET
      response:
        status: 200
        body: |
          [
            {
              "id": "{{uuid}}",
              "name": "Alice Johnson",
              "email": "alice@example.com",
              "createdAt": "{{now}}"
            },
            {
              "id": "{{uuid}}",
              "name": "Bob Smith",
              "email": "bob@example.com",
              "createdAt": "{{now}}"
            }
          ]

    - path: /users/{id}
      method: GET
      response:
        status: 200
        body: |
          {
            "id": "{{request.path.id}}",
            "name": "Alice Johnson",
            "email": "alice@example.com",
            "createdAt": "{{now}}"
          }

    - path: /users
      method: POST
      response:
        status: 201
        body: |
          {
            "id": "{{uuid}}",
            "name": "{{request.body.name}}",
            "email": "{{request.body.email}}",
            "createdAt": "{{now}}"
          }
</code></pre>
<h2 id="step-3-validate-your-config-optional-but-recommended"><a class="header" href="#step-3-validate-your-config-optional-but-recommended">Step 3: Validate Your Config (Optional but Recommended)</a></h2>
<pre><code class="language-bash">mockforge config validate --config my-api.yaml
</code></pre>
<p>You should see:</p>
<pre><code>‚úÖ Configuration is valid

üìä Summary:
   Found 3 HTTP routes
</code></pre>
<h2 id="step-4-start-the-server-10-seconds"><a class="header" href="#step-4-start-the-server-10-seconds">Step 4: Start the Server (10 seconds)</a></h2>
<pre><code class="language-bash">mockforge serve --config my-api.yaml
</code></pre>
<p>You‚Äôll see:</p>
<pre><code>MockForge v1.0.0 starting...
HTTP server listening on 0.0.0.0:3000
Ready to serve requests at http://localhost:3000
</code></pre>
<h2 id="step-5-test-it-30-seconds"><a class="header" href="#step-5-test-it-30-seconds">Step 5: Test It (30 seconds)</a></h2>
<p>Open a new terminal and test your endpoints:</p>
<pre><code class="language-bash"># Get all users
curl http://localhost:3000/users

# Get a specific user
curl http://localhost:3000/users/123

# Create a new user
curl -X POST http://localhost:3000/users \
  -H "Content-Type: application/json" \
  -d '{"name": "Charlie Brown", "email": "charlie@example.com"}'
</code></pre>
<p><strong>What just happened?</strong></p>
<ul>
<li><code>{{uuid}}</code> generates a unique ID each time</li>
<li><code>{{now}}</code> adds the current timestamp</li>
<li><code>{{request.path.id}}</code> captures the ID from the URL</li>
<li><code>{{request.body.name}}</code> reads data from POST requests</li>
</ul>
<h2 id="step-6-enable-dynamic-data-1-minute"><a class="header" href="#step-6-enable-dynamic-data-1-minute">Step 6: Enable Dynamic Data (1 minute)</a></h2>
<p>Want different data each time? Enable template expansion:</p>
<pre><code class="language-bash"># Stop the server (Ctrl+C), then restart:
MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true mockforge serve --config my-api.yaml
</code></pre>
<p>Now every request returns unique UUIDs and timestamps!</p>
<h2 id="step-7-add-the-admin-ui-30-seconds"><a class="header" href="#step-7-add-the-admin-ui-30-seconds">Step 7: Add the Admin UI (30 seconds)</a></h2>
<p>Want to see requests in real-time?</p>
<pre><code class="language-bash">mockforge serve --config my-api.yaml --admin --admin-port 9080
</code></pre>
<p>Open http://localhost:9080 in your browser to see:</p>
<ul>
<li>Live request logs</li>
<li>API metrics</li>
<li>Configuration controls</li>
</ul>
<h2 id="whats-next"><a class="header" href="#whats-next">What‚Äôs Next?</a></h2>
<p><strong>In the next 5 minutes</strong>, you could:</p>
<ol>
<li>
<p><strong>Use an OpenAPI Spec</strong> instead of YAML routes:</p>
<pre><code class="language-bash">mockforge serve --spec your-api.json --admin
</code></pre>
</li>
<li>
<p><strong>Add a Plugin</strong> for custom data generation:</p>
<pre><code class="language-bash">mockforge plugin install auth-jwt
mockforge serve --config my-api.yaml --admin
</code></pre>
</li>
<li>
<p><strong>Mock a WebSocket</strong> for real-time features:</p>
<pre><code class="language-yaml">websocket:
  port: 3001
  replay_file: chat-messages.jsonl
</code></pre>
</li>
<li>
<p><strong>Share with Your Team</strong> using workspace sync:</p>
<pre><code class="language-bash">mockforge sync start --directory ./team-mocks
git add team-mocks &amp;&amp; git commit -m "Add user API mocks"
</code></pre>
</li>
</ol>
<h2 id="common-next-steps"><a class="header" href="#common-next-steps">Common Next Steps</a></h2>
<div class="table-wrapper"><table><thead><tr><th>What You Need</th><th>Where to Go</th></tr></thead><tbody>
<tr><td>OpenAPI/Swagger integration</td><td><a href="getting-started/../user-guide/http-mocking/openapi.html">OpenAPI Guide</a></td></tr>
<tr><td>More realistic fake data</td><td><a href="getting-started/../user-guide/http-mocking/dynamic-data.html">Dynamic Data Guide</a></td></tr>
<tr><td>WebSocket/real-time mocking</td><td><a href="getting-started/../user-guide/websocket-mocking.html">WebSocket Guide</a></td></tr>
<tr><td>gRPC service mocking</td><td><a href="getting-started/../user-guide/grpc-mocking.html">gRPC Guide</a></td></tr>
<tr><td>Custom authentication</td><td><a href="getting-started/../user-guide/security.html">Security Guide</a></td></tr>
<tr><td>Team collaboration</td><td><a href="getting-started/../user-guide/sync.html">Sync Guide</a></td></tr>
</tbody></table>
</div>
<h2 id="troubleshooting-1"><a class="header" href="#troubleshooting-1">Troubleshooting</a></h2>
<p><strong>Port already in use?</strong></p>
<pre><code class="language-bash">mockforge serve --config my-api.yaml --http-port 8080
</code></pre>
<p><strong>Templates not working?</strong>
Make sure you set <code>MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true</code> or add it to your config:</p>
<pre><code class="language-yaml">http:
  response_template_expand: true
</code></pre>
<p><strong>Config errors?</strong></p>
<pre><code class="language-bash"># Validate your configuration
mockforge config validate --config my-api.yaml

# See all available options
# https://github.com/SaaSy-Solutions/mockforge/blob/main/config.template.yaml
</code></pre>
<p><strong>Need help?</strong></p>
<ul>
<li>Check the <a href="getting-started/../reference/config-validation.html">Configuration Validation Guide</a></li>
<li>Review the <a href="https://github.com/SaaSy-Solutions/mockforge/blob/main/config.template.yaml">Complete Config Template</a></li>
<li>See <a href="getting-started/../reference/troubleshooting.html">Troubleshooting Guide</a></li>
<li>Check the <a href="getting-started/../reference/faq.html">FAQ</a></li>
</ul>
<hr />
<p><strong>Congratulations!</strong> You now have a working mock API that your frontend team can use immediately. The best part? As the real API evolves, just update your config file to match.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="quick-start-1"><a class="header" href="#quick-start-1">Quick Start</a></h1>
<p>Get MockForge running in under 5 minutes with this hands-on guide. We‚Äôll create a mock API server and test it with real HTTP requests.</p>
<h2 id="prerequisites-2"><a class="header" href="#prerequisites-2">Prerequisites</a></h2>
<p>Ensure MockForge is <a href="getting-started/installation.html">installed</a> and available in your PATH.</p>
<h2 id="step-1-start-a-basic-http-mock-server"><a class="header" href="#step-1-start-a-basic-http-mock-server">Step 1: Start a Basic HTTP Mock Server</a></h2>
<p>MockForge can serve mock APIs defined in OpenAPI specifications. Let‚Äôs use the included example:</p>
<pre><code class="language-bash"># Navigate to the MockForge directory (if building from source)
cd mockforge

# Start the server with the demo OpenAPI spec
mockforge serve --spec examples/openapi-demo.json --http-port 3000
</code></pre>
<p>You should see output like:</p>
<pre><code>MockForge v0.1.0 starting...
HTTP server listening on 0.0.0.0:3000
OpenAPI spec loaded from examples/openapi-demo.json
Ready to serve requests at http://localhost:3000
</code></pre>
<h2 id="step-2-test-your-mock-api"><a class="header" href="#step-2-test-your-mock-api">Step 2: Test Your Mock API</a></h2>
<p>Open a new terminal and test the API endpoints:</p>
<pre><code class="language-bash"># Health check endpoint
curl http://localhost:3000/ping
</code></pre>
<p>Expected response:</p>
<pre><code class="language-json">{
  "status": "pong",
  "timestamp": "2025-09-12T17:20:01.512504405+00:00",
  "requestId": "550e8400-e29b-41d4-a716-446655440000"
}
</code></pre>
<pre><code class="language-bash"># List users endpoint
curl http://localhost:3000/users
</code></pre>
<p>Expected response:</p>
<pre><code class="language-json">[
  {
    "id": "550e8400-e29b-41d4-a716-446655440001",
    "name": "John Doe",
    "email": "john@example.com",
    "createdAt": "2025-09-12T17:20:01.512504405+00:00",
    "active": true
  }
]
</code></pre>
<pre><code class="language-bash"># Create a new user
curl -X POST http://localhost:3000/users \
  -H "Content-Type: application/json" \
  -d '{"name": "Jane Smith", "email": "jane@example.com"}'
</code></pre>
<pre><code class="language-bash"># Get user by ID (path parameter)
curl http://localhost:3000/users/123
</code></pre>
<h2 id="step-3-enable-template-expansion"><a class="header" href="#step-3-enable-template-expansion">Step 3: Enable Template Expansion</a></h2>
<p>MockForge supports dynamic content generation. Enable template expansion for more realistic data:</p>
<pre><code class="language-bash"># Stop the current server (Ctrl+C), then restart with templates enabled
MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true \
mockforge serve --spec examples/openapi-demo.json --http-port 3000
</code></pre>
<p>Now test the endpoints again - you‚Äôll see different UUIDs and timestamps each time!</p>
<h2 id="step-4-add-websocket-support"><a class="header" href="#step-4-add-websocket-support">Step 4: Add WebSocket Support</a></h2>
<p>MockForge can also mock WebSocket connections. Let‚Äôs add WebSocket support to our server:</p>
<pre><code class="language-bash"># Stop the server, then restart with WebSocket support
MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true \
MOCKFORGE_WS_REPLAY_FILE=examples/ws-demo.jsonl \
mockforge serve --spec examples/openapi-demo.json --ws-port 3001 --http-port 3000
</code></pre>
<h2 id="step-5-test-websocket-connection"><a class="header" href="#step-5-test-websocket-connection">Step 5: Test WebSocket Connection</a></h2>
<p>Test the WebSocket endpoint (requires Node.js or a WebSocket client):</p>
<pre><code class="language-bash"># Using Node.js
node -e "
const WebSocket = require('ws');
const ws = new WebSocket('ws://localhost:3001/ws');
ws.on('open', () =&gt; {
  console.log('Connected! Sending CLIENT_READY...');
  ws.send('CLIENT_READY');
});
ws.on('message', (data) =&gt; {
  console.log('Received:', data.toString());
  if (data.toString().includes('ACK')) {
    ws.send('ACK');
  }
  if (data.toString().includes('CONFIRMED')) {
    ws.send('CONFIRMED');
  }
});
ws.on('close', () =&gt; console.log('Connection closed'));
"
</code></pre>
<p>Expected WebSocket message flow:</p>
<ol>
<li>Send <code>CLIENT_READY</code></li>
<li>Receive welcome message with session ID</li>
<li>Receive data message, respond with <code>ACK</code></li>
<li>Receive heartbeat messages</li>
<li>Receive notification, respond with <code>CONFIRMED</code></li>
</ol>
<h2 id="step-6-enable-admin-ui-optional"><a class="header" href="#step-6-enable-admin-ui-optional">Step 6: Enable Admin UI (Optional)</a></h2>
<p>For a visual interface to manage your mock server:</p>
<pre><code class="language-bash"># Stop the server, then restart with admin UI
MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true \
MOCKFORGE_WS_REPLAY_FILE=examples/ws-demo.jsonl \
mockforge serve --spec examples/openapi-demo.json \
  --admin --admin-port 9080 \
  --http-port 3000 --ws-port 3001
</code></pre>
<p>Access the admin interface at: http://localhost:9080</p>
<h2 id="step-7-using-configuration-files"><a class="header" href="#step-7-using-configuration-files">Step 7: Using Configuration Files</a></h2>
<p>Instead of environment variables, you can use a configuration file:</p>
<pre><code class="language-bash"># Stop the server, then start with config file
mockforge serve --config demo-config.yaml
</code></pre>
<h2 id="step-8-docker-alternative"><a class="header" href="#step-8-docker-alternative">Step 8: Docker Alternative</a></h2>
<p>If you prefer Docker:</p>
<pre><code class="language-bash"># Build and run with Docker
docker build -t mockforge .
docker run -p 3000:3000 -p 3001:3001 -p 9080:9080 \
  -e MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true \
  -e MOCKFORGE_WS_REPLAY_FILE=examples/ws-demo.jsonl \
  mockforge
</code></pre>
<h2 id="whats-next-1"><a class="header" href="#whats-next-1">What‚Äôs Next?</a></h2>
<p>Congratulations! You now have a fully functional mock server running. Here are some next steps:</p>
<ul>
<li>Learn about <a href="getting-started/concepts.html">Basic Concepts</a> to understand how MockForge works</li>
<li>Explore <a href="getting-started/../user-guide/http-mocking.html">HTTP Mocking</a> for advanced REST API features</li>
<li>Try <a href="getting-started/../user-guide/websocket-mocking.html">WebSocket Mocking</a> for real-time communication</li>
<li>Check out the <a href="getting-started/../user-guide/admin-ui.html">Admin UI</a> for visual management</li>
</ul>
<h2 id="troubleshooting-2"><a class="header" href="#troubleshooting-2">Troubleshooting</a></h2>
<h3 id="server-wont-start-1"><a class="header" href="#server-wont-start-1">Server won‚Äôt start</a></h3>
<ul>
<li>Check if ports 3000, 3001, or 9080 are already in use</li>
<li>Verify the OpenAPI spec file path is correct</li>
<li>Ensure MockForge is properly installed</li>
</ul>
<h3 id="template-variables-not-working"><a class="header" href="#template-variables-not-working">Template variables not working</a></h3>
<ul>
<li>Make sure <code>MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true</code> is set</li>
<li>Check that template syntax <code>{{variable}}</code> is used correctly</li>
</ul>
<h3 id="websocket-connection-fails"><a class="header" href="#websocket-connection-fails">WebSocket connection fails</a></h3>
<ul>
<li>Verify WebSocket port (default 3001) is accessible</li>
<li>Check that <code>MOCKFORGE_WS_REPLAY_FILE</code> points to a valid replay file</li>
<li>Ensure the replay file uses the correct JSONL format</li>
</ul>
<h3 id="need-help"><a class="header" href="#need-help">Need help?</a></h3>
<ul>
<li>Check the <a href="getting-started/../../examples/README.html">examples README</a> for detailed testing scripts</li>
<li>Review <a href="getting-started/../configuration/files.html">Configuration Files</a> for advanced setup</li>
<li>Visit the <a href="getting-started/../reference/troubleshooting.html">Troubleshooting</a> guide</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="basic-concepts"><a class="header" href="#basic-concepts">Basic Concepts</a></h1>
<p>Understanding MockForge‚Äôs core concepts will help you make the most of its capabilities. This guide explains the fundamental ideas behind MockForge‚Äôs design and functionality.</p>
<h2 id="multi-protocol-architecture"><a class="header" href="#multi-protocol-architecture">Multi-Protocol Architecture</a></h2>
<p>MockForge is designed to mock multiple communication protocols within a single, unified framework:</p>
<h3 id="httprest-apis"><a class="header" href="#httprest-apis">HTTP/REST APIs</a></h3>
<ul>
<li><strong>OpenAPI/Swagger Support</strong>: Define API contracts using industry-standard OpenAPI specifications</li>
<li><strong>Dynamic Response Generation</strong>: Generate realistic responses based on request parameters</li>
<li><strong>Request/Response Matching</strong>: Route requests to appropriate mock responses based on HTTP methods, paths, and parameters</li>
</ul>
<h3 id="websocket-connections"><a class="header" href="#websocket-connections">WebSocket Connections</a></h3>
<ul>
<li><strong>Replay Mode</strong>: Simulate scripted message sequences from recorded interactions</li>
<li><strong>Interactive Mode</strong>: Respond dynamically to client messages</li>
<li><strong>State Management</strong>: Maintain connection state across message exchanges</li>
</ul>
<h3 id="grpc-services"><a class="header" href="#grpc-services">gRPC Services</a></h3>
<ul>
<li><strong>Protocol Buffer Integration</strong>: Mock services defined with .proto files</li>
<li><strong>Dynamic Service Discovery</strong>: Automatically discover and compile .proto files</li>
<li><strong>Streaming Support</strong>: Handle unary, server streaming, client streaming, and bidirectional streaming</li>
<li><strong>Reflection Support</strong>: Built-in gRPC reflection for service discovery</li>
</ul>
<h2 id="response-generation-strategies"><a class="header" href="#response-generation-strategies">Response Generation Strategies</a></h2>
<p>MockForge offers multiple approaches to generating mock responses:</p>
<h3 id="1-static-responses"><a class="header" href="#1-static-responses">1. Static Responses</a></h3>
<p>Define fixed response payloads that are returned for matching requests:</p>
<pre><code class="language-json">{
  "status": "success",
  "data": {
    "id": 123,
    "name": "Example Item"
  }
}
</code></pre>
<h3 id="2-template-based-dynamic-responses"><a class="header" href="#2-template-based-dynamic-responses">2. Template-Based Dynamic Responses</a></h3>
<p>Use template variables for dynamic content generation:</p>
<pre><code class="language-json">{
  "id": "{{uuid}}",
  "timestamp": "{{now}}",
  "randomValue": "{{randInt 1 100}}",
  "userData": "{{request.body}}"
}
</code></pre>
<h3 id="3-scenario-based-responses"><a class="header" href="#3-scenario-based-responses">3. Scenario-Based Responses</a></h3>
<p>Define complex interaction scenarios with conditional logic and state management.</p>
<h3 id="4-advanced-data-synthesis-grpc"><a class="header" href="#4-advanced-data-synthesis-grpc">4. Advanced Data Synthesis (gRPC)</a></h3>
<p>For gRPC services, MockForge provides sophisticated data synthesis capabilities:</p>
<ul>
<li><strong>Smart Field Inference</strong>: Automatically detects data types from field names (emails, phones, IDs)</li>
<li><strong>Deterministic Generation</strong>: Reproducible test data with seeded randomness</li>
<li><strong>Relationship Awareness</strong>: Maintains referential integrity across related entities</li>
<li><strong>RAG-Driven Generation</strong>: Uses domain knowledge for contextually appropriate data</li>
</ul>
<h2 id="template-system"><a class="header" href="#template-system">Template System</a></h2>
<p>MockForge‚Äôs template system enables dynamic content generation using Handlebars-style syntax:</p>
<h3 id="built-in-template-functions"><a class="header" href="#built-in-template-functions">Built-in Template Functions</a></h3>
<h4 id="data-generation"><a class="header" href="#data-generation">Data Generation</a></h4>
<ul>
<li><code>{{uuid}}</code> - Generate unique UUID v4 identifiers</li>
<li><code>{{now}}</code> - Current timestamp in ISO 8601 format</li>
<li><code>{{now+1h}}</code> - Future timestamps with offset support</li>
<li><code>{{randInt min max}}</code> - Random integers within a range</li>
<li><code>{{randFloat min max}}</code> - Random floating-point numbers</li>
</ul>
<h4 id="request-data-access"><a class="header" href="#request-data-access">Request Data Access</a></h4>
<ul>
<li><code>{{request.body}}</code> - Access complete request body</li>
<li><code>{{request.body.field}}</code> - Access specific JSON fields</li>
<li><code>{{request.path.param}}</code> - Access URL path parameters</li>
<li><code>{{request.query.param}}</code> - Access query string parameters</li>
<li><code>{{request.header.name}}</code> - Access HTTP headers</li>
</ul>
<h4 id="conditional-logic"><a class="header" href="#conditional-logic">Conditional Logic</a></h4>
<ul>
<li><code>{{#if condition}}content{{/if}}</code> - Conditional content rendering</li>
<li><code>{{#each array}}item{{/each}}</code> - Iterate over arrays</li>
</ul>
<h3 id="template-expansion-control"><a class="header" href="#template-expansion-control">Template Expansion Control</a></h3>
<p>Templates are only processed when explicitly enabled:</p>
<pre><code class="language-bash"># Enable template expansion
MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true
</code></pre>
<p>This security feature prevents accidental template processing in production environments.</p>
<h2 id="configuration-hierarchy"><a class="header" href="#configuration-hierarchy">Configuration Hierarchy</a></h2>
<p>MockForge supports multiple configuration methods with clear precedence:</p>
<h3 id="1-command-line-arguments-highest-priority"><a class="header" href="#1-command-line-arguments-highest-priority">1. Command Line Arguments (Highest Priority)</a></h3>
<pre><code class="language-bash">mockforge serve --http-port 3000 --ws-port 3001 --spec api.json
</code></pre>
<h3 id="2-environment-variables"><a class="header" href="#2-environment-variables">2. Environment Variables</a></h3>
<pre><code class="language-bash">MOCKFORGE_HTTP_PORT=3000
MOCKFORGE_WS_PORT=3001
MOCKFORGE_OPENAPI_SPEC=api.json
</code></pre>
<h3 id="3-configuration-files-lowest-priority"><a class="header" href="#3-configuration-files-lowest-priority">3. Configuration Files (Lowest Priority)</a></h3>
<pre><code class="language-yaml"># config.yaml
server:
  http_port: 3000
  ws_port: 3001
spec: api.json
</code></pre>
<h2 id="server-modes"><a class="header" href="#server-modes">Server Modes</a></h2>
<h3 id="development-mode"><a class="header" href="#development-mode">Development Mode</a></h3>
<ul>
<li><strong>Template Expansion</strong>: Enabled by default for dynamic content</li>
<li><strong>Verbose Logging</strong>: Detailed request/response logging</li>
<li><strong>Admin UI</strong>: Enabled for visual server management</li>
<li><strong>CORS</strong>: Permissive cross-origin requests</li>
</ul>
<h3 id="production-mode"><a class="header" href="#production-mode">Production Mode</a></h3>
<ul>
<li><strong>Template Expansion</strong>: Disabled by default for security</li>
<li><strong>Minimal Logging</strong>: Essential information only</li>
<li><strong>Performance Optimized</strong>: Reduced overhead for high-throughput scenarios</li>
</ul>
<h2 id="request-matching"><a class="header" href="#request-matching">Request Matching</a></h2>
<p>MockForge uses a sophisticated matching system to route requests to appropriate responses:</p>
<h3 id="http-request-matching"><a class="header" href="#http-request-matching">HTTP Request Matching</a></h3>
<ol>
<li><strong>Method Matching</strong>: GET, POST, PUT, DELETE, PATCH</li>
<li><strong>Path Matching</strong>: Exact path or parameterized routes</li>
<li><strong>Query Parameter Matching</strong>: Optional query string conditions</li>
<li><strong>Header Matching</strong>: Conditional responses based on request headers</li>
<li><strong>Body Matching</strong>: Match against request payload structure</li>
</ol>
<h3 id="priority-order"><a class="header" href="#priority-order">Priority Order</a></h3>
<ol>
<li>Most specific match first (method + path + query + headers + body)</li>
<li>Fall back to less specific matches</li>
<li>Default response for unmatched requests</li>
</ol>
<h2 id="state-management"><a class="header" href="#state-management">State Management</a></h2>
<p>For complex scenarios, MockForge supports maintaining state across requests:</p>
<h3 id="session-state"><a class="header" href="#session-state">Session State</a></h3>
<ul>
<li><strong>Connection-specific data</strong> persists across WebSocket messages</li>
<li><strong>HTTP session cookies</strong> maintain state between requests</li>
<li><strong>Scenario progression</strong> tracks interaction flow</li>
</ul>
<h3 id="global-state"><a class="header" href="#global-state">Global State</a></h3>
<ul>
<li><strong>Shared data</strong> accessible across all connections</li>
<li><strong>Configuration updates</strong> applied dynamically</li>
<li><strong>Metrics and counters</strong> maintained server-wide</li>
</ul>
<h2 id="extensibility"><a class="header" href="#extensibility">Extensibility</a></h2>
<p>MockForge is designed for extension through multiple mechanisms:</p>
<h3 id="custom-response-generators"><a class="header" href="#custom-response-generators">Custom Response Generators</a></h3>
<p>Implement custom logic for generating complex responses based on business rules.</p>
<h3 id="plugin-system"><a class="header" href="#plugin-system">Plugin System</a></h3>
<p>Extend functionality through compiled plugins for specialized use cases.</p>
<h3 id="configuration-extensions"><a class="header" href="#configuration-extensions">Configuration Extensions</a></h3>
<p>Add custom configuration options for domain-specific requirements.</p>
<h2 id="security-considerations"><a class="header" href="#security-considerations">Security Considerations</a></h2>
<h3 id="template-injection-prevention"><a class="header" href="#template-injection-prevention">Template Injection Prevention</a></h3>
<ul>
<li>Templates are disabled by default in production</li>
<li>Explicit opt-in required for template processing</li>
<li>Input validation prevents malicious template injection</li>
</ul>
<h3 id="access-control"><a class="header" href="#access-control">Access Control</a></h3>
<ul>
<li>Configurable CORS policies</li>
<li>Request rate limiting options</li>
<li>Authentication simulation support</li>
</ul>
<h3 id="data-privacy"><a class="header" href="#data-privacy">Data Privacy</a></h3>
<ul>
<li>Request/response logging controls</li>
<li>Sensitive data masking capabilities</li>
<li>Compliance-friendly configuration options</li>
</ul>
<h2 id="performance-characteristics"><a class="header" href="#performance-characteristics">Performance Characteristics</a></h2>
<h3 id="throughput"><a class="header" href="#throughput">Throughput</a></h3>
<ul>
<li><strong>HTTP APIs</strong>: 10,000+ requests/second (depending on response complexity)</li>
<li><strong>WebSocket</strong>: 1,000+ concurrent connections</li>
<li><strong>Memory Usage</strong>: Minimal overhead per connection</li>
</ul>
<h3 id="scalability"><a class="header" href="#scalability">Scalability</a></h3>
<ul>
<li><strong>Horizontal Scaling</strong>: Multiple instances behind load balancer</li>
<li><strong>Resource Efficiency</strong>: Low CPU and memory footprint</li>
<li><strong>Concurrent Users</strong>: Support for thousands of simultaneous connections</li>
</ul>
<h2 id="integration-patterns"><a class="header" href="#integration-patterns">Integration Patterns</a></h2>
<p>MockForge works well in various development and testing scenarios:</p>
<h3 id="api-development"><a class="header" href="#api-development">API Development</a></h3>
<ul>
<li><strong>Contract-First Development</strong>: Mock APIs before implementation</li>
<li><strong>Parallel Development</strong>: Frontend and backend teams work independently</li>
<li><strong>Integration Testing</strong>: Validate API contracts between services</li>
</ul>
<h3 id="microservices-testing"><a class="header" href="#microservices-testing">Microservices Testing</a></h3>
<ul>
<li><strong>Service Virtualization</strong>: Mock dependent services during testing</li>
<li><strong>Chaos Engineering</strong>: Simulate service failures and latency</li>
<li><strong>Load Testing</strong>: Generate realistic traffic patterns</li>
</ul>
<h3 id="cicd-pipelines"><a class="header" href="#cicd-pipelines">CI/CD Pipelines</a></h3>
<ul>
<li><strong>Automated Testing</strong>: Mock external dependencies in test environments</li>
<li><strong>Deployment Validation</strong>: Verify application behavior with mock services</li>
<li><strong>Performance Benchmarking</strong>: Consistent test conditions across environments</li>
</ul>
<p>This foundation will help you understand how to effectively use MockForge for your specific use case. The following guides provide detailed instructions for configuring and using each protocol and feature.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="the-five-pillars-of-mockforge-1"><a class="header" href="#the-five-pillars-of-mockforge-1">The Five Pillars of MockForge</a></h1>
<p><strong>Version:</strong> 1.0.0
<strong>Last Updated:</strong> 2025-01-27</p>
<p>MockForge is built on five foundational pillars that define our product vision and guide every feature we build. These pillars ensure that MockForge delivers a cohesive, powerful mocking experience that scales from solo developers to enterprise teams.</p>
<h2 id="overview"><a class="header" href="#overview">Overview</a></h2>
<p>Every feature in MockForge maps to one or more pillars. This structure helps us:</p>
<ul>
<li><strong>Communicate value</strong> clearly in changelogs, docs, and marketing</li>
<li><strong>Prioritize development</strong> based on pillar investment</li>
<li><strong>Maintain consistency</strong> across features and releases</li>
<li><strong>Guide users</strong> to the right features for their needs</li>
</ul>
<hr />
<h2 id="the-five-pillars-1"><a class="header" href="#the-five-pillars-1">The Five Pillars</a></h2>
<h3 id="reality--everything-that-makes-mocks-feel-like-a-real-evolving-backend-1"><a class="header" href="#reality--everything-that-makes-mocks-feel-like-a-real-evolving-backend-1">[Reality] ‚Äì Everything that makes mocks feel like a real, evolving backend</a></h3>
<p><strong>Purpose:</strong> Make mocks indistinguishable from production backends through realistic behavior, state management, and dynamic data generation.</p>
<p><strong>Key Capabilities:</strong></p>
<ul>
<li>Realistic data generation with relationships and constraints</li>
<li>Stateful behavior and persistence</li>
<li>Network condition simulation (latency, packet loss, failures)</li>
<li>Time-based mutations and temporal simulation</li>
<li>Progressive data evolution and drift</li>
<li>Multi-protocol support (HTTP, gRPC, WebSocket, Kafka, MQTT, AMQP, SMTP, FTP, TCP)</li>
</ul>
<p><strong>Example Features:</strong></p>
<ul>
<li><strong>Reality Continuum</strong>: Blend mock and real data with configurable reality levels</li>
<li><strong>Reality Slider</strong>: Hot-reload reality level adjustments</li>
<li><strong>Smart Personas</strong>: Consistent cross-endpoint data generation</li>
<li><strong>Generative Schema Mode</strong>: Dynamic mock data generation without seed data</li>
<li><strong>Chaos Lab</strong>: Interactive network condition simulation</li>
<li><strong>Deceptive Deploy</strong>: Advanced testing scenarios with realistic failures</li>
<li><strong>Virtual Backend Reality (VBR)</strong>: Virtual database layer with CRUD operations</li>
<li><strong>Temporal Simulation</strong>: Time travel and time-based data mutations</li>
<li><strong>Latency Injection</strong>: Configurable latency profiles and recording</li>
<li><strong>Response Selection Modes</strong>: Sequential, random, and weighted response selection</li>
<li><strong>Template Expansion</strong>: Dynamic data generation with faker functions</li>
<li><strong>Capture Scrubbing</strong>: Deterministic replay with data sanitization</li>
</ul>
<p><strong>Use Cases:</strong></p>
<ul>
<li>Frontend teams need realistic data that evolves over time</li>
<li>Testing resilience and failure scenarios</li>
<li>Simulating production-like network conditions</li>
<li>Creating believable mock backends before real APIs exist</li>
</ul>
<hr />
<h3 id="contracts--schema-drift-validation-and-safety-nets-1"><a class="header" href="#contracts--schema-drift-validation-and-safety-nets-1">[Contracts] ‚Äì Schema, drift, validation, and safety nets</a></h3>
<p><strong>Purpose:</strong> Ensure API contracts are correct, validated, and stay in sync with real backends.</p>
<p><strong>Key Capabilities:</strong></p>
<ul>
<li>OpenAPI/GraphQL schema validation</li>
<li>Request/response validation with detailed error reporting</li>
<li>Contract drift detection and monitoring</li>
<li>Automatic API sync and change detection</li>
<li>Schema-driven mock generation</li>
<li>Cross-endpoint validation and referential integrity</li>
<li>Multi-protocol contract support (HTTP, gRPC, WebSocket, MQTT, Kafka)</li>
<li>Contract fitness functions for quality enforcement</li>
<li>Consumer impact analysis for downstream dependencies</li>
</ul>
<p><strong>Example Features:</strong></p>
<ul>
<li><strong>AI Contract Diff</strong>: Compare and visualize API contract changes</li>
<li><strong>Automatic API Sync &amp; Change Detection</strong>: Periodic polling and sync for upstream API changes</li>
<li><strong>Request/Response Validation</strong>: Built-in validation with configurable modes (disabled, warn, enforce)</li>
<li><strong>OpenAPI Integration</strong>: Full OpenAPI v3 support with deep $ref resolution</li>
<li><strong>Schema Validation</strong>: Composite schemas (oneOf/anyOf/allOf) support</li>
<li><strong>Validation Modes</strong>: Runtime admin UI to view/toggle validation mode</li>
<li><strong>Contract Testing</strong>: Verify API contracts match specifications</li>
<li><strong>Protocol Contracts</strong>: gRPC, WebSocket, MQTT, and Kafka contract management</li>
<li><strong>Fitness Functions</strong>: Custom tests to enforce contract quality and evolution rules</li>
<li><strong>Consumer Impact Analysis</strong>: Map endpoints to SDK methods and consuming applications</li>
<li><strong>Drift Budgets</strong>: Configurable thresholds for acceptable contract changes</li>
</ul>
<p><strong>Use Cases:</strong></p>
<ul>
<li>Catch breaking changes before they reach production</li>
<li>Ensure mocks stay in sync with real APIs</li>
<li>Validate API contracts during development</li>
<li>Detect schema drift automatically</li>
</ul>
<hr />
<h3 id="devx--sdks-generators-playgrounds-ergonomics-1"><a class="header" href="#devx--sdks-generators-playgrounds-ergonomics-1">[DevX] ‚Äì SDKs, generators, playgrounds, ergonomics</a></h3>
<p><strong>Purpose:</strong> Make MockForge effortless to use, integrate, and extend for developers.</p>
<p><strong>Key Capabilities:</strong></p>
<ul>
<li>Multi-language SDKs (Rust, Node.js, Python, Go, Java, .NET)</li>
<li>Client code generation (React, Vue, Angular, Svelte)</li>
<li>Interactive playgrounds and admin UI</li>
<li>CLI tooling and configuration management</li>
<li>Comprehensive documentation and examples</li>
<li>Plugin system for extensibility</li>
</ul>
<p><strong>Example Features:</strong></p>
<ul>
<li><strong>ForgeConnect SDK</strong>: Complete SDK implementation with full feature set</li>
<li><strong>GraphQL + REST Playground</strong>: Interactive playground with workspace filtering</li>
<li><strong>Multi-Language SDKs</strong>: Native SDKs for 6 languages</li>
<li><strong>Client Generators</strong>: React, Vue, Angular, Svelte client code generation</li>
<li><strong>CLI Tool</strong>: Full-featured command-line interface</li>
<li><strong>Admin UI</strong>: Modern React-based admin interface</li>
<li><strong>Configuration Management</strong>: YAML/JSON config files with profiles</li>
<li><strong>Browser Proxy Mode</strong>: Seamless integration with browser workflows</li>
<li><strong>Git Sync</strong>: Workspace synchronization via Git</li>
<li><strong>Plugin System</strong>: WASM-based plugin architecture</li>
<li><strong>E2E Test Suite</strong>: Comprehensive end-to-end testing tools</li>
<li><strong>Custom Routes</strong>: Flexible routing configuration</li>
<li><strong>Voice + LLM Interface</strong>: Voice interface with Speech-to-Text support</li>
<li><strong>WireMock-Inspired Features</strong>: Familiar patterns for WireMock users</li>
</ul>
<p><strong>Use Cases:</strong></p>
<ul>
<li>Embed mock servers directly in test suites</li>
<li>Generate type-safe API clients automatically</li>
<li>Integrate with existing development workflows</li>
<li>Extend functionality with custom plugins</li>
</ul>
<hr />
<h3 id="cloud--registry-orgs-governance-monetization-marketplace-1"><a class="header" href="#cloud--registry-orgs-governance-monetization-marketplace-1">[Cloud] ‚Äì Registry, orgs, governance, monetization, marketplace</a></h3>
<p><strong>Purpose:</strong> Enable team collaboration, sharing, and scaling from solo developers to enterprise organizations.</p>
<p><strong>Key Capabilities:</strong></p>
<ul>
<li>Organization and user management</li>
<li>Scenario marketplace and sharing</li>
<li>Registry server for mock distribution</li>
<li>Cloud workspaces and synchronization</li>
<li>Governance and access controls</li>
<li>Monetization infrastructure</li>
</ul>
<p><strong>Example Features:</strong></p>
<ul>
<li><strong>Cloud Workspaces</strong>: Shared workspaces with team collaboration</li>
<li><strong>Scenario Marketplace</strong>: Browse and share mock scenarios</li>
<li><strong>Registry Server</strong>: Centralized mock distribution and discovery</li>
<li><strong>Organization Management</strong>: Multi-tenant organization support</li>
<li><strong>User Management</strong>: Team member and permission management</li>
<li><strong>Cloud Sync</strong>: Synchronize workspaces across devices</li>
<li><strong>Security Controls</strong>: Enterprise-grade access controls and audit trails</li>
<li><strong>Cloud Monetization</strong>: Pricing models and subscription management</li>
<li><strong>Enhanced Metrics</strong>: Team-level analytics and monitoring</li>
</ul>
<p><strong>Use Cases:</strong></p>
<ul>
<li>Share mock scenarios across teams</li>
<li>Manage enterprise deployments</li>
<li>Discover and reuse community scenarios</li>
<li>Scale from individual to team usage</li>
</ul>
<hr />
<h3 id="ai--llmvoice-flows-ai-diffassist-generative-behaviors-1"><a class="header" href="#ai--llmvoice-flows-ai-diffassist-generative-behaviors-1">[AI] ‚Äì LLM/voice flows, AI diff/assist, generative behaviors</a></h3>
<p><strong>Purpose:</strong> Leverage artificial intelligence to automate mock generation, enhance data realism, and assist developers.</p>
<p><strong>Key Capabilities:</strong></p>
<ul>
<li>LLM-powered mock generation</li>
<li>AI-driven data synthesis</li>
<li>Voice interface for mock creation</li>
<li>Intelligent contract analysis</li>
<li>Generative data behaviors</li>
<li>Natural language to mock conversion</li>
</ul>
<p><strong>Example Features:</strong></p>
<ul>
<li><strong>MockAI</strong>: Intelligent mock generation from natural language</li>
<li><strong>AI Response Generation</strong>: LLM-powered realistic response generation</li>
<li><strong>AI Contract Diff</strong>: AI-assisted contract comparison and analysis</li>
<li><strong>Voice + LLM Interface</strong>: Voice-driven mock creation and management</li>
<li><strong>Generative Schema Mode</strong>: AI-powered schema extrapolation</li>
<li><strong>AI Event Streams</strong>: LLM-generated narrative-driven WebSocket events</li>
<li><strong>Data Drift Simulation</strong>: AI-driven evolving mock data</li>
<li><strong>Smart Data Generation</strong>: RAG-powered synthetic data with relationship awareness</li>
</ul>
<p><strong>Use Cases:</strong></p>
<ul>
<li>Generate mocks from natural language descriptions</li>
<li>Create realistic data without manual configuration</li>
<li>Analyze and compare API contracts intelligently</li>
<li>Build mocks through voice commands</li>
</ul>
<hr />
<h2 id="pillar-feature-matrix"><a class="header" href="#pillar-feature-matrix">Pillar Feature Matrix</a></h2>
<p>This matrix shows how key MockForge features map to the five pillars:</p>
<div class="table-wrapper"><table><thead><tr><th>Feature</th><th>Reality</th><th>Contracts</th><th>DevX</th><th>Cloud</th><th>AI</th></tr></thead><tbody>
<tr><td><strong>Reality Continuum</strong></td><td>‚úÖ</td><td></td><td></td><td></td><td></td></tr>
<tr><td><strong>Reality Slider</strong></td><td>‚úÖ</td><td></td><td>‚úÖ</td><td></td><td></td></tr>
<tr><td><strong>Smart Personas</strong></td><td>‚úÖ</td><td></td><td></td><td></td><td>‚úÖ</td></tr>
<tr><td><strong>Generative Schema Mode</strong></td><td>‚úÖ</td><td>‚úÖ</td><td></td><td></td><td>‚úÖ</td></tr>
<tr><td><strong>Chaos Lab</strong></td><td>‚úÖ</td><td></td><td>‚úÖ</td><td></td><td></td></tr>
<tr><td><strong>Deceptive Deploy</strong></td><td>‚úÖ</td><td></td><td></td><td></td><td></td></tr>
<tr><td><strong>VBR Engine</strong></td><td>‚úÖ</td><td>‚úÖ</td><td></td><td></td><td></td></tr>
<tr><td><strong>Temporal Simulation</strong></td><td>‚úÖ</td><td></td><td>‚úÖ</td><td></td><td></td></tr>
<tr><td><strong>AI Contract Diff</strong></td><td></td><td>‚úÖ</td><td>‚úÖ</td><td></td><td>‚úÖ</td></tr>
<tr><td><strong>Automatic API Sync</strong></td><td></td><td>‚úÖ</td><td></td><td></td><td></td></tr>
<tr><td><strong>Request/Response Validation</strong></td><td></td><td>‚úÖ</td><td>‚úÖ</td><td></td><td></td></tr>
<tr><td><strong>ForgeConnect SDK</strong></td><td></td><td></td><td>‚úÖ</td><td></td><td></td></tr>
<tr><td><strong>Client Generators</strong></td><td></td><td>‚úÖ</td><td>‚úÖ</td><td></td><td></td></tr>
<tr><td><strong>GraphQL + REST Playground</strong></td><td></td><td></td><td>‚úÖ</td><td></td><td></td></tr>
<tr><td><strong>Admin UI</strong></td><td></td><td></td><td>‚úÖ</td><td></td><td></td></tr>
<tr><td><strong>Plugin System</strong></td><td></td><td></td><td>‚úÖ</td><td></td><td></td></tr>
<tr><td><strong>Cloud Workspaces</strong></td><td></td><td></td><td></td><td>‚úÖ</td><td></td></tr>
<tr><td><strong>Scenario Marketplace</strong></td><td></td><td></td><td></td><td>‚úÖ</td><td></td></tr>
<tr><td><strong>Registry Server</strong></td><td></td><td></td><td></td><td>‚úÖ</td><td></td></tr>
<tr><td><strong>Organization Management</strong></td><td></td><td></td><td></td><td>‚úÖ</td><td></td></tr>
<tr><td><strong>MockAI</strong></td><td></td><td></td><td>‚úÖ</td><td></td><td>‚úÖ</td></tr>
<tr><td><strong>Voice + LLM Interface</strong></td><td></td><td></td><td>‚úÖ</td><td></td><td>‚úÖ</td></tr>
<tr><td><strong>AI Event Streams</strong></td><td>‚úÖ</td><td></td><td></td><td></td><td>‚úÖ</td></tr>
<tr><td><strong>Data Drift Simulation</strong></td><td>‚úÖ</td><td></td><td></td><td></td><td>‚úÖ</td></tr>
</tbody></table>
</div>
<hr />
<h2 id="using-pillars-in-changelog-entries"><a class="header" href="#using-pillars-in-changelog-entries">Using Pillars in Changelog Entries</a></h2>
<p>When adding features to the changelog, tag them with one or more relevant pillars:</p>
<pre><code class="language-markdown">- **[Reality] Smart Personas** with array generation and relationship inference

- **[Contracts][DevX] AI Contract Diff** with interactive playground integration

- **[Cloud] Organization management endpoints** for team collaboration
</code></pre>
<p><strong>Guidelines:</strong></p>
<ul>
<li>Use <code>[Pillar]</code> format with square brackets</li>
<li>Multiple pillars: <code>[Pillar1][Pillar2]</code></li>
<li>Tag the primary pillar first, then secondary pillars</li>
<li>Every major feature should have at least one pillar tag</li>
<li>Minor fixes and internal changes may not need tags</li>
</ul>
<hr />
<h2 id="pillar-investment-by-release"><a class="header" href="#pillar-investment-by-release">Pillar Investment by Release</a></h2>
<p>Understanding which pillars receive investment in each release helps users understand the product direction:</p>
<ul>
<li><strong>Reality-heavy releases</strong>: Focus on making mocks more realistic and production-like</li>
<li><strong>Contracts-heavy releases</strong>: Emphasis on validation, sync, and contract safety</li>
<li><strong>DevX-heavy releases</strong>: Improved ergonomics, SDKs, and developer experience</li>
<li><strong>Cloud-heavy releases</strong>: Team features, collaboration, and enterprise capabilities</li>
<li><strong>AI-heavy releases</strong>: Intelligent automation and AI-powered features</li>
</ul>
<hr />
<h2 id="documentation-by-pillar"><a class="header" href="#documentation-by-pillar">Documentation by Pillar</a></h2>
<p>This section organizes MockForge documentation by pillar to help you find relevant guides quickly.</p>
<p><strong>New to MockForge?</strong> Start with <a href="../../docs/JOURNEYS_BY_PILLAR.html">Journeys by Pillar</a> to choose the onboarding path that best fits your needs.</p>
<h3 id="reality-documentation"><a class="header" href="#reality-documentation">[Reality] Documentation</a></h3>
<p><strong>Getting Started:</strong></p>
<ul>
<li><a href="../../docs/../book/src/getting-started/reality-first.html">Reality-First Onboarding</a> - Start here for reality features</li>
</ul>
<p><strong>Core Features:</strong></p>
<ul>
<li><a href="../../docs/REALITY_CONTINUUM.html">Reality Continuum</a> - Blend mock and real data</li>
<li><a href="../../docs/PERSONAS.html">Smart Personas</a> - Consistent cross-endpoint data generation</li>
<li><a href="../../docs/REALITY_SLIDER.html">Reality Slider</a> - Hot-reload reality level adjustments</li>
<li><a href="../../docs/CHAOS_LAB.html">Chaos Lab</a> - Interactive network condition simulation</li>
<li><a href="../../docs/BEHAVIORAL_CLONING.html">Behavioral Cloning</a> - Record and replay realistic flows</li>
<li><a href="../../docs/REALITY_TRACE.html">Reality Trace</a> - Observability for mock behavior</li>
</ul>
<p><strong>Advanced:</strong></p>
<ul>
<li><a href="../../docs/LIFECYCLES_AND_TIME.html">Lifecysles and Time</a> - Time-based mutations and temporal simulation</li>
<li><a href="../../docs/DECEPTIVE_DEPLOY.html">Deceptive Deploy</a> - Advanced testing scenarios</li>
</ul>
<h3 id="contracts-documentation"><a class="header" href="#contracts-documentation">[Contracts] Documentation</a></h3>
<p><strong>Getting Started:</strong></p>
<ul>
<li><a href="../../docs/../book/src/getting-started/contracts-first.html">Contracts-First Onboarding</a> - Start here for contract features</li>
</ul>
<p><strong>Core Features:</strong></p>
<ul>
<li><a href="../../docs/DRIFT_BUDGETS.html">Drift Budgets</a> - Configurable thresholds for contract changes</li>
<li><a href="../../docs/PROTOCOL_CONTRACTS.html">Protocol Contracts</a> - Multi-protocol contract management</li>
<li><a href="../../docs/CONTRACT_FITNESS.html">Contract Fitness</a> - Quality enforcement functions</li>
<li><a href="../../docs/CONSUMER_IMPACT_ANALYSIS.html">Consumer Impact Analysis</a> - Map endpoints to consumers</li>
</ul>
<p><strong>Advanced:</strong></p>
<ul>
<li><a href="../../docs/DRIFT_BUDGET_SETUP.html">Drift Budget Setup</a> - Configuration guide</li>
</ul>
<h3 id="devx-documentation"><a class="header" href="#devx-documentation">[DevX] Documentation</a></h3>
<p><strong>Getting Started:</strong></p>
<ul>
<li><a href="../../docs/../book/src/getting-started/devx-first.html">DevX-First Onboarding</a> - Start here for developer experience features</li>
</ul>
<p><strong>Core Features:</strong></p>
<ul>
<li><a href="../../docs/ADMIN_UI_QUICKSTART.html">Admin UI Quickstart</a> - Interactive playground</li>
<li><a href="../../docs/PLUGIN_MARKETPLACE_PRODUCTION.html">Plugin Marketplace</a> - Extend MockForge</li>
<li><a href="../../docs/MULTI_FRAMEWORK_CLIENT_GENERATION.html">Multi-Framework Client Generation</a> - Generate clients</li>
</ul>
<p><strong>Advanced:</strong></p>
<ul>
<li><a href="../../docs/DEVELOPER_WORKFLOW_INTEGRATION.html">Developer Workflow Integration</a> - Integrate into workflows</li>
<li><a href="../../docs/REALITY_TRACE.html">Reality Trace</a> - Developer debugging tools</li>
</ul>
<h3 id="cloud-documentation"><a class="header" href="#cloud-documentation">[Cloud] Documentation</a></h3>
<p><strong>Getting Started:</strong></p>
<ul>
<li><a href="../../docs/../book/src/getting-started/cloud-first.html">Cloud-First Onboarding</a> - Start here for cloud features</li>
</ul>
<p><strong>Core Features:</strong></p>
<ul>
<li><a href="../../docs/CLOUD_ENVIRONMENTS.html">Cloud Environments</a> - Multi-tenant workspaces</li>
<li><a href="../../docs/SCENARIOS_MARKETPLACE.html">Scenario Marketplace</a> - Discover and share scenarios</li>
<li><a href="../../docs/MARKETPLACE_MONITORING.html">Marketplace Monitoring</a> - Analytics and dashboards</li>
<li><a href="../../docs/CLOUD_SYNC_IMPLEMENTATION_GUIDE.html">Cloud Sync Implementation</a> - Synchronization guide</li>
<li><a href="../../docs/RBAC_GUIDE.html">RBAC Guide</a> - Access control and governance</li>
</ul>
<p><strong>Advanced:</strong></p>
<ul>
<li><a href="../../docs/ENTERPRISE_DEPLOYMENT_GUIDE.html">Enterprise Deployment Guide</a> - Enterprise features</li>
<li><a href="../../docs/CLOUD_SAAS_MVP_GUIDE.html">Cloud SaaS MVP Guide</a> - SaaS implementation</li>
</ul>
<h3 id="ai-documentation"><a class="header" href="#ai-documentation">[AI] Documentation</a></h3>
<p><strong>Getting Started:</strong></p>
<ul>
<li><a href="../../docs/../book/src/getting-started/ai-first.html">AI-First Onboarding</a> - Start here for AI features</li>
</ul>
<p><strong>Core Features:</strong></p>
<ul>
<li><a href="../../docs/AI_STUDIO.html">AI Studio</a> - Unified AI interface</li>
<li><a href="../../docs/MOCKAI_USAGE.html">MockAI Usage</a> - Natural language mock generation</li>
<li><a href="../../docs/PROTOCOL_CONTRACTS.html#ai-contract-diff">AI Contract Diff</a> - Intelligent contract analysis</li>
</ul>
<p><strong>Advanced:</strong></p>
<ul>
<li><a href="../../docs/AI_FEATURES_README.html">AI Features README</a> - Complete AI feature overview</li>
<li><a href="../../docs/AI_DRIVEN_MOCKING.html">AI-Driven Mocking</a> - AI-powered mock generation</li>
</ul>
<h3 id="cross-pillar-documentation"><a class="header" href="#cross-pillar-documentation">Cross-Pillar Documentation</a></h3>
<ul>
<li><a href="../../docs/JOURNEYS_BY_PILLAR.html">Journeys by Pillar</a> - Choose your onboarding journey</li>
<li><a href="../../docs/contributing/PILLAR_TAGGING.html">Pillar Tagging Guide</a> - How to tag code with pillars</li>
<li><a href="../../docs/contributing/PILLAR_QUERIES.html">Pillar Queries Guide</a> - Query by pillar</li>
</ul>
<hr />
<h2 id="references"><a class="header" href="#references">References</a></h2>
<ul>
<li><a href="../../docs/../CHANGELOG.html">Changelog</a> - See pillar tags in action</li>
<li><a href="../../docs/../book/src/getting-started/getting-started.html">Getting Started Guide</a> - Learn about MockForge</li>
<li><a href="../../docs/../CONTRIBUTING.html">Contributing Guide</a> - How to contribute with pillar tagging</li>
<li><a href="../../docs/../book/src/contributing/release.html">Release Process</a> - Release process with pillar requirements</li>
</ul>
<hr />
<h2 id="questions"><a class="header" href="#questions">Questions?</a></h2>
<p>If you‚Äôre unsure which pillar(s) a feature belongs to:</p>
<ol>
<li><strong>Reality</strong>: Does it make mocks feel more like real backends?</li>
<li><strong>Contracts</strong>: Does it validate, sync, or monitor API contracts?</li>
<li><strong>DevX</strong>: Does it improve developer experience or ergonomics?</li>
<li><strong>Cloud</strong>: Does it enable team collaboration or sharing?</li>
<li><strong>AI</strong>: Does it use AI/LLM to automate or enhance functionality?</li>
</ol>
<p>Many features span multiple pillars‚Äîthat‚Äôs intentional and encouraged!</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="reality-first-onboarding"><a class="header" href="#reality-first-onboarding">Reality-First Onboarding</a></h1>
<p><strong>Pillars:</strong> [Reality]</p>
<p>[Reality] - Everything that makes mocks feel like a real, evolving backend</p>
<h2 id="start-here-if"><a class="header" href="#start-here-if">Start Here If‚Ä¶</a></h2>
<p>You care about <strong>realism</strong>. You want mocks that feel indistinguishable from production backends, with realistic data, stateful behavior, and production-like network conditions.</p>
<p>Perfect for:</p>
<ul>
<li>Frontend teams needing realistic data that evolves over time</li>
<li>Testing resilience and failure scenarios</li>
<li>Simulating production-like network conditions</li>
<li>Creating believable mock backends before real APIs exist</li>
</ul>
<h2 id="quick-start-5-minutes"><a class="header" href="#quick-start-5-minutes">Quick Start: 5 Minutes</a></h2>
<p>Let‚Äôs create a realistic mock API with Smart Personas and Reality Continuum:</p>
<pre><code class="language-bash"># Install MockForge
cargo install mockforge-cli

# Create a simple config with reality features
cat &gt; mockforge.yaml &lt;&lt;EOF
workspaces:
  - name: realistic-api
    reality:
      level: 3  # Moderate Realism
      personas:
        enabled: true
    endpoints:
      - path: /api/users/{id}
        method: GET
        response:
          body: |
            {
              "id": "{{persona.user.id}}",
              "name": "{{persona.user.name}}",
              "email": "{{persona.user.email}}"
            }
EOF

# Start the server
mockforge serve --config mockforge.yaml
</code></pre>
<p>Now test it:</p>
<pre><code class="language-bash"># Request the same user ID multiple times - persona ensures consistency
curl http://localhost:3000/api/users/123
curl http://localhost:3000/api/users/123  # Same user data!
</code></pre>
<h2 id="key-reality-features"><a class="header" href="#key-reality-features">Key Reality Features</a></h2>
<h3 id="1-reality-continuum"><a class="header" href="#1-reality-continuum">1. Reality Continuum</a></h3>
<p>Blend mock and real data seamlessly:</p>
<pre><code class="language-yaml">reality:
  continuum:
    enabled: true
    blend_ratio: 0.5  # 50% mock, 50% real
    upstream_url: https://api.example.com
</code></pre>
<p><strong>Why it matters:</strong> Develop against a backend that‚Äôs still under construction by gradually transitioning from mock to real.</p>
<p><strong>Learn more:</strong> <a href="getting-started/../../docs/REALITY_CONTINUUM.html">Reality Continuum Guide</a></p>
<h3 id="2-smart-personas"><a class="header" href="#2-smart-personas">2. Smart Personas</a></h3>
<p>Generate consistent, relationship-aware data across endpoints:</p>
<pre><code class="language-yaml">reality:
  personas:
    enabled: true
    entities:
      - type: user
        fields:
          - name: id
            generator: uuid
          - name: email
            generator: email
      - type: order
        relationships:
          - field: user_id
            links_to: user.id
</code></pre>
<p><strong>Why it matters:</strong> Maintain data consistency across your entire mock API. When you request a user and their orders, the relationships are preserved.</p>
<p><strong>Learn more:</strong> <a href="getting-started/../../docs/PERSONAS.html">Smart Personas Guide</a></p>
<h3 id="3-reality-slider"><a class="header" href="#3-reality-slider">3. Reality Slider</a></h3>
<p>Adjust realism levels on the fly:</p>
<pre><code class="language-yaml">reality:
  level: 3  # 1=Static, 2=Light, 3=Moderate, 4=High, 5=Production Chaos
</code></pre>
<p><strong>Why it matters:</strong> Instantly transform your mock environment to match different testing scenarios without manual configuration.</p>
<p><strong>Learn more:</strong> <a href="getting-started/../../docs/REALITY_SLIDER.html">Reality Slider Guide</a></p>
<h3 id="4-chaos-lab"><a class="header" href="#4-chaos-lab">4. Chaos Lab</a></h3>
<p>Simulate network conditions and failures:</p>
<pre><code class="language-yaml">chaos:
  enabled: true
  latency:
    mean_ms: 200
    std_dev_ms: 50
  failures:
    error_rate: 0.05  # 5% of requests fail
    status_codes: [500, 502, 503]
</code></pre>
<p><strong>Why it matters:</strong> Test how your application handles real-world network conditions and failures.</p>
<p><strong>Learn more:</strong> <a href="getting-started/../../docs/CHAOS_LAB.html">Chaos Lab Guide</a></p>
<h3 id="5-temporal-simulation"><a class="header" href="#5-temporal-simulation">5. Temporal Simulation</a></h3>
<p>Time travel and time-based data mutations:</p>
<pre><code class="language-yaml">time_travel:
  enabled: true
  virtual_clock: true
  scheduled_responses:
    - time: "2025-01-01T00:00:00Z"
      endpoint: /api/events
      response: {...}
</code></pre>
<p><strong>Why it matters:</strong> Test time-dependent features, scheduled events, and data evolution over time.</p>
<p><strong>Learn more:</strong> <a href="getting-started/../../docs/TIME_TRAVEL.html">Time Travel Guide</a></p>
<h2 id="next-steps-2"><a class="header" href="#next-steps-2">Next Steps</a></h2>
<h3 id="explore-reality-features"><a class="header" href="#explore-reality-features">Explore Reality Features</a></h3>
<ol>
<li>
<p><strong>Reality Continuum</strong>: <a href="getting-started/../../docs/REALITY_CONTINUUM.html">Complete Guide</a></p>
<ul>
<li>Learn about blend ratios and merge strategies</li>
<li>Configure time-based progression</li>
<li>Set up fallback handling</li>
</ul>
</li>
<li>
<p><strong>Smart Personas</strong>: <a href="getting-started/../../docs/PERSONAS.html">Complete Guide</a></p>
<ul>
<li>Create persona graphs with relationships</li>
<li>Configure lifecycle states</li>
<li>Understand fidelity scores</li>
</ul>
</li>
<li>
<p><strong>Reality Slider</strong>: <a href="getting-started/../../docs/REALITY_SLIDER.html">Complete Guide</a></p>
<ul>
<li>Understand reality levels</li>
<li>Configure hot-reload</li>
<li>Coordinate chaos, latency, and AI</li>
</ul>
</li>
<li>
<p><strong>Chaos Lab</strong>: <a href="getting-started/../../docs/CHAOS_LAB.html">Complete Guide</a></p>
<ul>
<li>Configure latency profiles</li>
<li>Set up failure injection</li>
<li>Simulate network conditions</li>
</ul>
</li>
<li>
<p><strong>Temporal Simulation</strong>: <a href="getting-started/../../docs/TIME_TRAVEL.html">Complete Guide</a></p>
<ul>
<li>Use virtual clocks</li>
<li>Schedule time-based responses</li>
<li>Test time-dependent features</li>
</ul>
</li>
</ol>
<h3 id="related-pillars"><a class="header" href="#related-pillars">Related Pillars</a></h3>
<p>Once you‚Äôve mastered Reality, explore these complementary pillars:</p>
<ul>
<li>
<p><strong>[Contracts]</strong> - Add validation and drift detection to ensure your realistic mocks stay in sync with real APIs</p>
<ul>
<li><a href="getting-started/contracts-first.html">Contracts-First Onboarding</a></li>
<li><a href="getting-started/../../docs/DRIFT_BUDGETS.html">Drift Budgets Guide</a></li>
</ul>
</li>
<li>
<p><strong>[DevX]</strong> - Improve your workflow with SDKs, generators, and developer tools</p>
<ul>
<li><a href="getting-started/../../user-guide/http-mocking.html">DevX Features</a></li>
<li><a href="getting-started/../../reference/cli.html">CLI Reference</a></li>
</ul>
</li>
<li>
<p><strong>[AI]</strong> - Enhance realism with AI-powered data generation</p>
<ul>
<li><a href="getting-started/ai-first.html">AI-First Onboarding</a></li>
<li><a href="getting-started/../../docs/MOCKAI_USAGE.html">MockAI Guide</a></li>
</ul>
</li>
</ul>
<h2 id="examples-2"><a class="header" href="#examples-2">Examples</a></h2>
<h3 id="example-1-realistic-e-commerce-api"><a class="header" href="#example-1-realistic-e-commerce-api">Example 1: Realistic E-Commerce API</a></h3>
<pre><code class="language-yaml">workspaces:
  - name: ecommerce
    reality:
      level: 4  # High Realism
      personas:
        enabled: true
        entities:
          - type: user
          - type: product
          - type: order
            relationships:
              - field: user_id
                links_to: user.id
              - field: product_id
                links_to: product.id
    endpoints:
      - path: /api/users/{id}
        method: GET
        response:
          body: |
            {
              "id": "{{persona.user.id}}",
              "name": "{{persona.user.name}}",
              "orders": "{{persona.user.orders}}"
            }
</code></pre>
<h3 id="example-2-production-like-testing"><a class="header" href="#example-2-production-like-testing">Example 2: Production-Like Testing</a></h3>
<pre><code class="language-yaml">reality:
  level: 5  # Production Chaos
chaos:
  enabled: true
  latency:
    distribution: normal
    mean_ms: 300
    std_dev_ms: 100
  failures:
    error_rate: 0.02
    status_codes: [500, 502, 503, 504]
</code></pre>
<h2 id="troubleshooting-3"><a class="header" href="#troubleshooting-3">Troubleshooting</a></h2>
<h3 id="personas-not-working"><a class="header" href="#personas-not-working">Personas Not Working</a></h3>
<p>Ensure personas are enabled in your config:</p>
<pre><code class="language-yaml">reality:
  personas:
    enabled: true
</code></pre>
<h3 id="reality-continuum-not-blending"><a class="header" href="#reality-continuum-not-blending">Reality Continuum Not Blending</a></h3>
<p>Check your upstream URL and blend ratio:</p>
<pre><code class="language-yaml">reality:
  continuum:
    enabled: true
    blend_ratio: 0.5
    upstream_url: https://api.example.com  # Must be accessible
</code></pre>
<h3 id="chaos-not-injecting"><a class="header" href="#chaos-not-injecting">Chaos Not Injecting</a></h3>
<p>Verify chaos is enabled and configured:</p>
<pre><code class="language-yaml">chaos:
  enabled: true
  latency:
    mean_ms: 200
</code></pre>
<h2 id="resources"><a class="header" href="#resources">Resources</a></h2>
<ul>
<li><a href="getting-started/../../docs/PILLARS.html">Complete Pillars Documentation</a></li>
<li><a href="getting-started/../../docs/REALITY_CONTINUUM.html">Reality Features Overview</a></li>
<li><a href="getting-started/../../api/rust.html">API Reference</a></li>
<li><a href="https://github.com/SaaSy-Solutions/mockforge/tree/main/examples">Examples Repository</a></li>
</ul>
<hr />
<p><strong>Ready to dive deeper?</strong> Continue to the <a href="getting-started/../../docs/REALITY_CONTINUUM.html">Reality Continuum Guide</a> or explore <a href="getting-started/../../docs/PILLARS.html#reality--everything-that-makes-mocks-feel-like-a-real-evolving-backend">all Reality features</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="contracts-first-onboarding"><a class="header" href="#contracts-first-onboarding">Contracts-First Onboarding</a></h1>
<p><strong>Pillars:</strong> [Contracts]</p>
<p>[Contracts] - Schema, drift, validation, and safety nets</p>
<h2 id="start-here-if-1"><a class="header" href="#start-here-if-1">Start Here If‚Ä¶</a></h2>
<p>You‚Äôre a <strong>Platform/API team</strong>. You need to ensure API contracts are correct, validated, and stay in sync with real backends. You want to catch breaking changes before they reach production.</p>
<p>Perfect for:</p>
<ul>
<li>API teams managing contract evolution</li>
<li>Platform teams ensuring contract consistency</li>
<li>Teams needing automatic API sync and change detection</li>
<li>Organizations requiring contract validation and drift monitoring</li>
</ul>
<h2 id="quick-start-5-minutes-1"><a class="header" href="#quick-start-5-minutes-1">Quick Start: 5 Minutes</a></h2>
<p>Let‚Äôs set up contract validation and drift detection:</p>
<pre><code class="language-bash"># Install MockForge
cargo install mockforge-cli

# Create a config with contract validation
cat &gt; mockforge.yaml &lt;&lt;EOF
workspaces:
  - name: api-contracts
    validation:
      mode: enforce  # disabled, warn, or enforce
      openapi_spec: https://api.example.com/openapi.json
    drift:
      enabled: true
      budgets:
        - endpoint: /api/users
          breaking_changes: 0
          non_breaking_changes: 5
    endpoints:
      - path: /api/users
        method: GET
        openapi_operation: getUsers
        response:
          body: |
            {
              "users": []
            }
EOF

# Start the server with validation
mockforge serve --config mockforge.yaml --validate
</code></pre>
<p>Now test validation:</p>
<pre><code class="language-bash"># Valid request - should succeed
curl -X POST http://localhost:3000/api/users \
  -H "Content-Type: application/json" \
  -d '{"name": "John", "email": "john@example.com"}'

# Invalid request - should return 422 with validation errors
curl -X POST http://localhost:3000/api/users \
  -H "Content-Type: application/json" \
  -d '{"invalid": "field"}'
</code></pre>
<h2 id="key-contracts-features"><a class="header" href="#key-contracts-features">Key Contracts Features</a></h2>
<h3 id="1-requestresponse-validation"><a class="header" href="#1-requestresponse-validation">1. Request/Response Validation</a></h3>
<p>Validate requests and responses against OpenAPI schemas:</p>
<pre><code class="language-yaml">validation:
  mode: enforce  # disabled, warn, or enforce
  openapi_spec: ./api-spec.yaml
  strict_mode: true
</code></pre>
<p><strong>Why it matters:</strong> Catch contract violations early, before they reach production. Get detailed 422 error responses that help developers fix issues quickly.</p>
<p><strong>Learn more:</strong> <a href="getting-started/../../user-guide/http-mocking/openapi.html">Validation Guide</a></p>
<h3 id="2-contract-drift-detection"><a class="header" href="#2-contract-drift-detection">2. Contract Drift Detection</a></h3>
<p>Monitor contract changes and detect breaking changes:</p>
<pre><code class="language-yaml">drift:
  enabled: true
  sync_interval: 3600  # Check every hour
  upstream_spec: https://api.example.com/openapi.json
  budgets:
    - endpoint: /api/users
      breaking_changes: 0  # No breaking changes allowed
      non_breaking_changes: 10  # Max 10 non-breaking changes
</code></pre>
<p><strong>Why it matters:</strong> Stay informed about contract changes. Get alerts when drift budgets are exceeded. Prevent breaking changes from reaching consumers.</p>
<p><strong>Learn more:</strong> <a href="getting-started/../../docs/DRIFT_BUDGETS.html">Drift Budgets Guide</a></p>
<h3 id="3-automatic-api-sync"><a class="header" href="#3-automatic-api-sync">3. Automatic API Sync</a></h3>
<p>Automatically sync contracts from upstream APIs:</p>
<pre><code class="language-yaml">sync:
  enabled: true
  sources:
    - url: https://api.example.com/openapi.json
      interval: 3600
      on_change: alert  # alert, update, or ignore
</code></pre>
<p><strong>Why it matters:</strong> Keep mocks in sync with real APIs automatically. Get notified when upstream contracts change.</p>
<p><strong>Learn more:</strong> <a href="getting-started/../../docs/DRIFT_BUDGETS.html#automatic-api-sync">API Sync Guide</a></p>
<h3 id="4-ai-contract-diff"><a class="header" href="#4-ai-contract-diff">4. AI Contract Diff</a></h3>
<p>Intelligently compare and analyze contract changes:</p>
<pre><code class="language-yaml">ai_contract_diff:
  enabled: true
  llm_provider: openai
  analysis_depth: detailed
</code></pre>
<p><strong>Why it matters:</strong> Understand the impact of contract changes. Get AI-powered recommendations for handling breaking changes.</p>
<p><strong>Learn more:</strong> <a href="getting-started/../../docs/DRIFT_BUDGETS.html#ai-contract-diff">AI Contract Diff Guide</a></p>
<h3 id="5-multi-protocol-contracts"><a class="header" href="#5-multi-protocol-contracts">5. Multi-Protocol Contracts</a></h3>
<p>Manage contracts across HTTP, gRPC, WebSocket, MQTT, and Kafka:</p>
<pre><code class="language-yaml">protocols:
  grpc:
    proto_files:
      - ./api.proto
    validation: true
  websocket:
    message_schemas:
      - type: user_message
        schema: ./schemas/user.json
</code></pre>
<p><strong>Why it matters:</strong> Ensure contract consistency across all transport layers, not just HTTP/REST.</p>
<p><strong>Learn more:</strong> <a href="getting-started/../../docs/PROTOCOL_CONTRACTS.html">Protocol Contracts Guide</a></p>
<h2 id="next-steps-3"><a class="header" href="#next-steps-3">Next Steps</a></h2>
<h3 id="explore-contracts-features"><a class="header" href="#explore-contracts-features">Explore Contracts Features</a></h3>
<ol>
<li>
<p><strong>Validation</strong>: <a href="getting-started/../../user-guide/http-mocking/openapi.html">Complete Guide</a></p>
<ul>
<li>Configure validation modes</li>
<li>Set up OpenAPI specs</li>
<li>Understand validation errors</li>
</ul>
</li>
<li>
<p><strong>Drift Budgets</strong>: <a href="getting-started/../../docs/DRIFT_BUDGETS.html">Complete Guide</a></p>
<ul>
<li>Define drift budgets</li>
<li>Configure GitOps integration</li>
<li>Set up alerts</li>
</ul>
</li>
<li>
<p><strong>API Sync</strong>: <a href="getting-started/../../docs/DRIFT_BUDGETS.html#automatic-api-sync">Complete Guide</a></p>
<ul>
<li>Configure automatic sync</li>
<li>Set up change detection</li>
<li>Handle sync events</li>
</ul>
</li>
<li>
<p><strong>Protocol Contracts</strong>: <a href="getting-started/../../docs/PROTOCOL_CONTRACTS.html">Complete Guide</a></p>
<ul>
<li>Manage gRPC contracts</li>
<li>Configure WebSocket schemas</li>
<li>Set up MQTT/Kafka contracts</li>
</ul>
</li>
<li>
<p><strong>AI Contract Diff</strong>: <a href="getting-started/../../docs/DRIFT_BUDGETS.html#ai-contract-diff">Complete Guide</a></p>
<ul>
<li>Enable AI analysis</li>
<li>Understand recommendations</li>
<li>Handle breaking changes</li>
</ul>
</li>
</ol>
<h3 id="related-pillars-1"><a class="header" href="#related-pillars-1">Related Pillars</a></h3>
<p>Once you‚Äôve mastered Contracts, explore these complementary pillars:</p>
<ul>
<li>
<p><strong>[Reality]</strong> - Add realistic behavior to your validated mocks</p>
<ul>
<li><a href="getting-started/reality-first.html">Reality-First Onboarding</a></li>
<li><a href="getting-started/../../docs/REALITY_CONTINUUM.html">Reality Continuum Guide</a></li>
</ul>
</li>
<li>
<p><strong>[DevX]</strong> - Improve your workflow with SDKs and developer tools</p>
<ul>
<li><a href="getting-started/../../user-guide/http-mocking.html">DevX Features</a></li>
<li><a href="getting-started/../../reference/cli.html">CLI Reference</a></li>
</ul>
</li>
<li>
<p><strong>[AI]</strong> - Enhance contract analysis with AI-powered insights</p>
<ul>
<li><a href="getting-started/ai-first.html">AI-First Onboarding</a></li>
<li><a href="getting-started/../../docs/DRIFT_BUDGETS.html#ai-contract-diff">AI Contract Diff Guide</a></li>
</ul>
</li>
</ul>
<h2 id="examples-3"><a class="header" href="#examples-3">Examples</a></h2>
<h3 id="example-1-strict-validation"><a class="header" href="#example-1-strict-validation">Example 1: Strict Validation</a></h3>
<pre><code class="language-yaml">workspaces:
  - name: strict-api
    validation:
      mode: enforce
      openapi_spec: ./api-spec.yaml
      strict_mode: true
      validate_responses: true
    endpoints:
      - path: /api/users
        method: POST
        openapi_operation: createUser
        response:
          body: |
            {
              "id": "{{uuid}}",
              "name": "{{faker.name}}",
              "email": "{{faker.email}}"
            }
</code></pre>
<h3 id="example-2-drift-monitoring"><a class="header" href="#example-2-drift-monitoring">Example 2: Drift Monitoring</a></h3>
<pre><code class="language-yaml">drift:
  enabled: true
  sync_interval: 1800  # Check every 30 minutes
  upstream_spec: https://api.example.com/openapi.json
  budgets:
    - endpoint: /api/users
      breaking_changes: 0
      non_breaking_changes: 5
      field_churn_percent: 10
    - endpoint: /api/orders
      breaking_changes: 0
      non_breaking_changes: 10
  gitops:
    enabled: true
    on_violation: create_pr
    branch_prefix: contract-update
</code></pre>
<h3 id="example-3-multi-protocol-contracts"><a class="header" href="#example-3-multi-protocol-contracts">Example 3: Multi-Protocol Contracts</a></h3>
<pre><code class="language-yaml">protocols:
  grpc:
    proto_files:
      - ./api.proto
    validation: true
    drift:
      enabled: true
  websocket:
    message_schemas:
      - type: user_message
        schema: ./schemas/user.json
    validation: true
</code></pre>
<h2 id="troubleshooting-4"><a class="header" href="#troubleshooting-4">Troubleshooting</a></h2>
<h3 id="validation-not-working"><a class="header" href="#validation-not-working">Validation Not Working</a></h3>
<p>Ensure validation mode is set correctly:</p>
<pre><code class="language-yaml">validation:
  mode: enforce  # Must be 'enforce' or 'warn', not 'disabled'
  openapi_spec: ./api-spec.yaml  # Must be valid OpenAPI spec
</code></pre>
<h3 id="drift-detection-not-triggering"><a class="header" href="#drift-detection-not-triggering">Drift Detection Not Triggering</a></h3>
<p>Check your sync configuration:</p>
<pre><code class="language-yaml">drift:
  enabled: true
  sync_interval: 3600  # Must be &gt; 0
  upstream_spec: https://api.example.com/openapi.json  # Must be accessible
</code></pre>
<h3 id="contract-sync-failing"><a class="header" href="#contract-sync-failing">Contract Sync Failing</a></h3>
<p>Verify your upstream URL and network access:</p>
<pre><code class="language-bash"># Test upstream accessibility
curl https://api.example.com/openapi.json
</code></pre>
<h2 id="resources-1"><a class="header" href="#resources-1">Resources</a></h2>
<ul>
<li><a href="getting-started/../../docs/PILLARS.html">Complete Pillars Documentation</a></li>
<li><a href="getting-started/../../docs/PILLARS.html#contracts--schema-drift-validation-and-safety-nets">Contracts Features Overview</a></li>
<li><a href="getting-started/../../api/rust.html">API Reference</a></li>
<li><a href="https://github.com/SaaSy-Solutions/mockforge/tree/main/examples">Examples Repository</a></li>
</ul>
<hr />
<p><strong>Ready to dive deeper?</strong> Continue to the <a href="getting-started/../../docs/DRIFT_BUDGETS.html">Drift Budgets Guide</a> or explore <a href="getting-started/../../docs/PILLARS.html#contracts--schema-drift-validation-and-safety-nets">all Contracts features</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="ai-first-onboarding"><a class="header" href="#ai-first-onboarding">AI-First Onboarding</a></h1>
<p><strong>Pillars:</strong> [AI]</p>
<p>[AI] - LLM/voice flows, AI diff/assist, generative behaviors</p>
<h2 id="start-here-if-2"><a class="header" href="#start-here-if-2">Start Here If‚Ä¶</a></h2>
<p>You want <strong>natural-language-driven mocks</strong>. You want to generate mocks from descriptions, use voice commands, and leverage AI to automate mock creation and enhance data realism.</p>
<p>Perfect for:</p>
<ul>
<li>Teams wanting to generate mocks from natural language descriptions</li>
<li>Developers who prefer conversational interfaces</li>
<li>Teams needing AI-powered contract analysis</li>
<li>Organizations wanting to automate mock generation</li>
</ul>
<h2 id="quick-start-5-minutes-2"><a class="header" href="#quick-start-5-minutes-2">Quick Start: 5 Minutes</a></h2>
<p>Let‚Äôs create a mock API using natural language:</p>
<pre><code class="language-bash"># Install MockForge
cargo install mockforge-cli

# Start MockForge with AI features enabled
mockforge serve --ai-enabled

# Use MockAI to generate a mock from natural language
curl -X POST http://localhost:3000/__mockforge/ai/generate \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Create a REST API for a todo app with endpoints to list, create, update, and delete todos. Todos have id, title, description, completed status, and created date."
  }'
</code></pre>
<p>Or use the voice interface:</p>
<pre><code class="language-bash"># Start voice mode
mockforge voice

# Say: "Create a REST API for a todo app with CRUD operations"
</code></pre>
<h2 id="key-ai-features"><a class="header" href="#key-ai-features">Key AI Features</a></h2>
<h3 id="1-mockai---natural-language-mock-generation"><a class="header" href="#1-mockai---natural-language-mock-generation">1. MockAI - Natural Language Mock Generation</a></h3>
<p>Generate complete mock APIs from natural language descriptions:</p>
<pre><code class="language-bash"># Generate a mock API
curl -X POST http://localhost:3000/__mockforge/ai/generate \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Create a user management API with endpoints for registration, login, and profile management"
  }'
</code></pre>
<p><strong>Why it matters:</strong> Create mocks instantly without writing YAML or code. Describe what you need in plain English, and MockAI generates the complete API.</p>
<p><strong>Learn more:</strong> <a href="getting-started/../../docs/MOCKAI_USAGE.html">MockAI Guide</a></p>
<h3 id="2-voice--llm-interface"><a class="header" href="#2-voice--llm-interface">2. Voice + LLM Interface</a></h3>
<p>Build mocks using voice commands:</p>
<pre><code class="language-bash"># Start voice mode
mockforge voice

# Example commands:
# "Create a REST API for an e-commerce store"
# "Add an endpoint to get product details by ID"
# "Generate realistic product data with names, prices, and descriptions"
</code></pre>
<p><strong>Why it matters:</strong> Build mocks hands-free using natural language. Perfect for rapid prototyping and iterative development.</p>
<p><strong>Learn more:</strong> <a href="getting-started/../../docs/MOCKAI_USAGE.html#voice-interface">Voice Interface Guide</a></p>
<h3 id="3-ai-contract-diff"><a class="header" href="#3-ai-contract-diff">3. AI Contract Diff</a></h3>
<p>Intelligently analyze and compare contract changes:</p>
<pre><code class="language-yaml">ai_contract_diff:
  enabled: true
  llm_provider: openai
  analysis_depth: detailed
  generate_recommendations: true
</code></pre>
<p><strong>Why it matters:</strong> Understand the impact of contract changes with AI-powered analysis. Get recommendations for handling breaking changes.</p>
<p><strong>Learn more:</strong> <a href="getting-started/../../docs/DRIFT_BUDGETS.html#ai-contract-diff">AI Contract Diff Guide</a></p>
<h3 id="4-generative-schema-mode"><a class="header" href="#4-generative-schema-mode">4. Generative Schema Mode</a></h3>
<p>Generate complete API ecosystems from JSON examples:</p>
<pre><code class="language-yaml">generative_schema:
  enabled: true
  examples:
    - path: ./examples/user.json
      entity_type: user
    - path: ./examples/order.json
      entity_type: order
</code></pre>
<p><strong>Why it matters:</strong> Create entire API ecosystems from a few example JSON payloads. Automatically infer routes, relationships, and schemas.</p>
<p><strong>Learn more:</strong> <a href="getting-started/../../docs/AI_SCHEMA_EXTRAPOLATION.html">Generative Schema Guide</a></p>
<h3 id="5-ai-event-streams"><a class="header" href="#5-ai-event-streams">5. AI Event Streams</a></h3>
<p>Generate narrative-driven WebSocket events:</p>
<pre><code class="language-yaml">websocket:
  ai_streams:
    enabled: true
    narrative: "A user browsing an e-commerce site, adding items to cart, and completing a purchase"
    event_types:
      - page_view
      - product_view
      - add_to_cart
      - checkout
</code></pre>
<p><strong>Why it matters:</strong> Create realistic, narrative-driven event streams for testing real-time features.</p>
<p><strong>Learn more:</strong> <a href="getting-started/../../docs/AI_DRIVEN_MOCKING.html">AI Event Streams Guide</a></p>
<h2 id="next-steps-4"><a class="header" href="#next-steps-4">Next Steps</a></h2>
<h3 id="explore-ai-features"><a class="header" href="#explore-ai-features">Explore AI Features</a></h3>
<ol>
<li>
<p><strong>MockAI</strong>: <a href="getting-started/../../docs/MOCKAI_USAGE.html">Complete Guide</a></p>
<ul>
<li>Generate mocks from natural language</li>
<li>Refine and iterate on generated mocks</li>
<li>Understand AI generation rules</li>
</ul>
</li>
<li>
<p><strong>Voice Interface</strong>: <a href="getting-started/../../docs/MOCKAI_USAGE.html#voice-interface">Complete Guide</a></p>
<ul>
<li>Set up voice commands</li>
<li>Use conversational mode</li>
<li>Generate OpenAPI specs from voice</li>
</ul>
</li>
<li>
<p><strong>AI Contract Diff</strong>: <a href="getting-started/../../docs/DRIFT_BUDGETS.html#ai-contract-diff">Complete Guide</a></p>
<ul>
<li>Enable AI analysis</li>
<li>Understand recommendations</li>
<li>Handle breaking changes</li>
</ul>
</li>
<li>
<p><strong>Generative Schema</strong>: <a href="getting-started/../../docs/AI_SCHEMA_EXTRAPOLATION.html">Complete Guide</a></p>
<ul>
<li>Generate APIs from JSON examples</li>
<li>Configure entity relationships</li>
<li>Customize route generation</li>
</ul>
</li>
<li>
<p><strong>AI Event Streams</strong>: <a href="getting-started/../../docs/AI_DRIVEN_MOCKING.html">Complete Guide</a></p>
<ul>
<li>Create narrative-driven events</li>
<li>Configure event types</li>
<li>Test real-time features</li>
</ul>
</li>
</ol>
<h3 id="related-pillars-2"><a class="header" href="#related-pillars-2">Related Pillars</a></h3>
<p>Once you‚Äôve mastered AI, explore these complementary pillars:</p>
<ul>
<li>
<p><strong>[Reality]</strong> - Enhance AI-generated mocks with realistic behavior</p>
<ul>
<li><a href="getting-started/reality-first.html">Reality-First Onboarding</a></li>
<li><a href="getting-started/../../docs/PERSONAS.html">Smart Personas Guide</a></li>
</ul>
</li>
<li>
<p><strong>[Contracts]</strong> - Add validation to AI-generated mocks</p>
<ul>
<li><a href="getting-started/contracts-first.html">Contracts-First Onboarding</a></li>
<li><a href="getting-started/../../user-guide/http-mocking/openapi.html">Validation Guide</a></li>
</ul>
</li>
<li>
<p><strong>[DevX]</strong> - Improve your AI workflow with SDKs and tools</p>
<ul>
<li><a href="getting-started/../../user-guide/http-mocking.html">DevX Features</a></li>
<li><a href="getting-started/../../reference/cli.html">CLI Reference</a></li>
</ul>
</li>
</ul>
<h2 id="examples-4"><a class="header" href="#examples-4">Examples</a></h2>
<h3 id="example-1-natural-language-mock-generation"><a class="header" href="#example-1-natural-language-mock-generation">Example 1: Natural Language Mock Generation</a></h3>
<pre><code class="language-bash"># Generate a complete e-commerce API
curl -X POST http://localhost:3000/__mockforge/ai/generate \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Create a REST API for an e-commerce store with products, cart, and checkout endpoints. Products have id, name, price, description, and stock. Cart items link to products and have quantity."
  }'
</code></pre>
<h3 id="example-2-voice-driven-development"><a class="header" href="#example-2-voice-driven-development">Example 2: Voice-Driven Development</a></h3>
<pre><code class="language-bash"># Start voice mode
mockforge voice

# Interactive session:
# You: "Create a user authentication API"
# MockForge: "I've created a user authentication API with /register and /login endpoints. Would you like to add password reset?"
# You: "Yes, add password reset with email verification"
# MockForge: "Added /reset-password and /verify-email endpoints. The API is ready!"
</code></pre>
<h3 id="example-3-ai-enhanced-personas"><a class="header" href="#example-3-ai-enhanced-personas">Example 3: AI-Enhanced Personas</a></h3>
<pre><code class="language-yaml">reality:
  personas:
    enabled: true
    ai_generation: true
    ai_config:
      provider: openai
      model: gpt-4
      generate_relationships: true
      generate_lifecycle_states: true
</code></pre>
<h3 id="example-4-generative-schema-from-examples"><a class="header" href="#example-4-generative-schema-from-examples">Example 4: Generative Schema from Examples</a></h3>
<pre><code class="language-yaml">generative_schema:
  enabled: true
  examples:
    - path: ./examples/user.json
      entity_type: user
      routes:
        - GET /users
        - GET /users/{id}
        - POST /users
        - PUT /users/{id}
        - DELETE /users/{id}
    - path: ./examples/order.json
      entity_type: order
      relationships:
        - field: user_id
          links_to: user.id
</code></pre>
<h2 id="troubleshooting-5"><a class="header" href="#troubleshooting-5">Troubleshooting</a></h2>
<h3 id="ai-generation-not-working"><a class="header" href="#ai-generation-not-working">AI Generation Not Working</a></h3>
<p>Ensure AI features are enabled:</p>
<pre><code class="language-yaml">ai:
  enabled: true
  provider: openai  # or anthropic, etc.
  api_key: ${OPENAI_API_KEY}
</code></pre>
<h3 id="voice-interface-not-responding"><a class="header" href="#voice-interface-not-responding">Voice Interface Not Responding</a></h3>
<p>Check your microphone permissions and voice configuration:</p>
<pre><code class="language-yaml">voice:
  enabled: true
  provider: openai
  speech_to_text: true
</code></pre>
<h3 id="ai-contract-diff-not-analyzing"><a class="header" href="#ai-contract-diff-not-analyzing">AI Contract Diff Not Analyzing</a></h3>
<p>Verify your LLM provider configuration:</p>
<pre><code class="language-yaml">ai_contract_diff:
  enabled: true
  llm_provider: openai
  api_key: ${OPENAI_API_KEY}
</code></pre>
<h2 id="resources-2"><a class="header" href="#resources-2">Resources</a></h2>
<ul>
<li><a href="getting-started/../../docs/PILLARS.html">Complete Pillars Documentation</a></li>
<li><a href="getting-started/../../docs/PILLARS.html#ai--llmvoice-flows-ai-diffassist-generative-behaviors">AI Features Overview</a></li>
<li><a href="getting-started/../../docs/MOCKAI_USAGE.html">MockAI Guide</a></li>
<li><a href="getting-started/../../api/rust.html">API Reference</a></li>
<li><a href="https://github.com/SaaSy-Solutions/mockforge/tree/main/examples">Examples Repository</a></li>
</ul>
<hr />
<p><strong>Ready to dive deeper?</strong> Continue to the <a href="getting-started/../../docs/MOCKAI_USAGE.html">MockAI Guide</a> or explore <a href="getting-started/../../docs/PILLARS.html#ai--llmvoice-flows-ai-diffassist-generative-behaviors">all AI features</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="tutorials-1"><a class="header" href="#tutorials-1">Tutorials</a></h1>
<p>Welcome to the MockForge tutorials! These step-by-step guides walk you through common workflows and real-world scenarios.</p>
<p>Each tutorial is designed to be completed in 5-10 minutes and focuses on a specific goal.</p>
<h2 id="getting-started-tutorials"><a class="header" href="#getting-started-tutorials">Getting Started Tutorials</a></h2>
<h3 id="your-first-mock-api-in-5-minutes-1"><a class="header" href="#your-first-mock-api-in-5-minutes-1"><a href="tutorials/../getting-started/five-minute-api.html">Your First Mock API in 5 Minutes</a></a></h3>
<p><strong>Time</strong>: 5 minutes | <strong>Level</strong>: Beginner</p>
<p>The fastest way to get started with MockForge. Create a simple REST API from scratch and test it.</p>
<p><strong>You‚Äôll learn:</strong></p>
<ul>
<li>Basic YAML configuration</li>
<li>Template variables</li>
<li>Starting the server</li>
<li>Testing endpoints</li>
</ul>
<p><strong>Perfect for</strong>: First-time users who want to see MockForge in action immediately.</p>
<hr />
<h2 id="common-workflow-tutorials"><a class="header" href="#common-workflow-tutorials">Common Workflow Tutorials</a></h2>
<h3 id="mock-a-rest-api-from-an-openapi-spec"><a class="header" href="#mock-a-rest-api-from-an-openapi-spec"><a href="tutorials/mock-openapi-spec.html">Mock a REST API from an OpenAPI Spec</a></a></h3>
<p><strong>Time</strong>: 3 minutes | <strong>Level</strong>: Beginner</p>
<p>Automatically generate mock endpoints from your OpenAPI/Swagger specification.</p>
<p><strong>You‚Äôll learn:</strong></p>
<ul>
<li>Loading OpenAPI specs</li>
<li>Auto-generated responses</li>
<li>Request validation</li>
<li>Overriding specific endpoints</li>
</ul>
<p><strong>Perfect for</strong>: Teams with existing API documentation who want instant mocks.</p>
<hr />
<h3 id="admin-ui-walkthrough"><a class="header" href="#admin-ui-walkthrough"><a href="tutorials/admin-ui-walkthrough.html">Admin UI Walkthrough</a></a></h3>
<p><strong>Time</strong>: 5 minutes | <strong>Level</strong>: Beginner</p>
<p>Discover MockForge‚Äôs visual interface for managing your mock server without editing config files.</p>
<p><strong>You‚Äôll learn:</strong></p>
<ul>
<li>Dashboard navigation</li>
<li>Live request logs</li>
<li>Fixture management</li>
<li>Latency and fault simulation</li>
<li>Full-text search</li>
</ul>
<p><strong>Perfect for</strong>: Visual learners and teams who prefer UI over CLI.</p>
<hr />
<h3 id="add-a-custom-plugin"><a class="header" href="#add-a-custom-plugin"><a href="tutorials/add-custom-plugin.html">Add a Custom Plugin</a></a></h3>
<p><strong>Time</strong>: 10 minutes | <strong>Level</strong>: Intermediate</p>
<p>Extend MockForge with plugins for custom authentication, data generation, or business logic.</p>
<p><strong>You‚Äôll learn:</strong></p>
<ul>
<li>Installing pre-built plugins</li>
<li>Using plugins in configs</li>
<li>Creating your own plugin</li>
<li>Plugin security and permissions</li>
</ul>
<p><strong>Perfect for</strong>: Developers who need custom functionality beyond built-in features.</p>
<hr />
<h2 id="scenario-based-tutorials"><a class="header" href="#scenario-based-tutorials">Scenario-Based Tutorials</a></h2>
<h3 id="coming-soon"><a class="header" href="#coming-soon">Coming Soon</a></h3>
<p>We‚Äôre working on tutorials for these common scenarios:</p>
<ul>
<li><strong>Frontend Development Workflow</strong>: Set up mocks for a React/Vue/Angular app</li>
<li><strong>Microservices Testing</strong>: Mock a multi-service architecture</li>
<li><strong>Team Collaboration</strong>: Share mocks with Git and workspace sync</li>
<li><strong>CI/CD Integration</strong>: Use MockForge in automated testing pipelines</li>
<li><strong>Performance Testing</strong>: Simulate load and measure application behavior</li>
<li><strong>WebSocket Real-Time Apps</strong>: Mock chat, notifications, and live updates</li>
<li><strong>gRPC Service Development</strong>: Work with Protocol Buffers and streaming</li>
</ul>
<p>Want to see a specific tutorial? <a href="https://github.com/SaaSy-Solutions/mockforge/issues">Open an issue</a> with your suggestion!</p>
<hr />
<h2 id="tutorial-format"><a class="header" href="#tutorial-format">Tutorial Format</a></h2>
<p>Each tutorial follows this structure:</p>
<ol>
<li><strong>Goal</strong>: What you‚Äôll accomplish</li>
<li><strong>Time</strong>: How long it takes</li>
<li><strong>Prerequisites</strong>: What you need before starting</li>
<li><strong>Step-by-step instructions</strong>: Clear, numbered steps</li>
<li><strong>Code examples</strong>: Ready-to-use configurations</li>
<li><strong>Troubleshooting</strong>: Common issues and solutions</li>
<li><strong>What‚Äôs next</strong>: Related guides and advanced topics</li>
</ol>
<h2 id="how-to-use-these-tutorials"><a class="header" href="#how-to-use-these-tutorials">How to Use These Tutorials</a></h2>
<h3 id="for-beginners"><a class="header" href="#for-beginners">For Beginners</a></h3>
<p>Start with <strong>‚ÄúYour First Mock API in 5 Minutes‚Äù</strong>, then move to <strong>‚ÄúMock a REST API from an OpenAPI Spec‚Äù</strong> if you have existing API documentation.</p>
<h3 id="for-teams"><a class="header" href="#for-teams">For Teams</a></h3>
<p>Have team members complete <strong>‚ÄúAdmin UI Walkthrough‚Äù</strong> to get comfortable with the visual interface, then explore <strong>‚ÄúTeam Collaboration‚Äù</strong> (coming soon) for multi-user workflows.</p>
<h3 id="for-developers"><a class="header" href="#for-developers">For Developers</a></h3>
<p>Jump straight to <strong>‚ÄúAdd a Custom Plugin‚Äù</strong> if you need advanced customization, or start with the basic tutorials to understand core concepts first.</p>
<h2 id="contributing-tutorials"><a class="header" href="#contributing-tutorials">Contributing Tutorials</a></h2>
<p>Found a tutorial helpful? Have ideas for new ones? We welcome contributions!</p>
<p>See our <a href="tutorials/../contributing/setup.html">Contributing Guide</a> for details on how to submit tutorial ideas or write your own.</p>
<hr />
<h2 id="quick-reference"><a class="header" href="#quick-reference">Quick Reference</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Tutorial</th><th>Time</th><th>Level</th><th>Tags</th></tr></thead><tbody>
<tr><td><a href="tutorials/../getting-started/five-minute-api.html">Your First Mock API</a></td><td>5 min</td><td>Beginner</td><td>Getting Started, HTTP, Basic</td></tr>
<tr><td><a href="tutorials/mock-openapi-spec.html">Mock OpenAPI Spec</a></td><td>3 min</td><td>Beginner</td><td>HTTP, OpenAPI, Validation</td></tr>
<tr><td><a href="tutorials/admin-ui-walkthrough.html">Admin UI Walkthrough</a></td><td>5 min</td><td>Beginner</td><td>Admin UI, Monitoring, Visual</td></tr>
<tr><td><a href="tutorials/add-custom-plugin.html">Add Custom Plugin</a></td><td>10 min</td><td>Intermediate</td><td>Plugins, Extension, WASM</td></tr>
</tbody></table>
</div>
<hr />
<p><strong>Ready to start?</strong> Pick a tutorial above and follow along. Each one is designed to give you hands-on experience with MockForge‚Äôs powerful features.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="the-golden-path-blueprint--dev-setup--integration"><a class="header" href="#the-golden-path-blueprint--dev-setup--integration">The Golden Path: Blueprint ‚Üí Dev-Setup ‚Üí Integration</a></h1>
<p>This guide walks you through the <strong>Golden Path</strong> - the fastest way to get from zero to a fully integrated mock API in your frontend application. This path is designed to take less than 10 minutes and provide a magical first experience.</p>
<h2 id="overview-1"><a class="header" href="#overview-1">Overview</a></h2>
<p>The Golden Path consists of three steps:</p>
<ol>
<li><strong>Blueprint</strong>: Start with a pre-configured app archetype</li>
<li><strong>Dev-Setup</strong>: One-command frontend integration</li>
<li><strong>Integration</strong>: Use generated code in your app</li>
</ol>
<h2 id="step-1-choose-and-create-from-a-blueprint"><a class="header" href="#step-1-choose-and-create-from-a-blueprint">Step 1: Choose and Create from a Blueprint</a></h2>
<p>Blueprints are pre-configured application archetypes that include:</p>
<ul>
<li><strong>Personas</strong>: Realistic user profiles with consistent data</li>
<li><strong>Reality defaults</strong>: Optimized realism levels for your use case</li>
<li><strong>Sample flows</strong>: Common workflows (signup, checkout, etc.)</li>
<li><strong>Scenarios</strong>: Happy paths, known failures, and slow paths</li>
<li><strong>Contracts</strong>: JSON Schema validation for endpoints</li>
<li><strong>Playground collections</strong>: Pre-configured test scenarios</li>
</ul>
<h3 id="available-blueprints"><a class="header" href="#available-blueprints">Available Blueprints</a></h3>
<p>List available blueprints:</p>
<pre><code class="language-bash">mockforge blueprint list
</code></pre>
<p>You‚Äôll see blueprints like:</p>
<ul>
<li><strong>b2c-saas</strong>: B2C SaaS with authentication, subscriptions, and billing</li>
<li><strong>ecommerce</strong>: E-commerce with products, cart, and checkout</li>
<li><strong>banking-lite</strong>: Banking app with accounts, transactions, and transfers</li>
</ul>
<h3 id="create-your-project"><a class="header" href="#create-your-project">Create Your Project</a></h3>
<p>Choose a blueprint and create your project:</p>
<pre><code class="language-bash"># For a B2C SaaS app
mockforge init my-saas-app --blueprint b2c-saas

# For an e-commerce app
mockforge init my-store --blueprint ecommerce

# For a banking app
mockforge init my-bank --blueprint banking-lite
</code></pre>
<p>This command:</p>
<ul>
<li>Creates a new project directory</li>
<li>Copies all blueprint files (config, personas, flows, scenarios, contracts)</li>
<li>Sets up the <code>mockforge.yaml</code> configuration</li>
<li>Creates a README with API documentation</li>
</ul>
<h3 id="explore-what-you-got"><a class="header" href="#explore-what-you-got">Explore What You Got</a></h3>
<pre><code class="language-bash">cd my-saas-app
ls -la
</code></pre>
<p>You‚Äôll see:</p>
<ul>
<li><code>mockforge.yaml</code> - Main configuration</li>
<li><code>personas/</code> - User personas with consistent data</li>
<li><code>scenarios/</code> - Multi-step API workflows</li>
<li><code>contracts/</code> - JSON Schema validation</li>
<li><code>README.md</code> - API documentation</li>
</ul>
<h3 id="start-the-mock-server"><a class="header" href="#start-the-mock-server">Start the Mock Server</a></h3>
<pre><code class="language-bash">mockforge serve
</code></pre>
<p>Your mock API is now running! Visit <code>http://localhost:3000</code> to see it in action.</p>
<p><strong>Try it out:</strong></p>
<pre><code class="language-bash"># Test the signup endpoint
curl -X POST http://localhost:3000/api/auth/signup \
  -H "Content-Type: application/json" \
  -d '{"email": "user@example.com", "password": "password123"}'
</code></pre>
<h2 id="step-2-one-command-frontend-integration"><a class="header" href="#step-2-one-command-frontend-integration">Step 2: One-Command Frontend Integration</a></h2>
<p>Now that your mock API is running, integrate it into your frontend application with a single command.</p>
<h3 id="supported-frameworks"><a class="header" href="#supported-frameworks">Supported Frameworks</a></h3>
<p>The <code>dev-setup</code> command supports:</p>
<ul>
<li><strong>React</strong> / <strong>Next.js</strong></li>
<li><strong>Vue</strong> / <strong>Nuxt</strong></li>
<li><strong>Angular</strong></li>
<li><strong>Svelte</strong></li>
</ul>
<h3 id="run-dev-setup"><a class="header" href="#run-dev-setup">Run Dev-Setup</a></h3>
<p>Navigate to your frontend project and run:</p>
<pre><code class="language-bash"># For React
mockforge dev-setup react

# For Vue
mockforge dev-setup vue

# For Angular
mockforge dev-setup angular

# For Svelte
mockforge dev-setup svelte
</code></pre>
<h3 id="what-dev-setup-does"><a class="header" href="#what-dev-setup-does">What Dev-Setup Does</a></h3>
<p>The command automatically:</p>
<ol>
<li><strong>Detects your project structure</strong> - Finds your frontend framework and configuration</li>
<li><strong>Detects existing MockForge workspace</strong> - If you‚Äôre in a blueprint project, it auto-detects the config</li>
<li><strong>Auto-detects OpenAPI spec</strong> - Finds <code>openapi.yaml</code>, <code>openapi.json</code>, or spec in <code>mockforge.yaml</code></li>
<li><strong>Generates typed client</strong> - Creates a fully-typed API client from your OpenAPI spec</li>
<li><strong>Creates framework examples</strong> - Generates example hooks/composables/services</li>
<li><strong>Sets up environment variables</strong> - Creates <code>.env.mockforge.example</code> with configuration</li>
<li><strong>Installs dependencies</strong> - Adds required packages to your <code>package.json</code></li>
</ol>
<h3 id="example-output"><a class="header" href="#example-output">Example Output</a></h3>
<pre><code>üöÄ Setting up MockForge for react...

  ‚úì Detected project root: /path/to/my-frontend
  ‚úì Detected existing MockForge workspace configuration
    Base URL: http://localhost:3000
    Reality level: moderate
  ‚úì Found OpenAPI spec: openapi.yaml
  ‚úì Generated typed client: src/mockforge/client.ts
  ‚úì Created React Query hooks: src/mockforge/hooks.ts
  ‚úì Created example component: src/components/MockForgeExample.tsx
  ‚úì Created environment template: .env.mockforge.example

‚úÖ Setup complete!

Next steps:
  1. Copy .env.mockforge.example to .env.local
  2. Check out src/components/MockForgeExample.tsx
  3. Start using the generated hooks in your components
</code></pre>
<h2 id="step-3-integrate-into-your-app"><a class="header" href="#step-3-integrate-into-your-app">Step 3: Integrate into Your App</a></h2>
<p>Now use the generated code in your application.</p>
<h3 id="react--nextjs-example"><a class="header" href="#react--nextjs-example">React / Next.js Example</a></h3>
<pre><code class="language-tsx">import { useGetUsers, useCreateUser } from '@/mockforge/hooks';

function UsersList() {
  const { data: users, isLoading, error } = useGetUsers();
  const createUser = useCreateUser();

  const handleCreate = async () =&gt; {
    await createUser.mutateAsync({
      email: 'newuser@example.com',
      name: 'New User',
    });
  };

  if (isLoading) return &lt;div&gt;Loading...&lt;/div&gt;;
  if (error) return &lt;div&gt;Error: {error.message}&lt;/div&gt;;

  return (
    &lt;div&gt;
      &lt;button onClick={handleCreate}&gt;Create User&lt;/button&gt;
      &lt;ul&gt;
        {users?.map(user =&gt; (
          &lt;li key={user.id}&gt;{user.name} - {user.email}&lt;/li&gt;
        ))}
      &lt;/ul&gt;
    &lt;/div&gt;
  );
}
</code></pre>
<h3 id="vue--nuxt-example"><a class="header" href="#vue--nuxt-example">Vue / Nuxt Example</a></h3>
<pre><code class="language-vue">&lt;template&gt;
  &lt;div&gt;
    &lt;button @click="createUser"&gt;Create User&lt;/button&gt;
    &lt;ul v-if="users"&gt;
      &lt;li v-for="user in users" :key="user.id"&gt;
        {{ user.name }} - {{ user.email }}
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/div&gt;
&lt;/template&gt;

&lt;script setup&gt;
import { useGetUsers, useCreateUser } from '@/mockforge/composables';

const { data: users, isLoading, error } = useGetUsers();
const { mutate: createUser } = useCreateUser();

const handleCreate = () =&gt; {
  createUser({
    email: 'newuser@example.com',
    name: 'New User',
  });
};
&lt;/script&gt;
</code></pre>
<h3 id="angular-example"><a class="header" href="#angular-example">Angular Example</a></h3>
<pre><code class="language-typescript">import { Component } from '@angular/core';
import { UserService } from '@/mockforge/services/user.service';

@Component({
  selector: 'app-users',
  template: `
    &lt;button (click)="createUser()"&gt;Create User&lt;/button&gt;
    &lt;ul&gt;
      &lt;li *ngFor="let user of users$ | async"&gt;
        {{ user.name }} - {{ user.email }}
      &lt;/li&gt;
    &lt;/ul&gt;
  `,
})
export class UsersComponent {
  users$ = this.userService.getUsers();

  constructor(private userService: UserService) {}

  createUser() {
    this.userService.createUser({
      email: 'newuser@example.com',
      name: 'New User',
    }).subscribe();
  }
}
</code></pre>
<h3 id="svelte-example"><a class="header" href="#svelte-example">Svelte Example</a></h3>
<pre><code class="language-svelte">&lt;script&gt;
  import { getUsers, createUser } from '@/mockforge/stores';

  let users = $state([]);

  $effect(() =&gt; {
    getUsers().then(data =&gt; users = data);
  });

  async function handleCreate() {
    await createUser({
      email: 'newuser@example.com',
      name: 'New User',
    });
    // Refresh users
    users = await getUsers();
  }
&lt;/script&gt;

&lt;button on:click={handleCreate}&gt;Create User&lt;/button&gt;
&lt;ul&gt;
  {#each users as user}
    &lt;li&gt;{user.name} - {user.email}&lt;/li&gt;
  {/each}
&lt;/ul&gt;
</code></pre>
<h2 id="complete-workflow-example"><a class="header" href="#complete-workflow-example">Complete Workflow Example</a></h2>
<p>Let‚Äôs walk through a complete example from start to finish:</p>
<h3 id="1-create-project-from-blueprint"><a class="header" href="#1-create-project-from-blueprint">1. Create Project from Blueprint</a></h3>
<pre><code class="language-bash">mockforge init my-saas-app --blueprint b2c-saas
cd my-saas-app
</code></pre>
<h3 id="2-start-mock-server"><a class="header" href="#2-start-mock-server">2. Start Mock Server</a></h3>
<pre><code class="language-bash">mockforge serve
</code></pre>
<p>The server starts on <code>http://localhost:3000</code> with:</p>
<ul>
<li>Authentication endpoints (<code>/api/auth/*</code>)</li>
<li>User management (<code>/api/users/*</code>)</li>
<li>Subscription management (<code>/api/subscriptions/*</code>)</li>
<li>Billing endpoints (<code>/api/billing/*</code>)</li>
</ul>
<h3 id="3-set-up-frontend"><a class="header" href="#3-set-up-frontend">3. Set Up Frontend</a></h3>
<p>In a separate terminal, navigate to your React app:</p>
<pre><code class="language-bash">cd ../my-react-app
mockforge dev-setup react
</code></pre>
<p>This generates:</p>
<ul>
<li><code>src/mockforge/client.ts</code> - Typed API client</li>
<li><code>src/mockforge/hooks.ts</code> - React Query hooks</li>
<li><code>src/components/MockForgeExample.tsx</code> - Example component</li>
</ul>
<h3 id="4-configure-environment"><a class="header" href="#4-configure-environment">4. Configure Environment</a></h3>
<pre><code class="language-bash">cp .env.mockforge.example .env.local
</code></pre>
<p>Edit <code>.env.local</code>:</p>
<pre><code class="language-env">NEXT_PUBLIC_MOCKFORGE_URL=http://localhost:3000
MOCKFORGE_REALITY_LEVEL=moderate
</code></pre>
<h3 id="5-use-in-your-app"><a class="header" href="#5-use-in-your-app">5. Use in Your App</a></h3>
<pre><code class="language-tsx">// app/users/page.tsx
import { useGetUsers } from '@/mockforge/hooks';

export default function UsersPage() {
  const { data: users, isLoading } = useGetUsers();

  if (isLoading) return &lt;div&gt;Loading...&lt;/div&gt;;

  return (
    &lt;div&gt;
      &lt;h1&gt;Users&lt;/h1&gt;
      &lt;ul&gt;
        {users?.map(user =&gt; (
          &lt;li key={user.id}&gt;
            {user.name} ({user.email})
          &lt;/li&gt;
        ))}
      &lt;/ul&gt;
    &lt;/div&gt;
  );
}
</code></pre>
<h3 id="6-test-the-integration"><a class="header" href="#6-test-the-integration">6. Test the Integration</a></h3>
<pre><code class="language-bash"># Start your frontend app
npm run dev

# Visit http://localhost:3001 (or your app's port)
# You should see users loaded from the mock API!
</code></pre>
<h2 id="advanced-features"><a class="header" href="#advanced-features">Advanced Features</a></h2>
<h3 id="using-personas"><a class="header" href="#using-personas">Using Personas</a></h3>
<p>Blueprints include personas for consistent data. Use them in your tests:</p>
<pre><code class="language-typescript">// In your test or component
import { usePersona } from '@/mockforge/hooks';

// Use a specific persona
const { data: user } = useGetUser({ persona: 'premium-user' });
</code></pre>
<h3 id="using-scenarios"><a class="header" href="#using-scenarios">Using Scenarios</a></h3>
<p>Test different scenarios (happy path, failures, slow paths):</p>
<pre><code class="language-typescript">// Activate a scenario
await activateScenario('happy-path-signup');

// Make API calls - they'll follow the scenario
const response = await signup({ email: 'test@example.com' });
</code></pre>
<h3 id="config-validation"><a class="header" href="#config-validation">Config Validation</a></h3>
<p>The VS Code extension provides real-time validation:</p>
<ol>
<li>Open <code>mockforge.yaml</code> in VS Code</li>
<li>See inline errors for invalid configuration</li>
<li>Get autocomplete for all options</li>
</ol>
<h3 id="playground-integration"><a class="header" href="#playground-integration">Playground Integration</a></h3>
<p>Test endpoints interactively:</p>
<ol>
<li>Hover over an endpoint reference in your code</li>
<li>Click ‚ÄúOpen in Playground‚Äù</li>
<li>Test the endpoint with different parameters</li>
</ol>
<h2 id="troubleshooting-6"><a class="header" href="#troubleshooting-6">Troubleshooting</a></h2>
<h3 id="dev-setup-cant-find-openapi-spec"><a class="header" href="#dev-setup-cant-find-openapi-spec">Dev-Setup Can‚Äôt Find OpenAPI Spec</a></h3>
<p>If dev-setup can‚Äôt auto-detect your OpenAPI spec:</p>
<pre><code class="language-bash"># Specify it explicitly
mockforge dev-setup react --spec ./openapi.yaml
</code></pre>
<h3 id="mock-server-not-running"><a class="header" href="#mock-server-not-running">Mock Server Not Running</a></h3>
<p>Make sure the mock server is running:</p>
<pre><code class="language-bash"># In your blueprint project
mockforge serve
</code></pre>
<h3 id="type-errors-in-generated-client"><a class="header" href="#type-errors-in-generated-client">Type Errors in Generated Client</a></h3>
<p>Regenerate the client:</p>
<pre><code class="language-bash">mockforge dev-setup react --force
</code></pre>
<h3 id="port-conflicts-1"><a class="header" href="#port-conflicts-1">Port Conflicts</a></h3>
<p>If port 3000 is in use:</p>
<pre><code class="language-bash"># Change the port in mockforge.yaml
base_url: http://localhost:3001

# Or use environment variable
MOCKFORGE_PORT=3001 mockforge serve
</code></pre>
<h2 id="next-steps-5"><a class="header" href="#next-steps-5">Next Steps</a></h2>
<p>Now that you‚Äôve completed the Golden Path:</p>
<ol>
<li><strong>Explore Personas</strong>: Use different personas for varied test data</li>
<li><strong>Customize Reality</strong>: Adjust the reality slider for different test scenarios</li>
<li><strong>Add Scenarios</strong>: Create custom scenarios for your workflows</li>
<li><strong>Extend Contracts</strong>: Add more JSON Schema contracts for validation</li>
<li><strong>Create Custom Blueprints</strong>: Build your own blueprints for your team</li>
</ol>
<h2 id="related-documentation"><a class="header" href="#related-documentation">Related Documentation</a></h2>
<ul>
<li><a href="tutorials/../user-guide/blueprints.html">Blueprints Guide</a> - Learn more about blueprints</li>
<li><a href="tutorials/../api/cli.html#dev-setup">Dev-Setup Reference</a> - Complete CLI reference</li>
<li><a href="tutorials/./react-workflow.html">React Workflow Tutorial</a> - Detailed React integration</li>
<li><a href="tutorials/./vue-workflow.html">Vue Workflow Tutorial</a> - Detailed Vue integration</li>
<li><a href="tutorials/../user-guide/ide-integration.html">IDE Integration</a> - VS Code extension features</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="mock-a-rest-api-from-an-openapi-spec-1"><a class="header" href="#mock-a-rest-api-from-an-openapi-spec-1">Mock a REST API from an OpenAPI Spec</a></h1>
<p><strong>Goal</strong>: You have an OpenAPI specification (Swagger file) and want to automatically generate mock endpoints for frontend development.</p>
<p><strong>Time</strong>: 3 minutes</p>
<h2 id="what-youll-learn"><a class="header" href="#what-youll-learn">What You‚Äôll Learn</a></h2>
<ul>
<li>Load an OpenAPI/Swagger spec into MockForge</li>
<li>Auto-generate mock responses from schema definitions</li>
<li>Enable dynamic data with template expansion</li>
<li>Test your mocked API</li>
</ul>
<h2 id="prerequisites-3"><a class="header" href="#prerequisites-3">Prerequisites</a></h2>
<ul>
<li>MockForge installed (<a href="tutorials/../getting-started/installation.html">Installation Guide</a>)</li>
<li>An OpenAPI 3.0 or Swagger 2.0 spec file (JSON or YAML)</li>
</ul>
<h2 id="step-1-prepare-your-openapi-spec"><a class="header" href="#step-1-prepare-your-openapi-spec">Step 1: Prepare Your OpenAPI Spec</a></h2>
<p>Use your existing spec, or create a simple one for testing:</p>
<p><strong><code>petstore-api.json</code>:</strong></p>
<pre><code class="language-json">{
  "openapi": "3.0.0",
  "info": {
    "title": "Pet Store API",
    "version": "1.0.0"
  },
  "paths": {
    "/pets": {
      "get": {
        "summary": "List all pets",
        "responses": {
          "200": {
            "description": "Successful response",
            "content": {
              "application/json": {
                "schema": {
                  "type": "array",
                  "items": {
                    "$ref": "#/components/schemas/Pet"
                  }
                }
              }
            }
          }
        }
      },
      "post": {
        "summary": "Create a pet",
        "requestBody": {
          "required": true,
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/Pet"
              }
            }
          }
        },
        "responses": {
          "201": {
            "description": "Pet created",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Pet"
                }
              }
            }
          }
        }
      }
    },
    "/pets/{petId}": {
      "get": {
        "summary": "Get a pet by ID",
        "parameters": [
          {
            "name": "petId",
            "in": "path",
            "required": true,
            "schema": {
              "type": "string"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "Successful response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Pet"
                }
              }
            }
          }
        }
      }
    }
  },
  "components": {
    "schemas": {
      "Pet": {
        "type": "object",
        "required": ["id", "name"],
        "properties": {
          "id": {
            "type": "string",
            "example": "{{uuid}}"
          },
          "name": {
            "type": "string",
            "example": "Fluffy"
          },
          "species": {
            "type": "string",
            "example": "cat"
          },
          "age": {
            "type": "integer",
            "example": 3
          }
        }
      }
    }
  }
}
</code></pre>
<h2 id="step-2-start-mockforge-with-your-spec-1"><a class="header" href="#step-2-start-mockforge-with-your-spec-1">Step 2: Start MockForge with Your Spec</a></h2>
<pre><code class="language-bash">mockforge serve --spec petstore-api.json --http-port 3000
</code></pre>
<p><strong>What happened?</strong> MockForge:</p>
<ul>
<li>Parsed your OpenAPI spec</li>
<li>Created mock endpoints for all defined paths</li>
<li>Generated example responses from schemas</li>
</ul>
<h2 id="step-3-test-the-auto-generated-endpoints"><a class="header" href="#step-3-test-the-auto-generated-endpoints">Step 3: Test the Auto-Generated Endpoints</a></h2>
<pre><code class="language-bash"># List all pets
curl http://localhost:3000/pets

# Create a pet
curl -X POST http://localhost:3000/pets \
  -H "Content-Type: application/json" \
  -d '{"name": "Rex", "species": "dog", "age": 5}'

# Get a specific pet
curl http://localhost:3000/pets/123
</code></pre>
<h2 id="step-4-enable-dynamic-template-expansion"><a class="header" href="#step-4-enable-dynamic-template-expansion">Step 4: Enable Dynamic Template Expansion</a></h2>
<p>To get unique IDs and dynamic data on each request:</p>
<pre><code class="language-bash"># Stop the server (Ctrl+C), then restart with templates enabled:
MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true \
mockforge serve --spec petstore-api.json --http-port 3000
</code></pre>
<p>Now test again - the <code>{{uuid}}</code> in your schema examples will generate unique IDs!</p>
<h2 id="step-5-add-request-validation"><a class="header" href="#step-5-add-request-validation">Step 5: Add Request Validation</a></h2>
<p>MockForge can validate requests against your OpenAPI schema:</p>
<pre><code class="language-bash">MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true \
MOCKFORGE_REQUEST_VALIDATION=enforce \
mockforge serve --spec petstore-api.json --http-port 3000
</code></pre>
<p>Try sending an invalid request:</p>
<pre><code class="language-bash"># This will fail validation (missing required 'name' field)
curl -X POST http://localhost:3000/pets \
  -H "Content-Type: application/json" \
  -d '{"species": "dog"}'
</code></pre>
<p>Response:</p>
<pre><code class="language-json">{
  "error": "request validation failed",
  "details": [
    {
      "path": "body.name",
      "code": "required",
      "message": "Missing required field: name"
    }
  ]
}
</code></pre>
<h2 id="step-6-use-a-configuration-file-optional"><a class="header" href="#step-6-use-a-configuration-file-optional">Step 6: Use a Configuration File (Optional)</a></h2>
<p>For more control, create a config file:</p>
<p><strong><code>petstore-config.yaml</code>:</strong></p>
<pre><code class="language-yaml">server:
  http_port: 3000

spec: petstore-api.json

validation:
  mode: enforce

response:
  template_expand: true

admin:
  enabled: true
  port: 9080
</code></pre>
<p>Start with config:</p>
<pre><code class="language-bash">mockforge serve --config petstore-config.yaml
</code></pre>
<h2 id="advanced-override-specific-responses"><a class="header" href="#advanced-override-specific-responses">Advanced: Override Specific Responses</a></h2>
<p>You can override auto-generated responses for specific endpoints:</p>
<p><strong><code>petstore-config.yaml</code>:</strong></p>
<pre><code class="language-yaml">http:
  port: 3000
  openapi_spec: petstore-api.json
  response_template_expand: true

  # Override the GET /pets endpoint
  routes:
    - path: /pets
      method: GET
      response:
        status: 200
        body: |
          [
            {
              "id": "{{uuid}}",
              "name": "{{faker.name}}",
              "species": "cat",
              "age": {{randInt 1 15}}
            },
            {
              "id": "{{uuid}}",
              "name": "{{faker.name}}",
              "species": "dog",
              "age": {{randInt 1 15}}
            }
          ]
</code></pre>
<h2 id="step-7-configure-request-validation"><a class="header" href="#step-7-configure-request-validation">Step 7: Configure Request Validation</a></h2>
<p>MockForge supports comprehensive OpenAPI request validation. Update your config to enable validation:</p>
<pre><code class="language-yaml">validation:
  mode: enforce          # Reject invalid requests
  aggregate_errors: true # Combine multiple validation errors
  status_code: 422       # Use 422 for validation errors

# Optional: Skip validation for specific routes
validation:
  overrides:
    "GET /health": "off"  # Health checks don't need validation
</code></pre>
<p>Test validation by sending an invalid request:</p>
<pre><code class="language-bash"># This will fail validation (missing required fields)
curl -X POST http://localhost:3000/pets \
  -H "Content-Type: application/json" \
  -d '{"species": "dog"}'
</code></pre>
<p>Response:</p>
<pre><code class="language-json">{
  "error": "request validation failed",
  "status": 422,
  "details": [
    {
      "path": "body.name",
      "code": "required",
      "message": "Missing required field: name"
    }
  ]
}
</code></pre>
<h3 id="validation-modes"><a class="header" href="#validation-modes">Validation Modes</a></h3>
<ul>
<li><strong><code>off</code></strong>: Disable validation completely</li>
<li><strong><code>warn</code></strong>: Log warnings but allow invalid requests</li>
<li><strong><code>enforce</code></strong>: Reject invalid requests with error responses</li>
</ul>
<h2 id="common-use-cases-1"><a class="header" href="#common-use-cases-1">Common Use Cases</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Use Case</th><th>Configuration</th></tr></thead><tbody>
<tr><td><strong>Frontend development</strong></td><td>Enable CORS, template expansion</td></tr>
<tr><td><strong>API contract testing</strong></td><td>Enable request validation (enforce mode)</td></tr>
<tr><td><strong>Demo environments</strong></td><td>Use faker functions for realistic data</td></tr>
<tr><td><strong>Integration tests</strong></td><td>Disable template expansion for deterministic responses</td></tr>
</tbody></table>
</div>
<h2 id="troubleshooting-7"><a class="header" href="#troubleshooting-7">Troubleshooting</a></h2>
<p><strong>Spec not loading?</strong></p>
<ul>
<li>Verify the file path is correct</li>
<li>Check that the spec is valid OpenAPI 3.0 or Swagger 2.0</li>
<li>Use a validator like <a href="https://editor.swagger.io/">Swagger Editor</a></li>
</ul>
<p><strong>Validation too strict?</strong></p>
<pre><code class="language-bash"># Use 'warn' mode instead of 'enforce'
MOCKFORGE_REQUEST_VALIDATION=warn mockforge serve --spec petstore-api.json
</code></pre>
<p><strong>Need custom responses?</strong></p>
<ul>
<li>Add route overrides in your config file (see Advanced section above)</li>
<li>Or use <a href="tutorials/../user-guide/http-mocking/custom-responses.html">Custom Responses Guide</a></li>
</ul>
<h2 id="complete-workflow-example-1"><a class="header" href="#complete-workflow-example-1">Complete Workflow Example</a></h2>
<p>Here‚Äôs a complete workflow for generating mocks from an OpenAPI spec and using them in development:</p>
<h3 id="1-start-with-openapi-spec"><a class="header" href="#1-start-with-openapi-spec">1. Start with OpenAPI Spec</a></h3>
<pre><code class="language-bash"># Your API team provides this spec
cat petstore-api.json
</code></pre>
<h3 id="2-generate-mock-server"><a class="header" href="#2-generate-mock-server">2. Generate Mock Server</a></h3>
<pre><code class="language-bash"># Start MockForge with the spec
MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true \
  mockforge serve --spec petstore-api.json --http-port 3000 --admin
</code></pre>
<h3 id="3-test-generated-endpoints"><a class="header" href="#3-test-generated-endpoints">3. Test Generated Endpoints</a></h3>
<pre><code class="language-bash"># All endpoints from the spec are now available
curl http://localhost:3000/pets
curl http://localhost:3000/pets/123
curl -X POST http://localhost:3000/pets -d '{"name": "Fluffy", "species": "cat"}'
</code></pre>
<h3 id="4-monitor-in-admin-ui"><a class="header" href="#4-monitor-in-admin-ui">4. Monitor in Admin UI</a></h3>
<p>Visit http://localhost:9080 to see:</p>
<ul>
<li>All requests in real-time</li>
<li>Request/response bodies</li>
<li>Response times</li>
<li>Error rates</li>
</ul>
<h3 id="5-use-in-frontend-development"><a class="header" href="#5-use-in-frontend-development">5. Use in Frontend Development</a></h3>
<p>Point your frontend app to the mock server:</p>
<pre><code class="language-javascript">// In your React/Vue/Angular app
const API_URL = 'http://localhost:3000';

fetch(`${API_URL}/pets`)
  .then(res =&gt; res.json())
  .then(data =&gt; console.log('Pets:', data));
</code></pre>
<h3 id="6-iterate-as-api-evolves"><a class="header" href="#6-iterate-as-api-evolves">6. Iterate as API Evolves</a></h3>
<p>When the API spec changes:</p>
<pre><code class="language-bash"># 1. Update the OpenAPI spec file
vim petstore-api.json

# 2. Restart MockForge (it auto-reloads from spec)
# Or use watch mode if available

# 3. Regenerate client code (if using code generation)
mockforge client generate --spec petstore-api.json --framework react
</code></pre>
<h2 id="best-practices"><a class="header" href="#best-practices">Best Practices</a></h2>
<h3 id="organization"><a class="header" href="#organization">Organization</a></h3>
<ol>
<li>
<p><strong>Keep specs in version control</strong></p>
<pre><code class="language-bash">git add petstore-api.json
git commit -m "Add Pet Store API spec v1.2"
</code></pre>
</li>
<li>
<p><strong>Use environment-specific configs</strong></p>
<pre><code class="language-yaml"># mockforge.dev.yaml
http:
  port: 3000
  response_template_expand: true
  cors:
    enabled: true
</code></pre>
</li>
<li>
<p><strong>Document any custom overrides</strong></p>
<pre><code class="language-yaml"># Custom route overrides
http:
  routes:
    - path: /pets/{petId}
      method: GET
      response:
        # Override default response
        status: 200
        body: |
          {
            "id": "{{request.path.petId}}",
            "name": "Custom Pet",
            "species": "custom"
          }
</code></pre>
</li>
</ol>
<h3 id="testing"><a class="header" href="#testing">Testing</a></h3>
<ol>
<li>
<p><strong>Use deterministic data for tests</strong></p>
<pre><code class="language-yaml"># Disable template expansion for consistent test data
response:
  template_expand: false
</code></pre>
</li>
<li>
<p><strong>Enable validation for contract testing</strong></p>
<pre><code class="language-bash">mockforge serve --spec api.json --validation enforce
</code></pre>
</li>
<li>
<p><strong>Record test scenarios</strong></p>
<ul>
<li>Use Admin UI to record request/response pairs</li>
<li>Export as fixtures for automated tests</li>
</ul>
</li>
</ol>
<h2 id="whats-next-2"><a class="header" href="#whats-next-2">What‚Äôs Next?</a></h2>
<ul>
<li><a href="tutorials/../user-guide/http-mocking/dynamic-data.html">Dynamic Data Generation</a> - Add faker functions and advanced templates</li>
<li><a href="tutorials/react-workflow.html">React Workflow</a> - Complete React + MockForge setup</li>
<li><a href="tutorials/vue-workflow.html">Vue Workflow</a> - Complete Vue + MockForge setup</li>
<li><a href="tutorials/admin-ui-walkthrough.html">Admin UI Walkthrough</a> - Visualize and manage your mock server</li>
<li><a href="tutorials/add-custom-plugin.html">Add a Custom Plugin</a> - Extend MockForge with custom functionality</li>
<li><a href="tutorials/../user-guide/sync.html">Team Collaboration</a> - Share mocks with your team via Git</li>
</ul>
<hr />
<p><strong>Pro Tip</strong>: Keep your OpenAPI spec in version control alongside your mock configuration. As the real API evolves, update the spec and your frontend automatically benefits from the changes.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="react--mockforge-workflow"><a class="header" href="#react--mockforge-workflow">React + MockForge Workflow</a></h1>
<p><strong>Goal</strong>: Build a React application that uses MockForge as a backend mock server for development and testing.</p>
<p><strong>Time</strong>: 10-15 minutes</p>
<h2 id="overview-2"><a class="header" href="#overview-2">Overview</a></h2>
<p>This tutorial shows you how to:</p>
<ol>
<li>Set up MockForge with an OpenAPI specification</li>
<li>Generate TypeScript client code for React</li>
<li>Build a React app that consumes the mock API</li>
<li>Develop and test frontend features against mock data</li>
</ol>
<h2 id="prerequisites-4"><a class="header" href="#prerequisites-4">Prerequisites</a></h2>
<ul>
<li>MockForge installed (<a href="tutorials/../getting-started/installation.html">Installation Guide</a>)</li>
<li>Node.js 16+ and npm/pnpm installed</li>
<li>Basic React and TypeScript knowledge</li>
</ul>
<h2 id="step-1-prepare-your-openapi-specification"><a class="header" href="#step-1-prepare-your-openapi-specification">Step 1: Prepare Your OpenAPI Specification</a></h2>
<p>Create or use an existing OpenAPI spec. For this tutorial, we‚Äôll use a User Management API:</p>
<p><strong><code>user-management-api.json</code>:</strong></p>
<pre><code class="language-json">{
  "openapi": "3.0.3",
  "info": {
    "title": "User Management API",
    "version": "1.0.0"
  },
  "paths": {
    "/users": {
      "get": {
        "summary": "List all users",
        "responses": {
          "200": {
            "description": "List of users",
            "content": {
              "application/json": {
                "schema": {
                  "type": "array",
                  "items": {
                    "$ref": "#/components/schemas/User"
                  }
                }
              }
            }
          }
        }
      },
      "post": {
        "summary": "Create a user",
        "requestBody": {
          "required": true,
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/UserInput"
              }
            }
          }
        },
        "responses": {
          "201": {
            "description": "User created",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/User"
                }
              }
            }
          }
        }
      }
    },
    "/users/{id}": {
      "get": {
        "summary": "Get user by ID",
        "parameters": [
          {
            "name": "id",
            "in": "path",
            "required": true,
            "schema": {
              "type": "string"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "User details",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/User"
                }
              }
            }
          }
        }
      }
    }
  },
  "components": {
    "schemas": {
      "User": {
        "type": "object",
        "required": ["id", "name", "email"],
        "properties": {
          "id": {
            "type": "string",
            "example": "{{uuid}}"
          },
          "name": {
            "type": "string",
            "example": "John Doe"
          },
          "email": {
            "type": "string",
            "format": "email",
            "example": "john@example.com"
          },
          "createdAt": {
            "type": "string",
            "format": "date-time",
            "example": "{{now}}"
          }
        }
      },
      "UserInput": {
        "type": "object",
        "required": ["name", "email"],
        "properties": {
          "name": {
            "type": "string"
          },
          "email": {
            "type": "string",
            "format": "email"
          }
        }
      }
    }
  }
}
</code></pre>
<h2 id="step-2-start-mockforge-server"><a class="header" href="#step-2-start-mockforge-server">Step 2: Start MockForge Server</a></h2>
<p>Start the mock server with your OpenAPI spec:</p>
<pre><code class="language-bash"># Terminal 1: Start MockForge
MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true \
  mockforge serve --spec user-management-api.json --http-port 3000 --admin
</code></pre>
<p>You should see:</p>
<pre><code>üöÄ MockForge v1.0.0 starting...
üì° HTTP server listening on 0.0.0.0:3000
‚úÖ Ready to serve requests at http://localhost:3000
</code></pre>
<p><strong>Tip</strong>: Keep this terminal running. The <code>--admin</code> flag enables the admin UI at http://localhost:9080 for monitoring requests.</p>
<h2 id="step-3-create-react-application"><a class="header" href="#step-3-create-react-application">Step 3: Create React Application</a></h2>
<p>Create a new React app (or use an existing one):</p>
<pre><code class="language-bash"># Create React app with TypeScript
npx create-react-app my-app --template typescript
cd my-app
</code></pre>
<h2 id="step-4-generate-typescript-client-optional"><a class="header" href="#step-4-generate-typescript-client-optional">Step 4: Generate TypeScript Client (Optional)</a></h2>
<p>MockForge can generate type-safe React hooks from your OpenAPI spec:</p>
<pre><code class="language-bash"># Install MockForge CLI as dev dependency
npm install --save-dev mockforge-cli

# Add to package.json scripts
</code></pre>
<p>Update <code>package.json</code>:</p>
<pre><code class="language-json">{
  "scripts": {
    "generate-client": "mockforge client generate --spec ../user-management-api.json --framework react --output ./src/generated",
    "start": "react-scripts start",
    "build": "react-scripts build"
  }
}
</code></pre>
<p>Generate the client:</p>
<pre><code class="language-bash">npm run generate-client
</code></pre>
<p>This creates:</p>
<ul>
<li><code>src/generated/types.ts</code> - TypeScript type definitions</li>
<li><code>src/generated/hooks.ts</code> - React hooks for API calls</li>
</ul>
<h2 id="step-5-configure-react-app"><a class="header" href="#step-5-configure-react-app">Step 5: Configure React App</a></h2>
<h3 id="option-a-using-generated-hooks"><a class="header" href="#option-a-using-generated-hooks">Option A: Using Generated Hooks</a></h3>
<p>If you generated the client, use the hooks:</p>
<p><strong><code>src/App.tsx</code>:</strong></p>
<pre><code class="language-typescript">import React, { useState } from 'react';
import { useGetUsers, useCreateUser } from './generated/hooks';
import type { UserInput } from './generated/types';

function App() {
  const { data: users, loading, error, refetch } = useGetUsers();
  const { execute: createUser, loading: creating } = useCreateUser();
  
  const [formData, setFormData] = useState&lt;UserInput&gt;({
    name: '',
    email: ''
  });

  const handleSubmit = async (e: React.FormEvent) =&gt; {
    e.preventDefault();
    try {
      await createUser(formData);
      setFormData({ name: '', email: '' });
      refetch(); // Refresh user list
    } catch (error) {
      console.error('Failed to create user:', error);
    }
  };

  if (loading) return &lt;div&gt;Loading users...&lt;/div&gt;;
  if (error) return &lt;div&gt;Error: {error.message}&lt;/div&gt;;

  return (
    &lt;div className="App"&gt;
      &lt;h1&gt;User Management&lt;/h1&gt;
      
      &lt;form onSubmit={handleSubmit}&gt;
        &lt;input
          type="text"
          placeholder="Name"
          value={formData.name}
          onChange={(e) =&gt; setFormData({ ...formData, name: e.target.value })}
        /&gt;
        &lt;input
          type="email"
          placeholder="Email"
          value={formData.email}
          onChange={(e) =&gt; setFormData({ ...formData, email: e.target.value })}
        /&gt;
        &lt;button type="submit" disabled={creating}&gt;
          {creating ? 'Creating...' : 'Create User'}
        &lt;/button&gt;
      &lt;/form&gt;

      &lt;ul&gt;
        {users?.map(user =&gt; (
          &lt;li key={user.id}&gt;
            &lt;strong&gt;{user.name}&lt;/strong&gt; - {user.email}
          &lt;/li&gt;
        ))}
      &lt;/ul&gt;
    &lt;/div&gt;
  );
}

export default App;
</code></pre>
<h3 id="option-b-manual-fetch-implementation"><a class="header" href="#option-b-manual-fetch-implementation">Option B: Manual Fetch Implementation</a></h3>
<p>If you prefer manual implementation:</p>
<p><strong><code>src/App.tsx</code>:</strong></p>
<pre><code class="language-typescript">import React, { useState, useEffect } from 'react';

interface User {
  id: string;
  name: string;
  email: string;
  createdAt: string;
}

function App() {
  const [users, setUsers] = useState&lt;User[]&gt;([]);
  const [loading, setLoading] = useState(true);
  const [formData, setFormData] = useState({ name: '', email: '' });

  useEffect(() =&gt; {
    fetch('http://localhost:3000/users')
      .then(res =&gt; res.json())
      .then(data =&gt; {
        setUsers(data);
        setLoading(false);
      })
      .catch(err =&gt; {
        console.error('Error fetching users:', err);
        setLoading(false);
      });
  }, []);

  const handleSubmit = async (e: React.FormEvent) =&gt; {
    e.preventDefault();
    try {
      const res = await fetch('http://localhost:3000/users', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(formData)
      });
      const newUser = await res.json();
      setUsers([...users, newUser]);
      setFormData({ name: '', email: '' });
    } catch (error) {
      console.error('Failed to create user:', error);
    }
  };

  if (loading) return &lt;div&gt;Loading...&lt;/div&gt;;

  return (
    &lt;div className="App"&gt;
      &lt;h1&gt;User Management&lt;/h1&gt;
      
      &lt;form onSubmit={handleSubmit}&gt;
        &lt;input
          type="text"
          placeholder="Name"
          value={formData.name}
          onChange={(e) =&gt; setFormData({ ...formData, name: e.target.value })}
        /&gt;
        &lt;input
          type="email"
          placeholder="Email"
          value={formData.email}
          onChange={(e) =&gt; setFormData({ ...formData, email: e.target.value })}
        /&gt;
        &lt;button type="submit"&gt;Create User&lt;/button&gt;
      &lt;/form&gt;

      &lt;ul&gt;
        {users.map(user =&gt; (
          &lt;li key={user.id}&gt;
            &lt;strong&gt;{user.name}&lt;/strong&gt; - {user.email}
          &lt;/li&gt;
        ))}
      &lt;/ul&gt;
    &lt;/div&gt;
  );
}

export default App;
</code></pre>
<h2 id="step-6-configure-api-base-url"><a class="header" href="#step-6-configure-api-base-url">Step 6: Configure API Base URL</a></h2>
<p>Set the API URL as an environment variable:</p>
<p><strong><code>.env.development</code>:</strong></p>
<pre><code>REACT_APP_API_URL=http://localhost:3000
</code></pre>
<p><strong><code>.env.production</code>:</strong></p>
<pre><code>REACT_APP_API_URL=https://api.yourdomain.com
</code></pre>
<p>Update your fetch calls to use the environment variable:</p>
<pre><code class="language-typescript">const API_URL = process.env.REACT_APP_API_URL || 'http://localhost:3000';

fetch(`${API_URL}/users`)
</code></pre>
<h2 id="step-7-start-react-app"><a class="header" href="#step-7-start-react-app">Step 7: Start React App</a></h2>
<pre><code class="language-bash"># Terminal 2: Start React app
npm start
</code></pre>
<p>Your React app will be available at http://localhost:3001 (or 3000 if available).</p>
<h2 id="step-8-test-the-integration"><a class="header" href="#step-8-test-the-integration">Step 8: Test the Integration</a></h2>
<ol>
<li><strong>Create a user</strong>: Fill out the form and submit</li>
<li><strong>View users</strong>: See the list update with new users</li>
<li><strong>Monitor requests</strong>: Open http://localhost:9080 (Admin UI) to see all requests</li>
</ol>
<h2 id="development-workflow"><a class="header" href="#development-workflow">Development Workflow</a></h2>
<h3 id="typical-development-cycle"><a class="header" href="#typical-development-cycle">Typical Development Cycle</a></h3>
<ol>
<li><strong>Start MockForge</strong> with your API spec</li>
<li><strong>Develop React features</strong> against mock data</li>
<li><strong>View requests</strong> in Admin UI for debugging</li>
<li><strong>Update spec</strong> as API evolves</li>
<li><strong>Regenerate client</strong> when spec changes</li>
</ol>
<h3 id="updating-api-spec"><a class="header" href="#updating-api-spec">Updating API Spec</a></h3>
<p>When the OpenAPI spec changes:</p>
<pre><code class="language-bash"># Regenerate TypeScript client
npm run generate-client

# Restart MockForge with updated spec
# (Ctrl+C in Terminal 1, then restart)
mockforge serve --spec user-management-api.json --http-port 3000 --admin
</code></pre>
<h3 id="testing-1"><a class="header" href="#testing-1">Testing</a></h3>
<p>Run tests against the mock server:</p>
<pre><code class="language-bash"># Start mock server in background
mockforge serve --spec user-management-api.json --http-port 3000 &amp;
MOCKFORGE_PID=$!

# Run tests
npm test

# Stop mock server
kill $MOCKFORGE_PID
</code></pre>
<h2 id="common-issues"><a class="header" href="#common-issues">Common Issues</a></h2>
<h3 id="cors-errors"><a class="header" href="#cors-errors">CORS Errors</a></h3>
<p>If you see CORS errors, enable CORS in MockForge config:</p>
<pre><code class="language-yaml"># mockforge.yaml
http:
  port: 3000
  cors:
    enabled: true
    allowed_origins: ["http://localhost:3000", "http://localhost:3001"]
</code></pre>
<h3 id="template-variables-not-expanding"><a class="header" href="#template-variables-not-expanding">Template Variables Not Expanding</a></h3>
<p>Make sure template expansion is enabled:</p>
<pre><code class="language-bash">MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true mockforge serve ...
</code></pre>
<h3 id="client-generation-fails"><a class="header" href="#client-generation-fails">Client Generation Fails</a></h3>
<ul>
<li>Ensure MockForge CLI is in PATH</li>
<li>Check OpenAPI spec is valid JSON/YAML</li>
<li>Verify framework name is correct (<code>react</code>, not <code>reactjs</code>)</li>
</ul>
<h2 id="advanced-usage"><a class="header" href="#advanced-usage">Advanced Usage</a></h2>
<h3 id="custom-hooks"><a class="header" href="#custom-hooks">Custom Hooks</a></h3>
<p>Wrap generated hooks with custom logic:</p>
<pre><code class="language-typescript">import { useGetUsers as useGetUsersBase } from './generated/hooks';

export function useGetUsers() {
  const result = useGetUsersBase();
  
  // Add custom logic
  useEffect(() =&gt; {
    if (result.data) {
      console.log('Users loaded:', result.data.length);
    }
  }, [result.data]);
  
  return result;
}
</code></pre>
<h3 id="error-handling"><a class="header" href="#error-handling">Error Handling</a></h3>
<p>Implement global error handling:</p>
<pre><code class="language-typescript">import { useGetUsers, useCreateUser } from './generated/hooks';

function App() {
  const { data, error } = useGetUsers();
  
  if (error) {
    // Show user-friendly error message
    return &lt;ErrorDisplay error={error} /&gt;;
  }
  
  // ... rest of component
}
</code></pre>
<h3 id="request-interceptors"><a class="header" href="#request-interceptors">Request Interceptors</a></h3>
<p>Add authentication or custom headers:</p>
<pre><code class="language-typescript">// In generated/hooks.ts, modify the base configuration
const apiConfig = {
  baseUrl: 'http://localhost:3000',
  headers: {
    'Authorization': `Bearer ${getToken()}`,
  }
};
</code></pre>
<h2 id="next-steps-6"><a class="header" href="#next-steps-6">Next Steps</a></h2>
<ul>
<li><strong>View Complete Example</strong>: See <a href="tutorials/../../examples/react-demo/">React Demo</a> for a full implementation</li>
<li><strong>Learn Vue Workflow</strong>: <a href="tutorials/vue-workflow.html">Vue + MockForge Workflow</a></li>
<li><strong>Explore Admin UI</strong>: <a href="tutorials/admin-ui-walkthrough.html">Admin UI Walkthrough</a></li>
<li><strong>Advanced Features</strong>: <a href="tutorials/../user-guide/http-mocking/dynamic-data.html">Dynamic Data Generation</a></li>
</ul>
<hr />
<p><strong>Need help?</strong> Check the <a href="tutorials/../reference/faq.html">FAQ</a> or <a href="tutorials/../reference/troubleshooting.html">Troubleshooting Guide</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="vue--mockforge-workflow"><a class="header" href="#vue--mockforge-workflow">Vue + MockForge Workflow</a></h1>
<p><strong>Goal</strong>: Build a Vue 3 application that uses MockForge as a backend mock server for development and testing.</p>
<p><strong>Time</strong>: 10-15 minutes</p>
<h2 id="overview-3"><a class="header" href="#overview-3">Overview</a></h2>
<p>This tutorial shows you how to:</p>
<ol>
<li>Set up MockForge with an OpenAPI specification</li>
<li>Generate TypeScript client code for Vue 3</li>
<li>Build a Vue app that consumes the mock API using Pinia</li>
<li>Develop and test frontend features against mock data</li>
</ol>
<h2 id="prerequisites-5"><a class="header" href="#prerequisites-5">Prerequisites</a></h2>
<ul>
<li>MockForge installed (<a href="tutorials/../getting-started/installation.html">Installation Guide</a>)</li>
<li>Node.js 16+ and npm/pnpm installed</li>
<li>Basic Vue 3 and TypeScript knowledge</li>
</ul>
<h2 id="step-1-prepare-your-openapi-specification-1"><a class="header" href="#step-1-prepare-your-openapi-specification-1">Step 1: Prepare Your OpenAPI Specification</a></h2>
<p>Create or use an existing OpenAPI spec. We‚Äôll use the same User Management API from the React tutorial:</p>
<p><strong><code>user-management-api.json</code>:</strong></p>
<pre><code class="language-json">{
  "openapi": "3.0.3",
  "info": {
    "title": "User Management API",
    "version": "1.0.0"
  },
  "paths": {
    "/users": {
      "get": {
        "summary": "List all users",
        "responses": {
          "200": {
            "description": "List of users",
            "content": {
              "application/json": {
                "schema": {
                  "type": "array",
                  "items": {
                    "$ref": "#/components/schemas/User"
                  }
                }
              }
            }
          }
        }
      },
      "post": {
        "summary": "Create a user",
        "requestBody": {
          "required": true,
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/UserInput"
              }
            }
          }
        },
        "responses": {
          "201": {
            "description": "User created",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/User"
                }
              }
            }
          }
        }
      }
    },
    "/users/{id}": {
      "get": {
        "summary": "Get user by ID",
        "parameters": [
          {
            "name": "id",
            "in": "path",
            "required": true,
            "schema": {
              "type": "string"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "User details",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/User"
                }
              }
            }
          }
        }
      }
    }
  },
  "components": {
    "schemas": {
      "User": {
        "type": "object",
        "required": ["id", "name", "email"],
        "properties": {
          "id": {
            "type": "string",
            "example": "{{uuid}}"
          },
          "name": {
            "type": "string",
            "example": "John Doe"
          },
          "email": {
            "type": "string",
            "format": "email",
            "example": "john@example.com"
          },
          "createdAt": {
            "type": "string",
            "format": "date-time",
            "example": "{{now}}"
          }
        }
      },
      "UserInput": {
        "type": "object",
        "required": ["name", "email"],
        "properties": {
          "name": {
            "type": "string"
          },
          "email": {
            "type": "string",
            "format": "email"
          }
        }
      }
    }
  }
}
</code></pre>
<h2 id="step-2-start-mockforge-server-1"><a class="header" href="#step-2-start-mockforge-server-1">Step 2: Start MockForge Server</a></h2>
<p>Start the mock server with your OpenAPI spec:</p>
<pre><code class="language-bash"># Terminal 1: Start MockForge
MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true \
  mockforge serve --spec user-management-api.json --http-port 3000 --admin
</code></pre>
<p>You should see:</p>
<pre><code>üöÄ MockForge v1.0.0 starting...
üì° HTTP server listening on 0.0.0.0:3000
‚úÖ Ready to serve requests at http://localhost:3000
</code></pre>
<p><strong>Tip</strong>: Keep this terminal running. The <code>--admin</code> flag enables the admin UI at http://localhost:9080.</p>
<h2 id="step-3-create-vue-application"><a class="header" href="#step-3-create-vue-application">Step 3: Create Vue Application</a></h2>
<p>Create a new Vue 3 app with TypeScript:</p>
<pre><code class="language-bash"># Create Vue app with TypeScript
npm create vue@latest my-app
cd my-app

# Select TypeScript when prompted
# Install dependencies
npm install
</code></pre>
<h2 id="step-4-install-pinia-state-management"><a class="header" href="#step-4-install-pinia-state-management">Step 4: Install Pinia (State Management)</a></h2>
<pre><code class="language-bash">npm install pinia
</code></pre>
<p>Set up Pinia in <code>src/main.ts</code>:</p>
<pre><code class="language-typescript">import { createApp } from 'vue'
import { createPinia } from 'pinia'
import App from './App.vue'

const app = createApp(App)
app.use(createPinia())
app.mount('#app')
</code></pre>
<h2 id="step-5-generate-typescript-client-optional"><a class="header" href="#step-5-generate-typescript-client-optional">Step 5: Generate TypeScript Client (Optional)</a></h2>
<p>MockForge can generate type-safe Vue composables from your OpenAPI spec:</p>
<pre><code class="language-bash"># Install MockForge CLI as dev dependency
npm install --save-dev mockforge-cli

# Add to package.json scripts
</code></pre>
<p>Update <code>package.json</code>:</p>
<pre><code class="language-json">{
  "scripts": {
    "generate-client": "mockforge client generate --spec ../user-management-api.json --framework vue --output ./src/generated",
    "dev": "vite",
    "build": "vue-tsc &amp;&amp; vite build"
  }
}
</code></pre>
<p>Generate the client:</p>
<pre><code class="language-bash">npm run generate-client
</code></pre>
<p>This creates:</p>
<ul>
<li><code>src/generated/types.ts</code> - TypeScript type definitions</li>
<li><code>src/generated/composables.ts</code> - Vue composables for API calls</li>
<li><code>src/generated/store.ts</code> - Pinia store for state management</li>
</ul>
<h2 id="step-6-configure-vue-app"><a class="header" href="#step-6-configure-vue-app">Step 6: Configure Vue App</a></h2>
<h3 id="option-a-using-generated-composables"><a class="header" href="#option-a-using-generated-composables">Option A: Using Generated Composables</a></h3>
<p>If you generated the client, use the composables:</p>
<p><strong><code>src/App.vue</code>:</strong></p>
<pre><code class="language-vue">&lt;template&gt;
  &lt;div class="app"&gt;
    &lt;h1&gt;User Management&lt;/h1&gt;
    
    &lt;form @submit.prevent="handleSubmit"&gt;
      &lt;input
        v-model="formData.name"
        type="text"
        placeholder="Name"
        required
      /&gt;
      &lt;input
        v-model="formData.email"
        type="email"
        placeholder="Email"
        required
      /&gt;
      &lt;button type="submit" :disabled="creating"&gt;
        {{ creating ? 'Creating...' : 'Create User' }}
      &lt;/button&gt;
    &lt;/form&gt;

    &lt;div v-if="loading"&gt;Loading users...&lt;/div&gt;
    &lt;div v-else-if="error"&gt;Error: {{ error.message }}&lt;/div&gt;
    &lt;ul v-else&gt;
      &lt;li v-for="user in users" :key="user.id"&gt;
        &lt;strong&gt;{{ user.name }}&lt;/strong&gt; - {{ user.email }}
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/div&gt;
&lt;/template&gt;

&lt;script setup lang="ts"&gt;
import { ref } from 'vue';
import { useGetUsers, useCreateUser } from './generated/composables';
import type { UserInput } from './generated/types';

const { data: users, loading, error, refetch } = useGetUsers();
const { execute: createUser, loading: creating } = useCreateUser();

const formData = ref&lt;UserInput&gt;({
  name: '',
  email: ''
});

const handleSubmit = async () =&gt; {
  try {
    await createUser(formData.value);
    formData.value = { name: '', email: '' };
    refetch(); // Refresh user list
  } catch (error) {
    console.error('Failed to create user:', error);
  }
};
&lt;/script&gt;

&lt;style scoped&gt;
.app {
  max-width: 800px;
  margin: 0 auto;
  padding: 20px;
}

form {
  margin-bottom: 20px;
}

input {
  margin-right: 10px;
  padding: 8px;
}

button {
  padding: 8px 16px;
  cursor: pointer;
}

ul {
  list-style: none;
  padding: 0;
}

li {
  padding: 10px;
  margin: 5px 0;
  background: #f5f5f5;
  border-radius: 4px;
}
&lt;/style&gt;
</code></pre>
<h3 id="option-b-manual-implementation-with-pinia-store"><a class="header" href="#option-b-manual-implementation-with-pinia-store">Option B: Manual Implementation with Pinia Store</a></h3>
<p>Create a Pinia store for user management:</p>
<p><strong><code>src/stores/userStore.ts</code>:</strong></p>
<pre><code class="language-typescript">import { defineStore } from 'pinia';
import { ref, computed } from 'vue';

interface User {
  id: string;
  name: string;
  email: string;
  createdAt: string;
}

interface UserInput {
  name: string;
  email: string;
}

const API_URL = import.meta.env.VITE_API_URL || 'http://localhost:3000';

export const useUserStore = defineStore('users', () =&gt; {
  const users = ref&lt;User[]&gt;([]);
  const loading = ref(false);
  const error = ref&lt;Error | null&gt;(null);

  const userCount = computed(() =&gt; users.value.length);

  async function fetchUsers() {
    loading.value = true;
    error.value = null;
    try {
      const response = await fetch(`${API_URL}/users`);
      if (!response.ok) throw new Error('Failed to fetch users');
      users.value = await response.json();
    } catch (e) {
      error.value = e as Error;
      console.error('Error fetching users:', e);
    } finally {
      loading.value = false;
    }
  }

  async function createUser(input: UserInput) {
    loading.value = true;
    error.value = null;
    try {
      const response = await fetch(`${API_URL}/users`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(input)
      });
      if (!response.ok) throw new Error('Failed to create user');
      const newUser = await response.json();
      users.value.push(newUser);
    } catch (e) {
      error.value = e as Error;
      console.error('Error creating user:', e);
      throw e;
    } finally {
      loading.value = false;
    }
  }

  return {
    users,
    loading,
    error,
    userCount,
    fetchUsers,
    createUser
  };
});
</code></pre>
<p>Use the store in your component:</p>
<p><strong><code>src/App.vue</code>:</strong></p>
<pre><code class="language-vue">&lt;template&gt;
  &lt;div class="app"&gt;
    &lt;h1&gt;User Management&lt;/h1&gt;
    
    &lt;form @submit.prevent="handleSubmit"&gt;
      &lt;input
        v-model="formData.name"
        type="text"
        placeholder="Name"
        required
      /&gt;
      &lt;input
        v-model="formData.email"
        type="email"
        placeholder="Email"
        required
      /&gt;
      &lt;button type="submit" :disabled="userStore.loading"&gt;
        {{ userStore.loading ? 'Creating...' : 'Create User' }}
      &lt;/button&gt;
    &lt;/form&gt;

    &lt;div v-if="userStore.loading &amp;&amp; userStore.users.length === 0"&gt;
      Loading users...
    &lt;/div&gt;
    &lt;div v-else-if="userStore.error"&gt;
      Error: {{ userStore.error.message }}
    &lt;/div&gt;
    &lt;ul v-else&gt;
      &lt;li v-for="user in userStore.users" :key="user.id"&gt;
        &lt;strong&gt;{{ user.name }}&lt;/strong&gt; - {{ user.email }}
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/div&gt;
&lt;/template&gt;

&lt;script setup lang="ts"&gt;
import { ref, onMounted } from 'vue';
import { useUserStore } from './stores/userStore';

const userStore = useUserStore();
const formData = ref({ name: '', email: '' });

onMounted(() =&gt; {
  userStore.fetchUsers();
});

const handleSubmit = async () =&gt; {
  try {
    await userStore.createUser(formData.value);
    formData.value = { name: '', email: '' };
  } catch (error) {
    // Error already handled in store
  }
};
&lt;/script&gt;
</code></pre>
<h2 id="step-7-configure-api-base-url"><a class="header" href="#step-7-configure-api-base-url">Step 7: Configure API Base URL</a></h2>
<p>Set the API URL as an environment variable:</p>
<p><strong><code>.env.development</code>:</strong></p>
<pre><code>VITE_API_URL=http://localhost:3000
</code></pre>
<p><strong><code>.env.production</code>:</strong></p>
<pre><code>VITE_API_URL=https://api.yourdomain.com
</code></pre>
<h2 id="step-8-start-vue-app"><a class="header" href="#step-8-start-vue-app">Step 8: Start Vue App</a></h2>
<pre><code class="language-bash"># Terminal 2: Start Vue app
npm run dev
</code></pre>
<p>Your Vue app will be available at http://localhost:5173 (or next available port).</p>
<h2 id="step-9-test-the-integration"><a class="header" href="#step-9-test-the-integration">Step 9: Test the Integration</a></h2>
<ol>
<li><strong>Create a user</strong>: Fill out the form and submit</li>
<li><strong>View users</strong>: See the list update with new users</li>
<li><strong>Monitor requests</strong>: Open http://localhost:9080 (Admin UI) to see all requests</li>
</ol>
<h2 id="development-workflow-1"><a class="header" href="#development-workflow-1">Development Workflow</a></h2>
<h3 id="typical-development-cycle-1"><a class="header" href="#typical-development-cycle-1">Typical Development Cycle</a></h3>
<ol>
<li><strong>Start MockForge</strong> with your API spec</li>
<li><strong>Develop Vue features</strong> against mock data</li>
<li><strong>View requests</strong> in Admin UI for debugging</li>
<li><strong>Update spec</strong> as API evolves</li>
<li><strong>Regenerate client</strong> when spec changes</li>
</ol>
<h3 id="updating-api-spec-1"><a class="header" href="#updating-api-spec-1">Updating API Spec</a></h3>
<p>When the OpenAPI spec changes:</p>
<pre><code class="language-bash"># Regenerate TypeScript client
npm run generate-client

# Restart MockForge with updated spec
# (Ctrl+C in Terminal 1, then restart)
mockforge serve --spec user-management-api.json --http-port 3000 --admin
</code></pre>
<h3 id="testing-with-vitest"><a class="header" href="#testing-with-vitest">Testing with Vitest</a></h3>
<p>Create tests against the mock server:</p>
<p><strong><code>src/components/__tests__/UserForm.spec.ts</code>:</strong></p>
<pre><code class="language-typescript">import { describe, it, expect, beforeEach } from 'vitest';
import { mount } from '@vue/test-utils';
import { setActivePinia, createPinia } from 'pinia';
import UserForm from '../UserForm.vue';

describe('UserForm', () =&gt; {
  beforeEach(() =&gt; {
    setActivePinia(createPinia());
  });

  it('creates a user', async () =&gt; {
    const wrapper = mount(UserForm);
    // Your test logic here
  });
});
</code></pre>
<h2 id="common-issues-1"><a class="header" href="#common-issues-1">Common Issues</a></h2>
<h3 id="cors-errors-1"><a class="header" href="#cors-errors-1">CORS Errors</a></h3>
<p>Enable CORS in MockForge config:</p>
<pre><code class="language-yaml"># mockforge.yaml
http:
  port: 3000
  cors:
    enabled: true
    allowed_origins: ["http://localhost:5173", "http://localhost:3000"]
</code></pre>
<h3 id="template-variables-not-expanding-1"><a class="header" href="#template-variables-not-expanding-1">Template Variables Not Expanding</a></h3>
<p>Make sure template expansion is enabled:</p>
<pre><code class="language-bash">MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true mockforge serve ...
</code></pre>
<h3 id="environment-variables-not-loading"><a class="header" href="#environment-variables-not-loading">Environment Variables Not Loading</a></h3>
<p>Vite requires the <code>VITE_</code> prefix for environment variables. Ensure your <code>.env</code> file uses:</p>
<pre><code>VITE_API_URL=http://localhost:3000
</code></pre>
<h2 id="advanced-usage-1"><a class="header" href="#advanced-usage-1">Advanced Usage</a></h2>
<h3 id="reactive-data-with-computed-properties"><a class="header" href="#reactive-data-with-computed-properties">Reactive Data with Computed Properties</a></h3>
<pre><code class="language-vue">&lt;script setup lang="ts"&gt;
import { computed } from 'vue';
import { useUserStore } from './stores/userStore';

const userStore = useUserStore();

const activeUsers = computed(() =&gt; 
  userStore.users.filter(u =&gt; !u.deleted)
);
&lt;/script&gt;
</code></pre>
<h3 id="error-handling-with-vue-toast"><a class="header" href="#error-handling-with-vue-toast">Error Handling with Vue Toast</a></h3>
<pre><code class="language-typescript">import { useToast } from 'vue-toastification';

const toast = useToast();

async function createUser(input: UserInput) {
  try {
    await userStore.createUser(input);
    toast.success('User created successfully!');
  } catch (error) {
    toast.error('Failed to create user');
  }
}
</code></pre>
<h2 id="next-steps-7"><a class="header" href="#next-steps-7">Next Steps</a></h2>
<ul>
<li><strong>View Complete Example</strong>: See <a href="tutorials/../../examples/vue-demo/">Vue Demo</a> for a full implementation</li>
<li><strong>Learn React Workflow</strong>: <a href="tutorials/react-workflow.html">React + MockForge Workflow</a></li>
<li><strong>Explore Admin UI</strong>: <a href="tutorials/admin-ui-walkthrough.html">Admin UI Walkthrough</a></li>
<li><strong>Advanced Features</strong>: <a href="tutorials/../user-guide/http-mocking/dynamic-data.html">Dynamic Data Generation</a></li>
</ul>
<hr />
<p><strong>Need help?</strong> Check the <a href="tutorials/../reference/faq.html">FAQ</a> or <a href="tutorials/../reference/troubleshooting.html">Troubleshooting Guide</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="admin-ui-walkthrough-1"><a class="header" href="#admin-ui-walkthrough-1">Admin UI Walkthrough</a></h1>
<p><strong>Goal</strong>: Use MockForge‚Äôs Admin UI to visually manage your mock server, view live logs, and configure settings without editing files.</p>
<p><strong>Time</strong>: 5 minutes</p>
<h2 id="what-youll-learn-1"><a class="header" href="#what-youll-learn-1">What You‚Äôll Learn</a></h2>
<ul>
<li>Access the Admin UI</li>
<li>View real-time request logs</li>
<li>Monitor server metrics</li>
<li>Manage fixtures with drag-and-drop</li>
<li>Configure latency and fault injection</li>
<li>Search and filter logs</li>
</ul>
<h2 id="prerequisites-6"><a class="header" href="#prerequisites-6">Prerequisites</a></h2>
<ul>
<li>MockForge installed and running</li>
<li>A basic understanding of MockForge concepts</li>
</ul>
<h2 id="step-1-start-mockforge-with-admin-ui"><a class="header" href="#step-1-start-mockforge-with-admin-ui">Step 1: Start MockForge with Admin UI</a></h2>
<p>You can run the Admin UI in two modes:</p>
<h3 id="standalone-mode-separate-port"><a class="header" href="#standalone-mode-separate-port">Standalone Mode (Separate Port)</a></h3>
<pre><code class="language-bash">mockforge serve --admin --admin-port 9080 --http-port 3000
</code></pre>
<p>Access at: <strong>http://localhost:9080</strong></p>
<h3 id="embedded-mode-under-http-server"><a class="header" href="#embedded-mode-under-http-server">Embedded Mode (Under HTTP Server)</a></h3>
<pre><code class="language-bash">mockforge serve --admin-embed --admin-mount-path /admin --http-port 3000
</code></pre>
<p>Access at: <strong>http://localhost:3000/admin</strong></p>
<p>For this tutorial, we‚Äôll use standalone mode for simplicity.</p>
<h2 id="step-2-access-the-dashboard"><a class="header" href="#step-2-access-the-dashboard">Step 2: Access the Dashboard</a></h2>
<p>Open your browser and navigate to <strong>http://localhost:9080</strong>.</p>
<p>You‚Äôll see the <strong>Dashboard</strong> with:</p>
<h3 id="server-status-section"><a class="header" href="#server-status-section">Server Status Section</a></h3>
<ul>
<li><strong>HTTP Server</strong>: Running on port 3000</li>
<li><strong>WebSocket Server</strong>: Status and port</li>
<li><strong>gRPC Server</strong>: Status and port</li>
<li><strong>Uptime</strong>: How long the server has been running</li>
</ul>
<h3 id="quick-stats"><a class="header" href="#quick-stats">Quick Stats</a></h3>
<ul>
<li><strong>Total Requests</strong>: Request counter</li>
<li><strong>Active Connections</strong>: Current open connections</li>
<li><strong>Average Response Time</strong>: Performance metrics</li>
<li><strong>Error Rate</strong>: Failed requests percentage</li>
</ul>
<h3 id="recent-activity"><a class="header" href="#recent-activity">Recent Activity</a></h3>
<ul>
<li>Last 10 requests with timestamps, methods, paths, and status codes</li>
</ul>
<h2 id="step-3-view-live-logs"><a class="header" href="#step-3-view-live-logs">Step 3: View Live Logs</a></h2>
<p>Click on the <strong>‚ÄúLogs‚Äù</strong> tab in the navigation.</p>
<h3 id="features-1"><a class="header" href="#features-1">Features:</a></h3>
<ul>
<li><strong>Real-time updates</strong>: Logs stream via Server-Sent Events (SSE)</li>
<li><strong>Color-coded levels</strong>: INFO (blue), WARN (yellow), ERROR (red)</li>
<li><strong>Request details</strong>: Method, path, status code, response time</li>
<li><strong>Search</strong>: Filter logs by keyword</li>
<li><strong>Auto-scroll</strong>: Automatically scroll to newest logs</li>
</ul>
<h3 id="try-it"><a class="header" href="#try-it">Try It:</a></h3>
<ol>
<li>Keep the logs tab open</li>
<li>In another terminal, send a request:
<pre><code class="language-bash">curl http://localhost:3000/users
</code></pre>
</li>
<li>Watch the log appear instantly in the UI!</li>
</ol>
<h3 id="log-search"><a class="header" href="#log-search">Log Search</a></h3>
<p>Use the search box to filter:</p>
<ul>
<li>Search by path: <code>/users</code></li>
<li>Search by method: <code>POST</code></li>
<li>Search by status: <code>404</code></li>
<li>Search by error message: <code>validation failed</code></li>
</ul>
<h2 id="step-4-explore-metrics"><a class="header" href="#step-4-explore-metrics">Step 4: Explore Metrics</a></h2>
<p>Click on the <strong>‚ÄúMetrics‚Äù</strong> tab.</p>
<h3 id="available-metrics"><a class="header" href="#available-metrics">Available Metrics:</a></h3>
<ul>
<li><strong>Request Rate</strong>: Requests per second over time</li>
<li><strong>Response Times</strong>: P50, P95, P99 latencies</li>
<li><strong>Status Code Distribution</strong>: 2xx, 4xx, 5xx breakdown</li>
<li><strong>Endpoint Performance</strong>: Slowest endpoints</li>
<li><strong>Error Trends</strong>: Error rates over time</li>
</ul>
<h3 id="use-cases"><a class="header" href="#use-cases">Use Cases:</a></h3>
<ul>
<li><strong>Performance testing</strong>: Monitor response times under load</li>
<li><strong>Debugging</strong>: Identify which endpoints are failing</li>
<li><strong>Capacity planning</strong>: See throughput limits</li>
</ul>
<h2 id="step-5-manage-fixtures"><a class="header" href="#step-5-manage-fixtures">Step 5: Manage Fixtures</a></h2>
<p>Click on the <strong>‚ÄúFixtures‚Äù</strong> tab.</p>
<h3 id="what-are-fixtures"><a class="header" href="#what-are-fixtures">What are Fixtures?</a></h3>
<p>Fixtures are saved mock scenarios - collections of requests and expected responses for testing.</p>
<h3 id="tree-view-interface"><a class="header" href="#tree-view-interface">Tree View Interface:</a></h3>
<pre><code>üìÅ Fixtures
  üìÅ User Management
    ‚úÖ Create User - Happy Path
    ‚úÖ Create User - Validation Error
    ‚úÖ Get User - Not Found
  üìÅ Order Processing
    ‚úÖ Create Order
    ‚úÖ Update Order Status
</code></pre>
<h3 id="actions"><a class="header" href="#actions">Actions:</a></h3>
<ol>
<li><strong>Drag and Drop</strong>: Reorganize fixtures into folders</li>
<li><strong>Run Fixture</strong>: Test a specific scenario</li>
<li><strong>Run Folder</strong>: Execute all fixtures in a folder</li>
<li><strong>Export</strong>: Download fixtures as JSON</li>
<li><strong>Import</strong>: Upload fixture collections</li>
</ol>
<h3 id="try-it-1"><a class="header" href="#try-it-1">Try It:</a></h3>
<ol>
<li>Click <strong>‚ÄúNew Fixture‚Äù</strong></li>
<li>Name it: ‚ÄúTest User Creation‚Äù</li>
<li>Configure:
<ul>
<li><strong>Method</strong>: POST</li>
<li><strong>Path</strong>: <code>/users</code></li>
<li><strong>Expected Status</strong>: 201</li>
<li><strong>Request Body</strong>:
<pre><code class="language-json">{"name": "Test User", "email": "test@example.com"}
</code></pre>
</li>
</ul>
</li>
<li>Click <strong>‚ÄúSave‚Äù</strong></li>
<li>Click <strong>‚ÄúRun‚Äù</strong> to test it</li>
</ol>
<h2 id="step-6-configure-latency-simulation"><a class="header" href="#step-6-configure-latency-simulation">Step 6: Configure Latency Simulation</a></h2>
<p>Click on the <strong>‚ÄúConfiguration‚Äù</strong> tab, then <strong>‚ÄúLatency‚Äù</strong>.</p>
<h3 id="latency-profiles"><a class="header" href="#latency-profiles">Latency Profiles:</a></h3>
<p>MockForge can simulate various network conditions:</p>
<div class="table-wrapper"><table><thead><tr><th>Profile</th><th>Description</th><th>Latency</th></tr></thead><tbody>
<tr><td><strong>None</strong></td><td>No artificial delay</td><td>0ms</td></tr>
<tr><td><strong>Fast</strong></td><td>Local network</td><td>10-30ms</td></tr>
<tr><td><strong>Normal</strong></td><td>Good internet</td><td>50-150ms</td></tr>
<tr><td><strong>Slow</strong></td><td>Poor connection</td><td>300-800ms</td></tr>
<tr><td><strong>Very Slow</strong></td><td>Bad mobile</td><td>1000-3000ms</td></tr>
</tbody></table>
</div>
<h3 id="configure"><a class="header" href="#configure">Configure:</a></h3>
<ol>
<li>Select <strong>‚ÄúSlow‚Äù</strong> profile</li>
<li>Click <strong>‚ÄúApply‚Äù</strong></li>
<li>Test an endpoint:
<pre><code class="language-bash">time curl http://localhost:3000/users
</code></pre>
</li>
<li>Notice the delay!</li>
</ol>
<h3 id="per-endpoint-latency"><a class="header" href="#per-endpoint-latency">Per-Endpoint Latency:</a></h3>
<p>You can also configure latency for specific endpoints:</p>
<pre><code class="language-yaml"># In your config file
http:
  latency:
    enabled: true
    default_profile: normal
    endpoint_overrides:
      "POST /orders": slow       # Simulate slow order processing
      "GET /products": fast      # Fast product catalog
</code></pre>
<h2 id="step-7-enable-fault-injection"><a class="header" href="#step-7-enable-fault-injection">Step 7: Enable Fault Injection</a></h2>
<p>Still in the <strong>‚ÄúConfiguration‚Äù</strong> tab, click <strong>‚ÄúFault Injection‚Äù</strong>.</p>
<h3 id="fault-types"><a class="header" href="#fault-types">Fault Types:</a></h3>
<ul>
<li><strong>Random Failures</strong>: Randomly return 500 errors</li>
<li><strong>Timeouts</strong>: Simulate request timeouts</li>
<li><strong>Malformed Responses</strong>: Return invalid JSON</li>
<li><strong>Connection Drops</strong>: Close connections unexpectedly</li>
</ul>
<h3 id="configure-1"><a class="header" href="#configure-1">Configure:</a></h3>
<ol>
<li><strong>Enable Fault Injection</strong>: Toggle ON</li>
<li><strong>Error Rate</strong>: Set to 20% (1 in 5 requests fails)</li>
<li><strong>Fault Type</strong>: Select ‚ÄúRandom Failures‚Äù</li>
<li>Click <strong>‚ÄúApply‚Äù</strong></li>
</ol>
<h3 id="test-it"><a class="header" href="#test-it">Test It:</a></h3>
<pre><code class="language-bash"># Run this multiple times - some will fail!
for i in {1..10}; do
  curl http://localhost:3000/users
  echo ""
done
</code></pre>
<p>You‚Äôll see some requests return 500 errors, simulating an unreliable backend.</p>
<h2 id="step-8-search-across-services"><a class="header" href="#step-8-search-across-services">Step 8: Search Across Services</a></h2>
<p>Click on the <strong>‚ÄúSearch‚Äù</strong> tab.</p>
<h3 id="full-text-search"><a class="header" href="#full-text-search">Full-Text Search:</a></h3>
<p>Search across:</p>
<ul>
<li>Service names</li>
<li>Endpoint paths</li>
<li>Request/response bodies</li>
<li>Log messages</li>
<li>Configuration values</li>
</ul>
<h3 id="try-it-2"><a class="header" href="#try-it-2">Try It:</a></h3>
<ol>
<li>Search for <code>users</code> - finds all user-related endpoints</li>
<li>Search for <code>POST</code> - finds all POST endpoints</li>
<li>Search for <code>validation</code> - finds validation errors in logs</li>
</ol>
<h2 id="step-9-proxy-configuration-advanced"><a class="header" href="#step-9-proxy-configuration-advanced">Step 9: Proxy Configuration (Advanced)</a></h2>
<p>Click <strong>‚ÄúConfiguration‚Äù</strong> ‚Üí <strong>‚ÄúProxy‚Äù</strong>.</p>
<h3 id="hybrid-mode"><a class="header" href="#hybrid-mode">Hybrid Mode:</a></h3>
<p>MockForge can act as a proxy, forwarding unknown requests to a real backend:</p>
<ol>
<li><strong>Enable Proxy</strong>: Toggle ON</li>
<li><strong>Target URL</strong>: <code>https://api.example.com</code></li>
<li><strong>Fallback Mode</strong>: ‚ÄúForward unknown requests‚Äù</li>
<li>Click <strong>‚ÄúApply‚Äù</strong></li>
</ol>
<p>Now:</p>
<ul>
<li>Mocked endpoints return mock data</li>
<li>Unknown endpoints are forwarded to the real API</li>
<li>Perfect for gradual migration!</li>
</ul>
<h2 id="common-workflows"><a class="header" href="#common-workflows">Common Workflows</a></h2>
<h3 id="workflow-1-debug-a-failing-test"><a class="header" href="#workflow-1-debug-a-failing-test">Workflow 1: Debug a Failing Test</a></h3>
<ol>
<li>Open <strong>Logs</strong> tab</li>
<li>Enable <strong>‚ÄúError Only‚Äù</strong> filter</li>
<li>Run your failing test</li>
<li>Find the error in real-time</li>
<li>Copy the request details</li>
<li>Fix your test or mock configuration</li>
</ol>
<h3 id="workflow-2-create-test-fixtures"><a class="header" href="#workflow-2-create-test-fixtures">Workflow 2: Create Test Fixtures</a></h3>
<ol>
<li>Run your application manually (e.g., click through the UI)</li>
<li>Admin UI captures all requests in <strong>Logs</strong></li>
<li>Click <strong>‚ÄúSave as Fixture‚Äù</strong> on interesting requests</li>
<li>Organize fixtures into folders</li>
<li>Run fixtures as smoke tests before deployment</li>
</ol>
<h3 id="workflow-3-performance-testing"><a class="header" href="#workflow-3-performance-testing">Workflow 3: Performance Testing</a></h3>
<ol>
<li>Clear metrics (<strong>Metrics</strong> ‚Üí <strong>‚ÄúReset‚Äù</strong>)</li>
<li>Run load test against MockForge</li>
<li>Monitor <strong>Metrics</strong> tab in real-time</li>
<li>Identify performance bottlenecks</li>
<li>Adjust mock configuration for better performance</li>
</ol>
<h3 id="workflow-4-demo-preparation"><a class="header" href="#workflow-4-demo-preparation">Workflow 4: Demo Preparation</a></h3>
<ol>
<li><strong>Fixtures</strong>: Create realistic demo scenarios</li>
<li><strong>Latency</strong>: Set to ‚ÄúFast‚Äù for smooth demos</li>
<li><strong>Fault Injection</strong>: Disable to prevent unexpected errors</li>
<li><strong>Logs</strong>: Keep open to show real-time activity</li>
</ol>
<h2 id="keyboard-shortcuts"><a class="header" href="#keyboard-shortcuts">Keyboard Shortcuts</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Shortcut</th><th>Action</th></tr></thead><tbody>
<tr><td><code>Ctrl+K</code></td><td>Open search</td></tr>
<tr><td><code>Ctrl+L</code></td><td>Jump to logs</td></tr>
<tr><td><code>Ctrl+M</code></td><td>Jump to metrics</td></tr>
<tr><td><code>Ctrl+R</code></td><td>Refresh dashboard</td></tr>
<tr><td><code>Esc</code></td><td>Close modals</td></tr>
</tbody></table>
</div>
<h2 id="troubleshooting-8"><a class="header" href="#troubleshooting-8">Troubleshooting</a></h2>
<p><strong>Admin UI not loading?</strong></p>
<ul>
<li>Check that the admin port (9080) isn‚Äôt blocked</li>
<li>Verify MockForge is running with <code>--admin</code> flag</li>
<li>Check browser console for JavaScript errors</li>
</ul>
<p><strong>Logs not updating?</strong></p>
<ul>
<li>Ensure Server-Sent Events (SSE) aren‚Äôt blocked by your browser or proxy</li>
<li>Try refreshing the page</li>
<li>Check that <code>/__mockforge/logs</code> endpoint is accessible</li>
</ul>
<p><strong>Fixtures not saving?</strong></p>
<ul>
<li>Verify you have write permissions to the MockForge data directory</li>
<li>Check disk space availability</li>
<li>Review logs for error messages</li>
</ul>
<h2 id="whats-next-3"><a class="header" href="#whats-next-3">What‚Äôs Next?</a></h2>
<ul>
<li><a href="tutorials/../user-guide/http-mocking/custom-responses.html">Custom Response Configuration</a> - Build advanced mock responses</li>
<li><a href="tutorials/../user-guide/security.html">Security Features</a> - Add authentication to Admin UI (v1.1+)</li>
<li><a href="tutorials/../user-guide/sync.html">Workspace Sync</a> - Share fixtures with your team</li>
<li><a href="tutorials/../user-guide/plugins.html">Plugin System</a> - Extend Admin UI functionality</li>
</ul>
<hr />
<p><strong>Pro Tip</strong>: Use browser bookmarks for quick access:</p>
<ul>
<li><code>http://localhost:9080/</code> - Dashboard</li>
<li><code>http://localhost:9080/?tab=logs</code> - Jump directly to logs</li>
<li><code>http://localhost:9080/?tab=metrics</code> - Jump directly to metrics</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="plugin-starter-guide"><a class="header" href="#plugin-starter-guide">Plugin Starter Guide</a></h1>
<p>This guide walks you through creating your first MockForge plugin from scratch. You‚Äôll learn how to scaffold a plugin project, implement plugin functionality, build it, and use it in MockForge.</p>
<h2 id="overview-4"><a class="header" href="#overview-4">Overview</a></h2>
<p>MockForge plugins extend the platform‚Äôs capabilities through a WebAssembly-based plugin system. Plugins can:</p>
<ul>
<li>Add custom template functions</li>
<li>Implement custom authentication logic</li>
<li>Generate dynamic responses</li>
<li>Connect to external data sources</li>
<li>Trigger webhooks</li>
<li>Add chaos engineering patterns</li>
</ul>
<h2 id="plugin-types"><a class="header" href="#plugin-types">Plugin Types</a></h2>
<p>MockForge supports several plugin types:</p>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Description</th><th>Use Case</th></tr></thead><tbody>
<tr><td><strong>template</strong></td><td>Custom template functions</td><td>Add domain-specific data generation functions</td></tr>
<tr><td><strong>auth</strong></td><td>Authentication handlers</td><td>Custom authentication logic (JWT, OAuth, etc.)</td></tr>
<tr><td><strong>response</strong></td><td>Response generators</td><td>Generate dynamic responses based on request data</td></tr>
<tr><td><strong>datasource</strong></td><td>Data source connectors</td><td>Connect to external data (CSV, databases, APIs)</td></tr>
<tr><td><strong>webhook</strong></td><td>Webhook triggers</td><td>Send outbound HTTP requests to external services</td></tr>
<tr><td><strong>chaos</strong></td><td>Chaos patterns</td><td>Add custom failure modes and latency patterns</td></tr>
</tbody></table>
</div>
<h2 id="step-1-scaffold-your-plugin"><a class="header" href="#step-1-scaffold-your-plugin">Step 1: Scaffold Your Plugin</a></h2>
<p>Use the <code>mockforge plugin init</code> command to create a new plugin project:</p>
<pre><code class="language-bash">mockforge plugin init my-custom-plugin --plugin-type template
</code></pre>
<p><strong>Options:</strong></p>
<ul>
<li><code>--plugin-type</code> (default: <code>template</code>): The type of plugin to create</li>
<li><code>--output</code> (optional): Output directory (defaults to plugin name)</li>
<li><code>--force</code>: Overwrite existing directory</li>
</ul>
<p><strong>Example for different types:</strong></p>
<pre><code class="language-bash"># Template plugin
mockforge plugin init my-template-plugin --plugin-type template

# Authentication plugin
mockforge plugin init my-auth-plugin --plugin-type auth

# Response plugin
mockforge plugin init my-response-plugin --plugin-type response

# Data source plugin
mockforge plugin init my-datasource-plugin --plugin-type datasource

# Webhook plugin
mockforge plugin init my-webhook-plugin --plugin-type webhook

# Chaos plugin
mockforge plugin init my-chaos-plugin --plugin-type chaos
</code></pre>
<h3 id="what-gets-created"><a class="header" href="#what-gets-created">What Gets Created</a></h3>
<p>The command creates a complete plugin project structure:</p>
<pre><code>my-custom-plugin/
‚îú‚îÄ‚îÄ Cargo.toml          # Rust dependencies and build config
‚îú‚îÄ‚îÄ plugin.yaml         # Plugin manifest with metadata
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ lib.rs         # Plugin implementation
‚îú‚îÄ‚îÄ README.md          # Plugin documentation template
‚îî‚îÄ‚îÄ .gitignore        # Git ignore file
</code></pre>
<h2 id="step-2-understand-the-plugin-structure"><a class="header" href="#step-2-understand-the-plugin-structure">Step 2: Understand the Plugin Structure</a></h2>
<h3 id="cargotoml"><a class="header" href="#cargotoml">Cargo.toml</a></h3>
<p>The <code>Cargo.toml</code> file defines your plugin‚Äôs dependencies:</p>
<pre><code class="language-toml">[package]
name = "my-custom-plugin"
version = "0.1.0"
edition = "2021"

[dependencies]
mockforge-plugin-core = { path = "../../../crates/mockforge-plugin-core" }
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
async-trait = "0.1"
</code></pre>
<h3 id="pluginyaml"><a class="header" href="#pluginyaml">plugin.yaml</a></h3>
<p>The <code>plugin.yaml</code> file is the plugin manifest:</p>
<pre><code class="language-yaml">id: my-custom-plugin
name: My Custom Plugin
version: 0.1.0
description: Description of what this plugin does
author: Your Name
license: MIT OR Apache-2.0

type: template  # template, auth, response, datasource, webhook, chaos

capabilities:
  network:
    allow_http: false
    allowed_hosts: []
  filesystem:
    read_paths: []
    write_paths: []
  resources:
    max_memory_bytes: 10485760  # 10MB
    max_cpu_percent: 50
    max_execution_time_ms: 1000

config_schema:
  type: object
  properties:
    # Plugin-specific configuration
</code></pre>
<h3 id="srclibrs"><a class="header" href="#srclibrs">src/lib.rs</a></h3>
<p>The <code>src/lib.rs</code> file contains your plugin implementation. The scaffolded code provides a template based on your plugin type.</p>
<h2 id="step-3-implement-your-plugin"><a class="header" href="#step-3-implement-your-plugin">Step 3: Implement Your Plugin</a></h2>
<h3 id="template-plugin-example"><a class="header" href="#template-plugin-example">Template Plugin Example</a></h3>
<p>Template plugins add custom functions to MockForge‚Äôs templating system:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_plugin_core::{
    TemplatePlugin, TemplatePluginConfig, TemplateFunction, 
    FunctionParameter, PluginContext, PluginResult, Result, Value
};
use std::collections::HashMap;

pub struct MyTemplatePlugin {
    config: TemplatePluginConfig,
}

#[async_trait::async_trait]
impl TemplatePlugin for MyTemplatePlugin {
    fn capabilities(&amp;self) -&gt; PluginCapabilities {
        PluginCapabilities {
            network: NetworkPermissions {
                allow_http: false,
                allowed_hosts: vec![],
                max_connections: 10,
            },
            filesystem: FilesystemPermissions {
                read_paths: vec![],
                write_paths: vec![],
                allow_temp_files: false,
            },
            resources: ResourceLimits {
                max_memory_bytes: 10 * 1024 * 1024, // 10MB
                max_cpu_percent: 50,
                max_execution_time_ms: 1000,
                max_concurrent_executions: 5,
            },
            custom: HashMap::new(),
        }
    }

    async fn initialize(&amp;self, _config: &amp;TemplatePluginConfig) -&gt; Result&lt;()&gt; {
        Ok(())
    }

    async fn register_functions(
        &amp;self,
        _context: &amp;PluginContext,
        _config: &amp;TemplatePluginConfig,
    ) -&gt; Result&lt;PluginResult&lt;HashMap&lt;String, TemplateFunction&gt;&gt;&gt; {
        let mut functions = HashMap::new();

        // Register a custom function
        functions.insert(
            "my_custom_function".to_string(),
            TemplateFunction::new(
                "my_custom_function",
                "Does something custom",
                "string"
            )
            .with_parameter(
                FunctionParameter::required("input", "string", "Input value")
            )
            .with_example("{{my_custom_function \"hello\"}}")
            .with_category("custom"),
        );

        Ok(PluginResult::success(functions, 0))
    }

    async fn execute_function(
        &amp;self,
        _context: &amp;PluginContext,
        function_name: &amp;str,
        args: &amp;[Value],
        _config: &amp;TemplatePluginConfig,
    ) -&gt; Result&lt;PluginResult&lt;Value&gt;&gt; {
        match function_name {
            "my_custom_function" =&gt; {
                let input = args.get(0)
                    .and_then(|v| v.as_str())
                    .ok_or_else(|| PluginError::execution("Missing input argument"))?;
                
                let result = format!("Processed: {}", input);
                Ok(PluginResult::success(Value::String(result), 0))
            }
            _ =&gt; Ok(PluginResult::failure(
                format!("Unknown function: {}", function_name),
                0
            )),
        }
    }

    // ... other required methods
}
<span class="boring">}</span></code></pre></pre>
<h3 id="response-plugin-example"><a class="header" href="#response-plugin-example">Response Plugin Example</a></h3>
<p>Response plugins generate custom responses based on request data:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_plugin_core::{
    ResponsePlugin, ResponsePluginConfig, ResponseRequest,
    ResponseData, PluginContext, PluginResult, Result
};
use std::collections::HashMap;

pub struct MyResponsePlugin {
    config: ResponsePluginConfig,
}

#[async_trait::async_trait]
impl ResponsePlugin for MyResponsePlugin {
    fn capabilities(&amp;self) -&gt; PluginCapabilities {
        // Define capabilities
    }

    async fn initialize(&amp;self, _config: &amp;ResponsePluginConfig) -&gt; Result&lt;()&gt; {
        Ok(())
    }

    async fn can_handle(
        &amp;self,
        _context: &amp;PluginContext,
        request: &amp;ResponseRequest,
        _config: &amp;ResponsePluginConfig,
    ) -&gt; Result&lt;PluginResult&lt;bool&gt;&gt; {
        // Determine if this plugin should handle the request
        let should_handle = request.path.starts_with("/api/custom");
        Ok(PluginResult::success(should_handle, 0))
    }

    async fn generate_response(
        &amp;self,
        _context: &amp;PluginContext,
        request: &amp;ResponseRequest,
        _config: &amp;ResponsePluginConfig,
    ) -&gt; Result&lt;PluginResult&lt;ResponseData&gt;&gt; {
        // Generate custom response
        let body = json!({
            "message": "Custom response",
            "path": request.path,
            "method": request.method.as_str(),
        });

        let response_data = ResponseData {
            status_code: 200,
            headers: HashMap::new(),
            body: serde_json::to_vec(&amp;body)?,
            content_type: "application/json".to_string(),
            metadata: HashMap::new(),
            cache_control: None,
            custom: HashMap::new(),
        };

        Ok(PluginResult::success(response_data, 0))
    }

    // ... other required methods
}
<span class="boring">}</span></code></pre></pre>
<h3 id="webhook-plugin-example"><a class="header" href="#webhook-plugin-example">Webhook Plugin Example</a></h3>
<p>Webhook plugins make outbound HTTP requests:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_plugin_core::{
    ResponsePlugin, ResponsePluginConfig, ResponseRequest,
    ResponseData, PluginContext, PluginResult, Result
};

pub struct MyWebhookPlugin {
    config: ResponsePluginConfig,
    webhook_url: String,
}

#[async_trait::async_trait]
impl ResponsePlugin for MyWebhookPlugin {
    fn capabilities(&amp;self) -&gt; PluginCapabilities {
        PluginCapabilities {
            network: NetworkPermissions {
                allow_http: true,  // Enable network access
                allowed_hosts: vec![
                    self.webhook_url
                        .strip_prefix("https://")
                        .or_else(|| self.webhook_url.strip_prefix("http://"))
                        .and_then(|url| url.split('/').next())
                        .unwrap_or("*")
                        .to_string()
                ],
                max_connections: 10,
            },
            // ... other capabilities
        }
    }

    async fn generate_response(
        &amp;self,
        _context: &amp;PluginContext,
        request: &amp;ResponseRequest,
        _config: &amp;ResponsePluginConfig,
    ) -&gt; Result&lt;PluginResult&lt;ResponseData&gt;&gt; {
        // Generate webhook payload
        let payload = json!({
            "event": "mockforge.request",
            "path": request.path,
            "method": request.method.as_str(),
            "timestamp": chrono::Utc::now().to_rfc3339(),
        });

        // In a real implementation, make HTTP request here
        // For security, this requires network capabilities

        let response_data = ResponseData {
            status_code: 200,
            headers: HashMap::new(),
            body: serde_json::to_vec(&amp;payload)?,
            content_type: "application/json".to_string(),
            metadata: HashMap::new(),
            cache_control: None,
            custom: HashMap::new(),
        };

        Ok(PluginResult::success(response_data, 0))
    }

    // ... other required methods
}
<span class="boring">}</span></code></pre></pre>
<h2 id="step-4-build-your-plugin"><a class="header" href="#step-4-build-your-plugin">Step 4: Build Your Plugin</a></h2>
<p>Build your plugin for WebAssembly:</p>
<pre><code class="language-bash">cd my-custom-plugin
cargo build --target wasm32-wasi --release
</code></pre>
<p>The compiled <code>.wasm</code> file will be in:</p>
<pre><code>target/wasm32-wasi/release/my_custom_plugin.wasm
</code></pre>
<h2 id="step-5-test-your-plugin"><a class="header" href="#step-5-test-your-plugin">Step 5: Test Your Plugin</a></h2>
<h3 id="unit-tests"><a class="header" href="#unit-tests">Unit Tests</a></h3>
<p>Add tests to your plugin:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_my_custom_function() {
        let plugin = MyTemplatePlugin::new();
        let config = TemplatePluginConfig::default();
        
        plugin.initialize(&amp;config).await.unwrap();
        
        let functions = plugin.register_functions(
            &amp;PluginContext::default(),
            &amp;config
        ).await.unwrap();
        
        assert!(functions.result.contains_key("my_custom_function"));
    }
}
<span class="boring">}</span></code></pre></pre>
<p>Run tests:</p>
<pre><code class="language-bash">cargo test
</code></pre>
<h3 id="integration-testing"><a class="header" href="#integration-testing">Integration Testing</a></h3>
<p>Test your plugin with MockForge:</p>
<ol>
<li>
<p><strong>Install the plugin:</strong></p>
<pre><code class="language-bash">mockforge plugin install ./my-custom-plugin
</code></pre>
</li>
<li>
<p><strong>List installed plugins:</strong></p>
<pre><code class="language-bash">mockforge plugin list
</code></pre>
</li>
<li>
<p><strong>Use in mockforge.yaml:</strong></p>
<pre><code class="language-yaml">plugins:
  - id: my-custom-plugin
    type: template
    config:
      # Plugin-specific config
</code></pre>
</li>
<li>
<p><strong>Start MockForge:</strong></p>
<pre><code class="language-bash">mockforge serve
</code></pre>
</li>
<li>
<p><strong>Test the plugin:</strong></p>
<pre><code class="language-bash"># For template plugins, use in templates
curl http://localhost:3000/api/test
</code></pre>
</li>
</ol>
<h2 id="step-6-learn-from-examples"><a class="header" href="#step-6-learn-from-examples">Step 6: Learn from Examples</a></h2>
<p>The MockForge repository includes comprehensive example plugins you can learn from:</p>
<h3 id="template-plugins"><a class="header" href="#template-plugins">Template Plugins</a></h3>
<p><strong><code>template-advanced/</code></strong> - Advanced template functions:</p>
<ul>
<li>Mathematical operations (sum, average)</li>
<li>Collection operations (group_by, sort)</li>
<li>Date/time formatting</li>
<li>UUID generation</li>
</ul>
<p><strong>Inspect:</strong></p>
<pre><code class="language-bash">cd examples/plugins/template-advanced/
cat src/lib.rs
cat README.md
</code></pre>
<p><strong><code>template-custom/</code></strong> - Domain-specific functions:</p>
<ul>
<li>Business data generation</li>
<li>Custom formatting</li>
<li>Domain-specific helpers</li>
</ul>
<h3 id="response-plugins"><a class="header" href="#response-plugins">Response Plugins</a></h3>
<p><strong><code>webhook-example/</code></strong> - Webhook functionality:</p>
<ul>
<li>Outbound HTTP requests</li>
<li>Payload signing</li>
<li>Event-based triggering</li>
</ul>
<p><strong>Inspect:</strong></p>
<pre><code class="language-bash">cd examples/plugins/webhook-example/
cat src/lib.rs
cat plugin.yaml
</code></pre>
<h3 id="authentication-plugins"><a class="header" href="#authentication-plugins">Authentication Plugins</a></h3>
<p><strong><code>auth-basic/</code></strong> - HTTP Basic Authentication:</p>
<ul>
<li>Credential validation</li>
<li>Realm configuration</li>
<li>Secure password handling</li>
</ul>
<p><strong>Inspect:</strong></p>
<pre><code class="language-bash">cd examples/plugins/auth-basic/
cat src/lib.rs
</code></pre>
<h3 id="data-source-plugins"><a class="header" href="#data-source-plugins">Data Source Plugins</a></h3>
<p><strong><code>datasource-csv/</code></strong> - CSV data source:</p>
<ul>
<li>CSV file parsing</li>
<li>Data querying</li>
<li>Type inference</li>
</ul>
<p><strong>Inspect:</strong></p>
<pre><code class="language-bash">cd examples/plugins/datasource-csv/
cat src/lib.rs
</code></pre>
<h2 id="complete-example-creating-a-template-plugin"><a class="header" href="#complete-example-creating-a-template-plugin">Complete Example: Creating a Template Plugin</a></h2>
<p>Let‚Äôs create a complete template plugin step-by-step:</p>
<h3 id="1-scaffold-the-plugin"><a class="header" href="#1-scaffold-the-plugin">1. Scaffold the Plugin</a></h3>
<pre><code class="language-bash">mockforge plugin init currency-formatter --plugin-type template
cd currency-formatter
</code></pre>
<h3 id="2-implement-the-plugin"><a class="header" href="#2-implement-the-plugin">2. Implement the Plugin</a></h3>
<p>Edit <code>src/lib.rs</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_plugin_core::{
    TemplatePlugin, TemplatePluginConfig, TemplateFunction,
    FunctionParameter, PluginContext, PluginResult, Result, Value
};
use std::collections::HashMap;

pub struct CurrencyFormatterPlugin {
    config: TemplatePluginConfig,
}

#[async_trait::async_trait]
impl TemplatePlugin for CurrencyFormatterPlugin {
    fn capabilities(&amp;self) -&gt; PluginCapabilities {
        PluginCapabilities {
            network: NetworkPermissions {
                allow_http: false,
                allowed_hosts: vec![],
                max_connections: 10,
            },
            filesystem: FilesystemPermissions {
                read_paths: vec![],
                write_paths: vec![],
                allow_temp_files: false,
            },
            resources: ResourceLimits {
                max_memory_bytes: 5 * 1024 * 1024, // 5MB
                max_cpu_percent: 50,
                max_execution_time_ms: 500,
                max_concurrent_executions: 5,
            },
            custom: HashMap::new(),
        }
    }

    async fn initialize(&amp;self, _config: &amp;TemplatePluginConfig) -&gt; Result&lt;()&gt; {
        Ok(())
    }

    async fn register_functions(
        &amp;self,
        _context: &amp;PluginContext,
        _config: &amp;TemplatePluginConfig,
    ) -&gt; Result&lt;PluginResult&lt;HashMap&lt;String, TemplateFunction&gt;&gt;&gt; {
        let mut functions = HashMap::new();

        functions.insert(
            "format_currency".to_string(),
            TemplateFunction::new(
                "format_currency",
                "Format a number as currency",
                "string"
            )
            .with_parameter(
                FunctionParameter::required("amount", "number", "Amount to format")
            )
            .with_parameter(
                FunctionParameter::optional("currency", "string", "Currency code (default: USD)")
            )
            .with_example("{{format_currency 1234.56 \"USD\"}}")
            .with_category("formatting"),
        );

        Ok(PluginResult::success(functions, 0))
    }

    async fn execute_function(
        &amp;self,
        _context: &amp;PluginContext,
        function_name: &amp;str,
        args: &amp;[Value],
        _config: &amp;TemplatePluginConfig,
    ) -&gt; Result&lt;PluginResult&lt;Value&gt;&gt; {
        match function_name {
            "format_currency" =&gt; {
                let amount = args.get(0)
                    .and_then(|v| v.as_f64())
                    .ok_or_else(|| PluginError::execution("Amount must be a number"))?;
                
                let currency = args.get(1)
                    .and_then(|v| v.as_str())
                    .unwrap_or("USD");
                
                let formatted = match currency {
                    "USD" =&gt; format!("${:.2}", amount),
                    "EUR" =&gt; format!("‚Ç¨{:.2}", amount),
                    "GBP" =&gt; format!("¬£{:.2}", amount),
                    _ =&gt; format!("{:.2} {}", amount, currency),
                };
                
                Ok(PluginResult::success(Value::String(formatted), 0))
            }
            _ =&gt; Ok(PluginResult::failure(
                format!("Unknown function: {}", function_name),
                0
            )),
        }
    }

    async fn get_data_source(
        &amp;self,
        _context: &amp;PluginContext,
        _data_source: &amp;str,
        _config: &amp;TemplatePluginConfig,
    ) -&gt; Result&lt;PluginResult&lt;Value&gt;&gt; {
        Ok(PluginResult::failure("No data sources available".to_string(), 0))
    }

    fn validate_config(&amp;self, _config: &amp;TemplatePluginConfig) -&gt; Result&lt;()&gt; {
        Ok(())
    }

    fn available_data_sources(&amp;self) -&gt; Vec&lt;String&gt; {
        vec![]
    }

    async fn cleanup(&amp;self) -&gt; Result&lt;()&gt; {
        Ok(())
    }
}

// Export the plugin
#[no_mangle]
pub extern "C" fn create_plugin() -&gt; *mut dyn TemplatePlugin {
    Box::into_raw(Box::new(CurrencyFormatterPlugin {
        config: TemplatePluginConfig::default(),
    }))
}

#[no_mangle]
pub extern "C" fn destroy_plugin(plugin: *mut dyn TemplatePlugin) {
    unsafe {
        drop(Box::from_raw(plugin));
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="3-update-pluginyaml"><a class="header" href="#3-update-pluginyaml">3. Update plugin.yaml</a></h3>
<pre><code class="language-yaml">id: currency-formatter
name: Currency Formatter
version: 0.1.0
description: Format numbers as currency strings
author: Your Name
license: MIT OR Apache-2.0

type: template

capabilities:
  network:
    allow_http: false
  filesystem:
    read_paths: []
    write_paths: []
  resources:
    max_memory_bytes: 5242880  # 5MB
    max_cpu_percent: 50
    max_execution_time_ms: 500
</code></pre>
<h3 id="4-build-and-test"><a class="header" href="#4-build-and-test">4. Build and Test</a></h3>
<pre><code class="language-bash"># Build
cargo build --target wasm32-wasi --release

# Test
cargo test

# Install
mockforge plugin install .

# Use in mockforge.yaml
</code></pre>
<h3 id="5-use-in-templates"><a class="header" href="#5-use-in-templates">5. Use in Templates</a></h3>
<pre><code class="language-yaml"># mockforge.yaml
responses:
  - path: /api/products
    method: GET
    body: |
      {
        "products": [
          {
            "name": "Product 1",
            "price": "{{format_currency 29.99 \"USD\"}}"
          }
        ]
      }
</code></pre>
<h2 id="best-practices-1"><a class="header" href="#best-practices-1">Best Practices</a></h2>
<h3 id="1-error-handling"><a class="header" href="#1-error-handling">1. Error Handling</a></h3>
<p>Always handle errors gracefully:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>async fn execute_function(
    &amp;self,
    _context: &amp;PluginContext,
    function_name: &amp;str,
    args: &amp;[Value],
    _config: &amp;TemplatePluginConfig,
) -&gt; Result&lt;PluginResult&lt;Value&gt;&gt; {
    match function_name {
        "my_function" =&gt; {
            let input = args.get(0)
                .and_then(|v| v.as_str())
                .ok_or_else(|| PluginError::execution("Missing required argument"))?;
            
            // Your logic here
            Ok(PluginResult::success(Value::String(result), 0))
        }
        _ =&gt; Ok(PluginResult::failure(
            format!("Unknown function: {}", function_name),
            0
        )),
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="2-resource-limits"><a class="header" href="#2-resource-limits">2. Resource Limits</a></h3>
<p>Set appropriate resource limits:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>resources: ResourceLimits {
    max_memory_bytes: 10 * 1024 * 1024,  // 10MB
    max_cpu_percent: 50,
    max_execution_time_ms: 1000,  // 1 second
    max_concurrent_executions: 5,
}
<span class="boring">}</span></code></pre></pre>
<h3 id="3-security"><a class="header" href="#3-security">3. Security</a></h3>
<ul>
<li>Only request necessary capabilities</li>
<li>Validate all inputs</li>
<li>Sanitize outputs</li>
<li>Use allowed_hosts for network access</li>
</ul>
<h3 id="4-documentation"><a class="header" href="#4-documentation">4. Documentation</a></h3>
<ul>
<li>Document all functions in <code>register_functions</code></li>
<li>Provide examples in function metadata</li>
<li>Include usage examples in README.md</li>
</ul>
<h2 id="troubleshooting-9"><a class="header" href="#troubleshooting-9">Troubleshooting</a></h2>
<h3 id="plugin-wont-build"><a class="header" href="#plugin-wont-build">Plugin Won‚Äôt Build</a></h3>
<p><strong>Issue:</strong> Compilation errors</p>
<p><strong>Solution:</strong></p>
<ul>
<li>Check that all dependencies are in <code>Cargo.toml</code></li>
<li>Ensure you‚Äôre using the correct Rust edition (2021)</li>
<li>Verify <code>mockforge-plugin-core</code> path is correct</li>
</ul>
<h3 id="plugin-not-loading"><a class="header" href="#plugin-not-loading">Plugin Not Loading</a></h3>
<p><strong>Issue:</strong> Plugin fails to load in MockForge</p>
<p><strong>Solution:</strong></p>
<ul>
<li>Check <code>plugin.yaml</code> syntax</li>
<li>Verify plugin type matches implementation</li>
<li>Check capability requirements</li>
<li>Review MockForge logs for errors</li>
</ul>
<h3 id="function-not-found"><a class="header" href="#function-not-found">Function Not Found</a></h3>
<p><strong>Issue:</strong> Template function not available</p>
<p><strong>Solution:</strong></p>
<ul>
<li>Ensure function is registered in <code>register_functions</code></li>
<li>Check function name matches exactly</li>
<li>Verify plugin is installed and enabled</li>
<li>Check plugin configuration</li>
</ul>
<h2 id="next-steps-8"><a class="header" href="#next-steps-8">Next Steps</a></h2>
<ol>
<li><strong>Explore Example Plugins</strong>: Study the example plugins in <code>examples/plugins/</code></li>
<li><strong>Read Plugin API Docs</strong>: See <code>crates/mockforge-plugin-core/src/</code> for trait definitions</li>
<li><strong>Join the Community</strong>: Share your plugins and get feedback</li>
<li><strong>Contribute</strong>: Submit your plugins to the marketplace</li>
</ol>
<h2 id="related-documentation-1"><a class="header" href="#related-documentation-1">Related Documentation</a></h2>
<ul>
<li><a href="tutorials/../user-guide/plugins.html">Plugin Development Guide</a> - Detailed plugin development</li>
<li><a href="tutorials/../../crates/mockforge-plugin-core/README.html">Plugin API Reference</a> - Complete API documentation</li>
<li><a href="tutorials/../../examples/plugins/README.html">Example Plugins</a> - All available examples</li>
<li><a href="tutorials/../../plugin-marketplace/README.html">Plugin Marketplace</a> - Share and discover plugins</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="ide-extension-guide"><a class="header" href="#ide-extension-guide">IDE Extension Guide</a></h1>
<p>This guide walks you through installing, configuring, and using the MockForge VS Code extension to enhance your development workflow with inline mock previews, config validation, and seamless playground integration.</p>
<h2 id="overview-5"><a class="header" href="#overview-5">Overview</a></h2>
<p>The MockForge VS Code extension brings the power of MockForge directly into your editor, providing:</p>
<ul>
<li><strong>Peek Mock Response</strong>: Hover over API endpoints to see mock responses inline</li>
<li><strong>Config Validation</strong>: Real-time validation of <code>mockforge.yaml</code> files with inline errors</li>
<li><strong>Mocks Explorer</strong>: Visual tree view of all mocks with real-time updates</li>
<li><strong>Playground Integration</strong>: Quick access to MockForge Playground from hover tooltips</li>
<li><strong>Mock Management</strong>: Create, edit, enable/disable, and delete mocks from VS Code</li>
</ul>
<h2 id="installation-3"><a class="header" href="#installation-3">Installation</a></h2>
<h3 id="from-vs-code-marketplace"><a class="header" href="#from-vs-code-marketplace">From VS Code Marketplace</a></h3>
<ol>
<li>Open VS Code</li>
<li>Go to Extensions (Ctrl+Shift+X / Cmd+Shift+X)</li>
<li>Search for ‚ÄúMockForge‚Äù</li>
<li>Click <strong>Install</strong></li>
</ol>
<p>Or install via command line:</p>
<pre><code class="language-bash">code --install-extension saasy-solutions.mockforge-vscode
</code></pre>
<h3 id="from-vsix-file"><a class="header" href="#from-vsix-file">From VSIX File</a></h3>
<p>If you have a <code>.vsix</code> file:</p>
<pre><code class="language-bash">code --install-extension mockforge-vscode-0.1.0.vsix
</code></pre>
<h3 id="verify-installation"><a class="header" href="#verify-installation">Verify Installation</a></h3>
<p>After installation, you should see:</p>
<ul>
<li>MockForge icon in the Activity Bar (left sidebar)</li>
<li>MockForge commands available in Command Palette (Ctrl+Shift+P / Cmd+Shift+P)</li>
</ul>
<h2 id="configuration"><a class="header" href="#configuration">Configuration</a></h2>
<h3 id="basic-setup"><a class="header" href="#basic-setup">Basic Setup</a></h3>
<p>Configure the extension in VS Code settings:</p>
<ol>
<li>Open Settings (Ctrl+, / Cmd+,)</li>
<li>Search for ‚Äúmockforge‚Äù</li>
<li>Configure the following:</li>
</ol>
<pre><code class="language-json">{
  "mockforge.serverUrl": "http://localhost:3000",
  "mockforge.autoConnect": true,
  "mockforge.showNotifications": true,
  "mockforge.inlinePreview.enabled": true
}
</code></pre>
<p><strong>Settings:</strong></p>
<ul>
<li><code>mockforge.serverUrl</code>: MockForge server URL (default: <code>http://localhost:3000</code>)</li>
<li><code>mockforge.autoConnect</code>: Automatically connect on startup (default: <code>true</code>)</li>
<li><code>mockforge.showNotifications</code>: Show notifications for mock changes (default: <code>true</code>)</li>
<li><code>mockforge.inlinePreview.enabled</code>: Enable inline preview of mock responses (default: <code>true</code>)</li>
</ul>
<h3 id="workspace-settings"><a class="header" href="#workspace-settings">Workspace Settings</a></h3>
<p>For project-specific configuration, add to <code>.vscode/settings.json</code>:</p>
<pre><code class="language-json">{
  "mockforge.serverUrl": "http://localhost:3000",
  "mockforge.autoConnect": true
}
</code></pre>
<h2 id="feature-1-peek-mock-response"><a class="header" href="#feature-1-peek-mock-response">Feature 1: Peek Mock Response</a></h2>
<p>The peek response feature shows mock responses when you hover over API endpoint references in your code.</p>
<h3 id="how-it-works"><a class="header" href="#how-it-works">How It Works</a></h3>
<ol>
<li><strong>Hover over an endpoint</strong> in your code (JavaScript, TypeScript, or YAML)</li>
<li><strong>See the mock response</strong> in a tooltip with headers and body</li>
<li><strong>Click ‚ÄúOpen in Playground‚Äù</strong> to test the endpoint interactively</li>
</ol>
<h3 id="supported-patterns"><a class="header" href="#supported-patterns">Supported Patterns</a></h3>
<p>The extension detects endpoints in various patterns:</p>
<p><strong>JavaScript/TypeScript:</strong></p>
<pre><code class="language-typescript">// fetch() calls
const response = await fetch('/api/users');

// axios calls
const data = await axios.get('/api/products');

// http client calls
const result = await http.get('/api/orders');
</code></pre>
<p><strong>YAML Config Files:</strong></p>
<pre><code class="language-yaml"># mockforge.yaml
responses:
  - path: /api/users
    method: GET
</code></pre>
<h3 id="example-usage"><a class="header" href="#example-usage">Example Usage</a></h3>
<p><strong>Before (without extension):</strong></p>
<ul>
<li>You write: <code>fetch('/api/users')</code></li>
<li>You have no idea what the response looks like</li>
<li>You need to run the app or check documentation</li>
</ul>
<p><strong>After (with extension):</strong></p>
<ul>
<li>You write: <code>fetch('/api/users')</code></li>
<li>You hover over the endpoint</li>
<li>You see:
<pre><code class="language-json">{
  "users": [
    {
      "id": 1,
      "name": "John Doe",
      "email": "john@example.com"
    }
  ]
}
</code></pre>
</li>
<li>You click ‚ÄúOpen in Playground‚Äù to test it</li>
</ul>
<h3 id="configuration-1"><a class="header" href="#configuration-1">Configuration</a></h3>
<p>Enable/disable peek response:</p>
<pre><code class="language-json">{
  "mockforge.inlinePreview.enabled": true
}
</code></pre>
<h3 id="troubleshooting-10"><a class="header" href="#troubleshooting-10">Troubleshooting</a></h3>
<p><strong>Preview not showing:</strong></p>
<ol>
<li>Ensure MockForge server is running</li>
<li>Check that <code>mockforge.inlinePreview.enabled</code> is <code>true</code></li>
<li>Verify the endpoint path matches a configured mock</li>
<li>Check VS Code output panel for errors</li>
</ol>
<p><strong>Preview shows ‚ÄúNo mock configured‚Äù:</strong></p>
<ul>
<li>The endpoint doesn‚Äôt have a mock configured</li>
<li>Click ‚ÄúOpen in Playground‚Äù to create one</li>
<li>Or add a mock in <code>mockforge.yaml</code></li>
</ul>
<h2 id="feature-2-config-validation"><a class="header" href="#feature-2-config-validation">Feature 2: Config Validation</a></h2>
<p>Get real-time validation for your <code>mockforge.yaml</code> files with inline error reporting.</p>
<h3 id="how-it-works-1"><a class="header" href="#how-it-works-1">How It Works</a></h3>
<ol>
<li><strong>Open <code>mockforge.yaml</code></strong> in VS Code</li>
<li><strong>See inline errors</strong> for invalid configuration</li>
<li><strong>Get helpful messages</strong> for missing fields, type mismatches, and invalid values</li>
<li><strong>Auto-detect schema type</strong> based on file name and location</li>
</ol>
<h3 id="supported-config-types"><a class="header" href="#supported-config-types">Supported Config Types</a></h3>
<p>The extension validates:</p>
<ul>
<li><strong>Main config</strong>: <code>mockforge.yaml</code>, <code>mockforge.yml</code>, <code>mockforge.json</code></li>
<li><strong>Blueprint config</strong>: <code>blueprint.yaml</code></li>
<li><strong>Reality config</strong>: Files in <code>reality/</code> directory or <code>reality*.yaml</code></li>
<li><strong>Persona config</strong>: Files in <code>personas/</code> directory</li>
</ul>
<h3 id="example-validation"><a class="header" href="#example-validation">Example Validation</a></h3>
<p><strong>Invalid Configuration:</strong></p>
<pre><code class="language-yaml"># mockforge.yaml
reality:
  level: invalid_level  # ‚ùå Error shown here
</code></pre>
<p><strong>Error Message:</strong></p>
<pre><code>Invalid reality level: invalid_level. Valid values: static, light, moderate, high, chaos
</code></pre>
<p><strong>Valid Configuration:</strong></p>
<pre><code class="language-yaml"># mockforge.yaml
reality:
  level: moderate  # ‚úÖ No errors
</code></pre>
<h3 id="schema-generation"><a class="header" href="#schema-generation">Schema Generation</a></h3>
<p>The extension can auto-generate schemas:</p>
<ol>
<li>
<p><strong>Run schema generation:</strong></p>
<pre><code class="language-bash">mockforge schema generate
</code></pre>
</li>
<li>
<p><strong>Schemas are saved</strong> to <code>schemas/</code> directory</p>
</li>
<li>
<p><strong>Extension auto-detects</strong> schemas in:</p>
<ul>
<li><code>schemas/</code> directory</li>
<li><code>.mockforge/</code> directory</li>
<li>Project root</li>
</ul>
</li>
</ol>
<h3 id="validation-features"><a class="header" href="#validation-features">Validation Features</a></h3>
<ul>
<li><strong>Real-time validation</strong>: Errors appear as you type</li>
<li><strong>Accurate positions</strong>: Line and column numbers for errors</li>
<li><strong>Helpful messages</strong>: Clear descriptions of what‚Äôs wrong</li>
<li><strong>Auto-detection</strong>: Automatically detects schema type</li>
<li><strong>Multiple schemas</strong>: Supports all MockForge config types</li>
</ul>
<h3 id="troubleshooting-11"><a class="header" href="#troubleshooting-11">Troubleshooting</a></h3>
<p><strong>Validation not working:</strong></p>
<ol>
<li>Ensure you have a <code>mockforge.yaml</code> file open</li>
<li>Check that schemas are available:
<ul>
<li>Look for <code>schemas/</code> directory</li>
<li>Or run <code>mockforge schema generate</code></li>
</ul>
</li>
<li>Check VS Code output panel for validation errors</li>
</ol>
<p><strong>Schema not found:</strong></p>
<ul>
<li>Run <code>mockforge schema generate</code> to create schemas</li>
<li>Or manually place schemas in <code>schemas/</code> directory</li>
</ul>
<h2 id="feature-3-mocks-explorer"><a class="header" href="#feature-3-mocks-explorer">Feature 3: Mocks Explorer</a></h2>
<p>Visual tree view of all your mocks with real-time WebSocket updates.</p>
<h3 id="accessing-mocks-explorer"><a class="header" href="#accessing-mocks-explorer">Accessing Mocks Explorer</a></h3>
<ol>
<li><strong>Click MockForge icon</strong> in Activity Bar (left sidebar)</li>
<li><strong>Open ‚ÄúMocks Explorer‚Äù</strong> view</li>
<li><strong>Browse all mocks</strong> in a tree view</li>
</ol>
<h3 id="features-2"><a class="header" href="#features-2">Features</a></h3>
<ul>
<li><strong>Color-coded by HTTP method</strong>: GET (blue), POST (green), PUT (orange), DELETE (red)</li>
<li><strong>Real-time updates</strong>: Changes sync automatically via WebSocket</li>
<li><strong>Context menu actions</strong>:
<ul>
<li>Edit Mock</li>
<li>Delete Mock</li>
<li>Toggle Mock (enable/disable)</li>
<li>View Details</li>
</ul>
</li>
</ul>
<h3 id="using-mocks-explorer"><a class="header" href="#using-mocks-explorer">Using Mocks Explorer</a></h3>
<p><strong>View Mocks:</strong></p>
<ol>
<li>Open Mocks Explorer</li>
<li>Click on a mock to see details</li>
<li>Expand folders to see grouped mocks</li>
</ol>
<p><strong>Edit Mock:</strong></p>
<ol>
<li>Right-click on a mock</li>
<li>Select ‚ÄúEdit Mock‚Äù</li>
<li>Modify JSON configuration</li>
<li>Save to update</li>
</ol>
<p><strong>Toggle Mock:</strong></p>
<ol>
<li>Right-click on a mock</li>
<li>Select ‚ÄúToggle Mock‚Äù</li>
<li>Mock is enabled/disabled</li>
</ol>
<p><strong>Delete Mock:</strong></p>
<ol>
<li>Right-click on a mock</li>
<li>Select ‚ÄúDelete Mock‚Äù</li>
<li>Confirm deletion</li>
</ol>
<h2 id="feature-4-playground-integration"><a class="header" href="#feature-4-playground-integration">Feature 4: Playground Integration</a></h2>
<p>Quick access to MockForge Playground from hover tooltips and commands.</p>
<h3 id="from-hover-tooltip"><a class="header" href="#from-hover-tooltip">From Hover Tooltip</a></h3>
<ol>
<li><strong>Hover over an endpoint</strong> in your code</li>
<li><strong>See the tooltip</strong> with mock response</li>
<li><strong>Click ‚ÄúOpen in Playground‚Äù</strong> link</li>
<li><strong>Playground opens</strong> in browser with endpoint pre-filled</li>
</ol>
<h3 id="from-command-palette"><a class="header" href="#from-command-palette">From Command Palette</a></h3>
<ol>
<li><strong>Open Command Palette</strong> (Ctrl+Shift+P / Cmd+Shift+P)</li>
<li><strong>Type ‚ÄúMockForge: Open Playground‚Äù</strong></li>
<li><strong>Enter endpoint details</strong> (method and path)</li>
<li><strong>Playground opens</strong> in browser</li>
</ol>
<h3 id="playground-url-format"><a class="header" href="#playground-url-format">Playground URL Format</a></h3>
<p>The extension constructs URLs like:</p>
<pre><code>http://localhost:3000/admin/#/playground?method=GET&amp;path=/api/users
</code></pre>
<p>For standalone admin UI:</p>
<pre><code>http://localhost:9080/#/playground?method=GET&amp;path=/api/users
</code></pre>
<h2 id="feature-5-server-control"><a class="header" href="#feature-5-server-control">Feature 5: Server Control</a></h2>
<p>Monitor your MockForge server status and statistics.</p>
<h3 id="accessing-server-control"><a class="header" href="#accessing-server-control">Accessing Server Control</a></h3>
<ol>
<li><strong>Click MockForge icon</strong> in Activity Bar</li>
<li><strong>Open ‚ÄúServer Control‚Äù</strong> view</li>
<li><strong>View server statistics</strong></li>
</ol>
<h3 id="information-displayed"><a class="header" href="#information-displayed">Information Displayed</a></h3>
<ul>
<li><strong>Connection status</strong>: Connected / Disconnected</li>
<li><strong>Server version</strong>: MockForge version</li>
<li><strong>Server port</strong>: Port number</li>
<li><strong>Uptime</strong>: How long server has been running</li>
<li><strong>Request count</strong>: Total requests processed</li>
<li><strong>Active mocks</strong>: Number of active mocks</li>
</ul>
<h3 id="quick-actions"><a class="header" href="#quick-actions">Quick Actions</a></h3>
<ul>
<li><strong>Start Server</strong>: Start MockForge server</li>
<li><strong>Stop Server</strong>: Stop MockForge server</li>
<li><strong>Restart Server</strong>: Restart MockForge server</li>
</ul>
<h2 id="complete-workflow-example-2"><a class="header" href="#complete-workflow-example-2">Complete Workflow Example</a></h2>
<p>Let‚Äôs walk through a complete workflow using all features:</p>
<h3 id="1-install-extension"><a class="header" href="#1-install-extension">1. Install Extension</a></h3>
<pre><code class="language-bash">code --install-extension saasy-solutions.mockforge-vscode
</code></pre>
<h3 id="2-start-mockforge-server"><a class="header" href="#2-start-mockforge-server">2. Start MockForge Server</a></h3>
<pre><code class="language-bash">mockforge serve
</code></pre>
<h3 id="3-configure-extension"><a class="header" href="#3-configure-extension">3. Configure Extension</a></h3>
<p>Add to <code>.vscode/settings.json</code>:</p>
<pre><code class="language-json">{
  "mockforge.serverUrl": "http://localhost:3000",
  "mockforge.autoConnect": true,
  "mockforge.inlinePreview.enabled": true
}
</code></pre>
<h3 id="4-create-mock-config"><a class="header" href="#4-create-mock-config">4. Create Mock Config</a></h3>
<p>Create <code>mockforge.yaml</code>:</p>
<pre><code class="language-yaml">http:
  port: 3000

responses:
  - path: /api/users
    method: GET
    body:
      users:
        - id: 1
          name: "John Doe"
          email: "john@example.com"
        - id: 2
          name: "Jane Smith"
          email: "jane@example.com"
</code></pre>
<h3 id="5-use-peek-response"><a class="header" href="#5-use-peek-response">5. Use Peek Response</a></h3>
<p>In your code:</p>
<pre><code class="language-typescript">// Hover over this endpoint to see the mock response
const response = await fetch('/api/users');
</code></pre>
<p><strong>Hover tooltip shows:</strong></p>
<pre><code class="language-json">{
  "users": [
    {
      "id": 1,
      "name": "John Doe",
      "email": "john@example.com"
    },
    {
      "id": 2,
      "name": "Jane Smith",
      "email": "jane@example.com"
    }
  ]
}
</code></pre>
<h3 id="6-open-in-playground"><a class="header" href="#6-open-in-playground">6. Open in Playground</a></h3>
<p>Click ‚ÄúOpen in Playground‚Äù in the hover tooltip to test the endpoint interactively.</p>
<h3 id="7-validate-config"><a class="header" href="#7-validate-config">7. Validate Config</a></h3>
<p>Edit <code>mockforge.yaml</code> and see real-time validation:</p>
<pre><code class="language-yaml">reality:
  level: moderate  # ‚úÖ Valid
</code></pre>
<pre><code class="language-yaml">reality:
  level: invalid  # ‚ùå Error: Invalid reality level
</code></pre>
<h3 id="8-manage-mocks"><a class="header" href="#8-manage-mocks">8. Manage Mocks</a></h3>
<ul>
<li>Open Mocks Explorer</li>
<li>View all mocks</li>
<li>Edit, delete, or toggle mocks</li>
<li>See real-time updates</li>
</ul>
<h2 id="advanced-usage-2"><a class="header" href="#advanced-usage-2">Advanced Usage</a></h2>
<h3 id="custom-server-url"><a class="header" href="#custom-server-url">Custom Server URL</a></h3>
<p>For different environments:</p>
<pre><code class="language-json">{
  "mockforge.serverUrl": "http://localhost:3001"
}
</code></pre>
<h3 id="disable-auto-connect"><a class="header" href="#disable-auto-connect">Disable Auto-Connect</a></h3>
<p>If you want to connect manually:</p>
<pre><code class="language-json">{
  "mockforge.autoConnect": false
}
</code></pre>
<h3 id="disable-notifications"><a class="header" href="#disable-notifications">Disable Notifications</a></h3>
<p>To reduce notification noise:</p>
<pre><code class="language-json">{
  "mockforge.showNotifications": false
}
</code></pre>
<h3 id="disable-peek-response"><a class="header" href="#disable-peek-response">Disable Peek Response</a></h3>
<p>If you don‚Äôt want inline previews:</p>
<pre><code class="language-json">{
  "mockforge.inlinePreview.enabled": false
}
</code></pre>
<h2 id="troubleshooting-12"><a class="header" href="#troubleshooting-12">Troubleshooting</a></h2>
<h3 id="extension-not-connecting"><a class="header" href="#extension-not-connecting">Extension Not Connecting</a></h3>
<p><strong>Symptoms:</strong></p>
<ul>
<li>Mocks Explorer shows ‚ÄúDisconnected‚Äù</li>
<li>Peek response doesn‚Äôt work</li>
<li>Server Control shows disconnected</li>
</ul>
<p><strong>Solutions:</strong></p>
<ol>
<li>Check that MockForge server is running</li>
<li>Verify <code>mockforge.serverUrl</code> setting is correct</li>
<li>Check VS Code output panel for connection errors</li>
<li>Try restarting the extension: Command Palette ‚Üí ‚ÄúMockForge: Restart Extension‚Äù</li>
</ol>
<h3 id="validation-not-working-1"><a class="header" href="#validation-not-working-1">Validation Not Working</a></h3>
<p><strong>Symptoms:</strong></p>
<ul>
<li>No inline errors in <code>mockforge.yaml</code></li>
<li>Validation errors not showing</li>
</ul>
<p><strong>Solutions:</strong></p>
<ol>
<li>Ensure you have a <code>mockforge.yaml</code> file open</li>
<li>Check that schemas are available:
<ul>
<li>Look for <code>schemas/</code> directory</li>
<li>Or run <code>mockforge schema generate</code></li>
</ul>
</li>
<li>Check VS Code output panel for validation errors</li>
<li>Try reloading the window: Command Palette ‚Üí ‚ÄúDeveloper: Reload Window‚Äù</li>
</ol>
<h3 id="peek-response-not-showing"><a class="header" href="#peek-response-not-showing">Peek Response Not Showing</a></h3>
<p><strong>Symptoms:</strong></p>
<ul>
<li>Hovering over endpoints doesn‚Äôt show tooltip</li>
<li>Tooltip shows ‚ÄúNo mock configured‚Äù</li>
</ul>
<p><strong>Solutions:</strong></p>
<ol>
<li>Ensure <code>mockforge.inlinePreview.enabled</code> is <code>true</code></li>
<li>Check that MockForge server is connected</li>
<li>Verify the endpoint path matches a configured mock</li>
<li>Try hovering over different endpoint patterns</li>
<li>Check VS Code output panel for errors</li>
</ol>
<h3 id="schema-not-found"><a class="header" href="#schema-not-found">Schema Not Found</a></h3>
<p><strong>Symptoms:</strong></p>
<ul>
<li>Validation says ‚ÄúSchema not available‚Äù</li>
<li>Auto-detection fails</li>
</ul>
<p><strong>Solutions:</strong></p>
<ol>
<li>Run <code>mockforge schema generate</code> to create schemas</li>
<li>Ensure schemas are in <code>schemas/</code> directory</li>
<li>Check that schema file names match expected patterns</li>
<li>Verify schema JSON is valid</li>
</ol>
<h2 id="keyboard-shortcuts-1"><a class="header" href="#keyboard-shortcuts-1">Keyboard Shortcuts</a></h2>
<p>The extension doesn‚Äôt define custom keyboard shortcuts by default, but you can add them:</p>
<pre><code class="language-json">{
  "key": "ctrl+shift+m",
  "command": "mockforge.refreshMocks"
}
</code></pre>
<h2 id="commands"><a class="header" href="#commands">Commands</a></h2>
<p>All extension commands are available via Command Palette (Ctrl+Shift+P / Cmd+Shift+P):</p>
<ul>
<li><code>MockForge: Refresh Mocks</code> - Refresh mocks list</li>
<li><code>MockForge: Create Mock</code> - Create a new mock</li>
<li><code>MockForge: Open Playground</code> - Open playground in browser</li>
<li><code>MockForge: Show Logs</code> - Show extension logs</li>
<li><code>MockForge: Restart Extension</code> - Restart the extension</li>
</ul>
<h2 id="best-practices-2"><a class="header" href="#best-practices-2">Best Practices</a></h2>
<h3 id="1-keep-server-running"><a class="header" href="#1-keep-server-running">1. Keep Server Running</a></h3>
<p>For best experience, keep MockForge server running while developing.</p>
<h3 id="2-generate-schemas"><a class="header" href="#2-generate-schemas">2. Generate Schemas</a></h3>
<p>Run <code>mockforge schema generate</code> to enable config validation.</p>
<h3 id="3-use-workspace-settings"><a class="header" href="#3-use-workspace-settings">3. Use Workspace Settings</a></h3>
<p>Configure extension per-project in <code>.vscode/settings.json</code>.</p>
<h3 id="4-enable-auto-connect"><a class="header" href="#4-enable-auto-connect">4. Enable Auto-Connect</a></h3>
<p>Set <code>mockforge.autoConnect: true</code> for seamless workflow.</p>
<h3 id="5-check-output-panel"><a class="header" href="#5-check-output-panel">5. Check Output Panel</a></h3>
<p>If something doesn‚Äôt work, check VS Code output panel for errors.</p>
<h2 id="related-documentation-2"><a class="header" href="#related-documentation-2">Related Documentation</a></h2>
<ul>
<li><a href="tutorials/../user-guide/ide-integration.html">IDE Integration Guide</a> - Detailed feature reference</li>
<li><a href="tutorials/../../vscode-extension/README.html">VS Code Extension README</a> - Extension documentation</li>
<li><a href="tutorials/../user-guide/configuration/files.html">Configuration Files</a> - Config file format</li>
<li><a href="tutorials/../getting-started/getting-started.html">Getting Started</a> - MockForge basics</li>
</ul>
<h2 id="next-steps-9"><a class="header" href="#next-steps-9">Next Steps</a></h2>
<ol>
<li><strong>Install the extension</strong> and configure it</li>
<li><strong>Start MockForge server</strong> and connect</li>
<li><strong>Try peek response</strong> by hovering over endpoints</li>
<li><strong>Validate your config</strong> by editing <code>mockforge.yaml</code></li>
<li><strong>Explore Mocks Explorer</strong> to manage your mocks</li>
<li><strong>Use Playground</strong> to test endpoints interactively</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="add-a-custom-plugin-1"><a class="header" href="#add-a-custom-plugin-1">Add a Custom Plugin</a></h1>
<p><strong>Goal</strong>: Extend MockForge with a plugin to add custom authentication or data generation functionality.</p>
<p><strong>Time</strong>: 10 minutes</p>
<h2 id="what-youll-learn-2"><a class="header" href="#what-youll-learn-2">What You‚Äôll Learn</a></h2>
<ul>
<li>Install a plugin from a remote source</li>
<li>Install a plugin from a local file</li>
<li>Use a plugin in your mock configuration</li>
<li>Create a simple custom plugin</li>
<li>Test and debug plugins</li>
</ul>
<h2 id="prerequisites-7"><a class="header" href="#prerequisites-7">Prerequisites</a></h2>
<ul>
<li>MockForge installed (<a href="tutorials/../getting-started/installation.html">Installation Guide</a>)</li>
<li>Basic understanding of MockForge configuration</li>
<li>(Optional) Rust toolchain for building custom plugins</li>
</ul>
<h2 id="step-1-install-a-pre-built-plugin"><a class="header" href="#step-1-install-a-pre-built-plugin">Step 1: Install a Pre-Built Plugin</a></h2>
<p>MockForge comes with example plugins you can install immediately.</p>
<h3 id="install-the-jwt-authentication-plugin"><a class="header" href="#install-the-jwt-authentication-plugin">Install the JWT Authentication Plugin</a></h3>
<pre><code class="language-bash"># Install from the examples directory (if building from source)
mockforge plugin install examples/plugins/auth-jwt

# Or install from a URL (when published)
mockforge plugin install https://github.com/SaaSy-Solutions/mockforge/releases/download/v1.0.0/auth-jwt-plugin.wasm
</code></pre>
<h3 id="verify-installation-1"><a class="header" href="#verify-installation-1">Verify Installation</a></h3>
<pre><code class="language-bash">mockforge plugin list
</code></pre>
<p>Output:</p>
<pre><code>Installed Plugins:
  - auth-jwt (v1.0.0)
    Description: JWT authentication and token generation
    Author: MockForge Team
</code></pre>
<h2 id="step-2-use-the-plugin-in-your-configuration"><a class="header" href="#step-2-use-the-plugin-in-your-configuration">Step 2: Use the Plugin in Your Configuration</a></h2>
<p>Create a config file that uses the JWT plugin:</p>
<p><strong><code>api-with-auth.yaml</code>:</strong></p>
<pre><code class="language-yaml">http:
  port: 3000
  response_template_expand: true

  # Load the plugin
  plugins:
    - name: auth-jwt
      config:
        secret: "my-super-secret-key"
        algorithm: HS256
        expiry: 3600  # 1 hour

  routes:
    # Login endpoint - generates JWT token
    - path: /auth/login
      method: POST
      response:
        status: 200
        headers:
          Content-Type: application/json
        body: |
          {
            "token": "{{plugin:auth-jwt:generate_token({{request.body.username}})}}",
            "expiresIn": 3600
          }

    # Protected endpoint - validates JWT
    - path: /users/me
      method: GET
      middleware:
        - plugin: auth-jwt
          action: validate_token
      response:
        status: 200
        body: |
          {
            "id": "{{uuid}}",
            "username": "{{plugin:auth-jwt:get_claim(username)}}",
            "email": "{{plugin:auth-jwt:get_claim(email)}}"
          }
</code></pre>
<h2 id="step-3-test-the-plugin"><a class="header" href="#step-3-test-the-plugin">Step 3: Test the Plugin</a></h2>
<p>Start the server:</p>
<pre><code class="language-bash">mockforge serve --config api-with-auth.yaml
</code></pre>
<h3 id="login-and-get-token"><a class="header" href="#login-and-get-token">Login and Get Token</a></h3>
<pre><code class="language-bash">curl -X POST http://localhost:3000/auth/login \
  -H "Content-Type: application/json" \
  -d '{"username": "alice", "password": "secret123"}'
</code></pre>
<p>Response:</p>
<pre><code class="language-json">{
  "token": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VybmFtZSI6ImFsaWNlIiwiZXhwIjoxNzA5NTY3ODkwfQ.signature",
  "expiresIn": 3600
}
</code></pre>
<h3 id="use-token-to-access-protected-endpoint"><a class="header" href="#use-token-to-access-protected-endpoint">Use Token to Access Protected Endpoint</a></h3>
<pre><code class="language-bash"># Save the token
TOKEN="eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9..."

# Access protected endpoint
curl http://localhost:3000/users/me \
  -H "Authorization: Bearer $TOKEN"
</code></pre>
<p>Response:</p>
<pre><code class="language-json">{
  "id": "550e8400-e29b-41d4-a716-446655440000",
  "username": "alice",
  "email": "alice@example.com"
}
</code></pre>
<h3 id="try-without-token-should-fail"><a class="header" href="#try-without-token-should-fail">Try Without Token (Should Fail)</a></h3>
<pre><code class="language-bash">curl http://localhost:3000/users/me
</code></pre>
<p>Response:</p>
<pre><code class="language-json">{
  "error": "Unauthorized",
  "message": "Missing or invalid JWT token"
}
</code></pre>
<h2 id="step-4-install-the-template-crypto-plugin"><a class="header" href="#step-4-install-the-template-crypto-plugin">Step 4: Install the Template Crypto Plugin</a></h2>
<p>Let‚Äôs install another plugin for encryption in templates:</p>
<pre><code class="language-bash">mockforge plugin install examples/plugins/template-crypto
</code></pre>
<p><strong><code>crypto-config.yaml</code>:</strong></p>
<pre><code class="language-yaml">http:
  port: 3000
  response_template_expand: true

  plugins:
    - name: template-crypto
      config:
        default_algorithm: aes-256-gcm

  routes:
    - path: /encrypt
      method: POST
      response:
        status: 200
        body: |
          {
            "encrypted": "{{plugin:template-crypto:encrypt({{request.body.message}})}}",
            "algorithm": "aes-256-gcm"
          }

    - path: /decrypt
      method: POST
      response:
        status: 200
        body: |
          {
            "decrypted": "{{plugin:template-crypto:decrypt({{request.body.encrypted}})}}"
          }
</code></pre>
<p>Test it:</p>
<pre><code class="language-bash"># Encrypt a message
curl -X POST http://localhost:3000/encrypt \
  -H "Content-Type: application/json" \
  -d '{"message": "secret data"}'

# Decrypt the result
curl -X POST http://localhost:3000/decrypt \
  -H "Content-Type: application/json" \
  -d '{"encrypted": "base64-encrypted-string"}'
</code></pre>
<h2 id="step-5-create-a-simple-custom-plugin"><a class="header" href="#step-5-create-a-simple-custom-plugin">Step 5: Create a Simple Custom Plugin</a></h2>
<p>Let‚Äôs create a custom plugin that generates fake company data.</p>
<h3 id="project-structure"><a class="header" href="#project-structure">Project Structure</a></h3>
<pre><code class="language-bash">mkdir my-company-plugin
cd my-company-plugin
cargo init --lib
</code></pre>
<p><strong><code>Cargo.toml</code>:</strong></p>
<pre><code class="language-toml">[package]
name = "company-data-plugin"
version = "0.1.0"
edition = "2021"

[lib]
crate-type = ["cdylib"]

[dependencies]
mockforge-plugin-api = "1.0"
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
fake = { version = "2.9", features = ["derive"] }
</code></pre>
<p><strong><code>src/lib.rs</code>:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_plugin_api::{Plugin, PluginContext, PluginResult};
use fake::{Fake, faker::company::en::*};
use serde_json::json;

pub struct CompanyDataPlugin;

impl Plugin for CompanyDataPlugin {
    fn name(&amp;self) -&gt; &amp;str {
        "company-data"
    }

    fn version(&amp;self) -&gt; &amp;str {
        "0.1.0"
    }

    fn execute(&amp;self, ctx: &amp;PluginContext) -&gt; PluginResult {
        match ctx.action.as_str() {
            "generate_company" =&gt; {
                let company_name: String = CompanyName().fake();
                let industry: String = Industry().fake();
                let buzzword: String = Buzzword().fake();

                Ok(json!({
                    "name": company_name,
                    "industry": industry,
                    "tagline": buzzword,
                    "founded": (1950..2024).fake::&lt;i32&gt;(),
                    "employees": (10..10000).fake::&lt;i32&gt;()
                }))
            }
            "generate_tagline" =&gt; {
                Ok(json!({
                    "tagline": Buzzword().fake::&lt;String&gt;()
                }))
            }
            _ =&gt; Err(format!("Unknown action: {}", ctx.action))
        }
    }
}

mockforge_plugin_api::export_plugin!(CompanyDataPlugin);
<span class="boring">}</span></code></pre></pre>
<h3 id="build-the-plugin"><a class="header" href="#build-the-plugin">Build the Plugin</a></h3>
<pre><code class="language-bash">cargo build --release --target wasm32-unknown-unknown
</code></pre>
<p>The compiled plugin will be at:</p>
<pre><code>target/wasm32-unknown-unknown/release/company_data_plugin.wasm
</code></pre>
<h2 id="step-6-install-and-use-your-custom-plugin"><a class="header" href="#step-6-install-and-use-your-custom-plugin">Step 6: Install and Use Your Custom Plugin</a></h2>
<pre><code class="language-bash"># Install from local file
mockforge plugin install ./target/wasm32-unknown-unknown/release/company_data_plugin.wasm
</code></pre>
<p><strong><code>company-api.yaml</code>:</strong></p>
<pre><code class="language-yaml">http:
  port: 3000
  response_template_expand: true

  plugins:
    - name: company-data

  routes:
    - path: /companies
      method: GET
      response:
        status: 200
        body: |
          [
            {{plugin:company-data:generate_company()}},
            {{plugin:company-data:generate_company()}},
            {{plugin:company-data:generate_company()}}
          ]

    - path: /tagline
      method: GET
      response:
        status: 200
        body: "{{plugin:company-data:generate_tagline()}}"
</code></pre>
<p>Test it:</p>
<pre><code class="language-bash">mockforge serve --config company-api.yaml

# Generate fake companies
curl http://localhost:3000/companies
</code></pre>
<p>Response:</p>
<pre><code class="language-json">[
  {
    "name": "Acme Corporation",
    "industry": "Technology",
    "tagline": "Innovative solutions for tomorrow",
    "founded": 1985,
    "employees": 2500
  },
  {
    "name": "GlobalTech Industries",
    "industry": "Manufacturing",
    "tagline": "Building the future",
    "founded": 2001,
    "employees": 850
  },
  {
    "name": "DataSync Solutions",
    "industry": "Software",
    "tagline": "Connecting businesses worldwide",
    "founded": 2015,
    "employees": 120
  }
]
</code></pre>
<h2 id="step-7-plugin-management-commands"><a class="header" href="#step-7-plugin-management-commands">Step 7: Plugin Management Commands</a></h2>
<h3 id="list-installed-plugins"><a class="header" href="#list-installed-plugins">List Installed Plugins</a></h3>
<pre><code class="language-bash">mockforge plugin list
</code></pre>
<h3 id="get-plugin-info"><a class="header" href="#get-plugin-info">Get Plugin Info</a></h3>
<pre><code class="language-bash">mockforge plugin info auth-jwt
</code></pre>
<h3 id="update-a-plugin"><a class="header" href="#update-a-plugin">Update a Plugin</a></h3>
<pre><code class="language-bash">mockforge plugin update auth-jwt
</code></pre>
<h3 id="uninstall-a-plugin"><a class="header" href="#uninstall-a-plugin">Uninstall a Plugin</a></h3>
<pre><code class="language-bash">mockforge plugin uninstall company-data
</code></pre>
<h3 id="install-with-version-pinning"><a class="header" href="#install-with-version-pinning">Install with Version Pinning</a></h3>
<pre><code class="language-bash"># From Git with version tag
mockforge plugin install https://github.com/user/plugin#v1.2.0

# From URL with checksum verification
mockforge plugin install https://example.com/plugin.wasm --checksum sha256:abc123...
</code></pre>
<h2 id="common-plugin-use-cases"><a class="header" href="#common-plugin-use-cases">Common Plugin Use Cases</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Use Case</th><th>Plugin Type</th><th>Example</th></tr></thead><tbody>
<tr><td><strong>Authentication</strong></td><td>Middleware</td><td>JWT, OAuth2, API keys</td></tr>
<tr><td><strong>Data Generation</strong></td><td>Template function</td><td>Faker, custom generators</td></tr>
<tr><td><strong>Data Transformation</strong></td><td>Response modifier</td><td>Format converters, encryption</td></tr>
<tr><td><strong>External Integration</strong></td><td>Data source</td><td>Database, CSV files, APIs</td></tr>
<tr><td><strong>Custom Validation</strong></td><td>Request validator</td><td>Business rule enforcement</td></tr>
<tr><td><strong>Rate Limiting</strong></td><td>Middleware</td><td>Token bucket, sliding window</td></tr>
</tbody></table>
</div>
<h2 id="plugin-security"><a class="header" href="#plugin-security">Plugin Security</a></h2>
<p>MockForge plugins run in a <strong>WebAssembly sandbox</strong> with:</p>
<ul>
<li><strong>Memory isolation</strong>: Plugins can‚Äôt access host memory</li>
<li><strong>Resource limits</strong>: CPU and memory usage capped</li>
<li><strong>No network access</strong>: Plugins can‚Äôt make external requests (unless explicitly allowed)</li>
<li><strong>File system restrictions</strong>: Limited file access</li>
</ul>
<h3 id="configure-plugin-permissions"><a class="header" href="#configure-plugin-permissions">Configure Plugin Permissions</a></h3>
<p><strong><code>config.yaml</code>:</strong></p>
<pre><code class="language-yaml">plugins:
  security:
    max_memory_mb: 50
    max_execution_ms: 1000
    allow_network: false
    allow_file_access: false

  plugins:
    - name: auth-jwt
      permissions:
        network: false
        file_read: false

    - name: db-connector
      permissions:
        network: true  # Needs network for DB connection
        file_read: true
</code></pre>
<h2 id="debugging-plugins"><a class="header" href="#debugging-plugins">Debugging Plugins</a></h2>
<h3 id="enable-plugin-debug-logs"><a class="header" href="#enable-plugin-debug-logs">Enable Plugin Debug Logs</a></h3>
<pre><code class="language-bash">MOCKFORGE_LOG_LEVEL=debug mockforge serve --config api-with-auth.yaml
</code></pre>
<h3 id="test-plugin-in-isolation"><a class="header" href="#test-plugin-in-isolation">Test Plugin in Isolation</a></h3>
<pre><code class="language-bash">mockforge plugin test auth-jwt --action generate_token --input '{"username": "test"}'
</code></pre>
<h3 id="plugin-benchmarking"><a class="header" href="#plugin-benchmarking">Plugin Benchmarking</a></h3>
<pre><code class="language-bash">mockforge plugin bench auth-jwt --iterations 1000
</code></pre>
<h2 id="troubleshooting-13"><a class="header" href="#troubleshooting-13">Troubleshooting</a></h2>
<p><strong>Plugin not found after installation?</strong></p>
<pre><code class="language-bash"># Check plugin directory
mockforge plugin list --verbose

# Reinstall
mockforge plugin install ./path/to/plugin.wasm --force
</code></pre>
<p><strong>Plugin execution fails?</strong></p>
<ul>
<li>Check plugin logs with <code>MOCKFORGE_LOG_LEVEL=debug</code></li>
<li>Verify plugin configuration syntax</li>
<li>Test plugin in isolation with <code>mockforge plugin test</code></li>
</ul>
<p><strong>Plugin build fails?</strong></p>
<pre><code class="language-bash"># Ensure wasm target is installed
rustup target add wasm32-unknown-unknown

# Clean and rebuild
cargo clean
cargo build --release --target wasm32-unknown-unknown
</code></pre>
<h2 id="whats-next-4"><a class="header" href="#whats-next-4">What‚Äôs Next?</a></h2>
<ul>
<li><a href="tutorials/../../docs/plugins/api-reference/core.html">Plugin API Reference</a> - Complete plugin API documentation</li>
<li><a href="tutorials/../../docs/plugins/development-guide.html">Plugin Development Guide</a> - Advanced plugin development</li>
<li><a href="tutorials/../../docs/plugins/security/model.html">Security Model</a> - Plugin security architecture</li>
<li><a href="tutorials/../../examples/plugins/README.html">Example Plugins</a> - More plugin examples</li>
</ul>
<hr />
<p><strong>Pro Tip</strong>: Plugins can be version-controlled and shared with your team. Commit the <code>.wasm</code> file or the source code to Git, and everyone can use the same custom functionality!</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="getting-started-with-mqtt"><a class="header" href="#getting-started-with-mqtt">Getting Started with MQTT</a></h1>
<p>MockForge includes a fully functional MQTT (Message Queuing Telemetry Transport) broker for testing IoT and pub/sub workflows in your applications. This guide will help you get started quickly.</p>
<h2 id="quick-start-2"><a class="header" href="#quick-start-2">Quick Start</a></h2>
<h3 id="1-enable-mqtt-in-configuration"><a class="header" href="#1-enable-mqtt-in-configuration">1. Enable MQTT in Configuration</a></h3>
<p>Create a configuration file or modify your existing <code>config.yaml</code>:</p>
<pre><code class="language-yaml">mqtt:
  enabled: true
  port: 1883
  host: "0.0.0.0"
  max_connections: 1000
  max_packet_size: 1048576  # 1MB
  keep_alive_secs: 60
</code></pre>
<h3 id="2-start-the-server"><a class="header" href="#2-start-the-server">2. Start the Server</a></h3>
<pre><code class="language-bash">mockforge serve --config config.yaml
</code></pre>
<p>You should see:</p>
<pre><code>üì° MQTT broker listening on localhost:1883
</code></pre>
<h3 id="3-connect-and-publish-a-test-message"><a class="header" href="#3-connect-and-publish-a-test-message">3. Connect and Publish a Test Message</a></h3>
<p>Using the <code>mosquitto</code> command-line tools:</p>
<pre><code class="language-bash"># Install mosquitto clients (Ubuntu/Debian)
sudo apt install mosquitto-clients

# Or on macOS
brew install mosquitto

# Publish a test message
mosquitto_pub -h localhost -p 1883 -t "sensors/temperature" -m "25.5" -q 1

# Subscribe to receive messages
mosquitto_sub -h localhost -p 1883 -t "sensors/temperature" -q 1
</code></pre>
<h3 id="4-verify-message-handling"><a class="header" href="#4-verify-message-handling">4. Verify Message Handling</a></h3>
<p>Messages are processed according to your fixtures configuration. Check server logs for routing information and fixture matching.</p>
<h2 id="using-command-line-tools"><a class="header" href="#using-command-line-tools">Using Command-Line Tools</a></h2>
<h3 id="mosquitto_pub"><a class="header" href="#mosquitto_pub">mosquitto_pub</a></h3>
<p>Publish messages to topics:</p>
<pre><code class="language-bash"># Simple publish
mosquitto_pub -h localhost -p 1883 -t "sensors/temp/room1" -m "23.5"

# With QoS 1 (at least once delivery)
mosquitto_pub -h localhost -p 1883 -t "devices/status" -m "online" -q 1

# With retained message
mosquitto_pub -h localhost -p 1883 -t "config/max_temp" -m "30.0" -r

# JSON payload
mosquitto_pub -h localhost -p 1883 -t "sensors/data" -m '{"temperature": 22.1, "humidity": 65}'
</code></pre>
<h3 id="mosquitto_sub"><a class="header" href="#mosquitto_sub">mosquitto_sub</a></h3>
<p>Subscribe to topics:</p>
<pre><code class="language-bash"># Subscribe to specific topic
mosquitto_sub -h localhost -p 1883 -t "sensors/temp/room1"

# Subscribe with wildcards
mosquitto_sub -h localhost -p 1883 -t "sensors/temp/+"
mosquitto_sub -h localhost -p 1883 -t "devices/#"

# Subscribe to all topics (for debugging)
mosquitto_sub -h localhost -p 1883 -t "#"
</code></pre>
<h3 id="mqtt-cli-commands"><a class="header" href="#mqtt-cli-commands">MQTT CLI Commands</a></h3>
<p>MockForge provides MQTT-specific CLI commands:</p>
<pre><code class="language-bash"># List active topics
mockforge mqtt topics

# List connected clients
mockforge mqtt clients

# Publish a message
mockforge mqtt publish sensors/temperature 25.5 --qos 1

# Subscribe to topics
mockforge mqtt subscribe "sensors/#" --qos 0
</code></pre>
<h2 id="supported-mqtt-features"><a class="header" href="#supported-mqtt-features">Supported MQTT Features</a></h2>
<p>MockForge MQTT broker implements MQTT 3.1.1 and 5.0 specifications with the following features:</p>
<h3 id="quality-of-service-qos-levels"><a class="header" href="#quality-of-service-qos-levels">Quality of Service (QoS) Levels</a></h3>
<ul>
<li><strong>QoS 0</strong> - At most once delivery (fire and forget)</li>
<li><strong>QoS 1</strong> - At least once delivery (acknowledged delivery)</li>
<li><strong>QoS 2</strong> - Exactly once delivery (assured delivery)</li>
</ul>
<h3 id="topic-management"><a class="header" href="#topic-management">Topic Management</a></h3>
<ul>
<li><strong>Single-level wildcards</strong> (<code>+</code>) - Match one topic level</li>
<li><strong>Multi-level wildcards</strong> (<code>#</code>) - Match multiple topic levels</li>
<li><strong>Retained messages</strong> - Store last message per topic</li>
<li><strong>Clean sessions</strong> - Persistent vs ephemeral subscriptions</li>
</ul>
<h3 id="connection-management"><a class="header" href="#connection-management">Connection Management</a></h3>
<ul>
<li><strong>Keep-alive handling</strong> - Automatic client timeout</li>
<li><strong>Will messages</strong> - Last-will-and-testament</li>
<li><strong>Session persistence</strong> - Restore subscriptions on reconnect</li>
</ul>
<h2 id="basic-configuration-options"><a class="header" href="#basic-configuration-options">Basic Configuration Options</a></h2>
<pre><code class="language-yaml">mqtt:
  enabled: true              # Enable/disable MQTT broker
  port: 1883                 # Port (1883 for MQTT, 8883 for MQTT over TLS)
  host: "0.0.0.0"            # Bind address
  max_connections: 1000      # Maximum concurrent connections
  max_packet_size: 1048576   # Maximum packet size (1MB)
  keep_alive_secs: 60        # Default keep-alive timeout

  # Advanced options
  max_inflight_messages: 20  # Maximum QoS 1/2 messages in flight
  max_queued_messages: 100   # Maximum queued messages per client
</code></pre>
<h2 id="environment-variables-1"><a class="header" href="#environment-variables-1">Environment Variables</a></h2>
<p>Override configuration with environment variables:</p>
<pre><code class="language-bash">export MOCKFORGE_MQTT_ENABLED=true
export MOCKFORGE_MQTT_PORT=1883
export MOCKFORGE_MQTT_HOST=0.0.0.0
export MOCKFORGE_MQTT_MAX_CONNECTIONS=1000

mockforge serve
</code></pre>
<h2 id="next-steps-10"><a class="header" href="#next-steps-10">Next Steps</a></h2>
<ul>
<li><a href="protocols/mqtt/./configuration.html">Configuration Reference</a> - Detailed configuration options</li>
<li><a href="protocols/mqtt/./fixtures.html">Fixtures</a> - Create MQTT scenarios and mock responses</li>
<li><a href="protocols/mqtt/./examples.html">Examples</a> - Real-world usage examples</li>
</ul>
<h2 id="troubleshooting-14"><a class="header" href="#troubleshooting-14">Troubleshooting</a></h2>
<h3 id="connection-refused"><a class="header" href="#connection-refused">Connection Refused</a></h3>
<p><strong>Problem</strong>: Cannot connect to MQTT broker</p>
<p><strong>Solutions</strong>:</p>
<ol>
<li>Verify MQTT is enabled: <code>mqtt.enabled: true</code></li>
<li>Check the port isn‚Äôt in use: <code>lsof -i :1883</code></li>
<li>Ensure server is running: Look for ‚ÄúMQTT broker listening‚Äù in logs</li>
</ol>
<h3 id="messages-not-received"><a class="header" href="#messages-not-received">Messages Not Received</a></h3>
<p><strong>Problem</strong>: Messages published but not received by subscribers</p>
<p><strong>Solutions</strong>:</p>
<ol>
<li>Check topic matching patterns</li>
<li>Verify QoS levels are compatible</li>
<li>Check for retained message conflicts</li>
<li>Review server logs for routing information</li>
</ol>
<h3 id="wildcard-issues"><a class="header" href="#wildcard-issues">Wildcard Issues</a></h3>
<p><strong>Problem</strong>: Wildcard subscriptions not working as expected</p>
<p><strong>Solutions</strong>:</p>
<ol>
<li><code>+</code> matches exactly one level: <code>sensors/+/temperature</code></li>
<li><code>#</code> matches multiple levels: <code>devices/#</code></li>
<li>Wildcards only work in subscriptions, not publications</li>
</ol>
<h2 id="common-use-cases-2"><a class="header" href="#common-use-cases-2">Common Use Cases</a></h2>
<h3 id="iot-device-simulation"><a class="header" href="#iot-device-simulation">IoT Device Simulation</a></h3>
<pre><code class="language-python"># Simulate multiple IoT sensors
import paho.mqtt.client as mqtt
import time
import random

def simulate_sensor(sensor_id, topic_prefix):
    client = mqtt.Client(f"sensor_{sensor_id}")
    client.connect("localhost", 1883, 60)

    while True:
        temperature = 20 + random.uniform(-5, 5)
        payload = f'{{"sensor_id": "{sensor_id}", "temperature": {temperature:.1f}}}'

        client.publish(f"{topic_prefix}/temperature", payload, qos=1)
        time.sleep(5)

# Start multiple sensors
for i in range(3):
    simulate_sensor(f"sensor_{i}", f"sensors/room{i}")
</code></pre>
<h3 id="testing-mqtt-applications"><a class="header" href="#testing-mqtt-applications">Testing MQTT Applications</a></h3>
<pre><code class="language-javascript">// In your test suite (Node.js with mqtt.js)
const mqtt = require('mqtt');

describe('Temperature Monitoring', () =&gt; {
  let client;

  beforeAll(() =&gt; {
    client = mqtt.connect('mqtt://localhost:1883');
  });

  afterAll(() =&gt; {
    client.end();
  });

  test('receives temperature updates', (done) =&gt; {
    client.subscribe('sensors/temperature/+', { qos: 1 });

    client.on('message', (topic, message) =&gt; {
      const data = JSON.parse(message.toString());
      expect(data).toHaveProperty('sensor_id');
      expect(data).toHaveProperty('temperature');
      expect(data.temperature).toBeGreaterThan(-50);
      expect(data.temperature).toBeLessThan(100);
      done();
    });

    // Trigger temperature reading in your app
    // Your app should publish to sensors/temperature/+
  });
});
</code></pre>
<h3 id="cicd-integration"><a class="header" href="#cicd-integration">CI/CD Integration</a></h3>
<pre><code class="language-yaml"># .github/workflows/test.yml
- name: Start MockForge MQTT
  run: |
    mockforge serve --mqtt --mqtt-port 1883 &amp;
    sleep 2

- name: Run MQTT tests
  env:
    MQTT_HOST: localhost
    MQTT_PORT: 1883
  run: npm test
</code></pre>
<h2 id="whats-next-5"><a class="header" href="#whats-next-5">What‚Äôs Next?</a></h2>
<p>Now that you have a basic MQTT broker running, explore:</p>
<ol>
<li><strong><a href="protocols/mqtt/./fixtures.html">Fixtures</a></strong> - Define MQTT message patterns and mock responses</li>
<li><strong><a href="protocols/mqtt/./configuration.html">Configuration</a></strong> - Fine-tune broker behavior</li>
<li><strong><a href="protocols/mqtt/./examples.html">Examples</a></strong> - See real-world implementations</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="mqtt-configuration-reference"><a class="header" href="#mqtt-configuration-reference">MQTT Configuration Reference</a></h1>
<p>This document provides a comprehensive reference for configuring the MockForge MQTT broker. The MQTT implementation supports all standard MQTT 3.1.1 and 5.0 features with additional MockForge-specific configuration options.</p>
<h2 id="basic-configuration-1"><a class="header" href="#basic-configuration-1">Basic Configuration</a></h2>
<pre><code class="language-yaml">mqtt:
  # Enable/disable MQTT broker
  enabled: true

  # Server binding
  port: 1883
  host: "0.0.0.0"

  # Connection limits
  max_connections: 1000

  # Message size limits
  max_packet_size: 1048576  # 1MB

  # Connection timeouts
  keep_alive_secs: 60
</code></pre>
<h2 id="advanced-configuration"><a class="header" href="#advanced-configuration">Advanced Configuration</a></h2>
<h3 id="connection-management-1"><a class="header" href="#connection-management-1">Connection Management</a></h3>
<pre><code class="language-yaml">mqtt:
  # Maximum concurrent connections
  max_connections: 1000

  # Maximum packet size (bytes)
  max_packet_size: 1048576  # 1MB

  # Default keep-alive timeout (seconds)
  keep_alive_secs: 60

  # Maximum QoS 1/2 messages in flight per client
  max_inflight_messages: 20

  # Maximum queued messages per client
  max_queued_messages: 100
</code></pre>
<h3 id="quality-of-service-qos"><a class="header" href="#quality-of-service-qos">Quality of Service (QoS)</a></h3>
<p>MockForge supports all MQTT QoS levels:</p>
<ul>
<li><strong>QoS 0</strong>: At most once delivery (fire and forget)</li>
<li><strong>QoS 1</strong>: At least once delivery (acknowledged)</li>
<li><strong>QoS 2</strong>: Exactly once delivery (assured)</li>
</ul>
<p>QoS levels are configured per fixture and can be overridden by client requests.</p>
<h3 id="retained-messages"><a class="header" href="#retained-messages">Retained Messages</a></h3>
<pre><code class="language-yaml">mqtt:
  # Enable retained message support
  retained_messages_enabled: true

  # Maximum retained messages per topic
  max_retained_per_topic: 1

  # Maximum total retained messages
  max_total_retained: 10000
</code></pre>
<h3 id="session-management"><a class="header" href="#session-management">Session Management</a></h3>
<pre><code class="language-yaml">mqtt:
  # Enable persistent sessions
  persistent_sessions: true

  # Session expiry (seconds)
  session_expiry_secs: 3600

  # Clean session behavior
  force_clean_session: false
</code></pre>
<h2 id="tlsssl-configuration"><a class="header" href="#tlsssl-configuration">TLS/SSL Configuration</a></h2>
<p>For secure MQTT (MQTT over TLS):</p>
<pre><code class="language-yaml">mqtt:
  # Use TLS
  tls_enabled: true
  tls_port: 8883

  # Certificate paths
  tls_cert_path: "/path/to/server.crt"
  tls_key_path: "/path/to/server.key"

  # Client certificate verification
  tls_require_client_cert: false
  tls_ca_path: "/path/to/ca.crt"
</code></pre>
<h2 id="authentication-and-authorization"><a class="header" href="#authentication-and-authorization">Authentication and Authorization</a></h2>
<h3 id="basic-authentication"><a class="header" href="#basic-authentication">Basic Authentication</a></h3>
<pre><code class="language-yaml">mqtt:
  # Enable authentication
  auth_enabled: true

  # Authentication method
  auth_method: "basic"  # basic, jwt, oauth2

  # User database
  users:
    - username: "user1"
      password: "password1"
      permissions:
        - "publish:sensors/#"
        - "subscribe:actuators/#"
    - username: "device1"
      password: "devicepass"
      permissions:
        - "publish:devices/device1/#"
        - "subscribe:commands/device1/#"
</code></pre>
<h3 id="jwt-authentication"><a class="header" href="#jwt-authentication">JWT Authentication</a></h3>
<pre><code class="language-yaml">mqtt:
  auth_method: "jwt"

  jwt:
    # JWT issuer
    issuer: "mockforge"

    # JWT audience
    audience: "mqtt-clients"

    # Secret key or public key path
    secret: "your-jwt-secret"
    # OR
    public_key_path: "/path/to/public.pem"

    # Token validation
    validate_exp: true
    validate_iat: true
    validate_nbf: true

    # Custom claims mapping
    claims_mapping:
      permissions: "perms"
      client_id: "client"
</code></pre>
<h2 id="topic-authorization"><a class="header" href="#topic-authorization">Topic Authorization</a></h2>
<pre><code class="language-yaml">mqtt:
  # Topic access control
  topic_acl:
    # Allow anonymous access to these topics
    anonymous_topics:
      - "public/#"

    # Deny access to these topics
    denied_topics:
      - "admin/#"
      - "system/#"

    # Require authentication for these topics
    authenticated_topics:
      - "private/#"
      - "secure/#"
</code></pre>
<h2 id="logging-and-monitoring"><a class="header" href="#logging-and-monitoring">Logging and Monitoring</a></h2>
<pre><code class="language-yaml">mqtt:
  # Log level
  log_level: "info"

  # Enable connection logging
  log_connections: true

  # Enable message logging (WARNING: can be verbose)
  log_messages: false

  # Metrics collection
  metrics_enabled: true

  # Prometheus metrics
  metrics_path: "/metrics"
  metrics_port: 9090
</code></pre>
<h2 id="performance-tuning"><a class="header" href="#performance-tuning">Performance Tuning</a></h2>
<pre><code class="language-yaml">mqtt:
  # Thread pool size
  worker_threads: 4

  # Connection backlog
  connection_backlog: 1024

  # Socket options
  socket:
    # TCP_NODELAY
    no_delay: true

    # SO_KEEPALIVE
    keep_alive: true

    # Buffer sizes
    send_buffer_size: 65536
    recv_buffer_size: 65536
</code></pre>
<h2 id="environment-variables-2"><a class="header" href="#environment-variables-2">Environment Variables</a></h2>
<p>Override configuration with environment variables:</p>
<pre><code class="language-bash"># Basic settings
export MOCKFORGE_MQTT_ENABLED=true
export MOCKFORGE_MQTT_PORT=1883
export MOCKFORGE_MQTT_HOST=0.0.0.0

# Connection limits
export MOCKFORGE_MQTT_MAX_CONNECTIONS=1000
export MOCKFORGE_MQTT_MAX_PACKET_SIZE=1048576

# TLS settings
export MOCKFORGE_MQTT_TLS_ENABLED=false
export MOCKFORGE_MQTT_TLS_CERT_PATH=/path/to/cert.pem
export MOCKFORGE_MQTT_TLS_KEY_PATH=/path/to/key.pem

# Authentication
export MOCKFORGE_MQTT_AUTH_ENABLED=true
export MOCKFORGE_MQTT_AUTH_METHOD=basic
</code></pre>
<h2 id="configuration-validation"><a class="header" href="#configuration-validation">Configuration Validation</a></h2>
<p>MockForge validates MQTT configuration on startup:</p>
<ul>
<li><strong>Port conflicts</strong>: Checks if the configured port is available</li>
<li><strong>Certificate validation</strong>: Verifies TLS certificates exist and are valid</li>
<li><strong>ACL consistency</strong>: Ensures topic ACL rules don‚Äôt conflict</li>
<li><strong>Resource limits</strong>: Validates connection and message limits are reasonable</li>
</ul>
<h2 id="configuration-examples"><a class="header" href="#configuration-examples">Configuration Examples</a></h2>
<h3 id="development-setup"><a class="header" href="#development-setup">Development Setup</a></h3>
<pre><code class="language-yaml">mqtt:
  enabled: true
  port: 1883
  host: "127.0.0.1"
  max_connections: 100
  log_connections: true
  log_messages: true
</code></pre>
<h3 id="production-setup"><a class="header" href="#production-setup">Production Setup</a></h3>
<pre><code class="language-yaml">mqtt:
  enabled: true
  port: 1883
  host: "0.0.0.0"
  max_connections: 10000
  tls_enabled: true
  tls_port: 8883
  tls_cert_path: "/etc/ssl/certs/mqtt.crt"
  tls_key_path: "/etc/ssl/private/mqtt.key"
  auth_enabled: true
  auth_method: "jwt"
  metrics_enabled: true
</code></pre>
<h3 id="iot-gateway"><a class="header" href="#iot-gateway">IoT Gateway</a></h3>
<pre><code class="language-yaml">mqtt:
  enabled: true
  port: 1883
  max_connections: 1000
  max_packet_size: 524288  # 512KB for sensor data
  keep_alive_secs: 300     # 5 minutes for battery-powered devices
  retained_messages_enabled: true
  max_total_retained: 5000
</code></pre>
<h2 id="troubleshooting-15"><a class="header" href="#troubleshooting-15">Troubleshooting</a></h2>
<h3 id="common-issues-2"><a class="header" href="#common-issues-2">Common Issues</a></h3>
<p><strong>High CPU Usage</strong></p>
<ul>
<li>Reduce <code>max_connections</code> or <code>worker_threads</code></li>
<li>Enable connection rate limiting</li>
<li>Check for connection leaks</li>
</ul>
<p><strong>Memory Issues</strong></p>
<ul>
<li>Lower <code>max_queued_messages</code> and <code>max_inflight_messages</code></li>
<li>Reduce <code>max_total_retained</code></li>
<li>Monitor retained message growth</li>
</ul>
<p><strong>Connection Timeouts</strong></p>
<ul>
<li>Increase <code>keep_alive_secs</code></li>
<li>Check network connectivity</li>
<li>Verify firewall settings</li>
</ul>
<p><strong>TLS Handshake Failures</strong></p>
<ul>
<li>Verify certificate validity</li>
<li>Check certificate chain</li>
<li>Ensure correct certificate format (PEM)</li>
</ul>
<h2 id="next-steps-11"><a class="header" href="#next-steps-11">Next Steps</a></h2>
<ul>
<li><a href="protocols/mqtt/../getting-started.html">Getting Started</a> - Basic MQTT setup</li>
<li><a href="protocols/mqtt/fixtures.html">Fixtures</a> - Define MQTT mock scenarios</li>
<li><a href="protocols/mqtt/examples.html">Examples</a> - Real-world usage examples</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="mqtt-fixtures"><a class="header" href="#mqtt-fixtures">MQTT Fixtures</a></h1>
<p>MQTT fixtures in MockForge define mock responses for MQTT topics. Unlike HTTP fixtures that respond to requests, MQTT fixtures define what messages should be published when clients publish to specific topics.</p>
<h2 id="basic-fixture-structure"><a class="header" href="#basic-fixture-structure">Basic Fixture Structure</a></h2>
<pre><code class="language-yaml">mqtt:
  fixtures:
    - identifier: "temperature-sensor"
      name: "Temperature Sensor Mock"
      topic_pattern: "^sensors/temperature/[^/]+$"
      qos: 1
      retained: false
      response:
        payload:
          sensor_id: "{{topic_param 2}}"
          temperature: "{{faker.float 15.0 35.0}}"
          unit: "celsius"
          timestamp: "{{now}}"
      auto_publish:
        enabled: false
        interval_ms: 1000
        count: 10
</code></pre>
<h2 id="topic-patterns"><a class="header" href="#topic-patterns">Topic Patterns</a></h2>
<p>MQTT fixtures use regex patterns to match topics:</p>
<pre><code class="language-yaml"># Match specific topic
topic_pattern: "^sensors/temperature/room1$"

# Match topic hierarchy with wildcards
topic_pattern: "^sensors/temperature/[^/]+$"

# Match multiple levels
topic_pattern: "^devices/.+/status$"

# Complex patterns
topic_pattern: "^([^/]+)/([^/]+)/(.+)$"
</code></pre>
<h2 id="response-configuration"><a class="header" href="#response-configuration">Response Configuration</a></h2>
<h3 id="static-responses"><a class="header" href="#static-responses">Static Responses</a></h3>
<pre><code class="language-yaml">response:
  payload:
    status: "online"
    version: "1.2.3"
    uptime: 3600
</code></pre>
<h3 id="dynamic-responses-with-templates"><a class="header" href="#dynamic-responses-with-templates">Dynamic Responses with Templates</a></h3>
<pre><code class="language-yaml">response:
  payload:
    sensor_id: "{{topic_param 1}}"
    temperature: "{{faker.float 20.0 30.0}}"
    humidity: "{{faker.float 40.0 80.0}}"
    timestamp: "{{now}}"
    random_id: "{{uuid}}"
</code></pre>
<h3 id="template-variables"><a class="header" href="#template-variables">Template Variables</a></h3>
<p>MockForge supports extensive templating for MQTT responses:</p>
<h4 id="topic-parameters"><a class="header" href="#topic-parameters">Topic Parameters</a></h4>
<ul>
<li><code>{{topic}}</code> - Full topic string</li>
<li><code>{{topic_param N}}</code> - Nth segment of topic (0-indexed)</li>
</ul>
<h4 id="random-data"><a class="header" href="#random-data">Random Data</a></h4>
<ul>
<li><code>{{uuid}}</code> - Random UUID</li>
<li><code>{{faker.float min max}}</code> - Random float between min and max</li>
<li><code>{{faker.int min max}}</code> - Random integer between min and max</li>
<li><code>{{rand.float}}</code> - Random float 0.0-1.0</li>
<li><code>{{rand.int}}</code> - Random integer</li>
</ul>
<h4 id="time-and-dates"><a class="header" href="#time-and-dates">Time and Dates</a></h4>
<ul>
<li><code>{{now}}</code> - Current timestamp (RFC3339)</li>
<li><code>{{now + 1h}}</code> - Future timestamp</li>
<li><code>{{now - 30m}}</code> - Past timestamp</li>
</ul>
<h4 id="environment-variables-3"><a class="header" href="#environment-variables-3">Environment Variables</a></h4>
<ul>
<li><code>{{env VAR_NAME}}</code> - Environment variable value</li>
</ul>
<h2 id="quality-of-service-qos-1"><a class="header" href="#quality-of-service-qos-1">Quality of Service (QoS)</a></h2>
<pre><code class="language-yaml"># QoS 0 - At most once (fire and forget)
qos: 0

# QoS 1 - At least once (acknowledged)
qos: 1

# QoS 2 - Exactly once (assured)
qos: 2
</code></pre>
<h2 id="retained-messages-1"><a class="header" href="#retained-messages-1">Retained Messages</a></h2>
<pre><code class="language-yaml"># Message is retained on the broker
retained: true

# Message is not retained
retained: false
</code></pre>
<h2 id="auto-publish-configuration"><a class="header" href="#auto-publish-configuration">Auto-Publish Configuration</a></h2>
<p>Automatically publish messages at regular intervals:</p>
<pre><code class="language-yaml">auto_publish:
  enabled: true
  interval_ms: 5000    # Publish every 5 seconds
  count: 100          # Publish 100 messages, then stop (optional)
</code></pre>
<h2 id="advanced-fixtures"><a class="header" href="#advanced-fixtures">Advanced Fixtures</a></h2>
<h3 id="conditional-responses"><a class="header" href="#conditional-responses">Conditional Responses</a></h3>
<pre><code class="language-yaml">fixtures:
  - identifier: "smart-sensor"
    name: "Smart Temperature Sensor"
    topic_pattern: "^sensors/temp/(.+)$"
    response:
      payload: |
        {
          "sensor_id": "{{topic_param 1}}",
          "temperature": {{faker.float 15.0 35.0}},
          "status": "{{#if (&gt; temperature 30.0)}}critical{{else}}normal{{/if}}",
          "timestamp": "{{now}}"
        }
    conditions:
      - variable: "temperature"
        operator: "&gt;"
        value: 30.0
        response:
          payload:
            sensor_id: "{{topic_param 1}}"
            temperature: "{{temperature}}"
            status: "critical"
            alert: true
</code></pre>
<h3 id="sequence-responses"><a class="header" href="#sequence-responses">Sequence Responses</a></h3>
<pre><code class="language-yaml">fixtures:
  - identifier: "sequence-demo"
    name: "Sequence Response Demo"
    topic_pattern: "^demo/sequence$"
    sequence:
      - payload:
          step: 1
          message: "Starting sequence"
      - payload:
          step: 2
          message: "Processing..."
      - payload:
          step: 3
          message: "Complete"
    sequence_reset: "manual"  # auto, manual, time
</code></pre>
<h3 id="error-simulation"><a class="header" href="#error-simulation">Error Simulation</a></h3>
<pre><code class="language-yaml">fixtures:
  - identifier: "faulty-sensor"
    name: "Faulty Sensor"
    topic_pattern: "^sensors/faulty/(.+)$"
    error_simulation:
      enabled: true
      error_rate: 0.1  # 10% of messages fail
      error_responses:
        - payload:
            error: "Sensor malfunction"
            code: "SENSOR_ERROR"
        - payload:
            error: "Communication timeout"
            code: "TIMEOUT"
</code></pre>
<h2 id="fixture-management"><a class="header" href="#fixture-management">Fixture Management</a></h2>
<h3 id="loading-fixtures"><a class="header" href="#loading-fixtures">Loading Fixtures</a></h3>
<pre><code class="language-bash"># Load fixtures from file
mockforge mqtt fixtures load ./fixtures/mqtt.yaml

# Load fixtures from directory
mockforge mqtt fixtures load ./fixtures/mqtt/
</code></pre>
<h3 id="auto-publish-control"><a class="header" href="#auto-publish-control">Auto-Publish Control</a></h3>
<pre><code class="language-bash"># Start auto-publishing for all fixtures
mockforge mqtt fixtures start-auto-publish

# Stop auto-publishing
mockforge mqtt fixtures stop-auto-publish

# Start specific fixture
mockforge mqtt fixtures start-auto-publish temperature-sensor
</code></pre>
<h3 id="fixture-validation"><a class="header" href="#fixture-validation">Fixture Validation</a></h3>
<p>MockForge validates fixtures on load:</p>
<ul>
<li><strong>Topic pattern syntax</strong> - Valid regex patterns</li>
<li><strong>Template variables</strong> - Available variables and functions</li>
<li><strong>QoS levels</strong> - Valid QoS values (0, 1, 2)</li>
<li><strong>JSON structure</strong> - Valid JSON payloads</li>
</ul>
<h2 id="examples-5"><a class="header" href="#examples-5">Examples</a></h2>
<h3 id="iot-sensor-network"><a class="header" href="#iot-sensor-network">IoT Sensor Network</a></h3>
<pre><code class="language-yaml">mqtt:
  fixtures:
    - identifier: "temp-sensor-room1"
      name: "Room 1 Temperature Sensor"
      topic_pattern: "^sensors/temperature/room1$"
      qos: 1
      retained: true
      response:
        payload:
          sensor_id: "room1"
          temperature: "{{faker.float 20.0 25.0}}"
          humidity: "{{faker.float 40.0 60.0}}"
          battery_level: "{{faker.float 80.0 100.0}}"
          timestamp: "{{now}}"

    - identifier: "motion-sensor"
      name: "Motion Sensor"
      topic_pattern: "^sensors/motion/(.+)$"
      qos: 0
      retained: false
      response:
        payload:
          sensor_id: "{{topic_param 1}}"
          motion_detected: "{{faker.boolean}}"
          timestamp: "{{now}}"
      auto_publish:
        enabled: true
        interval_ms: 30000  # Every 30 seconds
</code></pre>
<h3 id="smart-home-devices"><a class="header" href="#smart-home-devices">Smart Home Devices</a></h3>
<pre><code class="language-yaml">mqtt:
  fixtures:
    - identifier: "smart-light"
      name: "Smart Light Controller"
      topic_pattern: "^home/lights/(.+)/command$"
      qos: 1
      response:
        payload:
          device_id: "{{topic_param 1}}"
          command: "ack"
          status: "success"
          timestamp: "{{now}}"

    - identifier: "thermostat"
      name: "Smart Thermostat"
      topic_pattern: "^home/climate/thermostat$"
      qos: 2
      retained: true
      response:
        payload:
          temperature: "{{faker.float 18.0 25.0}}"
          humidity: "{{faker.float 35.0 65.0}}"
          mode: "{{faker.random_element heating cooling auto}}"
          setpoint: "{{faker.float 19.0 23.0}}"
          timestamp: "{{now}}"
</code></pre>
<h3 id="industrial-iot"><a class="header" href="#industrial-iot">Industrial IoT</a></h3>
<pre><code class="language-yaml">mqtt:
  fixtures:
    - identifier: "conveyor-belt"
      name: "Conveyor Belt Monitor"
      topic_pattern: "^factory/conveyor/(.+)/status$"
      qos: 1
      retained: true
      response:
        payload:
          conveyor_id: "{{topic_param 1}}"
          status: "{{faker.random_element running stopped maintenance}}"
          speed_rpm: "{{faker.float 50.0 150.0}}"
          temperature: "{{faker.float 25.0 45.0}}"
          vibration: "{{faker.float 0.1 2.0}}"
          timestamp: "{{now}}"
      auto_publish:
        enabled: true
        interval_ms: 5000

    - identifier: "quality-control"
      name: "Quality Control Station"
      topic_pattern: "^factory/qc/(.+)/result$"
      qos: 2
      response:
        payload:
          station_id: "{{topic_param 1}}"
          product_id: "{{uuid}}"
          quality_score: "{{faker.float 85.0 100.0}}"
          defects_found: "{{faker.int 0 3}}"
          passed: "{{#if (&gt; quality_score 90.0)}}true{{else}}false{{/if}}"
          timestamp: "{{now}}"
</code></pre>
<h2 id="best-practices-3"><a class="header" href="#best-practices-3">Best Practices</a></h2>
<h3 id="topic-design"><a class="header" href="#topic-design">Topic Design</a></h3>
<ul>
<li>Use hierarchical topics: <code>building/floor/room/device</code></li>
<li>Include device IDs: <code>sensors/temp/sensor_001</code></li>
<li>Use consistent naming conventions</li>
</ul>
<h3 id="qos-selection"><a class="header" href="#qos-selection">QoS Selection</a></h3>
<ul>
<li><strong>QoS 0</strong>: Sensor data, non-critical updates</li>
<li><strong>QoS 1</strong>: Important status updates, commands</li>
<li><strong>QoS 2</strong>: Critical control messages, financial data</li>
</ul>
<h3 id="retained-messages-2"><a class="header" href="#retained-messages-2">Retained Messages</a></h3>
<ul>
<li>Use for current state: <code>device/status</code>, <code>sensor/last_reading</code></li>
<li>Avoid for event data: <code>sensor/trigger</code>, <code>button/press</code></li>
</ul>
<h3 id="auto-publish"><a class="header" href="#auto-publish">Auto-Publish</a></h3>
<ul>
<li>Reasonable intervals: 1-60 seconds for sensors</li>
<li>Consider battery life for IoT devices</li>
<li>Use for simulation, not production data</li>
</ul>
<h2 id="next-steps-12"><a class="header" href="#next-steps-12">Next Steps</a></h2>
<ul>
<li><a href="protocols/mqtt/../getting-started.html">Getting Started</a> - Basic MQTT setup</li>
<li><a href="protocols/mqtt/configuration.html">Configuration</a> - Detailed configuration options</li>
<li><a href="protocols/mqtt/examples.html">Examples</a> - Real-world usage examples</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="mqtt-examples"><a class="header" href="#mqtt-examples">MQTT Examples</a></h1>
<p>This document provides real-world examples of using MockForge MQTT for testing IoT applications, microservices communication, and pub/sub systems.</p>
<h2 id="iot-device-simulation-1"><a class="header" href="#iot-device-simulation-1">IoT Device Simulation</a></h2>
<h3 id="smart-home-system"><a class="header" href="#smart-home-system">Smart Home System</a></h3>
<p><strong>Scenario</strong>: Test a smart home application that controls lights, thermostats, and security sensors.</p>
<p><strong>MockForge Configuration</strong>:</p>
<pre><code class="language-yaml">mqtt:
  enabled: true
  port: 1883

  fixtures:
    # Smart Lights
    - identifier: "living-room-light"
      name: "Living Room Light"
      topic_pattern: "^home/lights/living_room/command$"
      qos: 1
      response:
        payload:
          device_id: "living_room_light"
          status: "success"
          brightness: "{{faker.int 0 100}}"
          timestamp: "{{now}}"

    - identifier: "kitchen-light"
      name: "Kitchen Light"
      topic_pattern: "^home/lights/kitchen/command$"
      qos: 1
      response:
        payload:
          device_id: "kitchen_light"
          status: "success"
          color_temp: "{{faker.int 2700 6500}}"
          timestamp: "{{now}}"

    # Thermostat
    - identifier: "thermostat"
      name: "Smart Thermostat"
      topic_pattern: "^home/climate/thermostat$"
      qos: 2
      retained: true
      response:
        payload:
          temperature: "{{faker.float 18.0 25.0}}"
          humidity: "{{faker.float 35.0 65.0}}"
          mode: "{{faker.random_element heating cooling auto}}"
          setpoint: "{{faker.float 19.0 23.0}}"
          timestamp: "{{now}}"
      auto_publish:
        enabled: true
        interval_ms: 30000

    # Motion Sensors
    - identifier: "motion-sensor"
      name: "Motion Sensor"
      topic_pattern: "^home/security/motion/(.+)$"
      qos: 0
      response:
        payload:
          sensor_id: "{{topic_param 1}}"
          motion_detected: "{{faker.boolean}}"
          battery_level: "{{faker.float 70.0 100.0}}"
          timestamp: "{{now}}"
      auto_publish:
        enabled: true
        interval_ms: 15000
</code></pre>
<p><strong>Test Code (Python)</strong>:</p>
<pre><code class="language-python">import paho.mqtt.client as mqtt
import json
import time

def test_smart_home_integration():
    client = mqtt.Client("test-client")
    client.connect("localhost", 1883, 60)

    # Test light control
    client.publish("home/lights/living_room/command", json.dumps({
        "action": "turn_on",
        "brightness": 80
    }), qos=1)

    # Subscribe to responses
    responses = []
    def on_message(client, userdata, msg):
        responses.append(json.loads(msg.payload.decode()))

    client.on_message = on_message
    client.subscribe("home/lights/living_room/status")
    client.loop_start()

    # Wait for response
    time.sleep(1)
    client.loop_stop()

    assert len(responses) &gt; 0
    assert responses[0]["device_id"] == "living_room_light"
    assert responses[0]["status"] == "success"

    # Test thermostat reading
    client.subscribe("home/climate/thermostat")
    client.loop_start()
    time.sleep(2)  # Wait for auto-published message
    client.loop_stop()

    # Verify thermostat data
    thermostat_data = None
    for response in responses:
        if "temperature" in response:
            thermostat_data = response
            break

    assert thermostat_data is not None
    assert 18.0 &lt;= thermostat_data["temperature"] &lt;= 25.0
    assert thermostat_data["mode"] in ["heating", "cooling", "auto"]

    client.disconnect()
</code></pre>
<h3 id="industrial-iot-monitoring"><a class="header" href="#industrial-iot-monitoring">Industrial IoT Monitoring</a></h3>
<p><strong>Scenario</strong>: Test an industrial monitoring system with sensors, actuators, and PLCs.</p>
<p><strong>MockForge Configuration</strong>:</p>
<pre><code class="language-yaml">mqtt:
  enabled: true
  port: 1883
  max_connections: 100

  fixtures:
    # Temperature Sensors
    - identifier: "temp-sensor-1"
      name: "Temperature Sensor 1"
      topic_pattern: "^factory/sensors/temp/1$"
      qos: 1
      retained: true
      response:
        payload:
          sensor_id: "temp_1"
          temperature: "{{faker.float 20.0 80.0}}"
          unit: "celsius"
          status: "operational"
          timestamp: "{{now}}"
      auto_publish:
        enabled: true
        interval_ms: 5000

    # Pressure Sensors
    - identifier: "pressure-sensor"
      name: "Pressure Sensor"
      topic_pattern: "^factory/sensors/pressure/(.+)$"
      qos: 1
      response:
        payload:
          sensor_id: "{{topic_param 1}}"
          pressure: "{{faker.float 0.5 5.0}}"
          unit: "bar"
          threshold: 3.5
          alert: "{{#if (&gt; pressure 3.5)}}true{{else}}false{{/if}}"
          timestamp: "{{now}}"

    # Conveyor Belt Controller
    - identifier: "conveyor-controller"
      name: "Conveyor Belt Controller"
      topic_pattern: "^factory/actuators/conveyor/(.+)/command$"
      qos: 2
      response:
        payload:
          actuator_id: "{{topic_param 1}}"
          command_ack: true
          status: "executing"
          estimated_completion: "{{now + 5s}}"
          timestamp: "{{now}}"

    # Quality Control Station
    - identifier: "qc-station"
      name: "Quality Control Station"
      topic_pattern: "^factory/qc/station_(.+)/result$"
      qos: 2
      response:
        payload:
          station_id: "{{topic_param 1}}"
          product_id: "{{uuid}}"
          quality_score: "{{faker.float 85.0 100.0}}"
          defects: "{{faker.int 0 2}}"
          passed: "{{#if (&gt; quality_score 95.0)}}true{{else}}false{{/if}}"
          timestamp: "{{now}}"
</code></pre>
<p><strong>Test Code (JavaScript/Node.js)</strong>:</p>
<pre><code class="language-javascript">const mqtt = require('mqtt');

describe('Industrial IoT System', () =&gt; {
  let client;

  beforeAll(() =&gt; {
    client = mqtt.connect('mqtt://localhost:1883');
  });

  afterAll(() =&gt; {
    client.end();
  });

  test('sensor data collection', (done) =&gt; {
    const sensorData = [];

    client.subscribe('factory/sensors/temp/1');
    client.subscribe('factory/sensors/pressure/1');

    client.on('message', (topic, message) =&gt; {
      const data = JSON.parse(message.toString());
      sensorData.push({ topic, data });

      if (sensorData.length &gt;= 2) {
        // Verify temperature sensor
        const tempSensor = sensorData.find(s =&gt; s.topic === 'factory/sensors/temp/1');
        expect(tempSensor.data.temperature).toBeGreaterThanOrEqual(20);
        expect(tempSensor.data.temperature).toBeLessThanOrEqual(80);
        expect(tempSensor.data.unit).toBe('celsius');

        // Verify pressure sensor
        const pressureSensor = sensorData.find(s =&gt; s.topic === 'factory/sensors/pressure/1');
        expect(pressureSensor.data.pressure).toBeGreaterThanOrEqual(0.5);
        expect(pressureSensor.data.pressure).toBeLessThanOrEqual(5.0);
        expect(pressureSensor.data.unit).toBe('bar');

        client.unsubscribe(['factory/sensors/temp/1', 'factory/sensors/pressure/1']);
        done();
      }
    });

    // Trigger sensor readings
    client.publish('factory/sensors/temp/1/trigger', 'read');
    client.publish('factory/sensors/pressure/1/trigger', 'read');
  });

  test('actuator control', (done) =&gt; {
    client.subscribe('factory/actuators/conveyor/1/status');

    client.on('message', (topic, message) =&gt; {
      if (topic === 'factory/actuators/conveyor/1/status') {
        const status = JSON.parse(message.toString());
        expect(status.actuator_id).toBe('1');
        expect(status.command_ack).toBe(true);
        expect(status.status).toBe('executing');

        client.unsubscribe('factory/actuators/conveyor/1/status');
        done();
      }
    });

    // Send control command
    client.publish('factory/actuators/conveyor/1/command', JSON.stringify({
      action: 'start',
      speed: 50
    }), { qos: 2 });
  });

  test('quality control workflow', (done) =&gt; {
    client.subscribe('factory/qc/station_1/result');

    client.on('message', (topic, message) =&gt; {
      const result = JSON.parse(message.toString());
      expect(result.station_id).toBe('1');
      expect(result.quality_score).toBeGreaterThanOrEqual(85);
      expect(result.quality_score).toBeLessThanOrEqual(100);
      expect(typeof result.defects).toBe('number');
      expect(typeof result.passed).toBe('boolean');

      client.unsubscribe('factory/qc/station_1/result');
      done();
    });

    // Trigger quality check
    client.publish('factory/qc/station_1/check', JSON.stringify({
      product_id: 'PROD-001',
      batch_id: 'BATCH-2024'
    }));
  });
});
</code></pre>
<h2 id="microservices-communication"><a class="header" href="#microservices-communication">Microservices Communication</a></h2>
<h3 id="event-driven-architecture"><a class="header" href="#event-driven-architecture">Event-Driven Architecture</a></h3>
<p><strong>Scenario</strong>: Test microservices communicating via MQTT events.</p>
<p><strong>MockForge Configuration</strong>:</p>
<pre><code class="language-yaml">mqtt:
  enabled: true
  port: 1883

  fixtures:
    # User Service Events
    - identifier: "user-registered"
      name: "User Registration Event"
      topic_pattern: "^events/user/registered$"
      qos: 1
      response:
        payload:
          event_type: "user_registered"
          user_id: "{{uuid}}"
          email: "{{faker.email}}"
          timestamp: "{{now}}"
          source: "user-service"

    # Order Service Events
    - identifier: "order-created"
      name: "Order Created Event"
      topic_pattern: "^events/order/created$"
      qos: 1
      response:
        payload:
          event_type: "order_created"
          order_id: "{{uuid}}"
          user_id: "{{uuid}}"
          amount: "{{faker.float 10.0 500.0}}"
          currency: "USD"
          items: "{{faker.int 1 10}}"
          timestamp: "{{now}}"
          source: "order-service"

    # Payment Service Events
    - identifier: "payment-processed"
      name: "Payment Processed Event"
      topic_pattern: "^events/payment/processed$"
      qos: 2
      response:
        payload:
          event_type: "payment_processed"
          payment_id: "{{uuid}}"
          order_id: "{{uuid}}"
          amount: "{{faker.float 10.0 500.0}}"
          currency: "USD"
          status: "{{faker.random_element completed failed pending}}"
          method: "{{faker.random_element credit_card paypal bank_transfer}}"
          timestamp: "{{now}}"
          source: "payment-service"

    # Notification Service
    - identifier: "email-notification"
      name: "Email Notification"
      topic_pattern: "^commands/notification/email$"
      qos: 1
      response:
        payload:
          command_type: "send_email"
          notification_id: "{{uuid}}"
          recipient: "{{faker.email}}"
          subject: "Order Confirmation"
          template: "order_confirmation"
          status: "queued"
          timestamp: "{{now}}"
</code></pre>
<p><strong>Test Code (Go)</strong>:</p>
<pre><code class="language-go">package main

import (
    "encoding/json"
    "testing"
    "time"

    mqtt "github.com/eclipse/paho.mqtt.golang"
)

func TestEventDrivenWorkflow(t *testing.T) {
    opts := mqtt.NewClientOptions().AddBroker("tcp://localhost:1883")
    client := mqtt.NewClient(opts)

    if token := client.Connect(); token.Wait() &amp;&amp; token.Error() != nil {
        t.Fatalf("Failed to connect: %v", token.Error())
    }
    defer client.Disconnect(250)

    // Test user registration -&gt; order creation -&gt; payment -&gt; notification flow
    events := make(chan map[string]interface{}, 10)

    // Subscribe to all events
    client.Subscribe("events/#", 1, func(client mqtt.Client, msg mqtt.Message) {
        var event map[string]interface{}
        json.Unmarshal(msg.Payload(), &amp;event)
        events &lt;- event
    })

    // Trigger user registration
    userEvent := map[string]interface{}{
        "user_id": "user-123",
        "email": "user@example.com",
    }
    payload, _ := json.Marshal(userEvent)
    client.Publish("events/user/registered", 1, false, payload)

    // Wait for events
    timeout := time.After(5 * time.Second)
    receivedEvents := make(map[string]int)

    for {
        select {
        case event := &lt;-events:
            eventType := event["event_type"].(string)
            receivedEvents[eventType]++

            // Verify event structure
            switch eventType {
            case "user_registered":
                if event["user_id"] == nil || event["email"] == nil {
                    t.Errorf("Invalid user_registered event: %v", event)
                }
            case "order_created":
                if event["order_id"] == nil || event["amount"] == nil {
                    t.Errorf("Invalid order_created event: %v", event)
                }
            case "payment_processed":
                if event["payment_id"] == nil || event["status"] == nil {
                    t.Errorf("Invalid payment_processed event: %v", event)
                }
            }
        case &lt;-timeout:
            // Check that we received expected events
            if receivedEvents["user_registered"] == 0 {
                t.Error("Expected user_registered event")
            }
            if receivedEvents["order_created"] == 0 {
                t.Error("Expected order_created event")
            }
            if receivedEvents["payment_processed"] == 0 {
                t.Error("Expected payment_processed event")
            }
            return
        }
    }
}
</code></pre>
<h2 id="real-time-data-streaming"><a class="header" href="#real-time-data-streaming">Real-Time Data Streaming</a></h2>
<h3 id="live-dashboard-testing"><a class="header" href="#live-dashboard-testing">Live Dashboard Testing</a></h3>
<p><strong>Scenario</strong>: Test a real-time dashboard that displays sensor data and alerts.</p>
<p><strong>MockForge Configuration</strong>:</p>
<pre><code class="language-yaml">mqtt:
  enabled: true
  port: 1883

  fixtures:
    # Environmental Sensors
    - identifier: "env-sensor-cluster"
      name: "Environmental Sensor Cluster"
      topic_pattern: "^sensors/env/(.+)/(.+)$"
      qos: 0
      response:
        payload:
          sensor_type: "{{topic_param 2}}"
          location: "{{topic_param 1}}"
          value: "{{#switch topic_param.2}}
                     {{#case 'temperature'}}{{faker.float 15.0 35.0}}{{/case}}
                     {{#case 'humidity'}}{{faker.float 30.0 90.0}}{{/case}}
                     {{#case 'co2'}}{{faker.float 400.0 2000.0}}{{/case}}
                     {{#default}}0{{/default}}
                   {{/switch}}"
          unit: "{{#switch topic_param.2}}
                   {{#case 'temperature'}}celsius{{/case}}
                   {{#case 'humidity'}}percent{{/case}}
                   {{#case 'co2'}}ppm{{/case}}
                   {{#default}}unit{{/default}}
                 {{/switch}}"
          timestamp: "{{now}}"
      auto_publish:
        enabled: true
        interval_ms: 2000

    # System Alerts
    - identifier: "system-alerts"
      name: "System Alerts"
      topic_pattern: "^alerts/system/(.+)$"
      qos: 1
      response:
        payload:
          alert_type: "{{topic_param 1}}"
          severity: "{{faker.random_element info warning error critical}}"
          message: "{{#switch topic_param.1}}
                      {{#case 'temperature'}}High temperature detected{{/case}}
                      {{#case 'power'}}Power supply issue{{/case}}
                      {{#case 'network'}}Network connectivity lost{{/case}}
                      {{#default}}System alert{{/default}}
                    {{/switch}}"
          sensor_id: "{{uuid}}"
          timestamp: "{{now}}"
      auto_publish:
        enabled: true
        interval_ms: 30000
</code></pre>
<p><strong>Test Code (Rust)</strong>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use paho_mqtt as mqtt;
use std::time::Duration;

#[tokio::test]
async fn test_realtime_dashboard() {
    let create_opts = mqtt::CreateOptionsBuilder::new()
        .server_uri("tcp://localhost:1883")
        .client_id("dashboard-test")
        .finalize();

    let mut client = mqtt::AsyncClient::new(create_opts).unwrap();
    let conn_opts = mqtt::ConnectOptions::new();
    client.connect(conn_opts).await.unwrap();

    // Subscribe to sensor data
    client.subscribe("sensors/env/+/temperature", mqtt::QOS_0).await.unwrap();
    client.subscribe("sensors/env/+/humidity", mqtt::QOS_0).await.unwrap();
    client.subscribe("alerts/system/+", mqtt::QOS_1).await.unwrap();

    let mut receiver = client.get_stream(100);
    let mut message_count = 0;
    let mut alerts_received = 0;

    // Collect messages for 10 seconds
    let start_time = std::time::Instant::now();
    while start_time.elapsed() &lt; Duration::from_secs(10) {
        if let Ok(Some(msg)) = tokio::time::timeout(Duration::from_millis(100), receiver.recv()).await {
            message_count += 1;

            let payload: serde_json::Value = serde_json::from_str(&amp;msg.payload_str()).unwrap();

            // Verify sensor data structure
            if msg.topic().contains("sensors/env") {
                assert!(payload.get("sensor_type").is_some());
                assert!(payload.get("location").is_some());
                assert!(payload.get("value").is_some());
                assert!(payload.get("unit").is_some());
                assert!(payload.get("timestamp").is_some());
            }

            // Count alerts
            if msg.topic().contains("alerts/system") {
                alerts_received += 1;
                assert!(payload.get("alert_type").is_some());
                assert!(payload.get("severity").is_some());
                assert!(payload.get("message").is_some());
            }
        }
    }

    // Verify we received data
    assert!(message_count &gt; 0, "No messages received");
    assert!(alerts_received &gt; 0, "No alerts received");

    client.disconnect(None).await.unwrap();
}
<span class="boring">}</span></code></pre></pre>
<h2 id="cicd-integration-1"><a class="header" href="#cicd-integration-1">CI/CD Integration</a></h2>
<h3 id="automated-testing-pipeline"><a class="header" href="#automated-testing-pipeline">Automated Testing Pipeline</a></h3>
<pre><code class="language-yaml"># .github/workflows/mqtt-tests.yml
name: MQTT Integration Tests

on: [push, pull_request]

jobs:
  mqtt-tests:
    runs-on: ubuntu-latest

    services:
      mockforge:
        image: mockforge:latest
        ports:
          - 1883:1883
        env:
          MOCKFORGE_MQTT_ENABLED: true
          MOCKFORGE_MQTT_FIXTURES: ./test-fixtures/mqtt/

    steps:
      - uses: actions/checkout@v3

      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'

      - name: Install dependencies
        run: npm ci

      - name: Wait for MockForge
        run: |
          timeout 30 bash -c 'until nc -z localhost 1883; do sleep 1; done'

      - name: Run MQTT tests
        run: npm test -- --testPathPattern=mqtt
        env:
          MQTT_BROKER: localhost:1883
</code></pre>
<h2 id="performance-testing"><a class="header" href="#performance-testing">Performance Testing</a></h2>
<h3 id="load-testing-mqtt-broker"><a class="header" href="#load-testing-mqtt-broker">Load Testing MQTT Broker</a></h3>
<pre><code class="language-yaml">mqtt:
  enabled: true
  port: 1883
  max_connections: 1000

  fixtures:
    - identifier: "load-test-sensor"
      name: "Load Test Sensor"
      topic_pattern: "^loadtest/sensor/(.+)$"
      qos: 0
      response:
        payload:
          sensor_id: "{{topic_param 1}}"
          value: "{{faker.float 0.0 100.0}}"
          timestamp: "{{now}}"
</code></pre>
<p><strong>Load Test Script (Python)</strong>:</p>
<pre><code class="language-python">import paho.mqtt.client as mqtt
import threading
import time
import json

def create_publisher(client_id, num_messages):
    client = mqtt.Client(f"publisher-{client_id}")
    client.connect("localhost", 1883, 60)

    for i in range(num_messages):
        payload = {
            "sensor_id": f"sensor_{client_id}_{i}",
            "value": i * 1.5,
            "timestamp": time.time()
        }
        client.publish(f"loadtest/sensor/{client_id}", json.dumps(payload), qos=0)

    client.disconnect()

def load_test():
    num_publishers = 50
    messages_per_publisher = 100

    start_time = time.time()

    threads = []
    for i in range(num_publishers):
        thread = threading.Thread(target=create_publisher, args=(i, messages_per_publisher))
        threads.append(thread)
        thread.start()

    for thread in threads:
        thread.join()

    end_time = time.time()
    total_messages = num_publishers * messages_per_publisher
    duration = end_time - start_time

    print(f"Published {total_messages} messages in {duration:.2f} seconds")
    print(f"Throughput: {total_messages / duration:.0f} messages/second")

if __name__ == "__main__":
    load_test()
</code></pre>
<h2 id="next-steps-13"><a class="header" href="#next-steps-13">Next Steps</a></h2>
<ul>
<li><a href="protocols/mqtt/../getting-started.html">Getting Started</a> - Basic MQTT setup</li>
<li><a href="protocols/mqtt/configuration.html">Configuration</a> - Detailed configuration options</li>
<li><a href="protocols/mqtt/fixtures.html">Fixtures</a> - Define MQTT mock scenarios</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="getting-started-with-smtp"><a class="header" href="#getting-started-with-smtp">Getting Started with SMTP</a></h1>
<p>MockForge includes a fully functional SMTP (Simple Mail Transfer Protocol) server for testing email workflows in your applications. This guide will help you get started quickly.</p>
<h2 id="quick-start-3"><a class="header" href="#quick-start-3">Quick Start</a></h2>
<h3 id="1-enable-smtp-in-configuration"><a class="header" href="#1-enable-smtp-in-configuration">1. Enable SMTP in Configuration</a></h3>
<p>Create a configuration file or modify your existing <code>config.yaml</code>:</p>
<pre><code class="language-yaml">smtp:
  enabled: true
  port: 1025
  host: "0.0.0.0"
  hostname: "mockforge-smtp"
</code></pre>
<h3 id="2-start-the-server-1"><a class="header" href="#2-start-the-server-1">2. Start the Server</a></h3>
<pre><code class="language-bash">mockforge serve --config config.yaml
</code></pre>
<p>You should see:</p>
<pre><code>üìß SMTP server listening on localhost:1025
</code></pre>
<h3 id="3-send-a-test-email"><a class="header" href="#3-send-a-test-email">3. Send a Test Email</a></h3>
<p>Using Python‚Äôs built-in <code>smtplib</code>:</p>
<pre><code class="language-python">import smtplib
from email.message import EmailMessage

msg = EmailMessage()
msg['Subject'] = 'Test Email'
msg['From'] = 'sender@example.com'
msg['To'] = 'recipient@example.com'
msg.set_content('This is a test email from Python.')

with smtplib.SMTP('localhost', 1025) as server:
    server.send_message(msg)
    print("Email sent successfully!")
</code></pre>
<h3 id="4-verify-email-reception"><a class="header" href="#4-verify-email-reception">4. Verify Email Reception</a></h3>
<p>Currently, emails are stored in the in-memory mailbox. You can verify by checking the server logs or using the API endpoints (if UI is enabled).</p>
<h2 id="using-command-line-tools-1"><a class="header" href="#using-command-line-tools-1">Using Command-Line Tools</a></h2>
<h3 id="telnet"><a class="header" href="#telnet">telnet</a></h3>
<pre><code class="language-bash">telnet localhost 1025
&gt; EHLO client.example.com
&gt; MAIL FROM:&lt;sender@example.com&gt;
&gt; RCPT TO:&lt;recipient@example.com&gt;
&gt; DATA
&gt; Subject: Test Email
&gt;
&gt; This is a test email.
&gt; .
&gt; QUIT
</code></pre>
<h3 id="swaks-smtp-testing-tool"><a class="header" href="#swaks-smtp-testing-tool">swaks (SMTP Testing Tool)</a></h3>
<p><a href="http://www.jetmore.org/john/code/swaks/">swaks</a> is a powerful SMTP testing tool:</p>
<pre><code class="language-bash"># Install swaks
# On Ubuntu/Debian: apt install swaks
# On macOS: brew install swaks

# Send test email
swaks --to recipient@example.com \
      --from sender@example.com \
      --server localhost:1025 \
      --body "Test email from swaks" \
      --header "Subject: Test"
</code></pre>
<h2 id="supported-smtp-commands"><a class="header" href="#supported-smtp-commands">Supported SMTP Commands</a></h2>
<p>MockForge SMTP server implements RFC 5321 and supports:</p>
<ul>
<li><strong>HELO</strong> / <strong>EHLO</strong> - Client introduction</li>
<li><strong>MAIL FROM</strong> - Specify sender</li>
<li><strong>RCPT TO</strong> - Specify recipient(s)</li>
<li><strong>DATA</strong> - Send message content</li>
<li><strong>RSET</strong> - Reset session</li>
<li><strong>NOOP</strong> - No operation (keepalive)</li>
<li><strong>QUIT</strong> - End session</li>
<li><strong>HELP</strong> - List supported commands</li>
</ul>
<h2 id="basic-configuration-options-1"><a class="header" href="#basic-configuration-options-1">Basic Configuration Options</a></h2>
<pre><code class="language-yaml">smtp:
  enabled: true               # Enable/disable SMTP server
  port: 1025                  # Port (1025 for dev, 25 for prod)
  host: "0.0.0.0"             # Bind address
  hostname: "mockforge-smtp"  # Server hostname in greeting

  # Mailbox settings
  enable_mailbox: true
  max_mailbox_messages: 1000

  # Timeouts
  timeout_secs: 30
  max_connections: 100
</code></pre>
<h2 id="environment-variables-4"><a class="header" href="#environment-variables-4">Environment Variables</a></h2>
<p>Override configuration with environment variables:</p>
<pre><code class="language-bash">export MOCKFORGE_SMTP_ENABLED=true
export MOCKFORGE_SMTP_PORT=1025
export MOCKFORGE_SMTP_HOST=0.0.0.0
export MOCKFORGE_SMTP_HOSTNAME=my-smtp-server

mockforge serve
</code></pre>
<h2 id="next-steps-14"><a class="header" href="#next-steps-14">Next Steps</a></h2>
<ul>
<li><a href="protocols/smtp/./configuration.html">Configuration Reference</a> - Detailed configuration options</li>
<li><a href="protocols/smtp/./fixtures.html">Fixtures</a> - Create email scenarios and auto-replies</li>
<li><a href="protocols/smtp/./examples.html">Examples</a> - Real-world usage examples</li>
</ul>
<h2 id="troubleshooting-16"><a class="header" href="#troubleshooting-16">Troubleshooting</a></h2>
<h3 id="connection-refused-1"><a class="header" href="#connection-refused-1">Connection Refused</a></h3>
<p><strong>Problem</strong>: Cannot connect to SMTP server</p>
<p><strong>Solutions</strong>:</p>
<ol>
<li>Verify SMTP is enabled: <code>smtp.enabled: true</code></li>
<li>Check the port isn‚Äôt in use: <code>lsof -i :1025</code></li>
<li>Ensure server is running: Look for ‚ÄúSMTP server listening‚Äù in logs</li>
</ol>
<h3 id="email-not-received"><a class="header" href="#email-not-received">Email Not Received</a></h3>
<p><strong>Problem</strong>: Email sent but not stored</p>
<p><strong>Solutions</strong>:</p>
<ol>
<li>Check mailbox is enabled: <code>smtp.enable_mailbox: true</code></li>
<li>Verify mailbox size limit: <code>smtp.max_mailbox_messages</code></li>
<li>Check server logs for errors</li>
</ol>
<h3 id="permission-denied-on-port-25"><a class="header" href="#permission-denied-on-port-25">Permission Denied on Port 25</a></h3>
<p><strong>Problem</strong>: Cannot bind to port 25</p>
<p><strong>Solution</strong>: Ports below 1024 require root privileges. Use port 1025 for development or run with sudo for production testing.</p>
<h2 id="common-use-cases-3"><a class="header" href="#common-use-cases-3">Common Use Cases</a></h2>
<h3 id="testing-email-workflows"><a class="header" href="#testing-email-workflows">Testing Email Workflows</a></h3>
<pre><code class="language-python"># In your test suite
def test_user_registration_sends_welcome_email():
    # Register user (triggers email send)
    response = client.post('/register', json={
        'email': 'newuser@example.com',
        'password': 'secret'
    })

    assert response.status_code == 201

    # Verify email was sent to MockForge SMTP
    emails = get_emails_from_mockforge()
    assert len(emails) == 1
    assert emails[0]['to'] == 'newuser@example.com'
    assert 'Welcome' in emails[0]['subject']
</code></pre>
<h3 id="cicd-integration-2"><a class="header" href="#cicd-integration-2">CI/CD Integration</a></h3>
<pre><code class="language-yaml"># .github/workflows/test.yml
- name: Start MockForge SMTP
  run: |
    mockforge serve --smtp --smtp-port 1025 &amp;
    sleep 2

- name: Run tests
  env:
    SMTP_HOST: localhost
    SMTP_PORT: 1025
  run: pytest tests/
</code></pre>
<h2 id="whats-next-6"><a class="header" href="#whats-next-6">What‚Äôs Next?</a></h2>
<p>Now that you have a basic SMTP server running, explore:</p>
<ol>
<li><strong><a href="protocols/smtp/./fixtures.html">Fixtures</a></strong> - Define email acceptance rules and auto-replies</li>
<li><strong><a href="protocols/smtp/./configuration.html">Configuration</a></strong> - Fine-tune server behavior</li>
<li><strong><a href="protocols/smtp/./examples.html">Examples</a></strong> - See real-world implementations</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="smtp-configuration-reference"><a class="header" href="#smtp-configuration-reference">SMTP Configuration Reference</a></h1>
<p>This page provides comprehensive documentation for all SMTP configuration options in MockForge.</p>
<h2 id="configuration-file"><a class="header" href="#configuration-file">Configuration File</a></h2>
<p>Configuration can be provided via YAML or JSON files:</p>
<pre><code class="language-yaml"># config.yaml
smtp:
  # Server settings
  enabled: true
  port: 1025
  host: "0.0.0.0"
  hostname: "mockforge-smtp"

  # Connection settings
  timeout_secs: 30
  max_connections: 100

  # Mailbox settings
  enable_mailbox: true
  max_mailbox_messages: 1000

  # Fixtures
  fixtures_dir: "./fixtures/smtp"
</code></pre>
<h2 id="configuration-options"><a class="header" href="#configuration-options">Configuration Options</a></h2>
<h3 id="server-settings"><a class="header" href="#server-settings">Server Settings</a></h3>
<h4 id="enabled"><a class="header" href="#enabled"><code>enabled</code></a></h4>
<ul>
<li><strong>Type</strong>: <code>boolean</code></li>
<li><strong>Default</strong>: <code>false</code></li>
<li><strong>Description</strong>: Enable or disable the SMTP server</li>
</ul>
<pre><code class="language-yaml">smtp:
  enabled: true
</code></pre>
<h4 id="port"><a class="header" href="#port"><code>port</code></a></h4>
<ul>
<li><strong>Type</strong>: <code>integer</code></li>
<li><strong>Default</strong>: <code>1025</code></li>
<li><strong>Description</strong>: Port number for the SMTP server to listen on</li>
<li><strong>Notes</strong>:
<ul>
<li>Standard SMTP port is 25, but requires root/admin privileges</li>
<li>Common development ports: 1025, 2525, 5025</li>
<li>Must be between 1 and 65535</li>
</ul>
</li>
</ul>
<pre><code class="language-yaml">smtp:
  port: 1025
</code></pre>
<h4 id="host"><a class="header" href="#host"><code>host</code></a></h4>
<ul>
<li><strong>Type</strong>: <code>string</code></li>
<li><strong>Default</strong>: <code>"0.0.0.0"</code></li>
<li><strong>Description</strong>: IP address to bind the server to</li>
<li><strong>Options</strong>:
<ul>
<li><code>"0.0.0.0"</code> - Listen on all interfaces</li>
<li><code>"127.0.0.1"</code> - Listen only on localhost</li>
<li>Specific IP for network interface</li>
</ul>
</li>
</ul>
<pre><code class="language-yaml">smtp:
  host: "127.0.0.1"  # Localhost only
</code></pre>
<h4 id="hostname"><a class="header" href="#hostname"><code>hostname</code></a></h4>
<ul>
<li><strong>Type</strong>: <code>string</code></li>
<li><strong>Default</strong>: <code>"mockforge-smtp"</code></li>
<li><strong>Description</strong>: Server hostname used in SMTP greeting and responses</li>
<li><strong>Notes</strong>: Appears in <code>220</code> greeting and <code>250</code> HELO/EHLO responses</li>
</ul>
<pre><code class="language-yaml">smtp:
  hostname: "mail.example.com"
</code></pre>
<h3 id="connection-settings"><a class="header" href="#connection-settings">Connection Settings</a></h3>
<h4 id="timeout_secs"><a class="header" href="#timeout_secs"><code>timeout_secs</code></a></h4>
<ul>
<li><strong>Type</strong>: <code>integer</code></li>
<li><strong>Default</strong>: <code>30</code></li>
<li><strong>Description</strong>: Connection timeout in seconds</li>
<li><strong>Range</strong>: <code>1</code> to <code>3600</code> (1 second to 1 hour)</li>
</ul>
<pre><code class="language-yaml">smtp:
  timeout_secs: 60  # 1 minute timeout
</code></pre>
<h4 id="max_connections"><a class="header" href="#max_connections"><code>max_connections</code></a></h4>
<ul>
<li><strong>Type</strong>: <code>integer</code></li>
<li><strong>Default</strong>: <code>100</code></li>
<li><strong>Description</strong>: Maximum number of concurrent SMTP connections</li>
<li><strong>Notes</strong>: Prevents resource exhaustion from too many connections</li>
</ul>
<pre><code class="language-yaml">smtp:
  max_connections: 500
</code></pre>
<h3 id="mailbox-settings"><a class="header" href="#mailbox-settings">Mailbox Settings</a></h3>
<h4 id="enable_mailbox"><a class="header" href="#enable_mailbox"><code>enable_mailbox</code></a></h4>
<ul>
<li><strong>Type</strong>: <code>boolean</code></li>
<li><strong>Default</strong>: <code>true</code></li>
<li><strong>Description</strong>: Enable in-memory mailbox for storing received emails</li>
</ul>
<pre><code class="language-yaml">smtp:
  enable_mailbox: true
</code></pre>
<h4 id="max_mailbox_messages"><a class="header" href="#max_mailbox_messages"><code>max_mailbox_messages</code></a></h4>
<ul>
<li><strong>Type</strong>: <code>integer</code></li>
<li><strong>Default</strong>: <code>1000</code></li>
<li><strong>Description</strong>: Maximum number of emails to store in mailbox</li>
<li><strong>Notes</strong>:
<ul>
<li>Uses FIFO (First In, First Out) when limit is reached</li>
<li>Oldest emails are removed when limit is exceeded</li>
<li>Set to <code>0</code> for unlimited (not recommended)</li>
</ul>
</li>
</ul>
<pre><code class="language-yaml">smtp:
  max_mailbox_messages: 5000
</code></pre>
<h3 id="fixture-settings"><a class="header" href="#fixture-settings">Fixture Settings</a></h3>
<h4 id="fixtures_dir"><a class="header" href="#fixtures_dir"><code>fixtures_dir</code></a></h4>
<ul>
<li><strong>Type</strong>: <code>string</code> (path)</li>
<li><strong>Default</strong>: <code>null</code> (no fixtures)</li>
<li><strong>Description</strong>: Directory containing SMTP fixture files</li>
<li><strong>Notes</strong>:
<ul>
<li>Can be absolute or relative path</li>
<li>All <code>.yaml</code> and <code>.yml</code> files in directory will be loaded</li>
<li>See <a href="protocols/smtp/./fixtures.html">Fixtures documentation</a> for format</li>
</ul>
</li>
</ul>
<pre><code class="language-yaml">smtp:
  fixtures_dir: "./fixtures/smtp"
</code></pre>
<p>Or with absolute path:</p>
<pre><code class="language-yaml">smtp:
  fixtures_dir: "/opt/mockforge/fixtures/smtp"
</code></pre>
<h2 id="environment-variables-5"><a class="header" href="#environment-variables-5">Environment Variables</a></h2>
<p>All configuration options can be overridden with environment variables using the prefix <code>MOCKFORGE_SMTP_</code>:</p>
<div class="table-wrapper"><table><thead><tr><th>Environment Variable</th><th>Config Option</th><th>Example</th></tr></thead><tbody>
<tr><td><code>MOCKFORGE_SMTP_ENABLED</code></td><td><code>enabled</code></td><td><code>true</code></td></tr>
<tr><td><code>MOCKFORGE_SMTP_PORT</code></td><td><code>port</code></td><td><code>2525</code></td></tr>
<tr><td><code>MOCKFORGE_SMTP_HOST</code></td><td><code>host</code></td><td><code>127.0.0.1</code></td></tr>
<tr><td><code>MOCKFORGE_SMTP_HOSTNAME</code></td><td><code>hostname</code></td><td><code>testmail.local</code></td></tr>
</tbody></table>
</div>
<h3 id="example"><a class="header" href="#example">Example</a></h3>
<pre><code class="language-bash">export MOCKFORGE_SMTP_ENABLED=true
export MOCKFORGE_SMTP_PORT=2525
export MOCKFORGE_SMTP_HOST=0.0.0.0
export MOCKFORGE_SMTP_HOSTNAME=test-server

mockforge serve
</code></pre>
<h2 id="command-line-arguments"><a class="header" href="#command-line-arguments">Command-Line Arguments</a></h2>
<p>Override configuration via CLI arguments:</p>
<pre><code class="language-bash">mockforge serve \
  --smtp-port 2525 \
  --config ./config.yaml
</code></pre>
<h3 id="priority-order-1"><a class="header" href="#priority-order-1">Priority Order</a></h3>
<p>Configuration is applied in the following order (highest to lowest priority):</p>
<ol>
<li>Command-line arguments</li>
<li>Environment variables</li>
<li>Configuration file</li>
<li>Default values</li>
</ol>
<h2 id="complete-example"><a class="header" href="#complete-example">Complete Example</a></h2>
<h3 id="development-configuration"><a class="header" href="#development-configuration">Development Configuration</a></h3>
<pre><code class="language-yaml"># config.dev.yaml
smtp:
  enabled: true
  port: 1025
  host: "127.0.0.1"
  hostname: "dev-smtp"
  timeout_secs: 30
  max_connections: 50
  enable_mailbox: true
  max_mailbox_messages: 500
  fixtures_dir: "./fixtures/smtp"
</code></pre>
<h3 id="production-like-configuration"><a class="header" href="#production-like-configuration">Production-Like Configuration</a></h3>
<pre><code class="language-yaml"># config.prod.yaml
smtp:
  enabled: true
  port: 2525
  host: "0.0.0.0"
  hostname: "mockforge.example.com"
  timeout_secs: 60
  max_connections: 1000
  enable_mailbox: true
  max_mailbox_messages: 10000
  fixtures_dir: "/opt/mockforge/smtp-fixtures"
</code></pre>
<h3 id="cicd-configuration"><a class="header" href="#cicd-configuration">CI/CD Configuration</a></h3>
<pre><code class="language-yaml"># config.ci.yaml
smtp:
  enabled: true
  port: 1025
  host: "127.0.0.1"
  hostname: "ci-smtp"
  timeout_secs: 10
  max_connections: 10
  enable_mailbox: true
  max_mailbox_messages: 100
  fixtures_dir: "./test/fixtures/smtp"
</code></pre>
<h2 id="performance-tuning-1"><a class="header" href="#performance-tuning-1">Performance Tuning</a></h2>
<h3 id="high-volume-scenarios"><a class="header" href="#high-volume-scenarios">High-Volume Scenarios</a></h3>
<p>For testing high-volume email sending:</p>
<pre><code class="language-yaml">smtp:
  max_connections: 2000
  max_mailbox_messages: 50000
  timeout_secs: 120
</code></pre>
<p><strong>Memory considerations</strong>: Each stored email uses approximately 1-5 KB of memory depending on size. 50,000 emails ‚âà 50-250 MB.</p>
<h3 id="low-resource-environments"><a class="header" href="#low-resource-environments">Low-Resource Environments</a></h3>
<p>For constrained environments (CI, containers):</p>
<pre><code class="language-yaml">smtp:
  max_connections: 25
  max_mailbox_messages: 100
  timeout_secs: 15
</code></pre>
<h2 id="best-practices-4"><a class="header" href="#best-practices-4">Best Practices</a></h2>
<h3 id="security"><a class="header" href="#security">Security</a></h3>
<ol>
<li>
<p><strong>Bind to localhost in development</strong>:</p>
<pre><code class="language-yaml">host: "127.0.0.1"
</code></pre>
</li>
<li>
<p><strong>Use non-privileged ports</strong>:</p>
<pre><code class="language-yaml">port: 1025  # Not 25
</code></pre>
</li>
<li>
<p><strong>Limit connections</strong>:</p>
<pre><code class="language-yaml">max_connections: 100
</code></pre>
</li>
</ol>
<h3 id="testing-2"><a class="header" href="#testing-2">Testing</a></h3>
<ol>
<li>
<p><strong>Use fixtures for deterministic tests</strong>:</p>
<pre><code class="language-yaml">fixtures_dir: "./fixtures/smtp"
</code></pre>
</li>
<li>
<p><strong>Configure appropriate mailbox size</strong>:</p>
<pre><code class="language-yaml">max_mailbox_messages: 1000  # Adjust based on test suite
</code></pre>
</li>
<li>
<p><strong>Set realistic timeouts</strong>:</p>
<pre><code class="language-yaml">timeout_secs: 30  # Not too short, not too long
</code></pre>
</li>
</ol>
<h3 id="cicd"><a class="header" href="#cicd">CI/CD</a></h3>
<ol>
<li>
<p><strong>Use environment variables</strong> for flexibility:</p>
<pre><code class="language-bash">MOCKFORGE_SMTP_PORT=1025
</code></pre>
</li>
<li>
<p><strong>Start server in background</strong>:</p>
<pre><code class="language-bash">mockforge serve --smtp &amp;
</code></pre>
</li>
<li>
<p><strong>Use localhost binding</strong> for security:</p>
<pre><code class="language-yaml">host: "127.0.0.1"
</code></pre>
</li>
</ol>
<h2 id="troubleshooting-17"><a class="header" href="#troubleshooting-17">Troubleshooting</a></h2>
<h3 id="port-already-in-use"><a class="header" href="#port-already-in-use">Port Already in Use</a></h3>
<p><strong>Error</strong>: <code>Address already in use</code></p>
<p><strong>Solution</strong>:</p>
<pre><code class="language-bash"># Check what's using the port
lsof -i :1025

# Use a different port
mockforge serve --smtp-port 2525
</code></pre>
<h3 id="too-many-open-files"><a class="header" href="#too-many-open-files">Too Many Open Files</a></h3>
<p><strong>Error</strong>: <code>Too many open files</code></p>
<p><strong>Solution</strong>: Reduce <code>max_connections</code>:</p>
<pre><code class="language-yaml">smtp:
  max_connections: 50
</code></pre>
<h3 id="out-of-memory"><a class="header" href="#out-of-memory">Out of Memory</a></h3>
<p><strong>Error</strong>: OOM or slowdown with large mailbox</p>
<p><strong>Solution</strong>: Reduce <code>max_mailbox_messages</code>:</p>
<pre><code class="language-yaml">smtp:
  max_mailbox_messages: 1000
</code></pre>
<h2 id="related-documentation-3"><a class="header" href="#related-documentation-3">Related Documentation</a></h2>
<ul>
<li><a href="protocols/smtp/./getting-started.html">Getting Started</a></li>
<li><a href="protocols/smtp/./fixtures.html">Fixtures</a></li>
<li><a href="protocols/smtp/./examples.html">Examples</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="smtp-fixtures"><a class="header" href="#smtp-fixtures">SMTP Fixtures</a></h1>
<p>SMTP fixtures allow you to define email acceptance rules, auto-reply behavior, and storage options based on pattern matching. This enables sophisticated email testing scenarios.</p>
<h2 id="fixture-format"><a class="header" href="#fixture-format">Fixture Format</a></h2>
<p>Fixtures are defined in YAML format:</p>
<pre><code class="language-yaml">identifier: "welcome-email"
name: "Welcome Email Handler"
description: "Handles welcome emails to new users"

match_criteria:
  recipient_pattern: "^welcome@example\\.com$"
  sender_pattern: null
  subject_pattern: null
  match_all: false

response:
  status_code: 250
  message: "Message accepted"
  delay_ms: 0

auto_reply:
  enabled: false

storage:
  save_to_mailbox: true
  export_to_file: null

behavior:
  failure_rate: 0.0
  delay_ms: 0
</code></pre>
<h2 id="match-criteria"><a class="header" href="#match-criteria">Match Criteria</a></h2>
<h3 id="recipient_pattern"><a class="header" href="#recipient_pattern"><code>recipient_pattern</code></a></h3>
<ul>
<li><strong>Type</strong>: <code>string</code> (regex) or <code>null</code></li>
<li><strong>Description</strong>: Regular expression to match recipient email address</li>
<li><strong>Examples</strong>:
<ul>
<li><code>^user@example\.com$</code> - Exact match</li>
<li><code>^.*@example\.com$</code> - Any user at domain</li>
<li><code>^admin.*@.*\.com$</code> - Admin users at any .com domain</li>
</ul>
</li>
</ul>
<pre><code class="language-yaml">match_criteria:
  recipient_pattern: "^support@example\\.com$"
</code></pre>
<h3 id="sender_pattern"><a class="header" href="#sender_pattern"><code>sender_pattern</code></a></h3>
<ul>
<li><strong>Type</strong>: <code>string</code> (regex) or <code>null</code></li>
<li><strong>Description</strong>: Regular expression to match sender email address</li>
</ul>
<pre><code class="language-yaml">match_criteria:
  sender_pattern: "^no-reply@.*\\.com$"
</code></pre>
<h3 id="subject_pattern"><a class="header" href="#subject_pattern"><code>subject_pattern</code></a></h3>
<ul>
<li><strong>Type</strong>: <code>string</code> (regex) or <code>null</code></li>
<li><strong>Description</strong>: Regular expression to match email subject line</li>
</ul>
<pre><code class="language-yaml">match_criteria:
  subject_pattern: "^\\[URGENT\\].*"
</code></pre>
<h3 id="match_all"><a class="header" href="#match_all"><code>match_all</code></a></h3>
<ul>
<li><strong>Type</strong>: <code>boolean</code></li>
<li><strong>Default</strong>: <code>false</code></li>
<li><strong>Description</strong>: When <code>true</code>, this fixture matches all emails (catch-all)</li>
</ul>
<pre><code class="language-yaml">match_criteria:
  match_all: true  # Catch-all fixture
</code></pre>
<h3 id="matching-logic"><a class="header" href="#matching-logic">Matching Logic</a></h3>
<p>Patterns are evaluated in order:</p>
<ol>
<li>If <code>match_all</code> is <code>true</code>, fixture matches</li>
<li>Otherwise, <strong>all non-null patterns must match</strong>:
<ul>
<li>If <code>recipient_pattern</code> is set, it must match</li>
<li>If <code>sender_pattern</code> is set, it must match</li>
<li>If <code>subject_pattern</code> is set, it must match</li>
</ul>
</li>
</ol>
<h2 id="response-configuration-1"><a class="header" href="#response-configuration-1">Response Configuration</a></h2>
<h3 id="status_code"><a class="header" href="#status_code"><code>status_code</code></a></h3>
<ul>
<li><strong>Type</strong>: <code>integer</code></li>
<li><strong>Default</strong>: <code>250</code></li>
<li><strong>Description</strong>: SMTP status code to return</li>
<li><strong>Common codes</strong>:
<ul>
<li><code>250</code> - OK (success)</li>
<li><code>550</code> - Mailbox unavailable (rejection)</li>
<li><code>451</code> - Temporary failure</li>
<li><code>452</code> - Insufficient storage</li>
</ul>
</li>
</ul>
<pre><code class="language-yaml">response:
  status_code: 550  # Reject email
</code></pre>
<h3 id="message"><a class="header" href="#message"><code>message</code></a></h3>
<ul>
<li><strong>Type</strong>: <code>string</code></li>
<li><strong>Description</strong>: Response message text</li>
</ul>
<pre><code class="language-yaml">response:
  status_code: 250
  message: "Message accepted for delivery"
</code></pre>
<h3 id="delay_ms"><a class="header" href="#delay_ms"><code>delay_ms</code></a></h3>
<ul>
<li><strong>Type</strong>: <code>integer</code></li>
<li><strong>Default</strong>: <code>0</code></li>
<li><strong>Description</strong>: Artificial delay before responding (milliseconds)</li>
<li><strong>Use case</strong>: Simulate slow mail servers</li>
</ul>
<pre><code class="language-yaml">response:
  delay_ms: 500  # 500ms delay
</code></pre>
<h2 id="auto-reply"><a class="header" href="#auto-reply">Auto-Reply</a></h2>
<p>Auto-replies allow MockForge to automatically send response emails.</p>
<h3 id="basic-auto-reply"><a class="header" href="#basic-auto-reply">Basic Auto-Reply</a></h3>
<pre><code class="language-yaml">auto_reply:
  enabled: true
  from: "noreply@example.com"
  to: "{{from}}"  # Reply to sender
  subject: "Re: {{subject}}"
  body: |
    Thank you for your email.

    This is an automated response.
</code></pre>
<h3 id="template-variables-1"><a class="header" href="#template-variables-1">Template Variables</a></h3>
<p>Use template variables in auto-reply fields:</p>
<ul>
<li><code>{{from}}</code> - Original sender email</li>
<li><code>{{to}}</code> - Original recipient email</li>
<li><code>{{subject}}</code> - Original subject</li>
<li><code>{{from_name}}</code> - Extracted name from sender</li>
<li><code>{{now}}</code> - Current timestamp</li>
<li>Faker functions: <code>{{faker.name}}</code>, <code>{{faker.email}}</code>, etc.</li>
</ul>
<h3 id="example-welcome-email-auto-reply"><a class="header" href="#example-welcome-email-auto-reply">Example: Welcome Email Auto-Reply</a></h3>
<pre><code class="language-yaml">identifier: "welcome-autoresponder"
name: "Welcome Email Auto-Reply"

match_criteria:
  recipient_pattern: "^register@example\\.com$"

response:
  status_code: 250
  message: "Message accepted"

auto_reply:
  enabled: true
  from: "welcome@example.com"
  to: "{{from}}"
  subject: "Welcome to Example.com!"
  body: |
    Hi {{from_name}},

    Thank you for registering at Example.com!

    Your registration was received at {{now}}.

    If you have any questions, reply to this email.

    Best regards,
    The Example.com Team
</code></pre>
<h2 id="storage-configuration"><a class="header" href="#storage-configuration">Storage Configuration</a></h2>
<h3 id="save_to_mailbox"><a class="header" href="#save_to_mailbox"><code>save_to_mailbox</code></a></h3>
<ul>
<li><strong>Type</strong>: <code>boolean</code></li>
<li><strong>Default</strong>: <code>true</code></li>
<li><strong>Description</strong>: Store received email in in-memory mailbox</li>
</ul>
<pre><code class="language-yaml">storage:
  save_to_mailbox: true
</code></pre>
<h3 id="export_to_file"><a class="header" href="#export_to_file"><code>export_to_file</code></a></h3>
<ul>
<li><strong>Type</strong>: <code>string</code> (path) or <code>null</code></li>
<li><strong>Description</strong>: Export email to file on disk</li>
<li><strong>Format</strong>: Emails are saved as <code>.eml</code> files</li>
</ul>
<pre><code class="language-yaml">storage:
  save_to_mailbox: true
  export_to_file: "./emails/received"
</code></pre>
<p>File naming pattern: <code>{timestamp}_{from}_{to}.eml</code></p>
<p>Example: <code>20240315_143022_sender@example.com_recipient@example.com.eml</code></p>
<h2 id="behavior-configuration"><a class="header" href="#behavior-configuration">Behavior Configuration</a></h2>
<h3 id="failure_rate"><a class="header" href="#failure_rate"><code>failure_rate</code></a></h3>
<ul>
<li><strong>Type</strong>: <code>float</code> (0.0 to 1.0)</li>
<li><strong>Default</strong>: <code>0.0</code></li>
<li><strong>Description</strong>: Probability of simulated failure (for testing error handling)</li>
<li><strong>Examples</strong>:
<ul>
<li><code>0.0</code> - Never fail</li>
<li><code>0.1</code> - 10% failure rate</li>
<li><code>1.0</code> - Always fail</li>
</ul>
</li>
</ul>
<pre><code class="language-yaml">behavior:
  failure_rate: 0.05  # 5% of emails fail
</code></pre>
<h3 id="delay_ms-1"><a class="header" href="#delay_ms-1"><code>delay_ms</code></a></h3>
<ul>
<li><strong>Type</strong>: <code>integer</code></li>
<li><strong>Default</strong>: <code>0</code></li>
<li><strong>Description</strong>: Artificial delay before processing (milliseconds)</li>
</ul>
<pre><code class="language-yaml">behavior:
  delay_ms: 1000  # 1 second delay
</code></pre>
<h2 id="complete-examples"><a class="header" href="#complete-examples">Complete Examples</a></h2>
<h3 id="example-1-user-registration-emails"><a class="header" href="#example-1-user-registration-emails">Example 1: User Registration Emails</a></h3>
<pre><code class="language-yaml">identifier: "user-registration"
name: "User Registration Handler"
description: "Handles new user registration confirmation emails"

match_criteria:
  recipient_pattern: "^[^@]+@example\\.com$"
  subject_pattern: "^Registration Confirmation"

response:
  status_code: 250
  message: "Registration email accepted"
  delay_ms: 0

auto_reply:
  enabled: true
  from: "noreply@example.com"
  to: "{{from}}"
  subject: "Welcome! Please Confirm Your Email"
  body: |
    Hello,

    Thank you for registering!

    Please click the link below to confirm your email:
    https://example.com/confirm?token={{uuid}}

    This link expires in 24 hours.

    Best regards,
    Example.com Team

storage:
  save_to_mailbox: true
  export_to_file: "./logs/registration-emails"

behavior:
  failure_rate: 0.0
  delay_ms: 0
</code></pre>
<h3 id="example-2-support-ticket-system"><a class="header" href="#example-2-support-ticket-system">Example 2: Support Ticket System</a></h3>
<pre><code class="language-yaml">identifier: "support-tickets"
name: "Support Ticket Handler"
description: "Auto-responds to support emails"

match_criteria:
  recipient_pattern: "^support@example\\.com$"

response:
  status_code: 250
  message: "Support ticket created"

auto_reply:
  enabled: true
  from: "support@example.com"
  to: "{{from}}"
  subject: "Ticket Created: {{subject}}"
  body: |
    Your support ticket has been created.

    Ticket ID: {{uuid}}
    Subject: {{subject}}
    Created: {{now}}

    We'll respond within 24 hours.

    Support Team

storage:
  save_to_mailbox: true
</code></pre>
<h3 id="example-3-bounced-email-simulation"><a class="header" href="#example-3-bounced-email-simulation">Example 3: Bounced Email Simulation</a></h3>
<pre><code class="language-yaml">identifier: "bounce-simulation"
name: "Simulate Bounced Emails"
description: "Rejects emails to invalid addresses"

match_criteria:
  recipient_pattern: "^bounce-test@example\\.com$"

response:
  status_code: 550
  message: "Mailbox unavailable"
  delay_ms: 0

auto_reply:
  enabled: false

storage:
  save_to_mailbox: false

behavior:
  failure_rate: 1.0  # Always fail
</code></pre>
<h3 id="example-4-slow-server-simulation"><a class="header" href="#example-4-slow-server-simulation">Example 4: Slow Server Simulation</a></h3>
<pre><code class="language-yaml">identifier: "slow-server"
name: "Slow SMTP Server"
description: "Simulates slow mail server response"

match_criteria:
  recipient_pattern: "^slowtest@example\\.com$"

response:
  status_code: 250
  message: "OK"
  delay_ms: 5000  # 5 second delay

storage:
  save_to_mailbox: true

behavior:
  delay_ms: 3000  # Additional 3 second processing delay
</code></pre>
<h3 id="example-5-catch-all-default"><a class="header" href="#example-5-catch-all-default">Example 5: Catch-All Default</a></h3>
<pre><code class="language-yaml">identifier: "default-handler"
name: "Default Email Handler"
description: "Accepts all emails not matched by other fixtures"

match_criteria:
  match_all: true

response:
  status_code: 250
  message: "Message accepted"

auto_reply:
  enabled: false

storage:
  save_to_mailbox: true

behavior:
  failure_rate: 0.0
  delay_ms: 0
</code></pre>
<h2 id="loading-fixtures-1"><a class="header" href="#loading-fixtures-1">Loading Fixtures</a></h2>
<h3 id="directory-structure"><a class="header" href="#directory-structure">Directory Structure</a></h3>
<pre><code>fixtures/smtp/
‚îú‚îÄ‚îÄ welcome-email.yaml
‚îú‚îÄ‚îÄ support-tickets.yaml
‚îú‚îÄ‚îÄ bounce-simulation.yaml
‚îî‚îÄ‚îÄ default.yaml
</code></pre>
<h3 id="configuration-2"><a class="header" href="#configuration-2">Configuration</a></h3>
<pre><code class="language-yaml">smtp:
  fixtures_dir: "./fixtures/smtp"
</code></pre>
<h3 id="fixture-priority"><a class="header" href="#fixture-priority">Fixture Priority</a></h3>
<p>Fixtures are evaluated in <strong>alphabetical order by filename</strong>. First match wins (except <code>match_all</code>).</p>
<p>To control priority, use numbered prefixes:</p>
<pre><code>fixtures/smtp/
‚îú‚îÄ‚îÄ 01-bounce.yaml       # Highest priority
‚îú‚îÄ‚îÄ 02-welcome.yaml
‚îú‚îÄ‚îÄ 03-support.yaml
‚îî‚îÄ‚îÄ 99-default.yaml      # Lowest priority (catch-all)
</code></pre>
<h2 id="testing-fixtures"><a class="header" href="#testing-fixtures">Testing Fixtures</a></h2>
<h3 id="1-validate-fixture-syntax"><a class="header" href="#1-validate-fixture-syntax">1. Validate Fixture Syntax</a></h3>
<pre><code class="language-bash"># Future command (not yet implemented)
mockforge smtp fixtures validate ./fixtures/smtp/welcome.yaml
</code></pre>
<h3 id="2-test-fixture-matching"><a class="header" href="#2-test-fixture-matching">2. Test Fixture Matching</a></h3>
<p>Send test email:</p>
<pre><code class="language-bash">swaks --to welcome@example.com \
      --from test@test.com \
      --server localhost:1025 \
      --header "Subject: Test"
</code></pre>
<p>Check server logs for fixture match:</p>
<pre><code>[INFO] Matched fixture: welcome-email
</code></pre>
<h3 id="3-verify-auto-reply"><a class="header" href="#3-verify-auto-reply">3. Verify Auto-Reply</a></h3>
<p>Check mailbox or export directory for auto-reply email.</p>
<h2 id="best-practices-5"><a class="header" href="#best-practices-5">Best Practices</a></h2>
<h3 id="1-specific-before-general"><a class="header" href="#1-specific-before-general">1. Specific Before General</a></h3>
<p>Place specific fixtures before general catch-all fixtures:</p>
<pre><code>01-specific-user.yaml
02-domain-specific.yaml
99-catch-all.yaml
</code></pre>
<h3 id="2-use-descriptive-identifiers"><a class="header" href="#2-use-descriptive-identifiers">2. Use Descriptive Identifiers</a></h3>
<pre><code class="language-yaml">identifier: "welcome-new-users"  # Good
identifier: "fixture1"            # Bad
</code></pre>
<h3 id="3-document-with-descriptions"><a class="header" href="#3-document-with-descriptions">3. Document with Descriptions</a></h3>
<pre><code class="language-yaml">description: "Handles password reset emails with confirmation link"
</code></pre>
<h3 id="4-test-failure-scenarios"><a class="header" href="#4-test-failure-scenarios">4. Test Failure Scenarios</a></h3>
<pre><code class="language-yaml">behavior:
  failure_rate: 0.01  # Test with 1% failure
</code></pre>
<h3 id="5-limit-auto-replies"><a class="header" href="#5-limit-auto-replies">5. Limit Auto-Replies</a></h3>
<p>Don‚Äôt create auto-reply loops:</p>
<ul>
<li>Avoid auto-replying to <code>noreply@</code> addresses</li>
<li>Check sender before replying</li>
</ul>
<h2 id="troubleshooting-18"><a class="header" href="#troubleshooting-18">Troubleshooting</a></h2>
<h3 id="fixture-not-matching"><a class="header" href="#fixture-not-matching">Fixture Not Matching</a></h3>
<ol>
<li><strong>Check pattern syntax</strong>: Use regex tester (regex101.com)</li>
<li><strong>Check fixture order</strong>: Earlier fixtures may match first</li>
<li><strong>Enable debug logging</strong>: See which fixture matched</li>
<li><strong>Test with simple pattern</strong>: Start with <code>^.*@example\.com$</code></li>
</ol>
<h3 id="auto-reply-not-sending"><a class="header" href="#auto-reply-not-sending">Auto-Reply Not Sending</a></h3>
<ol>
<li><strong>Verify enabled</strong>: <code>auto_reply.enabled: true</code></li>
<li><strong>Check template syntax</strong>: Ensure valid template variables</li>
<li><strong>Check logs</strong>: Look for auto-reply errors</li>
</ol>
<h3 id="performance-issues"><a class="header" href="#performance-issues">Performance Issues</a></h3>
<ol>
<li><strong>Simplify regex</strong>: Complex patterns slow matching</li>
<li><strong>Reduce fixtures</strong>: Too many fixtures slow evaluation</li>
<li><strong>Disable storage</strong>: Set <code>save_to_mailbox: false</code> if not needed</li>
</ol>
<h2 id="related-documentation-4"><a class="header" href="#related-documentation-4">Related Documentation</a></h2>
<ul>
<li><a href="protocols/smtp/./getting-started.html">Getting Started</a></li>
<li><a href="protocols/smtp/./configuration.html">Configuration</a></li>
<li><a href="protocols/smtp/./examples.html">Examples</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="smtp-examples"><a class="header" href="#smtp-examples">SMTP Examples</a></h1>
<p>This page provides real-world examples of using MockForge SMTP for testing email workflows.</p>
<h2 id="table-of-contents-1"><a class="header" href="#table-of-contents-1">Table of Contents</a></h2>
<ul>
<li><a href="protocols/smtp/examples.html#testing-user-registration">Testing User Registration</a></li>
<li><a href="protocols/smtp/examples.html#password-reset-flow">Password Reset Flow</a></li>
<li><a href="protocols/smtp/examples.html#email-verification">Email Verification</a></li>
<li><a href="protocols/smtp/examples.html#newsletter-subscriptions">Newsletter Subscriptions</a></li>
<li><a href="protocols/smtp/examples.html#cicd-integration">CI/CD Integration</a></li>
<li><a href="protocols/smtp/examples.html#load-testing">Load Testing</a></li>
<li><a href="protocols/smtp/examples.html#multi-language-applications">Multi-Language Applications</a></li>
</ul>
<h2 id="testing-user-registration"><a class="header" href="#testing-user-registration">Testing User Registration</a></h2>
<h3 id="scenario"><a class="header" href="#scenario">Scenario</a></h3>
<p>Test that your application sends a welcome email when users register.</p>
<h3 id="fixture"><a class="header" href="#fixture">Fixture</a></h3>
<p><code>fixtures/smtp/welcome-email.yaml</code>:</p>
<pre><code class="language-yaml">identifier: "welcome-email"
name: "Welcome Email"
description: "Auto-responds to new user registration"

match_criteria:
  recipient_pattern: "^[^@]+@example\\.com$"
  subject_pattern: "^Welcome"

response:
  status_code: 250
  message: "Message accepted"

auto_reply:
  enabled: true
  from: "noreply@example.com"
  to: "{{from}}"
  subject: "Welcome to Our Platform!"
  body: |
    Hi there!

    Thank you for registering at our platform.

    Click here to verify your email:
    https://example.com/verify?token={{uuid}}

    Best regards,
    The Team

storage:
  save_to_mailbox: true
</code></pre>
<h3 id="python-test"><a class="header" href="#python-test">Python Test</a></h3>
<pre><code class="language-python">import smtplib
import requests
from email.message import EmailMessage

def test_user_registration_sends_welcome_email():
    # Register a new user
    response = requests.post('http://localhost:8080/api/register', json={
        'email': 'newuser@example.com',
        'password': 'SecurePass123',
        'name': 'Test User'
    })

    assert response.status_code == 201

    # Verify email was sent
    # (In real scenario, you'd query MockForge's mailbox API)
    # For now, manually check logs or implement mailbox checking

def send_test_email():
    """Helper to test fixture directly"""
    msg = EmailMessage()
    msg['Subject'] = 'Welcome to Our Platform'
    msg['From'] = 'system@myapp.com'
    msg['To'] = 'newuser@example.com'
    msg.set_content('Welcome!')

    with smtplib.SMTP('localhost', 1025) as server:
        server.send_message(msg)
        print("Test email sent!")

if __name__ == "__main__":
    send_test_email()
</code></pre>
<h3 id="nodejs-test"><a class="header" href="#nodejs-test">Node.js Test</a></h3>
<pre><code class="language-javascript">const nodemailer = require('nodemailer');
const axios = require('axios');
const assert = require('assert');

describe('User Registration', () =&gt; {
  it('should send welcome email', async () =&gt; {
    // Configure nodemailer to use MockForge
    const transporter = nodemailer.createTransport({
      host: 'localhost',
      port: 1025,
      secure: false,
    });

    // Register user
    const response = await axios.post('http://localhost:8080/api/register', {
      email: 'newuser@example.com',
      password: 'SecurePass123',
      name: 'Test User'
    });

    assert.strictEqual(response.status, 201);

    // Send test email
    await transporter.sendMail({
      from: 'system@myapp.com',
      to: 'newuser@example.com',
      subject: 'Welcome to Our Platform',
      text: 'Welcome!',
    });

    // In production, query MockForge mailbox API here
  });
});
</code></pre>
<h2 id="password-reset-flow"><a class="header" href="#password-reset-flow">Password Reset Flow</a></h2>
<h3 id="scenario-1"><a class="header" href="#scenario-1">Scenario</a></h3>
<p>Test password reset email with temporary token.</p>
<h3 id="fixture-1"><a class="header" href="#fixture-1">Fixture</a></h3>
<p><code>fixtures/smtp/password-reset.yaml</code>:</p>
<pre><code class="language-yaml">identifier: "password-reset"
name: "Password Reset"

match_criteria:
  recipient_pattern: "^.*@.*$"
  subject_pattern: "^Password Reset"

response:
  status_code: 250
  message: "Reset email accepted"

auto_reply:
  enabled: true
  from: "security@example.com"
  to: "{{from}}"
  subject: "Password Reset Instructions"
  body: |
    Hello,

    You requested a password reset.

    Click the link below to reset your password:
    https://example.com/reset?token={{uuid}}

    This link expires in 1 hour.

    If you didn't request this, please ignore this email.

    Security Team

storage:
  save_to_mailbox: true
  export_to_file: "./logs/password-resets"
</code></pre>
<h3 id="python-test-1"><a class="header" href="#python-test-1">Python Test</a></h3>
<pre><code class="language-python">import pytest
import smtplib
from email.message import EmailMessage

def trigger_password_reset(email):
    """Trigger password reset in your application"""
    import requests
    response = requests.post('http://localhost:8080/api/password-reset',
                            json={'email': email})
    return response.status_code == 200

def test_password_reset_email():
    email = 'user@example.com'

    # Trigger reset
    assert trigger_password_reset(email)

    # Verify email sent (check mailbox)
    # TODO: Implement mailbox API check

def test_password_reset_invalid_email():
    """Test that invalid email is rejected"""
    email = 'bounce-test@example.com'  # Configured to fail

    # This should fail
    assert not trigger_password_reset(email)
</code></pre>
<h2 id="email-verification"><a class="header" href="#email-verification">Email Verification</a></h2>
<h3 id="scenario-2"><a class="header" href="#scenario-2">Scenario</a></h3>
<p>Test email verification link generation and sending.</p>
<h3 id="fixture-2"><a class="header" href="#fixture-2">Fixture</a></h3>
<p><code>fixtures/smtp/email-verification.yaml</code>:</p>
<pre><code class="language-yaml">identifier: "email-verification"
name: "Email Verification"

match_criteria:
  subject_pattern: "^Verify Your Email"

response:
  status_code: 250
  message: "Verification email sent"

auto_reply:
  enabled: true
  from: "noreply@example.com"
  to: "{{from}}"
  subject: "Verify Your Email Address"
  body: |
    Please verify your email address by clicking below:

    https://example.com/verify?email={{to}}&amp;code={{faker.alphanumeric 32}}

    This link expires in 24 hours.

storage:
  save_to_mailbox: true
</code></pre>
<h3 id="go-test"><a class="header" href="#go-test">Go Test</a></h3>
<pre><code class="language-go">package main

import (
    "net/smtp"
    "testing"
)

func TestEmailVerification(t *testing.T) {
    // Setup
    smtpHost := "localhost:1025"
    from := "system@myapp.com"
    to := []string{"user@example.com"}

    // Create message
    message := []byte(
        "Subject: Verify Your Email\r\n" +
        "\r\n" +
        "Please verify your email.\r\n",
    )

    // Send email
    err := smtp.SendMail(smtpHost, nil, from, to, message)
    if err != nil {
        t.Fatalf("Failed to send email: %v", err)
    }

    // Verify sent (check mailbox)
    // TODO: Implement mailbox check
}
</code></pre>
<h2 id="newsletter-subscriptions"><a class="header" href="#newsletter-subscriptions">Newsletter Subscriptions</a></h2>
<h3 id="scenario-3"><a class="header" href="#scenario-3">Scenario</a></h3>
<p>Test newsletter subscription confirmation emails.</p>
<h3 id="fixture-3"><a class="header" href="#fixture-3">Fixture</a></h3>
<p><code>fixtures/smtp/newsletter.yaml</code>:</p>
<pre><code class="language-yaml">identifier: "newsletter-subscription"
name: "Newsletter Subscription"

match_criteria:
  recipient_pattern: "^newsletter@example\\.com$"

response:
  status_code: 250
  message: "Subscription received"

auto_reply:
  enabled: true
  from: "newsletter@example.com"
  to: "{{from}}"
  subject: "Confirm Your Newsletter Subscription"
  body: |
    Thanks for subscribing to our newsletter!

    Click to confirm: https://example.com/newsletter/confirm?email={{from}}

    You'll receive our weekly digest every Monday.

storage:
  save_to_mailbox: true
</code></pre>
<h3 id="ruby-test"><a class="header" href="#ruby-test">Ruby Test</a></h3>
<pre><code class="language-ruby">require 'mail'
require 'minitest/autorun'

class NewsletterTest &lt; Minitest::Test
  def setup
    Mail.defaults do
      delivery_method :smtp,
        address: "localhost",
        port: 1025
    end
  end

  def test_newsletter_subscription
    email = Mail.new do
      from     'user@test.com'
      to       'newsletter@example.com'
      subject  'Subscribe'
      body     'Please subscribe me'
    end

    email.deliver!

    # Verify subscription email sent
    # TODO: Check MockForge mailbox
  end
end
</code></pre>
<h2 id="cicd-integration-3"><a class="header" href="#cicd-integration-3">CI/CD Integration</a></h2>
<h3 id="github-actions"><a class="header" href="#github-actions">GitHub Actions</a></h3>
<p><code>.github/workflows/test.yml</code>:</p>
<pre><code class="language-yaml">name: Test Email Workflows

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest

    services:
      mockforge:
        image: mockforge/mockforge:latest
        ports:
          - 1025:1025
        env:
          MOCKFORGE_SMTP_ENABLED: true
          MOCKFORGE_SMTP_PORT: 1025

    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Run email tests
        env:
          SMTP_HOST: localhost
          SMTP_PORT: 1025
        run: |
          pytest tests/test_emails.py -v
</code></pre>
<h3 id="gitlab-ci"><a class="header" href="#gitlab-ci">GitLab CI</a></h3>
<p><code>.gitlab-ci.yml</code>:</p>
<pre><code class="language-yaml">test:
  image: python:3.11
  services:
    - name: mockforge/mockforge:latest
      alias: mockforge
  variables:
    MOCKFORGE_SMTP_ENABLED: "true"
    SMTP_HOST: mockforge
    SMTP_PORT: "1025"
  script:
    - pip install -r requirements.txt
    - pytest tests/test_emails.py
</code></pre>
<h3 id="docker-compose"><a class="header" href="#docker-compose">Docker Compose</a></h3>
<p><code>docker-compose.test.yml</code>:</p>
<pre><code class="language-yaml">version: '3.8'

services:
  mockforge:
    image: mockforge/mockforge:latest
    ports:
      - "1025:1025"
    environment:
      MOCKFORGE_SMTP_ENABLED: "true"
      MOCKFORGE_SMTP_PORT: 1025
    volumes:
      - ./fixtures:/fixtures

  app:
    build: .
    depends_on:
      - mockforge
    environment:
      SMTP_HOST: mockforge
      SMTP_PORT: 1025
    command: pytest tests/
</code></pre>
<h2 id="load-testing"><a class="header" href="#load-testing">Load Testing</a></h2>
<h3 id="scenario-4"><a class="header" href="#scenario-4">Scenario</a></h3>
<p>Test application performance with high email volume.</p>
<h3 id="python-load-test"><a class="header" href="#python-load-test">Python Load Test</a></h3>
<pre><code class="language-python">import concurrent.futures
import smtplib
from email.message import EmailMessage
import time

def send_email(index):
    """Send a single email"""
    msg = EmailMessage()
    msg['Subject'] = f'Load Test Email {index}'
    msg['From'] = f'loadtest{index}@test.com'
    msg['To'] = 'recipient@example.com'
    msg.set_content(f'This is load test email #{index}')

    try:
        with smtplib.SMTP('localhost', 1025, timeout=5) as server:
            server.send_message(msg)
        return True
    except Exception as e:
        print(f"Error sending email {index}: {e}")
        return False

def load_test(num_emails=1000, num_workers=10):
    """Send many emails concurrently"""
    print(f"Starting load test: {num_emails} emails with {num_workers} workers")

    start_time = time.time()

    with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:
        results = list(executor.map(send_email, range(num_emails)))

    end_time = time.time()
    duration = end_time - start_time

    success_count = sum(results)
    emails_per_second = num_emails / duration

    print(f"\nResults:")
    print(f"  Total emails: {num_emails}")
    print(f"  Successful: {success_count}")
    print(f"  Failed: {num_emails - success_count}")
    print(f"  Duration: {duration:.2f}s")
    print(f"  Throughput: {emails_per_second:.2f} emails/sec")

if __name__ == "__main__":
    load_test(num_emails=1000, num_workers=20)
</code></pre>
<h3 id="configuration-for-load-testing"><a class="header" href="#configuration-for-load-testing">Configuration for Load Testing</a></h3>
<pre><code class="language-yaml">smtp:
  enabled: true
  port: 1025
  host: "0.0.0.0"
  max_connections: 500
  max_mailbox_messages: 10000
  timeout_secs: 60
</code></pre>
<h2 id="multi-language-applications"><a class="header" href="#multi-language-applications">Multi-Language Applications</a></h2>
<h3 id="scenario-5"><a class="header" href="#scenario-5">Scenario</a></h3>
<p>Test internationalized email content.</p>
<h3 id="fixture-with-template"><a class="header" href="#fixture-with-template">Fixture with Template</a></h3>
<p><code>fixtures/smtp/i18n-welcome.yaml</code>:</p>
<pre><code class="language-yaml">identifier: "i18n-welcome"
name: "Internationalized Welcome"

match_criteria:
  recipient_pattern: "^[^@]+@example\\.com$"
  subject_pattern: "^Welcome|Bienvenue|Willkommen"

response:
  status_code: 250
  message: "Message accepted"

auto_reply:
  enabled: false  # Handle in application

storage:
  save_to_mailbox: true
</code></pre>
<h3 id="python-multi-language-test"><a class="header" href="#python-multi-language-test">Python Multi-Language Test</a></h3>
<pre><code class="language-python">import smtplib
from email.message import EmailMessage
from email.mime.text import MIMEText

def send_welcome_email(recipient, language='en'):
    """Send welcome email in specified language"""

    subjects = {
        'en': 'Welcome to Our Platform',
        'fr': 'Bienvenue sur notre plateforme',
        'de': 'Willkommen auf unserer Plattform',
        'es': 'Bienvenido a nuestra plataforma'
    }

    bodies = {
        'en': 'Welcome! Thank you for registering.',
        'fr': 'Bienvenue! Merci de vous √™tre inscrit.',
        'de': 'Willkommen! Danke f√ºr Ihre Registrierung.',
        'es': '¬°Bienvenido! Gracias por registrarse.'
    }

    msg = EmailMessage()
    msg['Subject'] = subjects.get(language, subjects['en'])
    msg['From'] = 'noreply@example.com'
    msg['To'] = recipient
    msg['Content-Language'] = language
    msg.set_content(bodies.get(language, bodies['en']))

    with smtplib.SMTP('localhost', 1025) as server:
        server.send_message(msg)

def test_multi_language_emails():
    """Test emails in multiple languages"""
    languages = ['en', 'fr', 'de', 'es']

    for lang in languages:
        send_welcome_email(f'user-{lang}@example.com', lang)
        print(f"Sent {lang} email")

if __name__ == "__main__":
    test_multi_language_emails()
</code></pre>
<h2 id="testing-email-bounces"><a class="header" href="#testing-email-bounces">Testing Email Bounces</a></h2>
<h3 id="scenario-6"><a class="header" href="#scenario-6">Scenario</a></h3>
<p>Test application handling of bounced emails.</p>
<h3 id="fixture-4"><a class="header" href="#fixture-4">Fixture</a></h3>
<p><code>fixtures/smtp/bounce-test.yaml</code>:</p>
<pre><code class="language-yaml">identifier: "bounce-simulation"
name: "Bounce Simulation"

match_criteria:
  recipient_pattern: "^bounce@example\\.com$"

response:
  status_code: 550
  message: "Mailbox unavailable"

storage:
  save_to_mailbox: false

behavior:
  failure_rate: 1.0  # Always fail
</code></pre>
<h3 id="test"><a class="header" href="#test">Test</a></h3>
<pre><code class="language-python">import smtplib
from email.message import EmailMessage

def test_bounce_handling():
    """Test that application handles bounces correctly"""

    msg = EmailMessage()
    msg['Subject'] = 'Test Bounce'
    msg['From'] = 'sender@test.com'
    msg['To'] = 'bounce@example.com'
    msg.set_content('This should bounce')

    try:
        with smtplib.SMTP('localhost', 1025) as server:
            server.send_message(msg)
        assert False, "Expected SMTPRecipientsRefused"
    except smtplib.SMTPRecipientsRefused as e:
        # Expected behavior
        print(f"Bounce handled correctly: {e}")
        assert '550' in str(e)
</code></pre>
<h2 id="integration-with-testing-frameworks"><a class="header" href="#integration-with-testing-frameworks">Integration with Testing Frameworks</a></h2>
<h3 id="pytest-fixture"><a class="header" href="#pytest-fixture">pytest Fixture</a></h3>
<pre><code class="language-python">import pytest
import smtplib
from email.message import EmailMessage

@pytest.fixture
def smtp_client():
    """Provides SMTP client connected to MockForge"""
    return smtplib.SMTP('localhost', 1025)

@pytest.fixture
def email_factory():
    """Factory for creating test emails"""
    def _create_email(to, subject="Test", body="Test body"):
        msg = EmailMessage()
        msg['Subject'] = subject
        msg['From'] = 'test@test.com'
        msg['To'] = to
        msg.set_content(body)
        return msg
    return _create_email

def test_with_fixtures(smtp_client, email_factory):
    """Test using pytest fixtures"""
    email = email_factory('user@example.com', subject='Welcome')
    smtp_client.send_message(email)
    # Verify email sent
</code></pre>
<h3 id="unittest-helper"><a class="header" href="#unittest-helper">unittest Helper</a></h3>
<pre><code class="language-python">import unittest
import smtplib

class EmailTestCase(unittest.TestCase):
    @classmethod
    def setUpClass(cls):
        """Set up SMTP connection for all tests"""
        cls.smtp_host = 'localhost'
        cls.smtp_port = 1025

    def send_test_email(self, to, subject, body):
        """Helper method to send test emails"""
        with smtplib.SMTP(self.smtp_host, self.smtp_port) as server:
            # ... send email
            pass

    def test_email_sending(self):
        self.send_test_email('test@example.com', 'Test', 'Body')
        # Verify
</code></pre>
<h2 id="best-practices-6"><a class="header" href="#best-practices-6">Best Practices</a></h2>
<ol>
<li><strong>Use dedicated fixtures</strong> for each test scenario</li>
<li><strong>Clean mailbox</strong> between test runs</li>
<li><strong>Test both success and failure</strong> scenarios</li>
<li><strong>Verify email content</strong>, not just delivery</li>
<li><strong>Use realistic delays</strong> in load tests</li>
<li><strong>Test internationalization</strong> early</li>
<li><strong>Mock external dependencies</strong> completely</li>
</ol>
<h2 id="troubleshooting-19"><a class="header" href="#troubleshooting-19">Troubleshooting</a></h2>
<h3 id="emails-not-received"><a class="header" href="#emails-not-received">Emails Not Received</a></h3>
<p>Check:</p>
<ol>
<li>SMTP server is running</li>
<li>Correct port (1025)</li>
<li>Fixture patterns match</li>
<li>Mailbox not full</li>
</ol>
<h3 id="slow-tests"><a class="header" href="#slow-tests">Slow Tests</a></h3>
<p>Optimize:</p>
<ol>
<li>Reduce <code>delay_ms</code> in fixtures</li>
<li>Disable <code>save_to_mailbox</code> if not needed</li>
<li>Use concurrent connections in load tests</li>
</ol>
<h3 id="fixture-not-matching-1"><a class="header" href="#fixture-not-matching-1">Fixture Not Matching</a></h3>
<p>Debug:</p>
<ol>
<li>Enable debug logging</li>
<li>Simplify regex patterns</li>
<li>Test patterns with regex101.com</li>
<li>Check fixture load order</li>
</ol>
<h2 id="related-documentation-5"><a class="header" href="#related-documentation-5">Related Documentation</a></h2>
<ul>
<li><a href="protocols/smtp/./getting-started.html">Getting Started</a></li>
<li><a href="protocols/smtp/./configuration.html">Configuration</a></li>
<li><a href="protocols/smtp/./fixtures.html">Fixtures</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="getting-started-with-ftp-mocking"><a class="header" href="#getting-started-with-ftp-mocking">Getting Started with FTP Mocking</a></h1>
<p>MockForge provides comprehensive FTP server mocking capabilities, allowing you to simulate FTP file transfers for testing and development purposes.</p>
<h2 id="quick-start-4"><a class="header" href="#quick-start-4">Quick Start</a></h2>
<h3 id="starting-an-ftp-server"><a class="header" href="#starting-an-ftp-server">Starting an FTP Server</a></h3>
<pre><code class="language-bash"># Start a basic FTP server on port 2121
mockforge ftp serve --port 2121

# Start with custom configuration
mockforge ftp serve --host 0.0.0.0 --port 2121 --virtual-root /ftp
</code></pre>
<h3 id="connecting-with-an-ftp-client"><a class="header" href="#connecting-with-an-ftp-client">Connecting with an FTP Client</a></h3>
<p>Once the server is running, you can connect using any FTP client:</p>
<pre><code class="language-bash"># Using lftp
lftp ftp://localhost:2121

# Using curl
curl ftp://localhost:2121/

# Using FileZilla or other GUI clients
# Host: localhost
# Port: 2121
# Username: (leave blank for anonymous)
# Password: (leave blank)
</code></pre>
<h2 id="basic-concepts-1"><a class="header" href="#basic-concepts-1">Basic Concepts</a></h2>
<h3 id="virtual-file-system"><a class="header" href="#virtual-file-system">Virtual File System</a></h3>
<p>MockForge FTP uses an in-memory virtual file system that supports:</p>
<ul>
<li><strong>Static files</strong>: Pre-defined content</li>
<li><strong>Template files</strong>: Dynamic content generation using Handlebars</li>
<li><strong>Generated files</strong>: Synthetic content (random, zeros, patterns)</li>
<li><strong>Upload handling</strong>: Configurable validation and storage rules</li>
</ul>
<h3 id="file-content-types"><a class="header" href="#file-content-types">File Content Types</a></h3>
<h4 id="static-content"><a class="header" href="#static-content">Static Content</a></h4>
<pre><code class="language-bash"># Add a static file
mockforge ftp vfs add /hello.txt --content "Hello, World!"
</code></pre>
<h4 id="template-content"><a class="header" href="#template-content">Template Content</a></h4>
<pre><code class="language-bash"># Add a template file with dynamic content
mockforge ftp vfs add /user.json --template '{"name": "{{faker.name}}", "id": "{{uuid}}", "timestamp": "{{now}}"}'
</code></pre>
<h4 id="generated-content"><a class="header" href="#generated-content">Generated Content</a></h4>
<pre><code class="language-bash"># Add a file with random content
mockforge ftp vfs add /random.bin --generate random --size 1024

# Add a file filled with zeros
mockforge ftp vfs add /zeros.bin --generate zeros --size 1024
</code></pre>
<h2 id="ftp-commands-supported"><a class="header" href="#ftp-commands-supported">FTP Commands Supported</a></h2>
<p>MockForge supports standard FTP commands:</p>
<ul>
<li><code>LIST</code> - Directory listing</li>
<li><code>RETR</code> - Download files</li>
<li><code>STOR</code> - Upload files</li>
<li><code>DELE</code> - Delete files</li>
<li><code>PWD</code> - Print working directory</li>
<li><code>SIZE</code> - Get file size</li>
<li><code>CWD</code> - Change directory (limited support)</li>
</ul>
<h2 id="example-session"><a class="header" href="#example-session">Example Session</a></h2>
<pre><code class="language-bash">$ mockforge ftp serve --port 2121 &amp;
$ lftp localhost:2121
lftp localhost:2121:~&gt; ls
-rw-r--r-- 1 mockforge ftp          0 Jan 01 00:00 test.txt
lftp localhost:2121:~&gt; put localfile.txt
lftp localhost:2121:~&gt; get test.txt
lftp localhost:2121:~&gt; quit
</code></pre>
<h2 id="next-steps-15"><a class="header" href="#next-steps-15">Next Steps</a></h2>
<ul>
<li><a href="protocols/ftp/configuration.html">Configuration</a> - Advanced server configuration</li>
<li><a href="protocols/ftp/fixtures.html">Fixtures</a> - Pre-configured file structures</li>
<li><a href="protocols/ftp/examples.html">Examples</a> - Complete usage examples</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="ftp-server-configuration"><a class="header" href="#ftp-server-configuration">FTP Server Configuration</a></h1>
<p>MockForge FTP servers can be configured through command-line options or configuration files.</p>
<h2 id="command-line-options"><a class="header" href="#command-line-options">Command Line Options</a></h2>
<h3 id="server-options"><a class="header" href="#server-options">Server Options</a></h3>
<pre><code class="language-bash">mockforge ftp serve [OPTIONS]
</code></pre>
<div class="table-wrapper"><table><thead><tr><th>Option</th><th>Description</th><th>Default</th></tr></thead><tbody>
<tr><td><code>--port &lt;PORT&gt;</code></td><td>FTP server port</td><td><code>2121</code></td></tr>
<tr><td><code>--host &lt;HOST&gt;</code></td><td>FTP server host</td><td><code>127.0.0.1</code></td></tr>
<tr><td><code>--virtual-root &lt;PATH&gt;</code></td><td>Virtual file system root path</td><td><code>/</code></td></tr>
<tr><td><code>--config &lt;FILE&gt;</code></td><td>Configuration file path</td><td>-</td></tr>
</tbody></table>
</div>
<h3 id="examples-6"><a class="header" href="#examples-6">Examples</a></h3>
<pre><code class="language-bash"># Basic server
mockforge ftp serve

# Custom port and host
mockforge ftp serve --port 2122 --host 0.0.0.0

# With configuration file
mockforge ftp serve --config ftp-config.yaml
</code></pre>
<h2 id="configuration-file-1"><a class="header" href="#configuration-file-1">Configuration File</a></h2>
<p>FTP servers can be configured using a YAML configuration file:</p>
<pre><code class="language-yaml">ftp:
  host: "127.0.0.1"
  port: 2121
  virtual_root: "/"
  fixtures:
    - name: "sample_files"
      description: "Sample files for testing"
      virtual_files:
        - path: "/welcome.txt"
          content:
            type: "static"
            content: "Welcome to MockForge FTP!"
          permissions: "644"
          owner: "ftp"
          group: "ftp"
      upload_rules:
        - path_pattern: "/uploads/.*"
          auto_accept: true
          max_size_bytes: 1048576  # 1MB
          allowed_extensions: ["txt", "json", "xml"]
          storage:
            type: "memory"
</code></pre>
<h2 id="virtual-file-system-configuration"><a class="header" href="#virtual-file-system-configuration">Virtual File System Configuration</a></h2>
<h3 id="file-content-types-1"><a class="header" href="#file-content-types-1">File Content Types</a></h3>
<h4 id="static-content-1"><a class="header" href="#static-content-1">Static Content</a></h4>
<pre><code class="language-yaml">content:
  type: "static"
  content: "Hello, World!"
</code></pre>
<h4 id="template-content-1"><a class="header" href="#template-content-1">Template Content</a></h4>
<pre><code class="language-yaml">content:
  type: "template"
  template: '{"user": "{{faker.name}}", "id": "{{uuid}}", "time": "{{now}}"}'
</code></pre>
<h4 id="generated-content-1"><a class="header" href="#generated-content-1">Generated Content</a></h4>
<pre><code class="language-yaml">content:
  type: "generated"
  size: 1024
  pattern: "random"  # random, zeros, ones, incremental
</code></pre>
<h3 id="upload-rules"><a class="header" href="#upload-rules">Upload Rules</a></h3>
<p>Upload rules control how files are accepted and stored:</p>
<pre><code class="language-yaml">upload_rules:
  - path_pattern: "/uploads/.*"  # Regex pattern
    auto_accept: true           # Auto-accept uploads
    max_size_bytes: 1048576     # Maximum file size
    allowed_extensions:         # Allowed file extensions
      - "txt"
      - "json"
    storage:                    # Storage backend
      type: "memory"           # memory, file, discard
</code></pre>
<h3 id="storage-options"><a class="header" href="#storage-options">Storage Options</a></h3>
<h4 id="memory-storage"><a class="header" href="#memory-storage">Memory Storage</a></h4>
<p>Files are stored in memory (default):</p>
<pre><code class="language-yaml">storage:
  type: "memory"
</code></pre>
<h4 id="file-storage"><a class="header" href="#file-storage">File Storage</a></h4>
<p>Files are written to the local filesystem:</p>
<pre><code class="language-yaml">storage:
  type: "file"
  path: "/tmp/uploads"
</code></pre>
<h4 id="discard-storage"><a class="header" href="#discard-storage">Discard Storage</a></h4>
<p>Files are accepted but not stored:</p>
<pre><code class="language-yaml">storage:
  type: "discard"
</code></pre>
<h2 id="template-variables-2"><a class="header" href="#template-variables-2">Template Variables</a></h2>
<p>When using template content, the following variables are available:</p>
<h3 id="timestamps"><a class="header" href="#timestamps">Timestamps</a></h3>
<ul>
<li><code>{{now}}</code> - Current timestamp in RFC3339 format</li>
<li><code>{{timestamp}}</code> - Unix timestamp (seconds)</li>
<li><code>{{date}}</code> - Current date (YYYY-MM-DD)</li>
<li><code>{{time}}</code> - Current time (HH:MM:SS)</li>
</ul>
<h3 id="random-values"><a class="header" href="#random-values">Random Values</a></h3>
<ul>
<li><code>{{random_int}}</code> - Random 64-bit integer</li>
<li><code>{{random_float}}</code> - Random float (0.0-1.0)</li>
<li><code>{{uuid}}</code> - Random UUID v4</li>
</ul>
<h3 id="sample-data"><a class="header" href="#sample-data">Sample Data</a></h3>
<ul>
<li><code>{{faker.name}}</code> - Random name</li>
<li><code>{{faker.email}}</code> - Random email address</li>
<li><code>{{faker.age}}</code> - Random age (18-80)</li>
</ul>
<h3 id="example-templates"><a class="header" href="#example-templates">Example Templates</a></h3>
<pre><code class="language-yaml"># JSON response with dynamic data
content:
  type: "template"
  template: |
    {
      "id": "{{uuid}}",
      "name": "{{faker.name}}",
      "email": "{{faker.email}}",
      "created_at": "{{now}}",
      "age": {{faker.age}}
    }

# Log file with timestamps
content:
  type: "template"
  template: "[{{timestamp}}] INFO: Application started at {{time}}"
</code></pre>
<h2 id="passive-mode-configuration"><a class="header" href="#passive-mode-configuration">Passive Mode Configuration</a></h2>
<p>FTP passive mode uses dynamic port ranges. The server automatically configures passive ports in the range 49152-65535.</p>
<h2 id="authentication"><a class="header" href="#authentication">Authentication</a></h2>
<p>Currently, MockForge FTP servers support anonymous access only. Authentication can be added in future versions.</p>
<h2 id="performance-tuning-2"><a class="header" href="#performance-tuning-2">Performance Tuning</a></h2>
<h3 id="memory-usage"><a class="header" href="#memory-usage">Memory Usage</a></h3>
<ul>
<li>Virtual file system stores all files in memory</li>
<li>Large files or many files may consume significant memory</li>
<li>Consider using file-based storage for large uploads</li>
</ul>
<h3 id="connection-limits"><a class="header" href="#connection-limits">Connection Limits</a></h3>
<ul>
<li>No built-in connection limits</li>
<li>Consider system ulimits for production use</li>
</ul>
<h3 id="timeouts"><a class="header" href="#timeouts">Timeouts</a></h3>
<ul>
<li>No configurable timeouts</li>
<li>Uses libunftp defaults</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="ftp-fixtures"><a class="header" href="#ftp-fixtures">FTP Fixtures</a></h1>
<p>FTP fixtures allow you to pre-configure file structures and upload rules for your mock FTP server.</p>
<h2 id="fixture-structure"><a class="header" href="#fixture-structure">Fixture Structure</a></h2>
<p>Fixtures are defined in YAML format and contain:</p>
<ul>
<li><strong>Virtual files</strong>: Pre-defined files in the virtual file system</li>
<li><strong>Upload rules</strong>: Rules for accepting and handling file uploads</li>
</ul>
<h2 id="basic-fixture-example"><a class="header" href="#basic-fixture-example">Basic Fixture Example</a></h2>
<pre><code class="language-yaml">fixtures:
  - name: "sample_files"
    description: "Sample files for testing FTP clients"
    virtual_files:
      - path: "/welcome.txt"
        content:
          type: "static"
          content: "Welcome to MockForge FTP Server!"
        permissions: "644"
        owner: "ftp"
        group: "ftp"
      - path: "/data.json"
        content:
          type: "template"
          template: '{"timestamp": "{{now}}", "server": "mockforge"}'
        permissions: "644"
        owner: "ftp"
        group: "ftp"
    upload_rules:
      - path_pattern: "/uploads/.*"
        auto_accept: true
        max_size_bytes: 1048576
        allowed_extensions: ["txt", "json", "xml"]
        storage:
          type: "memory"
</code></pre>
<h2 id="virtual-files"><a class="header" href="#virtual-files">Virtual Files</a></h2>
<h3 id="static-content-files"><a class="header" href="#static-content-files">Static Content Files</a></h3>
<pre><code class="language-yaml">virtual_files:
  - path: "/readme.txt"
    content:
      type: "static"
      content: |
        This is a mock FTP server.
        You can upload files to the /uploads directory.
    permissions: "644"
    owner: "ftp"
    group: "ftp"
</code></pre>
<h3 id="template-files"><a class="header" href="#template-files">Template Files</a></h3>
<pre><code class="language-yaml">virtual_files:
  - path: "/status.json"
    content:
      type: "template"
      template: |
        {
          "server": "MockForge FTP",
          "version": "1.0.0",
          "uptime": "{{timestamp}}",
          "status": "running"
        }
    permissions: "644"
    owner: "ftp"
    group: "ftp"
</code></pre>
<h3 id="generated-content-files"><a class="header" href="#generated-content-files">Generated Content Files</a></h3>
<pre><code class="language-yaml">virtual_files:
  - path: "/random.bin"
    content:
      type: "generated"
      size: 1024
      pattern: "random"
    permissions: "644"
    owner: "ftp"
    group: "ftp"
</code></pre>
<h2 id="upload-rules-1"><a class="header" href="#upload-rules-1">Upload Rules</a></h2>
<p>Upload rules control how the server handles file uploads.</p>
<h3 id="basic-upload-rule"><a class="header" href="#basic-upload-rule">Basic Upload Rule</a></h3>
<pre><code class="language-yaml">upload_rules:
  - path_pattern: "/uploads/.*"
    auto_accept: true
    storage:
      type: "memory"
</code></pre>
<h3 id="advanced-upload-rule"><a class="header" href="#advanced-upload-rule">Advanced Upload Rule</a></h3>
<pre><code class="language-yaml">upload_rules:
  - path_pattern: "/documents/.*"
    auto_accept: true
    validation:
      max_size_bytes: 5242880  # 5MB
      allowed_extensions: ["pdf", "doc", "docx", "txt"]
      mime_types: ["application/pdf", "application/msword"]
    storage:
      type: "file"
      path: "/tmp/uploads"
</code></pre>
<h3 id="validation-options"><a class="header" href="#validation-options">Validation Options</a></h3>
<h4 id="file-size-limits"><a class="header" href="#file-size-limits">File Size Limits</a></h4>
<pre><code class="language-yaml">validation:
  max_size_bytes: 1048576  # 1MB limit
</code></pre>
<h4 id="file-extensions"><a class="header" href="#file-extensions">File Extensions</a></h4>
<pre><code class="language-yaml">validation:
  allowed_extensions: ["jpg", "png", "gif"]
</code></pre>
<h4 id="mime-types"><a class="header" href="#mime-types">MIME Types</a></h4>
<pre><code class="language-yaml">validation:
  mime_types: ["image/jpeg", "image/png"]
</code></pre>
<h3 id="storage-backends"><a class="header" href="#storage-backends">Storage Backends</a></h3>
<h4 id="memory-storage-1"><a class="header" href="#memory-storage-1">Memory Storage</a></h4>
<p>Files are stored in memory (default):</p>
<pre><code class="language-yaml">storage:
  type: "memory"
</code></pre>
<h4 id="file-storage-1"><a class="header" href="#file-storage-1">File Storage</a></h4>
<p>Files are written to disk:</p>
<pre><code class="language-yaml">storage:
  type: "file"
  path: "/var/ftp/uploads"
</code></pre>
<h4 id="discard-storage-1"><a class="header" href="#discard-storage-1">Discard Storage</a></h4>
<p>Files are accepted but not stored:</p>
<pre><code class="language-yaml">storage:
  type: "discard"
</code></pre>
<h2 id="loading-fixtures-2"><a class="header" href="#loading-fixtures-2">Loading Fixtures</a></h2>
<h3 id="from-configuration-file"><a class="header" href="#from-configuration-file">From Configuration File</a></h3>
<pre><code class="language-bash">mockforge ftp serve --config ftp-config.yaml
</code></pre>
<h3 id="from-directory"><a class="header" href="#from-directory">From Directory</a></h3>
<pre><code class="language-bash">mockforge ftp fixtures load ./fixtures/ftp/
</code></pre>
<h3 id="validate-fixtures"><a class="header" href="#validate-fixtures">Validate Fixtures</a></h3>
<pre><code class="language-bash">mockforge ftp fixtures validate fixture.yaml
</code></pre>
<h2 id="example-complete-fixture"><a class="header" href="#example-complete-fixture">Example Complete Fixture</a></h2>
<pre><code class="language-yaml">fixtures:
  - name: "test_environment"
    description: "Complete test environment with various file types"
    virtual_files:
      # Static files
      - path: "/readme.txt"
        content:
          type: "static"
          content: "FTP Test Server - Upload files to /uploads/"
        permissions: "644"
        owner: "ftp"
        group: "ftp"

      # Template files
      - path: "/server-info.json"
        content:
          type: "template"
          template: |
            {
              "server": "MockForge FTP",
              "started_at": "{{now}}",
              "session_id": "{{uuid}}"
            }
        permissions: "644"
        owner: "ftp"
        group: "ftp"

      # Generated files
      - path: "/test-data.bin"
        content:
          type: "generated"
          size: 4096
          pattern: "random"
        permissions: "644"
        owner: "ftp"
        group: "ftp"

    upload_rules:
      # General uploads
      - path_pattern: "/uploads/.*"
        auto_accept: true
        validation:
          max_size_bytes: 10485760  # 10MB
        storage:
          type: "memory"

      # Image uploads
      - path_pattern: "/images/.*"
        auto_accept: true
        validation:
          max_size_bytes: 5242880  # 5MB
          allowed_extensions: ["jpg", "jpeg", "png", "gif"]
          mime_types: ["image/jpeg", "image/png", "image/gif"]
        storage:
          type: "file"
          path: "/tmp/images"

      # Log files (discard)
      - path_pattern: "/logs/.*"
        auto_accept: true
        storage:
          type: "discard"
</code></pre>
<h2 id="cli-management"><a class="header" href="#cli-management">CLI Management</a></h2>
<h3 id="list-fixtures"><a class="header" href="#list-fixtures">List Fixtures</a></h3>
<pre><code class="language-bash">mockforge ftp fixtures list
</code></pre>
<h3 id="load-fixtures"><a class="header" href="#load-fixtures">Load Fixtures</a></h3>
<pre><code class="language-bash"># Load from directory
mockforge ftp fixtures load ./fixtures/

# Load specific file
mockforge ftp fixtures load fixture.yaml
</code></pre>
<h3 id="validate-fixtures-1"><a class="header" href="#validate-fixtures-1">Validate Fixtures</a></h3>
<pre><code class="language-bash">mockforge ftp fixtures validate fixture.yaml
</code></pre>
<h2 id="virtual-file-system-management"><a class="header" href="#virtual-file-system-management">Virtual File System Management</a></h2>
<h3 id="add-files"><a class="header" href="#add-files">Add Files</a></h3>
<pre><code class="language-bash"># Static content
mockforge ftp vfs add /hello.txt --content "Hello World"

# Template content
mockforge ftp vfs add /user.json --template '{"name": "{{faker.name}}"}'

# Generated content
mockforge ftp vfs add /data.bin --generate random --size 1024
</code></pre>
<h3 id="list-files"><a class="header" href="#list-files">List Files</a></h3>
<pre><code class="language-bash">mockforge ftp vfs list /
</code></pre>
<h3 id="remove-files"><a class="header" href="#remove-files">Remove Files</a></h3>
<pre><code class="language-bash">mockforge ftp vfs remove /old-file.txt
</code></pre>
<h3 id="get-file-info"><a class="header" href="#get-file-info">Get File Info</a></h3>
<pre><code class="language-bash">mockforge ftp vfs info /hello.txt
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="ftp-examples"><a class="header" href="#ftp-examples">FTP Examples</a></h1>
<p>This section provides complete examples of using MockForge FTP for various testing scenarios.</p>
<h2 id="basic-ftp-server"><a class="header" href="#basic-ftp-server">Basic FTP Server</a></h2>
<h3 id="starting-a-simple-server"><a class="header" href="#starting-a-simple-server">Starting a Simple Server</a></h3>
<pre><code class="language-bash"># Start FTP server on default port 2121
mockforge ftp serve

# Start on custom port
mockforge ftp serve --port 2122

# Start with custom host
mockforge ftp serve --host 0.0.0.0 --port 2121
</code></pre>
<h3 id="connecting-with-ftp-clients"><a class="header" href="#connecting-with-ftp-clients">Connecting with FTP Clients</a></h3>
<h4 id="using-lftp"><a class="header" href="#using-lftp">Using lftp</a></h4>
<pre><code class="language-bash"># Connect to the server
lftp localhost:2121

# List files
lftp localhost:2121:~&gt; ls

# Download a file
lftp localhost:2121:~&gt; get test.txt

# Upload a file
lftp localhost:2121:~&gt; put localfile.txt

# Exit
lftp localhost:2121:~&gt; quit
</code></pre>
<h4 id="using-curl"><a class="header" href="#using-curl">Using curl</a></h4>
<pre><code class="language-bash"># List directory
curl ftp://localhost:2121/

# Download file
curl ftp://localhost:2121/test.txt -o downloaded.txt

# Upload file
curl -T localfile.txt ftp://localhost:2121/
</code></pre>
<h4 id="using-python"><a class="header" href="#using-python">Using Python</a></h4>
<pre><code class="language-python">import ftplib

# Connect to FTP server
ftp = ftplib.FTP('localhost', 'anonymous', '')

# List files
files = ftp.nlst()
print("Files:", files)

# Download file
with open('downloaded.txt', 'wb') as f:
    ftp.retrbinary('RETR test.txt', f.write)

# Upload file
with open('localfile.txt', 'rb') as f:
    ftp.storbinary('STOR uploaded.txt', f)

ftp.quit()
</code></pre>
<h2 id="file-management-examples"><a class="header" href="#file-management-examples">File Management Examples</a></h2>
<h3 id="adding-static-files"><a class="header" href="#adding-static-files">Adding Static Files</a></h3>
<pre><code class="language-bash"># Add a simple text file
mockforge ftp vfs add /hello.txt --content "Hello, FTP World!"

# Add a JSON file
mockforge ftp vfs add /config.json --content '{"server": "mockforge", "port": 2121}'

# Add a larger file
echo "This is a test file with multiple lines." &gt; test.txt
mockforge ftp vfs add /multiline.txt --content "$(cat test.txt)"
</code></pre>
<h3 id="adding-template-files"><a class="header" href="#adding-template-files">Adding Template Files</a></h3>
<pre><code class="language-bash"># Add a dynamic JSON response
mockforge ftp vfs add /user.json --template '{"id": "{{uuid}}", "name": "{{faker.name}}", "created": "{{now}}"}'

# Add a log file with timestamps
mockforge ftp vfs add /server.log --template '[{{timestamp}}] Server started at {{time}}'

# Add a status file
mockforge ftp vfs add /status.xml --template '&lt;?xml version="1.0"?&gt;&lt;status&gt;&lt;server&gt;MockForge&lt;/server&gt;&lt;time&gt;{{now}}&lt;/time&gt;&lt;/status&gt;'
</code></pre>
<h3 id="adding-generated-files"><a class="header" href="#adding-generated-files">Adding Generated Files</a></h3>
<pre><code class="language-bash"># Add a random binary file (1KB)
mockforge ftp vfs add /random.bin --generate random --size 1024

# Add a file filled with zeros (512 bytes)
mockforge ftp vfs add /zeros.dat --generate zeros --size 512

# Add an incremental pattern file
mockforge ftp vfs add /pattern.bin --generate incremental --size 256
</code></pre>
<h3 id="managing-files"><a class="header" href="#managing-files">Managing Files</a></h3>
<pre><code class="language-bash"># List all files
mockforge ftp vfs list /

# Get file information
mockforge ftp vfs info /hello.txt

# Remove a file
mockforge ftp vfs remove /old-file.txt
</code></pre>
<h2 id="configuration-examples-1"><a class="header" href="#configuration-examples-1">Configuration Examples</a></h2>
<h3 id="basic-configuration-file"><a class="header" href="#basic-configuration-file">Basic Configuration File</a></h3>
<pre><code class="language-yaml"># ftp-config.yaml
ftp:
  host: "127.0.0.1"
  port: 2121
  virtual_root: "/"
  fixtures:
    - name: "basic_files"
      description: "Basic test files"
      virtual_files:
        - path: "/readme.txt"
          content:
            type: "static"
            content: "Welcome to MockForge FTP Server"
          permissions: "644"
          owner: "ftp"
          group: "ftp"
      upload_rules:
        - path_pattern: "/uploads/.*"
          auto_accept: true
          storage:
            type: "memory"
</code></pre>
<h3 id="advanced-configuration-1"><a class="header" href="#advanced-configuration-1">Advanced Configuration</a></h3>
<pre><code class="language-yaml"># advanced-ftp-config.yaml
ftp:
  host: "0.0.0.0"
  port: 2121
  virtual_root: "/ftp"
  fixtures:
    - name: "api_test_files"
      description: "Files for API testing"
      virtual_files:
        # Static files
        - path: "/api/v1/users"
          content:
            type: "static"
            content: '[{"id": 1, "name": "Alice"}, {"id": 2, "name": "Bob"}]'
          permissions: "644"
          owner: "api"
          group: "users"

        # Template files
        - path: "/api/v1/status"
          content:
            type: "template"
            template: '{"status": "ok", "timestamp": "{{now}}", "version": "1.0.0"}'
          permissions: "644"
          owner: "api"
          group: "system"

        # Generated test data
        - path: "/test/data.bin"
          content:
            type: "generated"
            size: 1048576  # 1MB
            pattern: "random"
          permissions: "644"
          owner: "test"
          group: "data"

      upload_rules:
        # General uploads
        - path_pattern: "/uploads/.*"
          auto_accept: true
          validation:
            max_size_bytes: 10485760  # 10MB
          storage:
            type: "memory"

        # Image uploads
        - path_pattern: "/images/.*"
          auto_accept: true
          validation:
            max_size_bytes: 5242880  # 5MB
            allowed_extensions: ["jpg", "png", "gif"]
          storage:
            type: "file"
            path: "/tmp/ftp/images"

        # Log files (accepted but discarded)
        - path_pattern: "/logs/.*"
          auto_accept: true
          storage:
            type: "discard"
</code></pre>
<h2 id="testing-scenarios"><a class="header" href="#testing-scenarios">Testing Scenarios</a></h2>
<h3 id="file-upload-testing"><a class="header" href="#file-upload-testing">File Upload Testing</a></h3>
<pre><code class="language-bash"># Start server with upload configuration
mockforge ftp serve --config upload-config.yaml

# Test file upload with curl
echo "Test file content" &gt; test.txt
curl -T test.txt ftp://localhost:2121/uploads/

# Test large file upload
dd if=/dev/zero of=large.bin bs=1M count=5
curl -T large.bin ftp://localhost:2121/uploads/

# Test invalid file type
echo "invalid content" &gt; invalid.exe
curl -T invalid.exe ftp://localhost:2121/uploads/  # Should fail
</code></pre>
<h3 id="load-testing-1"><a class="header" href="#load-testing-1">Load Testing</a></h3>
<pre><code class="language-bash"># Start server
mockforge ftp serve --port 2121 &amp;

# Simple load test with parallel uploads
for i in {1..10}; do
  echo "File $i content" &gt; "file$i.txt"
  curl -T "file$i.txt" "ftp://localhost:2121/uploads/file$i.txt" &amp;
done
wait
</code></pre>
<h3 id="integration-testing-1"><a class="header" href="#integration-testing-1">Integration Testing</a></h3>
<h4 id="with-pytest"><a class="header" href="#with-pytest">With pytest</a></h4>
<pre><code class="language-python"># test_ftp_integration.py
import ftplib
import pytest
import tempfile
import os

class TestFTPIntegration:
    @pytest.fixture(scope="class")
    def ftp_client(self):
        # Connect to MockForge FTP server
        ftp = ftplib.FTP('localhost', 'anonymous', '')
        yield ftp
        ftp.quit()

    def test_list_files(self, ftp_client):
        files = ftp_client.nlst()
        assert len(files) &gt;= 0  # At least empty directory

    def test_download_file(self, ftp_client):
        # Assuming server has a test file
        with tempfile.NamedTemporaryFile(delete=False) as tmp:
            try:
                ftp_client.retrbinary('RETR test.txt', tmp.write)
                assert os.path.getsize(tmp.name) &gt; 0
            finally:
                os.unlink(tmp.name)

    def test_upload_file(self, ftp_client):
        # Create test file
        with tempfile.NamedTemporaryFile(mode='w', delete=False) as tmp:
            tmp.write("Test upload content")
            tmp_path = tmp.name

        try:
            # Upload file
            with open(tmp_path, 'rb') as f:
                ftp_client.storbinary('STOR uploaded.txt', f)

            # Verify upload (if server supports listing uploads)
            files = ftp_client.nlst()
            assert 'uploaded.txt' in [os.path.basename(f) for f in files]
        finally:
            os.unlink(tmp_path)
</code></pre>
<h4 id="with-java"><a class="header" href="#with-java">With Java</a></h4>
<pre><code class="language-java">// FtpIntegrationTest.java
import org.apache.commons.net.ftp.FTPClient;
import org.junit.jupiter.api.*;
import java.io.*;

class FtpIntegrationTest {
    private FTPClient ftpClient;

    @BeforeEach
    void setup() throws IOException {
        ftpClient = new FTPClient();
        ftpClient.connect("localhost", 2121);
        ftpClient.login("anonymous", "");
        ftpClient.enterLocalPassiveMode();
    }

    @AfterEach
    void teardown() throws IOException {
        if (ftpClient.isConnected()) {
            ftpClient.disconnect();
        }
    }

    @Test
    void testFileDownload() throws IOException {
        // Download a file
        File tempFile = File.createTempFile("downloaded", ".txt");
        try (FileOutputStream fos = new FileOutputStream(tempFile)) {
            boolean success = ftpClient.retrieveFile("test.txt", fos);
            Assertions.assertTrue(success, "File download should succeed");
            Assertions.assertTrue(tempFile.length() &gt; 0, "Downloaded file should not be empty");
        } finally {
            tempFile.delete();
        }
    }

    @Test
    void testFileUpload() throws IOException {
        // Create test file
        File tempFile = File.createTempFile("upload", ".txt");
        try (FileWriter writer = new FileWriter(tempFile)) {
            writer.write("Test upload content");
        }

        // Upload file
        try (FileInputStream fis = new FileInputStream(tempFile)) {
            boolean success = ftpClient.storeFile("uploaded.txt", fis);
            Assertions.assertTrue(success, "File upload should succeed");
        } finally {
            tempFile.delete();
        }
    }

    @Test
    void testDirectoryListing() throws IOException {
        FTPFile[] files = ftpClient.listFiles();
        Assertions.assertNotNull(files, "Directory listing should not be null");
        // Additional assertions based on expected files
    }
}
</code></pre>
<h2 id="docker-integration"><a class="header" href="#docker-integration">Docker Integration</a></h2>
<h3 id="running-in-docker"><a class="header" href="#running-in-docker">Running in Docker</a></h3>
<pre><code class="language-dockerfile"># Dockerfile
FROM mockforge:latest

# Copy FTP configuration
COPY ftp-config.yaml /app/config/

# Expose FTP port
EXPOSE 2121

# Start FTP server
CMD ["mockforge", "ftp", "serve", "--config", "/app/config/ftp-config.yaml"]
</code></pre>
<pre><code class="language-bash"># Build and run
docker build -t mockforge-ftp .
docker run -p 2121:2121 mockforge-ftp
</code></pre>
<h3 id="docker-compose-1"><a class="header" href="#docker-compose-1">Docker Compose</a></h3>
<pre><code class="language-yaml"># docker-compose.yml
version: '3.8'
services:
  ftp-server:
    image: mockforge:latest
    command: ["mockforge", "ftp", "serve", "--host", "0.0.0.0"]
    ports:
      - "2121:2121"
    volumes:
      - ./ftp-config.yaml:/app/config/ftp-config.yaml
      - ./uploads:/tmp/uploads
    environment:
      - RUST_LOG=info
</code></pre>
<h2 id="cicd-integration-4"><a class="header" href="#cicd-integration-4">CI/CD Integration</a></h2>
<h3 id="github-actions-example"><a class="header" href="#github-actions-example">GitHub Actions Example</a></h3>
<pre><code class="language-yaml"># .github/workflows/ftp-test.yml
name: FTP Integration Tests

on: [push, pull_request]

jobs:
  ftp-test:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v3

    - name: Setup Rust
      uses: actions-rust-lang/setup-rust-toolchain@v1

    - name: Build MockForge
      run: cargo build --release

    - name: Start FTP Server
      run: |
        ./target/release/mockforge ftp serve --port 2121 &amp;
        sleep 2

    - name: Run FTP Tests
      run: |
        # Test with lftp
        sudo apt-get update &amp;&amp; sudo apt-get install -y lftp
        echo "Test file content" &gt; test.txt
        lftp -c "open localhost:2121; put test.txt; ls; get test.txt -o downloaded.txt; quit"

        # Verify files
        test -f downloaded.txt
        grep -q "Test file content" downloaded.txt
</code></pre>
<h3 id="jenkins-pipeline"><a class="header" href="#jenkins-pipeline">Jenkins Pipeline</a></h3>
<pre><code class="language-groovy">// Jenkinsfile
pipeline {
    agent any

    stages {
        stage('FTP Integration Test') {
            steps {
                sh 'cargo build --release'

                // Start FTP server in background
                sh './target/release/mockforge ftp serve --port 2121 &amp;'
                sh 'sleep 3'

                // Run tests
                sh '''
                # Install FTP client
                apt-get update &amp;&amp; apt-get install -y lftp

                # Create test file
                echo "Integration test content" &gt; test.txt

                # Test FTP operations
                lftp -c "
                  open localhost:2121
                  put test.txt
                  ls
                  get test.txt -o downloaded.txt
                  quit
                "

                # Verify
                grep -q "Integration test content" downloaded.txt
                '''
            }
        }
    }
}
</code></pre>
<h2 id="troubleshooting-20"><a class="header" href="#troubleshooting-20">Troubleshooting</a></h2>
<h3 id="common-issues-3"><a class="header" href="#common-issues-3">Common Issues</a></h3>
<h4 id="connection-refused-2"><a class="header" href="#connection-refused-2">Connection Refused</a></h4>
<pre><code class="language-bash"># Check if server is running
netstat -tlnp | grep 2121

# Check server logs
mockforge ftp serve --port 2121 2&gt;&amp;1
</code></pre>
<h4 id="passive-mode-issues"><a class="header" href="#passive-mode-issues">Passive Mode Issues</a></h4>
<pre><code class="language-bash"># FTP clients may need passive mode
curl --ftp-pasv ftp://localhost:2121/
</code></pre>
<h4 id="file-permission-issues"><a class="header" href="#file-permission-issues">File Permission Issues</a></h4>
<pre><code class="language-bash"># Check file permissions in VFS
mockforge ftp vfs info /problematic-file.txt

# Check upload rules
mockforge ftp fixtures validate config.yaml
</code></pre>
<h4 id="memory-issues"><a class="header" href="#memory-issues">Memory Issues</a></h4>
<pre><code class="language-bash"># Monitor memory usage
ps aux | grep mockforge

# Use file storage for large files
# Configure storage type in upload rules
</code></pre>
<p>This completes the FTP implementation for MockForge. The server provides comprehensive FTP mocking capabilities with virtual file systems, template rendering, and configurable upload handling.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="http-mocking"><a class="header" href="#http-mocking">HTTP Mocking</a></h1>
<p>MockForge provides comprehensive HTTP API mocking capabilities with OpenAPI specification support, dynamic response generation, and advanced request matching. This guide covers everything you need to create realistic REST API mocks.</p>
<h2 id="openapi-integration"><a class="header" href="#openapi-integration">OpenAPI Integration</a></h2>
<p>MockForge uses OpenAPI (formerly Swagger) specifications as the foundation for HTTP API mocking. This industry-standard approach ensures your mocks accurately reflect real API contracts.</p>
<h3 id="loading-openapi-specifications"><a class="header" href="#loading-openapi-specifications">Loading OpenAPI Specifications</a></h3>
<pre><code class="language-bash"># Load from JSON file
mockforge serve --spec api-spec.json --http-port 3000

# Load from YAML file
mockforge serve --spec api-spec.yaml --http-port 3000

# Load from URL
mockforge serve --spec https://api.example.com/openapi.json --http-port 3000
</code></pre>
<h3 id="openapi-specification-structure"><a class="header" href="#openapi-specification-structure">OpenAPI Specification Structure</a></h3>
<p>MockForge supports OpenAPI 3.0+ specifications with the following key components:</p>
<ul>
<li><strong>Paths</strong>: API endpoint definitions</li>
<li><strong>Methods</strong>: HTTP verbs (GET, POST, PUT, DELETE, PATCH)</li>
<li><strong>Parameters</strong>: Path, query, and header parameters</li>
<li><strong>Request Bodies</strong>: JSON/XML payload schemas</li>
<li><strong>Responses</strong>: Status codes and response schemas</li>
<li><strong>Components</strong>: Reusable schemas and examples</li>
</ul>
<h3 id="example-openapi-specification"><a class="header" href="#example-openapi-specification">Example OpenAPI Specification</a></h3>
<pre><code class="language-yaml">openapi: 3.0.3
info:
  title: User Management API
  version: 1.0.0
paths:
  /users:
    get:
      summary: List users
      parameters:
        - name: limit
          in: query
          schema:
            type: integer
            default: 10
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: '#/components/schemas/User'
    post:
      summary: Create user
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/UserInput'
      responses:
        '201':
          description: User created
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/User'

  /users/{id}:
    get:
      summary: Get user by ID
      parameters:
        - name: id
          in: path
          required: true
          schema:
            type: string
      responses:
        '200':
          description: User found
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/User'
        '404':
          description: User not found

components:
  schemas:
    User:
      type: object
      properties:
        id:
          type: string
          format: uuid
        name:
          type: string
        email:
          type: string
          format: email
        createdAt:
          type: string
          format: date-time
    UserInput:
      type: object
      required:
        - name
        - email
      properties:
        name:
          type: string
        email:
          type: string
</code></pre>
<h2 id="dynamic-response-generation"><a class="header" href="#dynamic-response-generation">Dynamic Response Generation</a></h2>
<p>MockForge generates realistic responses automatically based on your OpenAPI schemas, with support for dynamic data through templates.</p>
<h3 id="automatic-response-generation"><a class="header" href="#automatic-response-generation">Automatic Response Generation</a></h3>
<p>For basic use cases, MockForge can generate responses directly from your OpenAPI schemas:</p>
<pre><code class="language-bash"># Start server with automatic response generation
mockforge serve --spec api-spec.json --http-port 3000
</code></pre>
<p>This generates:</p>
<ul>
<li><strong>UUIDs</strong> for ID fields</li>
<li><strong>Random data</strong> for string/number fields</li>
<li><strong>Current timestamps</strong> for date-time fields</li>
<li><strong>Valid email addresses</strong> for email fields</li>
</ul>
<h3 id="template-enhanced-responses"><a class="header" href="#template-enhanced-responses">Template-Enhanced Responses</a></h3>
<p>For more control, use MockForge‚Äôs template system in your OpenAPI examples:</p>
<pre><code class="language-yaml">paths:
  /users:
    get:
      responses:
        '200':
          description: List of users
          content:
            application/json:
              example:
                users:
                  - id: "{{uuid}}"
                    name: "John Doe"
                    email: "john@example.com"
                    createdAt: "{{now}}"
                    lastLogin: "{{now-1d}}"
                  - id: "{{uuid}}"
                    name: "Jane Smith"
                    email: "jane@example.com"
                    createdAt: "{{now-7d}}"
                    lastLogin: "{{now-2h}}"
</code></pre>
<h3 id="template-functions"><a class="header" href="#template-functions">Template Functions</a></h3>
<h4 id="data-generation-templates"><a class="header" href="#data-generation-templates">Data Generation Templates</a></h4>
<ul>
<li><code>{{uuid}}</code> - Generate unique UUID</li>
<li><code>{{now}}</code> - Current timestamp</li>
<li><code>{{now+1h}}</code> - Future timestamp</li>
<li><code>{{now-1d}}</code> - Past timestamp</li>
<li><code>{{randInt 1 100}}</code> - Random integer</li>
<li><code>{{randFloat 0.0 1.0}}</code> - Random float</li>
</ul>
<h4 id="request-data-templates"><a class="header" href="#request-data-templates">Request Data Templates</a></h4>
<ul>
<li><code>{{request.path.id}}</code> - Access path parameters</li>
<li><code>{{request.query.limit}}</code> - Access query parameters</li>
<li><code>{{request.header.Authorization}}</code> - Access headers</li>
<li><code>{{request.body.name}}</code> - Access request body fields</li>
</ul>
<h2 id="request-matching-and-routing"><a class="header" href="#request-matching-and-routing">Request Matching and Routing</a></h2>
<p>MockForge uses sophisticated matching to route requests to appropriate responses.</p>
<h3 id="matching-priority"><a class="header" href="#matching-priority">Matching Priority</a></h3>
<ol>
<li><strong>Exact Path + Method Match</strong></li>
<li><strong>Parameterized Path Match</strong> (e.g., <code>/users/{id}</code>)</li>
<li><strong>Query Parameter Conditions</strong></li>
<li><strong>Header-Based Conditions</strong></li>
<li><strong>Request Body Matching</strong></li>
<li><strong>Default Response</strong> (catch-all)</li>
</ol>
<h3 id="path-parameter-handling"><a class="header" href="#path-parameter-handling">Path Parameter Handling</a></h3>
<pre><code class="language-yaml">/users/{id}:
  get:
    parameters:
      - name: id
        in: path
        required: true
        schema:
          type: string
    responses:
      '200':
        content:
          application/json:
            example:
              id: "{{request.path.id}}"
              name: "User {{request.path.id}}"
              retrievedAt: "{{now}}"
</code></pre>
<h3 id="query-parameter-filtering"><a class="header" href="#query-parameter-filtering">Query Parameter Filtering</a></h3>
<pre><code class="language-yaml">/users:
  get:
    parameters:
      - name: status
        in: query
        schema:
          type: string
          enum: [active, inactive]
      - name: limit
        in: query
        schema:
          type: integer
          default: 10
    responses:
      '200':
        content:
          application/json:
            example: "{{#if (eq request.query.status 'active')}}active_users{{else}}all_users{{/if}}"
</code></pre>
<h2 id="response-scenarios"><a class="header" href="#response-scenarios">Response Scenarios</a></h2>
<p>MockForge supports multiple response scenarios for testing different conditions.</p>
<h3 id="success-responses"><a class="header" href="#success-responses">Success Responses</a></h3>
<pre><code class="language-yaml">responses:
  '200':
    description: Success
    content:
      application/json:
        example:
          status: "success"
          data: { ... }
</code></pre>
<h3 id="error-responses"><a class="header" href="#error-responses">Error Responses</a></h3>
<pre><code class="language-yaml">responses:
  '400':
    description: Bad Request
    content:
      application/json:
        example:
          error: "INVALID_INPUT"
          message: "The provided input is invalid"
  '404':
    description: Not Found
    content:
      application/json:
        example:
          error: "NOT_FOUND"
          message: "Resource not found"
  '500':
    description: Internal Server Error
    content:
      application/json:
        example:
          error: "INTERNAL_ERROR"
          message: "An unexpected error occurred"
</code></pre>
<h3 id="conditional-responses-1"><a class="header" href="#conditional-responses-1">Conditional Responses</a></h3>
<p>Use templates to return different responses based on request data:</p>
<pre><code class="language-yaml">responses:
  '200':
    content:
      application/json:
        example: |
          {{#if (eq request.query.format 'detailed')}}
          {
            "id": "{{uuid}}",
            "name": "Detailed User",
            "email": "user@example.com",
            "profile": {
              "bio": "Detailed user profile",
              "preferences": { ... }
            }
          }
          {{else}}
          {
            "id": "{{uuid}}",
            "name": "Basic User",
            "email": "user@example.com"
          }
          {{/if}}
</code></pre>
<h2 id="advanced-features-1"><a class="header" href="#advanced-features-1">Advanced Features</a></h2>
<h3 id="response-latency-simulation"><a class="header" href="#response-latency-simulation">Response Latency Simulation</a></h3>
<pre><code class="language-bash"># Add random latency (100-500ms)
MOCKFORGE_LATENCY_ENABLED=true \
MOCKFORGE_LATENCY_MIN_MS=100 \
MOCKFORGE_LATENCY_MAX_MS=500 \
mockforge serve --spec api-spec.json
</code></pre>
<h3 id="failure-injection"><a class="header" href="#failure-injection">Failure Injection</a></h3>
<pre><code class="language-bash"># Enable random failures (10% chance)
MOCKFORGE_FAILURES_ENABLED=true \
MOCKFORGE_FAILURE_RATE=0.1 \
mockforge serve --spec api-spec.json
</code></pre>
<h3 id="requestresponse-recording"><a class="header" href="#requestresponse-recording">Request/Response Recording</a></h3>
<pre><code class="language-bash"># Record all HTTP interactions
MOCKFORGE_RECORD_ENABLED=true \
mockforge serve --spec api-spec.json
</code></pre>
<h3 id="response-replay"><a class="header" href="#response-replay">Response Replay</a></h3>
<pre><code class="language-bash"># Replay recorded responses
MOCKFORGE_REPLAY_ENABLED=true \
mockforge serve --spec api-spec.json
</code></pre>
<h2 id="testing-your-mocks"><a class="header" href="#testing-your-mocks">Testing Your Mocks</a></h2>
<h3 id="manual-testing-with-curl"><a class="header" href="#manual-testing-with-curl">Manual Testing with curl</a></h3>
<pre><code class="language-bash"># Test GET endpoint
curl http://localhost:3000/users

# Test POST endpoint
curl -X POST http://localhost:3000/users \
  -H "Content-Type: application/json" \
  -d '{"name": "Test User", "email": "test@example.com"}'

# Test path parameters
curl http://localhost:3000/users/123

# Test query parameters
curl "http://localhost:3000/users?limit=5&amp;status=active"

# Test error scenarios
curl http://localhost:3000/users/999  # Should return 404
</code></pre>
<h3 id="automated-testing"><a class="header" href="#automated-testing">Automated Testing</a></h3>
<pre><code class="language-bash">#!/bin/bash
# test-api.sh

BASE_URL="http://localhost:3000"

echo "Testing User API..."

# Test user creation
USER_RESPONSE=$(curl -s -X POST $BASE_URL/users \
  -H "Content-Type: application/json" \
  -d '{"name": "Test User", "email": "test@example.com"}')

echo "Created user: $USER_RESPONSE"

# Extract user ID (assuming response contains id)
USER_ID=$(echo $USER_RESPONSE | jq -r '.id')

# Test user retrieval
RETRIEVED_USER=$(curl -s $BASE_URL/users/$USER_ID)
echo "Retrieved user: $RETRIEVED_USER"

# Test user listing
USER_LIST=$(curl -s $BASE_URL/users)
echo "User list: $USER_LIST"

echo "API tests completed!"
</code></pre>
<h2 id="best-practices-7"><a class="header" href="#best-practices-7">Best Practices</a></h2>
<h3 id="openapi-specification-tips"><a class="header" href="#openapi-specification-tips">OpenAPI Specification Tips</a></h3>
<ol>
<li><strong>Use descriptive operation IDs</strong> for better organization</li>
<li><strong>Include examples</strong> in your OpenAPI spec for consistent responses</li>
<li><strong>Define reusable components</strong> for common schemas</li>
<li><strong>Use appropriate HTTP status codes</strong> for different scenarios</li>
<li><strong>Document all parameters</strong> clearly</li>
</ol>
<h3 id="template-usage-guidelines"><a class="header" href="#template-usage-guidelines">Template Usage Guidelines</a></h3>
<ol>
<li><strong>Enable templates only when needed</strong> for security</li>
<li><strong>Use meaningful template variables</strong> for maintainability</li>
<li><strong>Test template expansion</strong> thoroughly</li>
<li><strong>Avoid complex logic in templates</strong> - keep it simple</li>
</ol>
<h3 id="response-design-principles"><a class="header" href="#response-design-principles">Response Design Principles</a></h3>
<ol>
<li><strong>Match real API behavior</strong> as closely as possible</li>
<li><strong>Include appropriate error responses</strong> for testing</li>
<li><strong>Use consistent data formats</strong> across endpoints</li>
<li><strong>Consider pagination</strong> for list endpoints</li>
<li><strong>Include metadata</strong> like timestamps and request IDs</li>
</ol>
<h3 id="performance-considerations"><a class="header" href="#performance-considerations">Performance Considerations</a></h3>
<ol>
<li><strong>Use static responses</strong> when dynamic data isn‚Äôt needed</li>
<li><strong>Limit template complexity</strong> to maintain response times</li>
<li><strong>Configure appropriate timeouts</strong> for your use case</li>
<li><strong>Monitor memory usage</strong> with large response payloads</li>
</ol>
<h2 id="troubleshooting-21"><a class="header" href="#troubleshooting-21">Troubleshooting</a></h2>
<h3 id="common-issues-4"><a class="header" href="#common-issues-4">Common Issues</a></h3>
<p><strong>Templates not expanding</strong>: Ensure <code>MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true</code></p>
<p><strong>OpenAPI spec not loading</strong>: Check file path and JSON/YAML syntax</p>
<p><strong>Wrong response returned</strong>: Verify request matching rules and parameter handling</p>
<p><strong>Performance issues</strong>: Reduce template complexity or use static responses</p>
<p><strong>Port conflicts</strong>: Change default ports with <code>--http-port</code> option</p>
<h2 id="advanced-behavior-and-simulation"><a class="header" href="#advanced-behavior-and-simulation">Advanced Behavior and Simulation</a></h2>
<p>MockForge supports advanced behavior simulation features for realistic API testing:</p>
<h3 id="record--playback"><a class="header" href="#record--playback">Record &amp; Playback</a></h3>
<p>Automatically record API interactions and convert them to replayable fixtures:</p>
<pre><code class="language-bash"># Record requests while proxying
mockforge serve --spec api-spec.json --proxy --record

# Convert recordings to stub mappings
mockforge recorder convert --input recordings.db --output fixtures/
</code></pre>
<h3 id="stateful-behavior"><a class="header" href="#stateful-behavior">Stateful Behavior</a></h3>
<p>Simulate stateful APIs where responses change based on previous requests:</p>
<pre><code class="language-yaml">core:
  stateful:
    enabled: true
    state_machines:
      - name: "order_workflow"
        resource_id_extract:
          type: "path_param"
          param: "order_id"
        transitions:
          - method: "POST"
            path_pattern: "/api/orders"
            from_state: "initial"
            to_state: "pending"
</code></pre>
<h3 id="per-route-fault-injection"><a class="header" href="#per-route-fault-injection">Per-Route Fault Injection</a></h3>
<p>Configure fault injection on specific routes:</p>
<pre><code class="language-yaml">core:
  routes:
    - path: "/api/payments/process"
      method: "POST"
      fault_injection:
        enabled: true
        probability: 0.05
        fault_types:
          - type: "http_error"
            status_code: 503
</code></pre>
<h3 id="per-route-latency"><a class="header" href="#per-route-latency">Per-Route Latency</a></h3>
<p>Simulate network conditions per route:</p>
<pre><code class="language-yaml">core:
  routes:
    - path: "/api/search"
      method: "GET"
      latency:
        enabled: true
        distribution: "normal"
        mean_ms: 500.0
        std_dev_ms: 100.0
</code></pre>
<h3 id="conditional-proxying"><a class="header" href="#conditional-proxying">Conditional Proxying</a></h3>
<p>Proxy requests conditionally based on request attributes:</p>
<pre><code class="language-yaml">core:
  proxy:
    rules:
      - pattern: "/api/admin/*"
        upstream_url: "https://admin-api.example.com"
        condition: "$.user.role == 'admin'"
</code></pre>
<p>For detailed documentation on these features, see <a href="user-guide/../../../docs/ADVANCED_BEHAVIOR_SIMULATION.html">Advanced Behavior and Simulation</a>.</p>
<p>For more advanced HTTP mocking features, see the following guides:</p>
<ul>
<li><a href="user-guide/http-mocking/openapi.html">OpenAPI Integration</a> - Advanced OpenAPI features</li>
<li><a href="user-guide/http-mocking/custom-responses.html">Custom Responses</a> - Complex response scenarios</li>
<li><a href="user-guide/http-mocking/dynamic-data.html">Dynamic Data</a> - Advanced templating techniques</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="openapi-integration-1"><a class="header" href="#openapi-integration-1">OpenAPI Integration</a></h1>
<p>MockForge provides advanced OpenAPI integration capabilities beyond basic spec loading and response generation. This guide covers sophisticated features for enterprise-grade API mocking.</p>
<h2 id="advanced-request-validation"><a class="header" href="#advanced-request-validation">Advanced Request Validation</a></h2>
<p>MockForge supports comprehensive request validation against OpenAPI schemas with multiple validation modes and granular control.</p>
<h3 id="validation-modes-1"><a class="header" href="#validation-modes-1">Validation Modes</a></h3>
<pre><code class="language-bash"># Disable validation completely
MOCKFORGE_REQUEST_VALIDATION=off mockforge serve --spec api-spec.json

# Log warnings but allow invalid requests
MOCKFORGE_REQUEST_VALIDATION=warn mockforge serve --spec api-spec.json

# Reject invalid requests (default)
MOCKFORGE_REQUEST_VALIDATION=enforce mockforge serve --spec api-spec.json
</code></pre>
<h3 id="response-validation"><a class="header" href="#response-validation">Response Validation</a></h3>
<p>Enable validation of generated responses against OpenAPI schemas:</p>
<pre><code class="language-bash"># Validate responses against schemas
MOCKFORGE_RESPONSE_VALIDATION=true mockforge serve --spec api-spec.json
</code></pre>
<h3 id="custom-validation-status-codes"><a class="header" href="#custom-validation-status-codes">Custom Validation Status Codes</a></h3>
<p>Configure HTTP status codes for validation failures:</p>
<pre><code class="language-bash"># Use 422 Unprocessable Entity for validation errors
MOCKFORGE_VALIDATION_STATUS=422 mockforge serve --spec api-spec.json
</code></pre>
<h3 id="validation-overrides"><a class="header" href="#validation-overrides">Validation Overrides</a></h3>
<p>Skip validation for specific routes:</p>
<pre><code class="language-yaml">validation:
  mode: enforce
  overrides:
    "GET /health": "off"
    "POST /webhooks/*": "warn"
</code></pre>
<h3 id="aggregated-error-reporting"><a class="header" href="#aggregated-error-reporting">Aggregated Error Reporting</a></h3>
<p>Control how validation errors are reported:</p>
<pre><code class="language-bash"># Report all validation errors at once
MOCKFORGE_AGGREGATE_ERRORS=true mockforge serve --spec api-spec.json

# Stop at first validation error
MOCKFORGE_AGGREGATE_ERRORS=false mockforge serve --spec api-spec.json
</code></pre>
<h2 id="security-scheme-validation"><a class="header" href="#security-scheme-validation">Security Scheme Validation</a></h2>
<p>MockForge validates authentication and authorization requirements defined in your OpenAPI spec.</p>
<h3 id="supported-security-schemes"><a class="header" href="#supported-security-schemes">Supported Security Schemes</a></h3>
<ul>
<li><strong>HTTP Basic Authentication</strong>: Validates <code>Authorization: Basic &lt;credentials&gt;</code> headers</li>
<li><strong>Bearer Tokens</strong>: Validates <code>Authorization: Bearer &lt;token&gt;</code> headers</li>
<li><strong>API Keys</strong>: Supports header and query parameter API keys</li>
<li><strong>OAuth2</strong>: Basic OAuth2 flow validation</li>
</ul>
<h3 id="security-validation-example"><a class="header" href="#security-validation-example">Security Validation Example</a></h3>
<pre><code class="language-yaml">openapi: 3.0.0
components:
  securitySchemes:
    bearerAuth:
      type: http
      scheme: bearer
    apiKey:
      type: apiKey
      in: header
      name: X-API-Key

security:
  - bearerAuth: []
  - apiKey: []

paths:
  /protected:
    get:
      security:
        - bearerAuth: []
</code></pre>
<pre><code class="language-bash"># Test with valid Bearer token
curl -H "Authorization: Bearer eyJ0eXAi..." http://localhost:3000/protected

# Test with API key
curl -H "X-API-Key: your-api-key" http://localhost:3000/protected
</code></pre>
<h2 id="schema-resolution-and-references"><a class="header" href="#schema-resolution-and-references">Schema Resolution and References</a></h2>
<p>MockForge fully supports OpenAPI schema references (<code>$ref</code>) for reusable components.</p>
<h3 id="component-references"><a class="header" href="#component-references">Component References</a></h3>
<pre><code class="language-yaml">components:
  schemas:
    User:
      type: object
      properties:
        id:
          type: string
          format: uuid
        name:
          type: string
        profile:
          $ref: '#/components/schemas/UserProfile'

    UserProfile:
      type: object
      properties:
        bio:
          type: string
        avatar:
          type: string
          format: uri

  responses:
    UserResponse:
      description: User data
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/User'

paths:
  /users/{id}:
    get:
      responses:
        '200':
          $ref: '#/components/responses/UserResponse'
</code></pre>
<h3 id="request-body-references"><a class="header" href="#request-body-references">Request Body References</a></h3>
<pre><code class="language-yaml">components:
  requestBodies:
    UserCreate:
      required: true
      content:
        application/json:
          schema:
            type: object
            required:
              - name
              - email
            properties:
              name:
                type: string
              email:
                type: string
                format: email

paths:
  /users:
    post:
      requestBody:
        $ref: '#/components/requestBodies/UserCreate'
</code></pre>
<h2 id="multiple-openapi-specifications"><a class="header" href="#multiple-openapi-specifications">Multiple OpenAPI Specifications</a></h2>
<p>MockForge can serve multiple OpenAPI specifications simultaneously with path-based routing.</p>
<h3 id="configuration-for-multiple-specs"><a class="header" href="#configuration-for-multiple-specs">Configuration for Multiple Specs</a></h3>
<pre><code class="language-yaml">server:
  http_port: 3000

specs:
  - name: user-api
    path: /api/v1
    spec: user-api.json
  - name: admin-api
    path: /api/admin
    spec: admin-api.json
</code></pre>
<h3 id="base-path-routing"><a class="header" href="#base-path-routing">Base Path Routing</a></h3>
<pre><code class="language-bash"># Routes to user-api.json endpoints
curl http://localhost:3000/api/v1/users

# Routes to admin-api.json endpoints
curl http://localhost:3000/api/admin/users
</code></pre>
<h2 id="advanced-routing-and-matching"><a class="header" href="#advanced-routing-and-matching">Advanced Routing and Matching</a></h2>
<p>MockForge provides sophisticated request matching beyond simple path/method combinations.</p>
<h3 id="path-parameter-constraints"><a class="header" href="#path-parameter-constraints">Path Parameter Constraints</a></h3>
<pre><code class="language-yaml">paths:
  /users/{id}:
    get:
      parameters:
        - name: id
          in: path
          required: true
          schema:
            type: string
            pattern: '^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$'
</code></pre>
<h3 id="query-parameter-matching"><a class="header" href="#query-parameter-matching">Query Parameter Matching</a></h3>
<pre><code class="language-yaml">paths:
  /users:
    get:
      parameters:
        - name: status
          in: query
          schema:
            type: string
            enum: [active, inactive, pending]
        - name: limit
          in: query
          schema:
            type: integer
            minimum: 1
            maximum: 100
            default: 10
</code></pre>
<h3 id="header-based-routing"><a class="header" href="#header-based-routing">Header-Based Routing</a></h3>
<pre><code class="language-yaml">paths:
  /api/v1/users:
    get:
      parameters:
        - name: X-API-Version
          in: header
          schema:
            type: string
            enum: [v1, v2]
</code></pre>
<h2 id="template-expansion-in-responses"><a class="header" href="#template-expansion-in-responses">Template Expansion in Responses</a></h2>
<p>Advanced template features for dynamic response generation.</p>
<h3 id="advanced-template-functions"><a class="header" href="#advanced-template-functions">Advanced Template Functions</a></h3>
<pre><code class="language-yaml">responses:
  '200':
    content:
      application/json:
        example:
          id: "{{uuid}}"
          createdAt: "{{now}}"
          expiresAt: "{{now+1h}}"
          lastModified: "{{now-30m}}"
          randomValue: "{{randInt 1 100}}"
          randomFloat: "{{randFloat 0.0 5.0}}"
          userAgent: "{{request.header.User-Agent}}"
          apiVersion: "{{request.header.X-API-Version}}"
          userId: "{{request.path.id}}"
          searchQuery: "{{request.query.q}}"
</code></pre>
<h3 id="conditional-templates"><a class="header" href="#conditional-templates">Conditional Templates</a></h3>
<pre><code class="language-yaml">responses:
  '200':
    content:
      application/json:
        example: |
          {{#if (eq request.query.format 'detailed')}}
          {
            "id": "{{uuid}}",
            "name": "Detailed User",
            "profile": {
              "bio": "User biography",
              "preferences": {}
            }
          }
          {{else}}
          {
            "id": "{{uuid}}",
            "name": "Basic User"
          }
          {{/if}}
</code></pre>
<h3 id="template-security"><a class="header" href="#template-security">Template Security</a></h3>
<p>Enable template expansion only when needed:</p>
<pre><code class="language-bash"># Enable template expansion
MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true mockforge serve --spec api-spec.json
</code></pre>
<h2 id="performance-optimization"><a class="header" href="#performance-optimization">Performance Optimization</a></h2>
<p>Strategies for handling large OpenAPI specifications efficiently.</p>
<h3 id="lazy-loading"><a class="header" href="#lazy-loading">Lazy Loading</a></h3>
<p>MockForge loads and parses OpenAPI specs on startup but generates routes lazily:</p>
<pre><code class="language-bash"># Monitor startup performance
time mockforge serve --spec large-api.json
</code></pre>
<h3 id="route-caching"><a class="header" href="#route-caching">Route Caching</a></h3>
<p>Generated routes are cached in memory for optimal performance:</p>
<pre><code class="language-bash"># Check memory usage with large specs
MOCKFORGE_LOG_LEVEL=debug mockforge serve --spec large-api.json
</code></pre>
<h3 id="validation-performance"><a class="header" href="#validation-performance">Validation Performance</a></h3>
<p>Disable expensive validations in high-throughput scenarios:</p>
<pre><code class="language-bash"># Disable response validation for better performance
MOCKFORGE_RESPONSE_VALIDATION=false mockforge serve --spec api-spec.json
</code></pre>
<h2 id="custom-validation-options"><a class="header" href="#custom-validation-options">Custom Validation Options</a></h2>
<p>Fine-tune validation behavior for your specific needs.</p>
<h3 id="validation-configuration"><a class="header" href="#validation-configuration">Validation Configuration</a></h3>
<pre><code class="language-yaml">validation:
  mode: enforce
  aggregate_errors: true
  validate_responses: false
  status_code: 422
  overrides:
    "GET /health": "off"
    "POST /webhooks/*": "warn"
  admin_skip_prefixes:
    - "/admin"
    - "/internal"
</code></pre>
<h3 id="environment-variables-6"><a class="header" href="#environment-variables-6">Environment Variables</a></h3>
<pre><code class="language-bash"># Validation mode
MOCKFORGE_REQUEST_VALIDATION=enforce

# Error aggregation
MOCKFORGE_AGGREGATE_ERRORS=true

# Response validation
MOCKFORGE_RESPONSE_VALIDATION=false

# Custom status code
MOCKFORGE_VALIDATION_STATUS=422

# Template expansion
MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true
</code></pre>
<h2 id="openapi-extensions"><a class="header" href="#openapi-extensions">OpenAPI Extensions</a></h2>
<p>MockForge supports OpenAPI extensions (<code>x-</code> prefixed properties) for custom behavior.</p>
<h3 id="custom-extensions"><a class="header" href="#custom-extensions">Custom Extensions</a></h3>
<pre><code class="language-yaml">paths:
  /users:
    get:
      x-mockforge-delay: 1000  # Add 1 second delay
      x-mockforge-failure-rate: 0.1  # 10% failure rate
      responses:
        '200':
          x-mockforge-template: true  # Enable template expansion
</code></pre>
<h3 id="vendor-extensions"><a class="header" href="#vendor-extensions">Vendor Extensions</a></h3>
<pre><code class="language-yaml">info:
  x-mockforge-config:
    enable_cors: true
    default_response_format: json

paths:
  /api/users:
    x-vendor-custom-behavior: enabled
</code></pre>
<h2 id="troubleshooting-22"><a class="header" href="#troubleshooting-22">Troubleshooting</a></h2>
<p>Common issues and solutions for advanced OpenAPI integration.</p>
<h3 id="validation-errors"><a class="header" href="#validation-errors">Validation Errors</a></h3>
<p><strong>Problem</strong>: Requests are rejected with validation errors</p>
<pre><code class="language-json">{
  "error": "request validation failed",
  "status": 422,
  "details": [
    {
      "path": "body.name",
      "code": "required",
      "message": "Missing required field: name"
    }
  ]
}
</code></pre>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Switch to warning mode
MOCKFORGE_REQUEST_VALIDATION=warn mockforge serve --spec api-spec.json

# Disable validation for specific routes
# Add to config.yaml:
validation:
  overrides:
    "POST /users": "off"
</code></pre>
<h3 id="schema-reference-issues"><a class="header" href="#schema-reference-issues">Schema Reference Issues</a></h3>
<p><strong>Problem</strong>: <code>$ref</code> references not resolving correctly</p>
<p><strong>Solutions</strong>:</p>
<ul>
<li>Ensure component names match exactly</li>
<li>Check that referenced components exist</li>
<li>Validate your OpenAPI spec with external tools</li>
</ul>
<h3 id="performance-issues-1"><a class="header" href="#performance-issues-1">Performance Issues</a></h3>
<p><strong>Problem</strong>: Slow startup or high memory usage with large specs</p>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Disable non-essential features
MOCKFORGE_RESPONSE_VALIDATION=false
MOCKFORGE_AGGREGATE_ERRORS=false

# Monitor with debug logging
MOCKFORGE_LOG_LEVEL=debug mockforge serve --spec api-spec.json
</code></pre>
<h3 id="security-validation-failures"><a class="header" href="#security-validation-failures">Security Validation Failures</a></h3>
<p><strong>Problem</strong>: Authentication requests failing</p>
<p><strong>Solutions</strong>:</p>
<ul>
<li>Verify security scheme definitions</li>
<li>Check header formats (e.g., <code>Bearer </code> prefix)</li>
<li>Ensure global security requirements are met</li>
</ul>
<h3 id="template-expansion-issues"><a class="header" href="#template-expansion-issues">Template Expansion Issues</a></h3>
<p><strong>Problem</strong>: Templates not expanding in responses</p>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Enable template expansion
MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true mockforge serve --spec api-spec.json

# Check template syntax
# Use {{variable}} format, not ${variable}
</code></pre>
<h2 id="best-practices-8"><a class="header" href="#best-practices-8">Best Practices</a></h2>
<h3 id="specification-management"><a class="header" href="#specification-management">Specification Management</a></h3>
<ol>
<li><strong>Version Control</strong>: Keep OpenAPI specs in version control alongside mock configurations</li>
<li><strong>Validation</strong>: Use external validators to ensure spec correctness</li>
<li><strong>Documentation</strong>: Include comprehensive examples and descriptions</li>
<li><strong>Modularity</strong>: Use components and references for maintainable specs</li>
</ol>
<h3 id="performance-tuning-3"><a class="header" href="#performance-tuning-3">Performance Tuning</a></h3>
<ol>
<li><strong>Selective Validation</strong>: Disable validation for high-traffic endpoints</li>
<li><strong>Template Usage</strong>: Only enable templates when dynamic data is needed</li>
<li><strong>Caching</strong>: Leverage MockForge‚Äôs built-in route caching</li>
<li><strong>Monitoring</strong>: Monitor memory usage and response times</li>
</ol>
<h3 id="security-considerations-1"><a class="header" href="#security-considerations-1">Security Considerations</a></h3>
<ol>
<li><strong>Validation Modes</strong>: Use appropriate validation levels for different environments</li>
<li><strong>Template Security</strong>: Be cautious with user-controlled template input</li>
<li><strong>Authentication</strong>: Properly configure security schemes for protected endpoints</li>
<li><strong>Overrides</strong>: Use validation overrides judiciously</li>
</ol>
<p>For basic OpenAPI integration features, see the <a href="user-guide/http-mocking/../http-mocking.html">HTTP Mocking guide</a>. For dynamic data generation, see the <a href="user-guide/http-mocking/dynamic-data.html">Dynamic Data guide</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="custom-responses"><a class="header" href="#custom-responses">Custom Responses</a></h1>
<p>MockForge provides multiple powerful ways to create custom HTTP responses beyond basic OpenAPI schema generation. This guide covers advanced response customization techniques including plugins, overrides, and dynamic generation.</p>
<h2 id="response-override-rules"><a class="header" href="#response-override-rules">Response Override Rules</a></h2>
<p>Override rules allow you to modify OpenAPI-generated responses using JSON patches without changing the original specification.</p>
<h3 id="basic-override-configuration"><a class="header" href="#basic-override-configuration">Basic Override Configuration</a></h3>
<pre><code class="language-yaml"># mockforge.yaml
http:
  openapi_spec: api-spec.json
  response_template_expand: true

# Override specific endpoints
overrides:
  - targets: ["path:/users"]
    patch:
      - op: replace
        path: "/responses/200/content/application~1json/example"
        value:
          users:
            - id: "{{uuid}}"
              name: "John Doe"
              email: "john@example.com"
            - id: "{{uuid}}"
              name: "Jane Smith"
              email: "jane@example.com"

  - targets: ["operation:getUser"]
    patch:
      - op: add
        path: "/responses/200/content/application~1json/example/profile"
        value:
          avatar: "https://example.com/avatar.jpg"
          bio: "User biography"
</code></pre>
<h3 id="override-targeting"><a class="header" href="#override-targeting">Override Targeting</a></h3>
<p>Target specific operations using different selectors:</p>
<pre><code class="language-yaml">overrides:
  # By operation ID
  - targets: ["operation:listUsers", "operation:createUser"]
    patch: [...]

  # By path pattern
  - targets: ["path:/users/*"]
    patch: [...]

  # By tag
  - targets: ["tag:Users"]
    patch: [...]

  # By regex
  - targets: ["regex:^/api/v[0-9]+/users$"]
    patch: [...]
</code></pre>
<h3 id="patch-operations"><a class="header" href="#patch-operations">Patch Operations</a></h3>
<p>Supported JSON patch operations:</p>
<pre><code class="language-yaml">overrides:
  - targets: ["path:/users"]
    patch:
      # Add new fields
      - op: add
        path: "/responses/200/content/application~1json/example/metadata"
        value:
          total: 100
          page: 1

      # Replace existing values
      - op: replace
        path: "/responses/200/content/application~1json/example/users/0/name"
        value: "Updated Name"

      # Remove fields
      - op: remove
        path: "/responses/200/content/application~1json/example/users/1/email"

      # Copy values
      - op: copy
        from: "/responses/200/content/application~1json/example/users/0/id"
        path: "/responses/200/content/application~1json/example/primaryUserId"

      # Move values
      - op: move
        from: "/responses/200/content/application~1json/example/temp"
        path: "/responses/200/content/application~1json/example/permanent"
</code></pre>
<h3 id="conditional-overrides"><a class="header" href="#conditional-overrides">Conditional Overrides</a></h3>
<p>Apply overrides based on request conditions:</p>
<pre><code class="language-yaml">overrides:
  - targets: ["path:/users"]
    when: "request.query.format == 'detailed'"
    patch:
      - op: add
        path: "/responses/200/content/application~1json/example/users/0/profile"
        value:
          bio: "Detailed user profile"
          preferences: {}

  - targets: ["path:/users"]
    when: "request.header.X-API-Version == 'v2'"
    patch:
      - op: add
        path: "/responses/200/content/application~1json/example/apiVersion"
        value: "v2"
</code></pre>
<h3 id="override-modes"><a class="header" href="#override-modes">Override Modes</a></h3>
<p>Control how patches are applied:</p>
<pre><code class="language-yaml">overrides:
  # Replace mode (default) - complete replacement
  - targets: ["path:/users"]
    mode: replace
    patch: [...]

  # Merge mode - deep merge objects and arrays
  - targets: ["path:/users"]
    mode: merge
    patch:
      - op: add
        path: "/responses/200/content/application~1json/example"
        value:
          additionalField: "value"
</code></pre>
<h2 id="response-plugins-1"><a class="header" href="#response-plugins-1">Response Plugins</a></h2>
<p>Create custom response generation logic using MockForge‚Äôs plugin system.</p>
<h3 id="response-generator-plugin"><a class="header" href="#response-generator-plugin">Response Generator Plugin</a></h3>
<p>Implement the <code>ResponsePlugin</code> trait for complete response control:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_plugin_core::*;

pub struct CustomResponsePlugin;

#[async_trait::async_trait]
impl ResponsePlugin for CustomResponsePlugin {
    fn capabilities(&amp;self) -&gt; PluginCapabilities {
        PluginCapabilities {
            network: NetworkCapabilities {
                allow_http_outbound: true,
                allowed_hosts: vec!["api.example.com".to_string()],
            },
            filesystem: FilesystemCapabilities::default(),
            resources: PluginResources {
                max_memory_bytes: 50 * 1024 * 1024,
                max_cpu_time_ms: 5000,
            },
            custom: HashMap::new(),
        }
    }

    async fn initialize(&amp;self, config: &amp;ResponsePluginConfig) -&gt; Result&lt;()&gt; {
        // Plugin initialization
        Ok(())
    }

    async fn can_handle(
        &amp;self,
        _context: &amp;PluginContext,
        request: &amp;ResponseRequest,
        _config: &amp;ResponsePluginConfig,
    ) -&gt; Result&lt;PluginResult&lt;bool&gt;&gt; {
        // Check if this plugin should handle the request
        let should_handle = request.path.starts_with("/api/custom/");
        Ok(PluginResult::success(should_handle, 0))
    }

    async fn generate_response(
        &amp;self,
        _context: &amp;PluginContext,
        request: &amp;ResponseRequest,
        _config: &amp;ResponsePluginConfig,
    ) -&gt; Result&lt;PluginResult&lt;ResponseData&gt;&gt; {
        // Generate custom response
        match request.path.as_str() {
            "/api/custom/weather" =&gt; {
                let weather_data = serde_json::json!({
                    "temperature": 22,
                    "condition": "sunny",
                    "location": request.query_param("location").unwrap_or("Unknown")
                });
                Ok(PluginResult::success(
                    ResponseData::json(200, &amp;weather_data)?,
                    0
                ))
            }
            "/api/custom/time" =&gt; {
                let time_data = serde_json::json!({
                    "current_time": chrono::Utc::now().to_rfc3339(),
                    "timezone": request.query_param("tz").unwrap_or("UTC")
                });
                Ok(PluginResult::success(
                    ResponseData::json(200, &amp;time_data)?,
                    0
                ))
            }
            _ =&gt; Ok(PluginResult::success(
                ResponseData::not_found("Custom endpoint not found"),
                0
            ))
        }
    }

    fn priority(&amp;self) -&gt; i32 { 100 }

    fn validate_config(&amp;self, _config: &amp;ResponsePluginConfig) -&gt; Result&lt;()&gt; {
        Ok(())
    }

    fn supported_content_types(&amp;self) -&gt; Vec&lt;String&gt; {
        vec!["application/json".to_string()]
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="plugin-configuration"><a class="header" href="#plugin-configuration">Plugin Configuration</a></h3>
<p>Configure response plugins in your MockForge setup:</p>
<pre><code class="language-yaml"># plugin.yaml
name: custom-response-plugin
version: "1.0.0"
type: response

config:
  enabled: true
  priority: 100
  content_types:
    - "application/json"
  url_patterns:
    - "/api/custom/*"
  methods:
    - "GET"
    - "POST"
  settings:
    external_api_timeout: 5000
    cache_enabled: true
</code></pre>
<h3 id="response-modifier-plugin"><a class="header" href="#response-modifier-plugin">Response Modifier Plugin</a></h3>
<p>Modify responses after generation using the <code>ResponseModifierPlugin</code> trait:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_plugin_core::*;

pub struct ResponseModifierPlugin;

#[async_trait::async_trait]
impl ResponseModifierPlugin for ResponseModifierPlugin {
    fn capabilities(&amp;self) -&gt; PluginCapabilities {
        PluginCapabilities::default()
    }

    async fn initialize(&amp;self, _config: &amp;ResponseModifierConfig) -&gt; Result&lt;()&gt; {
        Ok(())
    }

    async fn should_modify(
        &amp;self,
        _context: &amp;PluginContext,
        _request: &amp;ResponseRequest,
        response: &amp;ResponseData,
        _config: &amp;ResponseModifierConfig,
    ) -&gt; Result&lt;PluginResult&lt;bool&gt;&gt; {
        // Modify successful JSON responses
        let should_modify = response.status_code == 200 &amp;&amp;
                           response.content_type == "application/json";
        Ok(PluginResult::success(should_modify, 0))
    }

    async fn modify_response(
        &amp;self,
        _context: &amp;PluginContext,
        _request: &amp;ResponseRequest,
        mut response: ResponseData,
        _config: &amp;ResponseModifierConfig,
    ) -&gt; Result&lt;PluginResult&lt;ResponseData&gt;&gt; {
        // Add custom headers
        response.headers.insert(
            "X-Custom-Header".to_string(),
            "Modified by plugin".to_string()
        );

        // Add metadata to JSON responses
        if let Some(json_str) = response.body_as_string() {
            if let Ok(mut json_value) = serde_json::from_str::&lt;serde_json::Value&gt;(&amp;json_str) {
                if let Some(obj) = json_value.as_object_mut() {
                    obj.insert("_metadata".to_string(), serde_json::json!({
                        "modified_by": "ResponseModifierPlugin",
                        "timestamp": chrono::Utc::now().timestamp()
                    }));
                }

                let modified_body = serde_json::to_vec(&amp;json_value)
                    .map_err(|e| PluginError::execution(format!("JSON serialization error: {}", e)))?;
                response.body = modified_body;
            }
        }

        Ok(PluginResult::success(response, 0))
    }

    fn priority(&amp;self) -&gt; i32 { 50 }

    fn validate_config(&amp;self, _config: &amp;ResponseModifierConfig) -&gt; Result&lt;()&gt; {
        Ok(())
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="template-plugins-1"><a class="header" href="#template-plugins-1">Template Plugins</a></h2>
<p>Extend MockForge‚Äôs templating system with custom functions.</p>
<h3 id="custom-template-functions"><a class="header" href="#custom-template-functions">Custom Template Functions</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_plugin_core::*;

pub struct BusinessTemplatePlugin;

impl TemplatePlugin for BusinessTemplatePlugin {
    fn execute_function(
        &amp;mut self,
        function_name: &amp;str,
        args: &amp;[TemplateArg],
        _context: &amp;PluginContext,
    ) -&gt; PluginResult&lt;String&gt; {
        match function_name {
            "business_id" =&gt; {
                // Generate business-specific ID
                let id = format!("BIZ-{:010}", rand::random::&lt;u32&gt;());
                PluginResult::success(id, 0)
            }
            "department_name" =&gt; {
                // Generate department name
                let departments = ["Engineering", "Sales", "Marketing", "HR", "Finance"];
                let dept = departments[rand::random::&lt;usize&gt;() % departments.len()];
                PluginResult::success(dept.to_string(), 0)
            }
            "employee_data" =&gt; {
                // Generate complete employee object
                let employee = serde_json::json!({
                    "id": format!("EMP-{:06}", rand::random::&lt;u32&gt;() % 1000000),
                    "name": "{{faker.name}}",
                    "department": "{{department_name}}",
                    "salary": rand::random::&lt;u32&gt;() % 50000 + 50000,
                    "hire_date": "{{faker.date.past 365}}"
                });
                PluginResult::success(employee.to_string(), 0)
            }
            _ =&gt; PluginResult::failure(
                format!("Unknown function: {}", function_name),
                0
            )
        }
    }

    fn get_available_functions(&amp;self) -&gt; Vec&lt;TemplateFunction&gt; {
        vec![
            TemplateFunction {
                name: "business_id".to_string(),
                description: "Generate a business ID".to_string(),
                args: vec![],
                return_type: "string".to_string(),
            },
            TemplateFunction {
                name: "department_name".to_string(),
                description: "Generate a department name".to_string(),
                args: vec![],
                return_type: "string".to_string(),
            },
            TemplateFunction {
                name: "employee_data".to_string(),
                description: "Generate complete employee data".to_string(),
                args: vec![],
                return_type: "json".to_string(),
            },
        ]
    }

    fn get_capabilities(&amp;self) -&gt; PluginCapabilities {
        PluginCapabilities::default()
    }

    fn health_check(&amp;self) -&gt; PluginHealth {
        PluginHealth::healthy("Template plugin healthy".to_string(), PluginMetrics::default())
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="using-custom-templates"><a class="header" href="#using-custom-templates">Using Custom Templates</a></h3>
<pre><code class="language-yaml"># OpenAPI spec with custom templates
paths:
  /employees:
    get:
      responses:
        '200':
          content:
            application/json:
              example:
                employees:
                  - "{{employee_data}}"
                  - "{{employee_data}}"
                business_id: "{{business_id}}"
</code></pre>
<h2 id="configuration-based-custom-responses"><a class="header" href="#configuration-based-custom-responses">Configuration-Based Custom Responses</a></h2>
<p>Define custom responses directly in configuration files.</p>
<h3 id="route-specific-responses"><a class="header" href="#route-specific-responses">Route-Specific Responses</a></h3>
<pre><code class="language-yaml"># mockforge.yaml
http:
  port: 3000
  routes:
    - path: /api/custom/dashboard
      method: GET
      response:
        status: 200
        headers:
          Content-Type: application/json
          X-Custom-Header: Dashboard-Data
        body: |
          {
            "widgets": [
              {
                "id": "sales-chart",
                "type": "chart",
                "data": [120, 150, 180, 200, 250]
              },
              {
                "id": "user-stats",
                "type": "stats",
                "data": {
                  "total_users": 15420,
                  "active_users": 8920,
                  "new_signups": 245
                }
              }
            ],
            "last_updated": "{{now}}"
          }

    - path: /api/custom/report
      method: POST
      response:
        status: 201
        headers:
          Location: /api/reports/123
        body: |
          {
            "report_id": "RPT-{{randInt 1000 9999}}",
            "status": "processing",
            "estimated_completion": "{{now+5m}}"
          }
</code></pre>
<h3 id="dynamic-route-matching"><a class="header" href="#dynamic-route-matching">Dynamic Route Matching</a></h3>
<pre><code class="language-yaml">routes:
  # Path parameters
  - path: /api/users/{userId}/profile
    method: GET
    response:
      status: 200
      body: |
        {
          "user_id": "{{request.path.userId}}",
          "name": "{{faker.name}}",
          "email": "{{faker.email}}",
          "profile": {
            "bio": "{{faker.sentence}}",
            "location": "{{faker.city}}, {{faker.country}}"
          }
        }

  # Query parameter conditions
  - path: /api/search
    method: GET
    response:
      status: 200
      body: |
        {{#if (eq request.query.type 'users')}}
        {
          "results": [
            {"id": 1, "name": "John", "type": "user"},
            {"id": 2, "name": "Jane", "type": "user"}
          ]
        }
        {{else if (eq request.query.type 'posts')}}
        {
          "results": [
            {"id": 1, "title": "Post 1", "type": "post"},
            {"id": 2, "title": "Post 2", "type": "post"}
          ]
        }
        {{else}}
        {
          "results": [],
          "message": "No results found for type: {{request.query.type}}"
        }
        {{/if}}
</code></pre>
<h2 id="error-response-customization"><a class="header" href="#error-response-customization">Error Response Customization</a></h2>
<p>Create sophisticated error responses for different scenarios.</p>
<h3 id="structured-error-responses"><a class="header" href="#structured-error-responses">Structured Error Responses</a></h3>
<pre><code class="language-yaml">routes:
  - path: /api/users/{userId}
    method: GET
    response:
      status: 404
      headers:
        Content-Type: application/json
      body: |
        {
          "error": {
            "code": "USER_NOT_FOUND",
            "message": "User with ID {{request.path.userId}} not found",
            "details": {
              "user_id": "{{request.path.userId}}",
              "requested_at": "{{now}}",
              "request_id": "{{uuid}}"
            },
            "suggestions": [
              "Check if the user ID is correct",
              "Verify the user exists in the system",
              "Try searching by email instead"
            ]
          }
        }

  - path: /api/orders
    method: POST
    response:
      status: 422
      body: |
        {
          "error": {
            "code": "VALIDATION_ERROR",
            "message": "Request validation failed",
            "validation_errors": [
              {
                "field": "customer_email",
                "code": "invalid_format",
                "message": "Email format is invalid"
              },
              {
                "field": "order_items",
                "code": "min_items",
                "message": "At least one order item is required"
              }
            ]
          }
        }
</code></pre>
<h3 id="conditional-error-responses"><a class="header" href="#conditional-error-responses">Conditional Error Responses</a></h3>
<pre><code class="language-yaml">routes:
  - path: /api/payments
    method: POST
    response:
      status: 402
      condition: "request.header.X-Test-Mode == 'insufficient_funds'"
      body: |
        {
          "error": "INSUFFICIENT_FUNDS",
          "message": "Payment failed due to insufficient funds",
          "details": {
            "available_balance": 50.00,
            "requested_amount": 100.00,
            "currency": "USD"
          }
        }

  - path: /api/payments
    method: POST
    response:
      status: 500
      condition: "request.header.X-Test-Mode == 'server_error'"
      body: |
        {
          "error": "INTERNAL_SERVER_ERROR",
          "message": "An unexpected error occurred while processing payment",
          "reference_id": "ERR-{{randInt 100000 999999}}",
          "timestamp": "{{now}}"
        }
</code></pre>
<h2 id="advanced-response-features"><a class="header" href="#advanced-response-features">Advanced Response Features</a></h2>
<h3 id="response-delays-and-latency"><a class="header" href="#response-delays-and-latency">Response Delays and Latency</a></h3>
<pre><code class="language-yaml">routes:
  - path: /api/slow-endpoint
    method: GET
    response:
      status: 200
      delay_ms: 2000  # 2 second delay
      body: |
        {
          "message": "This response was delayed",
          "timestamp": "{{now}}"
        }

  - path: /api/variable-delay
    method: GET
    response:
      status: 200
      delay_ms: "{{randInt 100 5000}}"  # Random delay between 100ms-5s
      body: |
        {
          "message": "Random delay applied",
          "delay_applied_ms": "{{_delay_ms}}"
        }
</code></pre>
<h3 id="response-caching"><a class="header" href="#response-caching">Response Caching</a></h3>
<pre><code class="language-yaml">routes:
  - path: /api/cached-data
    method: GET
    response:
      status: 200
      headers:
        Cache-Control: max-age=300
        X-Cache-Status: "{{_cache_hit ? 'HIT' : 'MISS'}}"
      cache: true
      cache_ttl_seconds: 300
      body: |
        {
          "data": "This response may be cached",
          "generated_at": "{{now}}",
          "cache_expires_at": "{{now+5m}}"
        }
</code></pre>
<h3 id="binary-response-handling"><a class="header" href="#binary-response-handling">Binary Response Handling</a></h3>
<pre><code class="language-yaml">routes:
  - path: /api/download/{filename}
    method: GET
    response:
      status: 200
      headers:
        Content-Type: application/octet-stream
        Content-Disposition: attachment; filename="{{request.path.filename}}"
      body_file: "/path/to/binary/files/{{request.path.filename}}"

  - path: /api/images/{imageId}
    method: GET
    response:
      status: 200
      headers:
        Content-Type: image/png
        Cache-Control: max-age=3600
      body_base64: "iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNkYPhfDwAChwGA60e6kgAAAABJRU5ErkJggg=="
</code></pre>
<h2 id="testing-custom-responses"><a class="header" href="#testing-custom-responses">Testing Custom Responses</a></h2>
<h3 id="manual-testing"><a class="header" href="#manual-testing">Manual Testing</a></h3>
<pre><code class="language-bash"># Test custom route
curl http://localhost:3000/api/custom/dashboard

# Test with parameters
curl "http://localhost:3000/api/users/123/profile"

# Test error conditions
curl -H "X-Test-Mode: insufficient_funds" \
     http://localhost:3000/api/payments \
     -X POST \
     -d '{}'
</code></pre>
<h3 id="automated-testing-1"><a class="header" href="#automated-testing-1">Automated Testing</a></h3>
<pre><code class="language-bash">#!/bin/bash
# test-custom-responses.sh

BASE_URL="http://localhost:3000"

echo "Testing custom responses..."

# Test dashboard endpoint
DASHBOARD_RESPONSE=$(curl -s $BASE_URL/api/custom/dashboard)
echo "Dashboard response:"
echo $DASHBOARD_RESPONSE | jq '.'

# Test user profile with path parameter
USER_RESPONSE=$(curl -s $BASE_URL/api/users/456/profile)
echo "User profile response:"
echo $USER_RESPONSE | jq '.'

# Test error responses
ERROR_RESPONSE=$(curl -s -H "X-Test-Mode: insufficient_funds" \
                      -X POST \
                      -d '{}' \
                      $BASE_URL/api/payments)
echo "Error response:"
echo $ERROR_RESPONSE | jq '.'

echo "Custom response tests completed!"
</code></pre>
<h2 id="best-practices-9"><a class="header" href="#best-practices-9">Best Practices</a></h2>
<h3 id="plugin-development"><a class="header" href="#plugin-development">Plugin Development</a></h3>
<ol>
<li><strong>Resource Limits</strong>: Set appropriate memory and CPU limits for plugins</li>
<li><strong>Error Handling</strong>: Implement proper error handling and logging</li>
<li><strong>Testing</strong>: Thoroughly test plugins with various inputs</li>
<li><strong>Documentation</strong>: Document plugin capabilities and configuration options</li>
</ol>
<h3 id="override-usage"><a class="header" href="#override-usage">Override Usage</a></h3>
<ol>
<li><strong>Selective Application</strong>: Use specific targets to avoid unintended modifications</li>
<li><strong>Version Control</strong>: Keep override configurations in version control</li>
<li><strong>Testing</strong>: Test overrides with different request scenarios</li>
<li><strong>Performance</strong>: Minimize complex conditions and patch operations</li>
</ol>
<h3 id="response-design"><a class="header" href="#response-design">Response Design</a></h3>
<ol>
<li><strong>Consistency</strong>: Maintain consistent response formats across endpoints</li>
<li><strong>Error Details</strong>: Provide meaningful error messages and codes</li>
<li><strong>Metadata</strong>: Include relevant metadata like timestamps and request IDs</li>
<li><strong>Content Types</strong>: Set appropriate Content-Type headers</li>
</ol>
<h3 id="security-considerations-2"><a class="header" href="#security-considerations-2">Security Considerations</a></h3>
<ol>
<li><strong>Input Validation</strong>: Validate all inputs in custom plugins</li>
<li><strong>Resource Limits</strong>: Prevent resource exhaustion attacks</li>
<li><strong>Authentication</strong>: Implement proper authentication for sensitive endpoints</li>
<li><strong>Logging</strong>: Log security-relevant events without exposing sensitive data</li>
</ol>
<h2 id="troubleshooting-23"><a class="header" href="#troubleshooting-23">Troubleshooting</a></h2>
<h3 id="plugin-issues"><a class="header" href="#plugin-issues">Plugin Issues</a></h3>
<p><strong>Plugin not loading</strong>: Check plugin configuration and file paths
<strong>Plugin timeout</strong>: Increase resource limits or optimize plugin code
<strong>Plugin errors</strong>: Check plugin logs and error messages</p>
<h3 id="override-problems"><a class="header" href="#override-problems">Override Problems</a></h3>
<p><strong>Overrides not applying</strong>: Verify target selectors and patch syntax
<strong>JSON patch errors</strong>: Validate patch operations against JSON structure
<strong>Condition evaluation</strong>: Test conditional expressions with sample requests</p>
<h3 id="performance-issues-2"><a class="header" href="#performance-issues-2">Performance Issues</a></h3>
<p><strong>Slow responses</strong>: Profile plugin execution and optimize bottlenecks
<strong>Memory usage</strong>: Monitor plugin memory consumption and adjust limits
<strong>Template expansion</strong>: Simplify complex templates or use static responses</p>
<p>For basic HTTP mocking features, see the <a href="user-guide/http-mocking/../http-mocking.html">HTTP Mocking guide</a>. For advanced templating, see the <a href="user-guide/http-mocking/dynamic-data.html">Dynamic Data guide</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="dynamic-data"><a class="header" href="#dynamic-data">Dynamic Data</a></h1>
<p>MockForge provides powerful dynamic data generation capabilities through its templating system and faker integration. This guide covers generating realistic, varied responses for comprehensive API testing and development.</p>
<h2 id="template-expansion-basics"><a class="header" href="#template-expansion-basics">Template Expansion Basics</a></h2>
<p>MockForge uses a lightweight templating system with <code>{{token}}</code> syntax to inject dynamic values into responses.</p>
<h3 id="enabling-templates"><a class="header" href="#enabling-templates">Enabling Templates</a></h3>
<p>Templates are disabled by default for security. Enable them using:</p>
<pre><code class="language-bash"># Environment variable
MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true mockforge serve --spec api-spec.json

# Configuration file
http:
  response_template_expand: true
</code></pre>
<h3 id="basic-template-syntax"><a class="header" href="#basic-template-syntax">Basic Template Syntax</a></h3>
<pre><code class="language-yaml">paths:
  /users:
    get:
      responses:
        '200':
          content:
            application/json:
              example:
                users:
                  - id: "{{uuid}}"
                    name: "{{faker.name}}"
                    email: "{{faker.email}}"
                    created_at: "{{now}}"
</code></pre>
<h2 id="time-based-templates"><a class="header" href="#time-based-templates">Time-Based Templates</a></h2>
<p>Generate timestamps and time offsets for realistic temporal data.</p>
<h3 id="current-time"><a class="header" href="#current-time">Current Time</a></h3>
<pre><code class="language-yaml">responses:
  '200':
    content:
      application/json:
        example:
          current_time: "{{now}}"
          server_timestamp: "{{now}}"
</code></pre>
<h3 id="time-offsets"><a class="header" href="#time-offsets">Time Offsets</a></h3>
<pre><code class="language-yaml">responses:
  '200':
    content:
      application/json:
        example:
          created_at: "{{now-7d}}"
          expires_at: "{{now+1h}}"
          last_login: "{{now-30m}}"
          scheduled_for: "{{now+2h}}"
</code></pre>
<p><strong>Supported units:</strong></p>
<ul>
<li><code>s</code> - seconds</li>
<li><code>m</code> - minutes</li>
<li><code>h</code> - hours</li>
<li><code>d</code> - days</li>
</ul>
<h2 id="random-data-generation"><a class="header" href="#random-data-generation">Random Data Generation</a></h2>
<p>Generate random values for varied test data.</p>
<h3 id="random-integers"><a class="header" href="#random-integers">Random Integers</a></h3>
<pre><code class="language-yaml">responses:
  '200':
    content:
      application/json:
        example:
          user_count: "{{randInt 1 100}}"
          age: "{{randInt 18 80}}"
          score: "{{randInt -10 10}}"
</code></pre>
<h3 id="random-floats"><a class="header" href="#random-floats">Random Floats</a></h3>
<pre><code class="language-yaml">responses:
  '200':
    content:
      application/json:
        example:
          price: "{{randFloat 9.99 999.99}}"
          rating: "{{randFloat 1.0 5.0}}"
          percentage: "{{randFloat 0.0 100.0}}"
</code></pre>
<h2 id="uuid-generation"><a class="header" href="#uuid-generation">UUID Generation</a></h2>
<p>Generate unique identifiers for entities.</p>
<pre><code class="language-yaml">responses:
  '200':
    content:
      application/json:
        example:
          id: "{{uuid}}"
          order_id: "{{uuid}}"
          transaction_id: "{{uuid}}"
</code></pre>
<h2 id="faker-data-generation"><a class="header" href="#faker-data-generation">Faker Data Generation</a></h2>
<p>Generate realistic fake data using the Faker library.</p>
<h3 id="basic-faker-functions"><a class="header" href="#basic-faker-functions">Basic Faker Functions</a></h3>
<pre><code class="language-yaml">responses:
  '200':
    content:
      application/json:
        example:
          user:
            id: "{{uuid}}"
            name: "{{faker.name}}"
            email: "{{faker.email}}"
            created_at: "{{now}}"
</code></pre>
<h3 id="extended-faker-functions"><a class="header" href="#extended-faker-functions">Extended Faker Functions</a></h3>
<p>When the <code>data-faker</code> feature is enabled, additional functions are available:</p>
<pre><code class="language-yaml">responses:
  '200':
    content:
      application/json:
        example:
          user:
            name: "{{faker.name}}"
            email: "{{faker.email}}"
            phone: "{{faker.phone}}"
            address: "{{faker.address}}"
            company: "{{faker.company}}"
          product:
            name: "{{faker.word}}"
            description: "{{faker.sentence}}"
            color: "{{faker.color}}"
            url: "{{faker.url}}"
            ip_address: "{{faker.ip}}"
</code></pre>
<h3 id="disabling-faker"><a class="header" href="#disabling-faker">Disabling Faker</a></h3>
<p>For deterministic testing, disable faker tokens:</p>
<pre><code class="language-bash">MOCKFORGE_FAKE_TOKENS=false mockforge serve --spec api-spec.json
</code></pre>
<h2 id="request-data-access-1"><a class="header" href="#request-data-access-1">Request Data Access</a></h2>
<p>Access data from incoming requests to create dynamic responses.</p>
<h3 id="path-parameters"><a class="header" href="#path-parameters">Path Parameters</a></h3>
<pre><code class="language-yaml">paths:
  /users/{userId}:
    get:
      parameters:
        - name: userId
          in: path
          required: true
          schema:
            type: string
      responses:
        '200':
          content:
            application/json:
              example:
                id: "{{request.path.userId}}"
                name: "User {{request.path.userId}}"
                retrieved_at: "{{now}}"
</code></pre>
<h3 id="query-parameters"><a class="header" href="#query-parameters">Query Parameters</a></h3>
<pre><code class="language-yaml">paths:
  /users:
    get:
      parameters:
        - name: limit
          in: query
          schema:
            type: integer
            default: 10
        - name: format
          in: query
          schema:
            type: string
            enum: [brief, detailed]
      responses:
        '200':
          content:
            application/json:
              example: |
                {{#if (eq request.query.format 'detailed')}}
                {
                  "users": [
                    {
                      "id": "{{uuid}}",
                      "name": "{{faker.name}}",
                      "email": "{{faker.email}}",
                      "profile": {
                        "bio": "{{faker.sentence}}",
                        "location": "{{faker.address}}"
                      }
                    }
                  ],
                  "limit": {{request.query.limit}},
                  "format": "{{request.query.format}}"
                }
                {{else}}
                {
                  "users": [
                    {
                      "id": "{{uuid}}",
                      "name": "{{faker.name}}",
                      "email": "{{faker.email}}"
                    }
                  ],
                  "limit": {{request.query.limit}}
                }
                {{/if}}
</code></pre>
<h3 id="request-body-access"><a class="header" href="#request-body-access">Request Body Access</a></h3>
<pre><code class="language-yaml">paths:
  /users:
    post:
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                name:
                  type: string
                email:
                  type: string
      responses:
        '201':
          content:
            application/json:
              example:
                id: "{{uuid}}"
                name: "{{request.body.name}}"
                email: "{{request.body.email}}"
                created_at: "{{now}}"
                welcome_message: "Welcome {{request.body.name}}!"
</code></pre>
<h3 id="headers-access"><a class="header" href="#headers-access">Headers Access</a></h3>
<pre><code class="language-yaml">responses:
  '200':
    content:
      application/json:
        example:
          user_agent: "{{request.header.User-Agent}}"
          api_version: "{{request.header.X-API-Version}}"
          authorization: "{{request.header.Authorization}}"
</code></pre>
<h2 id="conditional-templates-1"><a class="header" href="#conditional-templates-1">Conditional Templates</a></h2>
<p>Use Handlebars-style conditionals for complex logic.</p>
<h3 id="basic-conditionals"><a class="header" href="#basic-conditionals">Basic Conditionals</a></h3>
<pre><code class="language-yaml">responses:
  '200':
    content:
      application/json:
        example: |
          {{#if (eq request.query.format 'detailed')}}
          {
            "data": {
              "id": "{{uuid}}",
              "name": "{{faker.name}}",
              "details": {
                "bio": "{{faker.paragraph}}",
                "stats": {
                  "login_count": {{randInt 1 1000}},
                  "last_active": "{{now-1d}}"
                }
              }
            }
          }
          {{else}}
          {
            "data": {
              "id": "{{uuid}}",
              "name": "{{faker.name}}"
            }
          }
          {{/if}}
</code></pre>
<h3 id="multiple-conditions"><a class="header" href="#multiple-conditions">Multiple Conditions</a></h3>
<pre><code class="language-yaml">responses:
  '200':
    content:
      application/json:
        example: |
          {{#if (eq request.query.type 'admin')}}
          {
            "user": {
              "id": "{{uuid}}",
              "name": "{{faker.name}}",
              "role": "admin",
              "permissions": ["read", "write", "delete", "admin"]
            }
          }
          {{else if (eq request.query.type 'premium')}}
          {
            "user": {
              "id": "{{uuid}}",
              "name": "{{faker.name}}",
              "role": "premium",
              "permissions": ["read", "write"]
            }
          }
          {{else}}
          {
            "user": {
              "id": "{{uuid}}",
              "name": "{{faker.name}}",
              "role": "basic",
              "permissions": ["read"]
            }
          }
          {{/if}}
</code></pre>
<h2 id="data-generation-templates-1"><a class="header" href="#data-generation-templates-1">Data Generation Templates</a></h2>
<p>MockForge includes built-in data generation templates for common entities.</p>
<h3 id="user-template"><a class="header" href="#user-template">User Template</a></h3>
<pre><code class="language-bash"># Generate user data
mockforge data template user --rows 10 --format json

# Output:
[
  {
    "id": "550e8400-e29b-41d4-a716-446655440000",
    "email": "john.doe@example.com",
    "name": "John Doe",
    "created_at": "2024-01-15T10:30:00Z",
    "active": true
  }
]
</code></pre>
<h3 id="product-template"><a class="header" href="#product-template">Product Template</a></h3>
<pre><code class="language-bash"># Generate product data
mockforge data template product --rows 5 --format csv

# Output:
id,name,description,price,category,in_stock
550e8400-e29b-41d4-a716-446655440001,Wireless Headphones,High-quality wireless headphones with noise cancellation,199.99,Electronics,true
</code></pre>
<h3 id="order-template"><a class="header" href="#order-template">Order Template</a></h3>
<pre><code class="language-bash"># Generate order data with relationships
mockforge data template order --rows 3 --format json --rag

# Output:
[
  {
    "id": "550e8400-e29b-41d4-a716-446655440002",
    "user_id": "550e8400-e29b-41d4-a716-446655440000",
    "total_amount": 299.97,
    "status": "completed",
    "created_at": "2024-01-16T14:20:00Z"
  }
]
</code></pre>
<h2 id="advanced-templating-features"><a class="header" href="#advanced-templating-features">Advanced Templating Features</a></h2>
<h3 id="encryption-functions"><a class="header" href="#encryption-functions">Encryption Functions</a></h3>
<p>Secure sensitive data in responses:</p>
<pre><code class="language-yaml">responses:
  '200':
    content:
      application/json:
        example:
          user:
            id: "{{uuid}}"
            name: "{{encrypt 'user_name' faker.name}}"
            email: "{{encrypt 'user_email' faker.email}}"
            ssn: "{{encrypt 'sensitive' '123-45-6789'}}"
</code></pre>
<h3 id="decryption"><a class="header" href="#decryption">Decryption</a></h3>
<p>Access encrypted data:</p>
<pre><code class="language-yaml"># In templates that need to decrypt
decrypted_name: "{{decrypt 'user_name' request.body.encrypted_name}}"
</code></pre>
<h3 id="file-system-access"><a class="header" href="#file-system-access">File System Access</a></h3>
<p>Read external files for dynamic content:</p>
<pre><code class="language-yaml">responses:
  '200':
    content:
      application/json:
        example:
          config: "{{fs.readFile 'config.json'}}"
          template: "{{fs.readFile 'templates/welcome.html'}}"
</code></pre>
<h2 id="request-chaining-context"><a class="header" href="#request-chaining-context">Request Chaining Context</a></h2>
<p>Access data from previous requests in chained scenarios.</p>
<h3 id="chain-variables"><a class="header" href="#chain-variables">Chain Variables</a></h3>
<pre><code class="language-yaml"># In chained request templates
responses:
  '200':
    content:
      application/json:
        example:
          previous_request_id: "{{chain.request_id}}"
          previous_user_id: "{{chain.user.id}}"
          session_token: "{{chain.auth.token}}"
</code></pre>
<h2 id="custom-template-plugins"><a class="header" href="#custom-template-plugins">Custom Template Plugins</a></h2>
<p>Extend templating with custom functions via plugins.</p>
<h3 id="template-plugin-example-1"><a class="header" href="#template-plugin-example-1">Template Plugin Example</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_plugin_core::*;

pub struct BusinessTemplatePlugin;

impl TemplatePlugin for BusinessTemplatePlugin {
    fn execute_function(
        &amp;mut self,
        function_name: &amp;str,
        args: &amp;[TemplateArg],
        _context: &amp;PluginContext,
    ) -&gt; PluginResult&lt;String&gt; {
        match function_name {
            "business_id" =&gt; {
                let id = format!("BIZ-{:010}", rand::random::&lt;u32&gt;());
                PluginResult::success(id, 0)
            }
            "department" =&gt; {
                let depts = ["Engineering", "Sales", "Marketing", "HR"];
                let dept = depts[rand::random::&lt;usize&gt;() % depts.len()];
                PluginResult::success(dept.to_string(), 0)
            }
            "salary" =&gt; {
                let salary = rand::random::&lt;u32&gt;() % 150000 + 50000;
                PluginResult::success(salary.to_string(), 0)
            }
            _ =&gt; PluginResult::failure(
                format!("Unknown function: {}", function_name),
                0
            )
        }
    }

    fn get_available_functions(&amp;self) -&gt; Vec&lt;TemplateFunction&gt; {
        vec![
            TemplateFunction {
                name: "business_id".to_string(),
                description: "Generate business ID".to_string(),
                args: vec![],
                return_type: "string".to_string(),
            },
            TemplateFunction {
                name: "department".to_string(),
                description: "Generate department name".to_string(),
                args: vec![],
                return_type: "string".to_string(),
            },
            TemplateFunction {
                name: "salary".to_string(),
                description: "Generate salary amount".to_string(),
                args: vec![],
                return_type: "string".to_string(),
            },
        ]
    }

    fn get_capabilities(&amp;self) -&gt; PluginCapabilities {
        PluginCapabilities::default()
    }

    fn health_check(&amp;self) -&gt; PluginHealth {
        PluginHealth::healthy("Business template plugin healthy".to_string(), PluginMetrics::default())
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="using-custom-templates-1"><a class="header" href="#using-custom-templates-1">Using Custom Templates</a></h3>
<pre><code class="language-yaml">responses:
  '200':
    content:
      application/json:
        example:
          employee:
            id: "{{business_id}}"
            name: "{{faker.name}}"
            department: "{{department}}"
            salary: "{{salary}}"
            hire_date: "{{now-1y}}"
</code></pre>
<h2 id="configuration-and-security"><a class="header" href="#configuration-and-security">Configuration and Security</a></h2>
<h3 id="template-security-settings"><a class="header" href="#template-security-settings">Template Security Settings</a></h3>
<pre><code class="language-yaml"># mockforge.yaml
http:
  response_template_expand: true
  template_security:
    allow_file_access: false
    allow_encryption: true
    max_template_depth: 10
    timeout_ms: 5000
</code></pre>
<h3 id="environment-variables-7"><a class="header" href="#environment-variables-7">Environment Variables</a></h3>
<pre><code class="language-bash"># Enable template expansion
MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true

# Disable faker for deterministic tests
MOCKFORGE_FAKE_TOKENS=false

# Set validation status for template errors
MOCKFORGE_VALIDATION_STATUS=422

# Control template execution timeout
MOCKFORGE_TEMPLATE_TIMEOUT_MS=5000
</code></pre>
<h2 id="testing-with-dynamic-data"><a class="header" href="#testing-with-dynamic-data">Testing with Dynamic Data</a></h2>
<h3 id="manual-testing-1"><a class="header" href="#manual-testing-1">Manual Testing</a></h3>
<pre><code class="language-bash"># Test template expansion
curl http://localhost:3000/users

# Test with query parameters
curl "http://localhost:3000/users?format=detailed&amp;limit=5"

# Test path parameters
curl http://localhost:3000/users/123

# Test POST with body access
curl -X POST http://localhost:3000/users \
  -H "Content-Type: application/json" \
  -d '{"name": "Test User", "email": "test@example.com"}'
</code></pre>
<h3 id="automated-testing-2"><a class="header" href="#automated-testing-2">Automated Testing</a></h3>
<pre><code class="language-bash">#!/bin/bash
# test-dynamic-data.sh

BASE_URL="http://localhost:3000"

echo "Testing dynamic data generation..."

# Test basic templates
USER_RESPONSE=$(curl -s $BASE_URL/users)
echo "User response with templates:"
echo $USER_RESPONSE | jq '.'

# Test conditional templates
DETAILED_RESPONSE=$(curl -s "$BASE_URL/users?format=detailed")
echo "Detailed format response:"
echo $DETAILED_RESPONSE | jq '.'

BASIC_RESPONSE=$(curl -s "$BASE_URL/users?format=basic")
echo "Basic format response:"
echo $BASIC_RESPONSE | jq '.'

# Test faker data
PRODUCT_RESPONSE=$(curl -s $BASE_URL/products)
echo "Product response with faker data:"
echo $PRODUCT_RESPONSE | jq '.'

echo "Dynamic data tests completed!"
</code></pre>
<h2 id="best-practices-10"><a class="header" href="#best-practices-10">Best Practices</a></h2>
<h3 id="template-usage"><a class="header" href="#template-usage">Template Usage</a></h3>
<ol>
<li><strong>Enable Selectively</strong>: Only enable template expansion where needed for security</li>
<li><strong>Validate Input</strong>: Sanitize request data used in templates</li>
<li><strong>Test Thoroughly</strong>: Test template expansion with various inputs</li>
<li><strong>Monitor Performance</strong>: Templates add processing overhead</li>
</ol>
<h3 id="data-generation-1"><a class="header" href="#data-generation-1">Data Generation</a></h3>
<ol>
<li><strong>Use Appropriate Faker</strong>: Choose faker functions that match your domain</li>
<li><strong>Maintain Consistency</strong>: Use consistent data patterns across endpoints</li>
<li><strong>Consider Relationships</strong>: Generate related data that makes sense together</li>
<li><strong>Balance Realism</strong>: Generate realistic but not sensitive data</li>
</ol>
<h3 id="security-considerations-3"><a class="header" href="#security-considerations-3">Security Considerations</a></h3>
<ol>
<li><strong>Input Sanitization</strong>: Never trust request data in templates</li>
<li><strong>File Access</strong>: Disable file system access in production if not needed</li>
<li><strong>Encryption</strong>: Use encryption functions for sensitive data</li>
<li><strong>Rate Limiting</strong>: Consider rate limiting for expensive template operations</li>
</ol>
<h3 id="performance-optimization-1"><a class="header" href="#performance-optimization-1">Performance Optimization</a></h3>
<ol>
<li><strong>Cache Static Parts</strong>: Cache template parsing for frequently used templates</li>
<li><strong>Limit Complexity</strong>: Avoid deeply nested conditionals and complex logic</li>
<li><strong>Profile Execution</strong>: Monitor template execution time and optimize slow functions</li>
<li><strong>Use Appropriate Timeouts</strong>: Set reasonable timeouts for template execution</li>
</ol>
<h2 id="troubleshooting-24"><a class="header" href="#troubleshooting-24">Troubleshooting</a></h2>
<h3 id="template-not-expanding"><a class="header" href="#template-not-expanding">Template Not Expanding</a></h3>
<p><strong>Problem</strong>: Templates appear as literal text in responses</p>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Enable template expansion
MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true mockforge serve --spec api-spec.json

# Check configuration
# Ensure response_template_expand: true in config
</code></pre>
<h3 id="faker-functions-not-working"><a class="header" href="#faker-functions-not-working">Faker Functions Not Working</a></h3>
<p><strong>Problem</strong>: Faker functions return empty or error values</p>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Ensure faker is enabled
MOCKFORGE_FAKE_TOKENS=true mockforge serve --spec api-spec.json

# Check if data-faker feature is enabled
# For extended faker functions, ensure the feature is compiled in
</code></pre>
<h3 id="request-data-access-issues"><a class="header" href="#request-data-access-issues">Request Data Access Issues</a></h3>
<p><strong>Problem</strong>: <code>request.*</code> variables are empty or undefined</p>
<p><strong>Solutions</strong>:</p>
<ul>
<li>Verify request format (JSON for body access)</li>
<li>Check parameter names match exactly</li>
<li>Ensure path/query parameters are properly defined in OpenAPI spec</li>
</ul>
<h3 id="performance-issues-3"><a class="header" href="#performance-issues-3">Performance Issues</a></h3>
<p><strong>Problem</strong>: Template expansion is slow</p>
<p><strong>Solutions</strong>:</p>
<ul>
<li>Simplify template logic</li>
<li>Cache frequently used values</li>
<li>Use static responses where dynamic data isn‚Äôt needed</li>
<li>Profile and optimize custom template functions</li>
</ul>
<p>For basic HTTP mocking features, see the <a href="user-guide/http-mocking/../http-mocking.html">HTTP Mocking guide</a>. For custom response generation, see the <a href="user-guide/http-mocking/custom-responses.html">Custom Responses guide</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="advanced-behavior-and-simulation-1"><a class="header" href="#advanced-behavior-and-simulation-1">Advanced Behavior and Simulation</a></h1>
<p>MockForge provides advanced behavior and simulation features that allow you to create realistic, stateful, and resilient API mocks. This guide covers record &amp; playback, stateful behavior simulation, fault injection, latency simulation, and conditional proxying.</p>
<h2 id="table-of-contents-2"><a class="header" href="#table-of-contents-2">Table of Contents</a></h2>
<ul>
<li><a href="user-guide/advanced-behavior.html#record--playback">Record &amp; Playback</a></li>
<li><a href="user-guide/advanced-behavior.html#stateful-behavior-simulation">Stateful Behavior Simulation</a></li>
<li><a href="user-guide/advanced-behavior.html#per-route-fault-injection">Per-Route Fault Injection</a></li>
<li><a href="user-guide/advanced-behavior.html#per-route-latency-simulation">Per-Route Latency Simulation</a></li>
<li><a href="user-guide/advanced-behavior.html#conditional-proxying">Conditional Proxying</a></li>
<li><a href="user-guide/advanced-behavior.html#browser-proxy-with-conditional-forwarding">Browser Proxy with Conditional Forwarding</a></li>
</ul>
<h2 id="record--playback-1"><a class="header" href="#record--playback-1">Record &amp; Playback</a></h2>
<p>The record &amp; playback feature allows you to capture real API interactions and convert them into replayable stub mappings.</p>
<h3 id="quick-start-5"><a class="header" href="#quick-start-5">Quick Start</a></h3>
<ol>
<li><strong>Start recording</strong> while proxying to a real service:</li>
</ol>
<pre><code class="language-bash">mockforge serve --spec api-spec.json --proxy --record
</code></pre>
<ol start="2">
<li><strong>Convert recordings</strong> to stub mappings:</li>
</ol>
<pre><code class="language-bash"># Convert a specific recording
mockforge recorder convert --recording-id abc123 --output fixtures/user-api.yaml

# Batch convert all recordings
mockforge recorder convert --input recordings.db --output fixtures/ --format yaml
</code></pre>
<h3 id="configuration-3"><a class="header" href="#configuration-3">Configuration</a></h3>
<pre><code class="language-yaml">core:
  recorder:
    enabled: true
    auto_convert: true
    output_dir: "./fixtures/recorded"
    format: "yaml"
    filters:
      min_status_code: 200
      max_status_code: 299
      exclude_paths:
        - "/health"
        - "/metrics"
</code></pre>
<h3 id="api-usage"><a class="header" href="#api-usage">API Usage</a></h3>
<pre><code class="language-bash"># Convert via API
curl -X POST http://localhost:9080/api/recorder/convert/abc123 \
  -H "Content-Type: application/json" \
  -d '{"format": "yaml"}'
</code></pre>
<h2 id="stateful-behavior-simulation"><a class="header" href="#stateful-behavior-simulation">Stateful Behavior Simulation</a></h2>
<p>Stateful behavior simulation allows responses to change based on previous requests, using state machines to track resource state.</p>
<h3 id="basic-example"><a class="header" href="#basic-example">Basic Example</a></h3>
<pre><code class="language-yaml">core:
  stateful:
    enabled: true
    state_machines:
      - name: "order_workflow"
        initial_state: "pending"
        states:
          - name: "pending"
            response:
              status_code: 200
              body_template: '{"order_id": "{{resource_id}}", "status": "pending"}'
          - name: "processing"
            response:
              status_code: 200
              body_template: '{"order_id": "{{resource_id}}", "status": "processing"}'
          - name: "shipped"
            response:
              status_code: 200
              body_template: '{"order_id": "{{resource_id}}", "status": "shipped"}'
        resource_id_extract:
          type: "path_param"
          param: "order_id"
        transitions:
          - method: "POST"
            path_pattern: "/api/orders"
            from_state: "initial"
            to_state: "pending"
          - method: "PUT"
            path_pattern: "/api/orders/{order_id}/process"
            from_state: "pending"
            to_state: "processing"
</code></pre>
<h3 id="resource-id-extraction"><a class="header" href="#resource-id-extraction">Resource ID Extraction</a></h3>
<p>Extract resource IDs from various sources:</p>
<pre><code class="language-yaml"># From path parameter
resource_id_extract:
  type: "path_param"
  param: "order_id"

# From header
resource_id_extract:
  type: "header"
  name: "X-Resource-ID"

# From JSONPath in request body
resource_id_extract:
  type: "json_path"
  path: "$.order.id"

# Composite (tries multiple sources)
resource_id_extract:
  type: "composite"
  extractors:
    - type: "path_param"
      param: "order_id"
    - type: "header"
      name: "X-Order-ID"
</code></pre>
<h2 id="per-route-fault-injection-1"><a class="header" href="#per-route-fault-injection-1">Per-Route Fault Injection</a></h2>
<p>Configure fault injection on specific routes with multiple fault types.</p>
<h3 id="configuration-4"><a class="header" href="#configuration-4">Configuration</a></h3>
<pre><code class="language-yaml">core:
  routes:
    - path: "/api/payments/process"
      method: "POST"
      fault_injection:
        enabled: true
        probability: 0.05  # 5% chance
        fault_types:
          - type: "http_error"
            status_code: 503
            message: "Service unavailable"
          - type: "timeout"
            duration_ms: 5000
          - type: "connection_error"
            message: "Connection refused"
</code></pre>
<h3 id="fault-types-1"><a class="header" href="#fault-types-1">Fault Types</a></h3>
<ul>
<li><strong>HTTP Error</strong>: Return specific status codes</li>
<li><strong>Connection Error</strong>: Simulate connection failures</li>
<li><strong>Timeout</strong>: Simulate request timeouts</li>
<li><strong>Partial Response</strong>: Truncate responses</li>
<li><strong>Payload Corruption</strong>: Corrupt response payloads</li>
</ul>
<h2 id="per-route-latency-simulation"><a class="header" href="#per-route-latency-simulation">Per-Route Latency Simulation</a></h2>
<p>Simulate network latency with various distributions.</p>
<h3 id="configuration-5"><a class="header" href="#configuration-5">Configuration</a></h3>
<pre><code class="language-yaml">core:
  routes:
    - path: "/api/search"
      method: "GET"
      latency:
        enabled: true
        probability: 0.8
        distribution: "normal"  # fixed, normal, exponential, uniform
        mean_ms: 500.0
        std_dev_ms: 100.0
        jitter_percent: 15.0
</code></pre>
<h3 id="distributions"><a class="header" href="#distributions">Distributions</a></h3>
<ul>
<li><strong>Fixed</strong>: Constant delay with optional jitter</li>
<li><strong>Normal</strong>: Gaussian distribution (realistic for most APIs)</li>
<li><strong>Exponential</strong>: Exponential distribution (simulates network delays)</li>
<li><strong>Uniform</strong>: Random delay within a range</li>
</ul>
<h2 id="conditional-proxying-1"><a class="header" href="#conditional-proxying-1">Conditional Proxying</a></h2>
<p>Proxy requests conditionally based on request attributes using expressions.</p>
<h3 id="basic-examples"><a class="header" href="#basic-examples">Basic Examples</a></h3>
<pre><code class="language-yaml">core:
  proxy:
    enabled: true
    rules:
      # Proxy admin requests
      - pattern: "/api/admin/*"
        upstream_url: "https://admin-api.example.com"
        condition: "$.user.role == 'admin'"
      
      # Proxy authenticated requests
      - pattern: "/api/protected/*"
        upstream_url: "https://protected-api.example.com"
        condition: "header[authorization] != ''"
      
      # Proxy based on query parameter
      - pattern: "/api/data/*"
        upstream_url: "https://data-api.example.com"
        condition: "query[env] == 'production'"
</code></pre>
<h3 id="condition-types"><a class="header" href="#condition-types">Condition Types</a></h3>
<h4 id="jsonpath-expressions"><a class="header" href="#jsonpath-expressions">JSONPath Expressions</a></h4>
<pre><code class="language-yaml">condition: "$.user.role == 'admin'"
condition: "$.order.amount &gt; 1000"
</code></pre>
<h4 id="header-checks"><a class="header" href="#header-checks">Header Checks</a></h4>
<pre><code class="language-yaml">condition: "header[authorization] != ''"
condition: "header[user-agent] == 'MobileApp/1.0'"
</code></pre>
<h4 id="query-parameters-1"><a class="header" href="#query-parameters-1">Query Parameters</a></h4>
<pre><code class="language-yaml">condition: "query[env] == 'production'"
condition: "query[version] == 'v2'"
</code></pre>
<h4 id="logical-operators"><a class="header" href="#logical-operators">Logical Operators</a></h4>
<pre><code class="language-yaml"># AND
condition: "AND(header[authorization] != '', $.user.role == 'admin')"

# OR
condition: "OR(query[env] == 'production', query[env] == 'staging')"

# NOT
condition: "NOT(query[env] == 'development')"
</code></pre>
<h2 id="browser-proxy-with-conditional-forwarding"><a class="header" href="#browser-proxy-with-conditional-forwarding">Browser Proxy with Conditional Forwarding</a></h2>
<p>The browser proxy mode supports the same conditional forwarding rules.</p>
<h3 id="usage"><a class="header" href="#usage">Usage</a></h3>
<pre><code class="language-bash"># Start browser proxy with conditional rules
mockforge proxy --port 8081 --config config.yaml
</code></pre>
<p>Configure your browser/mobile app to use <code>127.0.0.1:8081</code> as the HTTP proxy. All requests will be evaluated against conditional rules before proxying.</p>
<h3 id="example-configuration"><a class="header" href="#example-configuration">Example Configuration</a></h3>
<pre><code class="language-yaml">proxy:
  enabled: true
  rules:
    # Route admin users to production
    - pattern: "/api/admin/*"
      upstream_url: "https://admin-api.production.com"
      condition: "$.user.role == 'admin'"
    
    # Route authenticated users to staging
    - pattern: "/api/*"
      upstream_url: "https://api.staging.com"
      condition: "header[authorization] != ''"
</code></pre>
<h2 id="priority-chain"><a class="header" href="#priority-chain">Priority Chain</a></h2>
<p>MockForge processes requests through this priority chain:</p>
<ol>
<li><strong>Replay</strong> - Check for recorded fixtures</li>
<li><strong>Stateful</strong> - Check for stateful response handling</li>
<li><strong>Route Chaos</strong> - Apply per-route fault injection and latency</li>
<li><strong>Global Fail</strong> - Apply global/tag-based failure injection</li>
<li><strong>Proxy</strong> - Check for conditional proxying</li>
<li><strong>Mock</strong> - Generate mock response from OpenAPI spec</li>
<li><strong>Record</strong> - Record request for future replay</li>
</ol>
<h2 id="related-advanced-features"><a class="header" href="#related-advanced-features">Related Advanced Features</a></h2>
<p>MockForge includes many additional advanced features that complement the basic advanced behavior:</p>
<ul>
<li><strong><a href="user-guide/vbr-engine.html">VBR Engine</a></strong>: Virtual database layer with automatic CRUD generation</li>
<li><strong><a href="user-guide/temporal-simulation.html">Temporal Simulation</a></strong>: Time travel and time-based data mutations</li>
<li><strong><a href="user-guide/scenario-state-machines.html">Scenario State Machines</a></strong>: Visual flow editor for complex workflows</li>
<li><strong><a href="user-guide/mockai.html">MockAI</a></strong>: AI-powered intelligent response generation</li>
<li><strong><a href="user-guide/chaos-lab.html">Chaos Lab</a></strong>: Interactive network condition simulation</li>
<li><strong><a href="user-guide/reality-slider.html">Reality Slider</a></strong>: Unified control for mock environment realism</li>
</ul>
<p>For a complete overview, see <a href="user-guide/advanced-features.html">Advanced Features</a>.</p>
<h2 id="best-practices-11"><a class="header" href="#best-practices-11">Best Practices</a></h2>
<ol>
<li><strong>Start simple</strong> - Begin with basic configurations and add complexity gradually</li>
<li><strong>Test thoroughly</strong> - Verify state transitions and conditions work as expected</li>
<li><strong>Monitor performance</strong> - Latency injection can slow down tests</li>
<li><strong>Document conditions</strong> - Keep conditional logic well-documented</li>
<li><strong>Use version control</strong> - Track configuration changes over time</li>
</ol>
<h2 id="examples-7"><a class="header" href="#examples-7">Examples</a></h2>
<p>See the <a href="user-guide/../../../tests/fixtures/configs/example-advanced-features.yaml">example configuration file</a> for comprehensive examples of all features.</p>
<p>For more details, see the <a href="user-guide/../../../docs/ADVANCED_BEHAVIOR_SIMULATION.html">Advanced Behavior and Simulation documentation</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="grpc-mocking"><a class="header" href="#grpc-mocking">gRPC Mocking</a></h1>
<p>MockForge provides comprehensive gRPC service mocking with dynamic Protocol Buffer discovery, streaming support, and flexible service registration. This enables testing of gRPC-based microservices and APIs with realistic mock responses.</p>
<h2 id="overview-6"><a class="header" href="#overview-6">Overview</a></h2>
<p>MockForge‚Äôs gRPC mocking system offers:</p>
<ul>
<li><strong>Dynamic Proto Discovery</strong>: Automatically discovers and compiles <code>.proto</code> files from configurable directories</li>
<li><strong>Flexible Service Registration</strong>: Register and mock any gRPC service without hardcoding</li>
<li><strong>Streaming Support</strong>: Full support for unary, server streaming, client streaming, and bidirectional streaming</li>
<li><strong>Reflection Support</strong>: Built-in gRPC reflection for service discovery and testing</li>
<li><strong>Template Integration</strong>: Use MockForge‚Äôs template system for dynamic response generation</li>
<li><strong>Advanced Data Synthesis</strong>: Intelligent mock data generation with deterministic seeding, relationship awareness, and RAG-driven domain knowledge</li>
</ul>
<h2 id="quick-start-6"><a class="header" href="#quick-start-6">Quick Start</a></h2>
<h3 id="basic-grpc-server"><a class="header" href="#basic-grpc-server">Basic gRPC Server</a></h3>
<p>Start a gRPC mock server with default configuration:</p>
<pre><code class="language-bash"># Start with default proto directory (proto/)
mockforge serve --grpc-port 50051
</code></pre>
<h3 id="with-custom-proto-directory"><a class="header" href="#with-custom-proto-directory">With Custom Proto Directory</a></h3>
<pre><code class="language-bash"># Specify custom proto directory
MOCKFORGE_PROTO_DIR=my-protos mockforge serve --grpc-port 50051
</code></pre>
<h3 id="complete-example-1"><a class="header" href="#complete-example-1">Complete Example</a></h3>
<pre><code class="language-bash"># Start MockForge with HTTP, WebSocket, and gRPC support
MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true \
MOCKFORGE_WS_REPLAY_FILE=examples/ws-demo.jsonl \
MOCKFORGE_PROTO_DIR=examples/grpc-protos \
mockforge serve \
  --spec examples/openapi-demo.json \
  --http-port 3000 \
  --ws-port 3001 \
  --grpc-port 50051 \
  --admin --admin-port 9080
</code></pre>
<h2 id="proto-file-setup"><a class="header" href="#proto-file-setup">Proto File Setup</a></h2>
<h3 id="directory-structure-1"><a class="header" href="#directory-structure-1">Directory Structure</a></h3>
<p>MockForge automatically discovers <code>.proto</code> files in a configurable directory:</p>
<pre><code>your-project/
‚îú‚îÄ‚îÄ proto/                    # Default proto directory
‚îÇ   ‚îú‚îÄ‚îÄ user_service.proto   # Will be discovered
‚îÇ   ‚îú‚îÄ‚îÄ payment.proto        # Will be discovered
‚îÇ   ‚îî‚îÄ‚îÄ subdir/
‚îÇ       ‚îî‚îÄ‚îÄ analytics.proto  # Will be discovered (recursive)
‚îî‚îÄ‚îÄ examples/
    ‚îî‚îÄ‚îÄ grpc-protos/         # Custom proto directory
        ‚îî‚îÄ‚îÄ service.proto
</code></pre>
<h3 id="sample-proto-file"><a class="header" href="#sample-proto-file">Sample Proto File</a></h3>
<pre><code class="language-protobuf">syntax = "proto3";
package mockforge.user;

service UserService {
  rpc GetUser(GetUserRequest) returns (UserResponse);
  rpc ListUsers(ListUsersRequest) returns (stream UserResponse);
  rpc CreateUser(stream CreateUserRequest) returns (UserResponse);
  rpc Chat(stream ChatMessage) returns (stream ChatMessage);
}

message GetUserRequest {
  string user_id = 1;
}

message UserResponse {
  string user_id = 1;
  string name = 2;
  string email = 3;
  int64 created_at = 4;
  Status status = 5;
}

message ListUsersRequest {
  int32 limit = 1;
  string filter = 2;
}

message CreateUserRequest {
  string name = 1;
  string email = 2;
}

message ChatMessage {
  string user_id = 1;
  string content = 2;
  int64 timestamp = 3;
}

enum Status {
  UNKNOWN = 0;
  ACTIVE = 1;
  INACTIVE = 2;
  SUSPENDED = 3;
}
</code></pre>
<h2 id="dynamic-response-generation-1"><a class="header" href="#dynamic-response-generation-1">Dynamic Response Generation</a></h2>
<p>MockForge generates responses automatically based on your proto message schemas, with support for templates and custom logic.</p>
<h3 id="automatic-response-generation-1"><a class="header" href="#automatic-response-generation-1">Automatic Response Generation</a></h3>
<p>For basic use cases, MockForge generates responses from proto schemas:</p>
<ul>
<li><strong>Strings</strong>: Random realistic values</li>
<li><strong>Integers</strong>: Random numbers in appropriate ranges</li>
<li><strong>Timestamps</strong>: Current time or future dates</li>
<li><strong>Enums</strong>: Random valid enum values</li>
<li><strong>Messages</strong>: Nested objects with generated data</li>
<li><strong>Repeated fields</strong>: Arrays with multiple generated items</li>
</ul>
<h3 id="template-enhanced-responses-1"><a class="header" href="#template-enhanced-responses-1">Template-Enhanced Responses</a></h3>
<p>Use MockForge templates in proto comments for custom responses:</p>
<pre><code class="language-protobuf">message UserResponse {
  string user_id = 1; // {{uuid}}
  string name = 2; // {{request.user_id == "123" ? "John Doe" : "Jane Smith"}}
  string email = 3; // {{name | replace(" ", ".") | lower}}@example.com
  int64 created_at = 4; // {{now}}
  Status status = 5; // ACTIVE
}
</code></pre>
<h3 id="request-context-access"><a class="header" href="#request-context-access">Request Context Access</a></h3>
<p>Access request data in templates:</p>
<pre><code class="language-protobuf">message UserResponse {
  string user_id = 1; // {{request.user_id}}
  string requested_by = 2; // {{request.metadata.user_id}}
  string message = 3; // User {{request.user_id}} was retrieved
}
</code></pre>
<h2 id="testing-grpc-services"><a class="header" href="#testing-grpc-services">Testing gRPC Services</a></h2>
<h3 id="using-grpc-cli-tools"><a class="header" href="#using-grpc-cli-tools">Using gRPC CLI Tools</a></h3>
<h4 id="grpcurl-recommended"><a class="header" href="#grpcurl-recommended">grpcurl (Recommended)</a></h4>
<pre><code class="language-bash"># Install grpcurl
go install github.com/fullstorydev/grpcurl/cmd/grpcurl@latest

# List available services
grpcurl -plaintext localhost:50051 list

# Call a unary method
grpcurl -plaintext -d '{"user_id": "123"}' \
  localhost:50051 mockforge.user.UserService/GetUser

# Call a server streaming method
grpcurl -plaintext -d '{"limit": 5}' \
  localhost:50051 mockforge.user.UserService/ListUsers

# Call a client streaming method
echo '{"name": "Alice", "email": "alice@example.com"}' | \
grpcurl -plaintext -d @ \
  localhost:50051 mockforge.user.UserService/CreateUser
</code></pre>
<h4 id="grpcui-web-interface"><a class="header" href="#grpcui-web-interface">grpcui (Web Interface)</a></h4>
<pre><code class="language-bash"># Install grpcui
go install github.com/fullstorydev/grpcui/cmd/grpcui@latest

# Start web interface
grpcui -plaintext localhost:50051

# Open http://localhost:2633 in your browser
</code></pre>
<h3 id="programmatic-testing"><a class="header" href="#programmatic-testing">Programmatic Testing</a></h3>
<h4 id="nodejs-with-grpc-js"><a class="header" href="#nodejs-with-grpc-js">Node.js with grpc-js</a></h4>
<pre><code class="language-javascript">const grpc = require('@grpc/grpc-js');
const protoLoader = require('@grpc/proto-loader');

const packageDefinition = protoLoader.loadSync(
  'proto/user_service.proto',
  {
    keepCase: true,
    longs: String,
    enums: String,
    defaults: true,
    oneofs: true
  }
);

const protoDescriptor = grpc.loadPackageDefinition(packageDefinition);
const client = new protoDescriptor.mockforge.user.UserService(
  'localhost:50051',
  grpc.credentials.createInsecure()
);

// Unary call
client.GetUser({ user_id: '123' }, (error, response) =&gt; {
  if (error) {
    console.error('Error:', error);
  } else {
    console.log('Response:', response);
  }
});

// Server streaming
const stream = client.ListUsers({ limit: 5 });
stream.on('data', (response) =&gt; {
  console.log('User:', response);
});
stream.on('end', () =&gt; {
  console.log('Stream ended');
});
</code></pre>
<h4 id="python-with-grpcio"><a class="header" href="#python-with-grpcio">Python with grpcio</a></h4>
<pre><code class="language-python">import grpc
from user_service_pb2 import GetUserRequest
from user_service_pb2_grpc import UserServiceStub

channel = grpc.insecure_channel('localhost:50051')
stub = UserServiceStub(channel)

# Unary call
request = GetUserRequest(user_id='123')
response = stub.GetUser(request)
print(f"User: {response.name}, Email: {response.email}")

# Streaming
for user in stub.ListUsers(ListUsersRequest(limit=5)):
    print(f"User: {user.name}")
</code></pre>
<h2 id="advanced-configuration-2"><a class="header" href="#advanced-configuration-2">Advanced Configuration</a></h2>
<h3 id="custom-response-mappings"><a class="header" href="#custom-response-mappings">Custom Response Mappings</a></h3>
<p>Create custom response logic by implementing service handlers:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_grpc::{ServiceRegistry, ServiceImplementation};
use std::collections::HashMap;

struct CustomUserService {
    user_data: HashMap&lt;String, UserResponse&gt;,
}

impl ServiceImplementation for CustomUserService {
    fn handle_unary(&amp;self, method: &amp;str, request: &amp;[u8]) -&gt; Vec&lt;u8&gt; {
        match method {
            "GetUser" =&gt; {
                let req: GetUserRequest = prost::Message::decode(request).unwrap();
                let response = self.user_data.get(&amp;req.user_id)
                    .cloned()
                    .unwrap_or_else(|| UserResponse {
                        user_id: req.user_id,
                        name: "Unknown User".to_string(),
                        email: "unknown@example.com".to_string(),
                        created_at: std::time::SystemTime::now()
                            .duration_since(std::time::UNIX_EPOCH)
                            .unwrap().as_secs() as i64,
                        status: Status::Unknown as i32,
                    });
                let mut buf = Vec::new();
                response.encode(&amp;mut buf).unwrap();
                buf
            }
            _ =&gt; Vec::new(),
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="environment-variables-8"><a class="header" href="#environment-variables-8">Environment Variables</a></h3>
<pre><code class="language-bash"># Proto file configuration
MOCKFORGE_PROTO_DIR=proto/              # Directory containing .proto files
MOCKFORGE_GRPC_PORT=50051               # gRPC server port

# Service behavior
MOCKFORGE_GRPC_LATENCY_ENABLED=true     # Enable response latency
MOCKFORGE_GRPC_LATENCY_MIN_MS=10        # Minimum latency
MOCKFORGE_GRPC_LATENCY_MAX_MS=100       # Maximum latency

# Reflection settings
MOCKFORGE_GRPC_REFLECTION_ENABLED=true  # Enable gRPC reflection
</code></pre>
<h3 id="configuration-file-2"><a class="header" href="#configuration-file-2">Configuration File</a></h3>
<pre><code class="language-yaml">grpc:
  port: 50051
  proto_dir: "proto/"
  enable_reflection: true
  latency:
    enabled: true
    min_ms: 10
    max_ms: 100
  services:
    - name: "mockforge.user.UserService"
      implementation: "dynamic"
    - name: "custom.Service"
      implementation: "custom_handler"
</code></pre>
<h2 id="streaming-support"><a class="header" href="#streaming-support">Streaming Support</a></h2>
<p>MockForge supports all gRPC streaming patterns:</p>
<h3 id="unary-request--response"><a class="header" href="#unary-request--response">Unary (Request ‚Üí Response)</a></h3>
<pre><code class="language-protobuf">rpc GetUser(GetUserRequest) returns (UserResponse);
</code></pre>
<p>Standard request-response pattern used for simple operations.</p>
<h3 id="server-streaming-request--stream-of-responses"><a class="header" href="#server-streaming-request--stream-of-responses">Server Streaming (Request ‚Üí Stream of Responses)</a></h3>
<pre><code class="language-protobuf">rpc ListUsers(ListUsersRequest) returns (stream UserResponse);
</code></pre>
<p>Single request that returns multiple responses over time.</p>
<h3 id="client-streaming-stream-of-requests--response"><a class="header" href="#client-streaming-stream-of-requests--response">Client Streaming (Stream of Requests ‚Üí Response)</a></h3>
<pre><code class="language-protobuf">rpc CreateUsers(stream CreateUserRequest) returns (UserSummary);
</code></pre>
<p>Multiple requests sent as a stream, single response returned.</p>
<h3 id="bidirectional-streaming-stream--stream"><a class="header" href="#bidirectional-streaming-stream--stream">Bidirectional Streaming (Stream ‚Üî Stream)</a></h3>
<pre><code class="language-protobuf">rpc Chat(stream ChatMessage) returns (stream ChatMessage);
</code></pre>
<p>Both client and server can send messages independently.</p>
<h2 id="error-handling-1"><a class="header" href="#error-handling-1">Error Handling</a></h2>
<h3 id="grpc-status-codes"><a class="header" href="#grpc-status-codes">gRPC Status Codes</a></h3>
<p>MockForge supports all standard gRPC status codes:</p>
<pre><code class="language-protobuf">// In proto comments for custom error responses
rpc GetUser(GetUserRequest) returns (UserResponse);
// @error NOT_FOUND User not found
// @error INVALID_ARGUMENT Invalid user ID format
// @error INTERNAL Server error occurred
</code></pre>
<h3 id="custom-error-responses"><a class="header" href="#custom-error-responses">Custom Error Responses</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Custom error handling
fn handle_unary(&amp;self, method: &amp;str, request: &amp;[u8]) -&gt; Result&lt;Vec&lt;u8&gt;, tonic::Status&gt; {
    match method {
        "GetUser" =&gt; {
            let req: GetUserRequest = prost::Message::decode(request)?;

            if !is_valid_user_id(&amp;req.user_id) {
                return Err(tonic::Status::invalid_argument("Invalid user ID"));
            }

            match self.get_user(&amp;req.user_id) {
                Some(user) =&gt; {
                    let mut buf = Vec::new();
                    user.encode(&amp;mut buf)?;
                    Ok(buf)
                }
                None =&gt; Err(tonic::Status::not_found("User not found")),
            }
        }
        _ =&gt; Err(tonic::Status::unimplemented("Method not implemented")),
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="integration-patterns-1"><a class="header" href="#integration-patterns-1">Integration Patterns</a></h2>
<h3 id="microservices-testing-1"><a class="header" href="#microservices-testing-1">Microservices Testing</a></h3>
<pre><code class="language-bash"># Start multiple gRPC services
MOCKFORGE_PROTO_DIR=user-proto mockforge serve --grpc-port 50051 &amp;
MOCKFORGE_PROTO_DIR=payment-proto mockforge serve --grpc-port 50052 &amp;
MOCKFORGE_PROTO_DIR=inventory-proto mockforge serve --grpc-port 50053 &amp;

# Test service communication
grpcurl -plaintext localhost:50051 mockforge.user.UserService/GetUser \
  -d '{"user_id": "123"}'
</code></pre>
<h3 id="load-testing-2"><a class="header" href="#load-testing-2">Load Testing</a></h3>
<pre><code class="language-bash"># Simple load test with hey
hey -n 1000 -c 10 \
  grpcurl -plaintext -d '{"user_id": "123"}' \
    localhost:50051 mockforge.user.UserService/GetUser

# Advanced load testing with ghz
ghz --insecure \
    --proto proto/user_service.proto \
    --call mockforge.user.UserService.GetUser \
    --data '{"user_id": "123"}' \
    --concurrency 10 \
    --total 1000 \
    localhost:50051
</code></pre>
<h3 id="cicd-integration-5"><a class="header" href="#cicd-integration-5">CI/CD Integration</a></h3>
<pre><code class="language-yaml"># .github/workflows/test.yml
name: gRPC Tests
on: [push, pull_request]

jobs:
  grpc-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Setup Rust
        uses: actions-rust-lang/setup-rust-toolchain@v1
      - name: Start MockForge
        run: |
          cargo run --bin mockforge-cli -- serve --grpc-port 50051 &amp;
          sleep 5
      - name: Run gRPC Tests
        run: |
          npm install -g grpcurl
          grpcurl -plaintext localhost:50051 list
          # Add your test commands here
</code></pre>
<h2 id="best-practices-12"><a class="header" href="#best-practices-12">Best Practices</a></h2>
<h3 id="proto-file-organization"><a class="header" href="#proto-file-organization">Proto File Organization</a></h3>
<ol>
<li><strong>Clear Package Names</strong>: Use descriptive package names that reflect service domains</li>
<li><strong>Consistent Naming</strong>: Follow protobuf naming conventions</li>
<li><strong>Versioning</strong>: Include version information in package names when appropriate</li>
<li><strong>Documentation</strong>: Add comments to proto files for better API documentation</li>
</ol>
<h3 id="service-design"><a class="header" href="#service-design">Service Design</a></h3>
<ol>
<li><strong>Appropriate Streaming</strong>: Choose the right streaming pattern for your use case</li>
<li><strong>Error Handling</strong>: Define clear error conditions and status codes</li>
<li><strong>Pagination</strong>: Implement pagination for large result sets</li>
<li><strong>Backwards Compatibility</strong>: Design for evolution and backwards compatibility</li>
</ol>
<h3 id="testing-strategies"><a class="header" href="#testing-strategies">Testing Strategies</a></h3>
<ol>
<li><strong>Unit Tests</strong>: Test individual service methods</li>
<li><strong>Integration Tests</strong>: Test service interactions</li>
<li><strong>Load Tests</strong>: Verify performance under load</li>
<li><strong>Chaos Tests</strong>: Test failure scenarios and recovery</li>
</ol>
<h3 id="performance-optimization-2"><a class="header" href="#performance-optimization-2">Performance Optimization</a></h3>
<ol>
<li><strong>Response Caching</strong>: Cache frequently requested data</li>
<li><strong>Connection Pooling</strong>: Reuse gRPC connections</li>
<li><strong>Async Processing</strong>: Use async operations for I/O bound tasks</li>
<li><strong>Memory Management</strong>: Monitor and optimize memory usage</li>
</ol>
<h2 id="troubleshooting-25"><a class="header" href="#troubleshooting-25">Troubleshooting</a></h2>
<h3 id="common-issues-5"><a class="header" href="#common-issues-5">Common Issues</a></h3>
<p><strong>Proto files not found</strong>: Check <code>MOCKFORGE_PROTO_DIR</code> environment variable and directory permissions</p>
<p><strong>Service not available</strong>: Verify proto compilation succeeded and service names match</p>
<p><strong>Connection refused</strong>: Ensure gRPC port is accessible and not blocked by firewall</p>
<p><strong>Template errors</strong>: Check template syntax and available context variables</p>
<h3 id="debug-commands"><a class="header" href="#debug-commands">Debug Commands</a></h3>
<pre><code class="language-bash"># Check proto compilation
cargo build --verbose

# List available services
grpcurl -plaintext localhost:50051 list

# Check service methods
grpcurl -plaintext localhost:50051 describe mockforge.user.UserService

# Test with verbose output
grpcurl -plaintext -v -d '{"user_id": "123"}' \
  localhost:50051 mockforge.user.UserService/GetUser
</code></pre>
<h3 id="log-analysis"><a class="header" href="#log-analysis">Log Analysis</a></h3>
<pre><code class="language-bash"># View gRPC logs
tail -f mockforge.log | grep -i grpc

# Count requests by service
grep "grpc.*call" mockforge.log | cut -d' ' -f5 | sort | uniq -c

# Monitor errors
grep -i "grpc.*error" mockforge.log
</code></pre>
<p>For detailed implementation guides, see:</p>
<ul>
<li><a href="user-guide/grpc-mocking/protobuf.html">Protocol Buffers</a> - Working with .proto files</li>
<li><a href="user-guide/grpc-mocking/streaming.html">Streaming</a> - Advanced streaming patterns</li>
<li><a href="user-guide/grpc-mocking/advanced-data-synthesis.html">Advanced Data Synthesis</a> - Intelligent data generation with RAG and validation</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="protocol-buffers"><a class="header" href="#protocol-buffers">Protocol Buffers</a></h1>
<p>Protocol Buffers (protobuf) are the interface definition language used by gRPC services. MockForge provides comprehensive support for working with protobuf files, including automatic discovery, compilation, and dynamic service generation.</p>
<h2 id="understanding-proto-files"><a class="header" href="#understanding-proto-files">Understanding Proto Files</a></h2>
<h3 id="basic-structure"><a class="header" href="#basic-structure">Basic Structure</a></h3>
<p>A <code>.proto</code> file defines the service interface and message formats:</p>
<pre><code class="language-protobuf">syntax = "proto3";

package myapp.user;

import "google/protobuf/timestamp.proto";

// Service definition
service UserService {
  rpc GetUser(GetUserRequest) returns (User);
  rpc ListUsers(ListUsersRequest) returns (stream User);
  rpc CreateUser(CreateUserRequest) returns (User);
  rpc UpdateUser(UpdateUserRequest) returns (User);
  rpc DeleteUser(DeleteUserRequest) returns (google.protobuf.Empty);
}

// Message definitions
message GetUserRequest {
  string user_id = 1;
}

message User {
  string user_id = 1;
  string email = 2;
  string name = 3;
  google.protobuf.Timestamp created_at = 4;
  google.protobuf.Timestamp updated_at = 5;
  UserStatus status = 6;
  repeated string roles = 7;
}

message ListUsersRequest {
  int32 page_size = 1;
  string page_token = 2;
  string filter = 3;
}

message CreateUserRequest {
  string email = 1;
  string name = 2;
  repeated string roles = 3;
}

message UpdateUserRequest {
  string user_id = 1;
  string email = 2;
  string name = 3;
  repeated string roles = 4;
}

message DeleteUserRequest {
  string user_id = 1;
}

enum UserStatus {
  UNKNOWN = 0;
  ACTIVE = 1;
  INACTIVE = 2;
  SUSPENDED = 3;
}
</code></pre>
<h3 id="key-components"><a class="header" href="#key-components">Key Components</a></h3>
<h4 id="syntax-declaration"><a class="header" href="#syntax-declaration">Syntax Declaration</a></h4>
<pre><code class="language-protobuf">syntax = "proto3";
</code></pre>
<p>Declares the protobuf version. MockForge supports proto3.</p>
<h4 id="package-declaration"><a class="header" href="#package-declaration">Package Declaration</a></h4>
<pre><code class="language-protobuf">package myapp.user;
</code></pre>
<p>Defines the namespace for the service and messages.</p>
<h4 id="imports"><a class="header" href="#imports">Imports</a></h4>
<pre><code class="language-protobuf">import "google/protobuf/timestamp.proto";
</code></pre>
<p>Imports common protobuf types and other proto files.</p>
<h4 id="service-definition"><a class="header" href="#service-definition">Service Definition</a></h4>
<pre><code class="language-protobuf">service UserService {
  rpc GetUser(GetUserRequest) returns (User);
  // ... more methods
}
</code></pre>
<p>Defines the RPC methods available in the service.</p>
<h4 id="message-definitions"><a class="header" href="#message-definitions">Message Definitions</a></h4>
<pre><code class="language-protobuf">message User {
  string user_id = 1;
  string email = 2;
  // ... more fields
}
</code></pre>
<p>Defines the structure of data exchanged between client and server.</p>
<h4 id="enum-definitions"><a class="header" href="#enum-definitions">Enum Definitions</a></h4>
<pre><code class="language-protobuf">enum UserStatus {
  UNKNOWN = 0;
  ACTIVE = 1;
  // ... more values
}
</code></pre>
<p>Defines enumerated types with named constants.</p>
<h2 id="field-types"><a class="header" href="#field-types">Field Types</a></h2>
<h3 id="scalar-types"><a class="header" href="#scalar-types">Scalar Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Proto Type</th><th>Go Type</th><th>Java Type</th><th>C++ Type</th><th>Notes</th></tr></thead><tbody>
<tr><td>double</td><td>float64</td><td>double</td><td>double</td><td></td></tr>
<tr><td>float</td><td>float32</td><td>float</td><td>float</td><td></td></tr>
<tr><td>int32</td><td>int32</td><td>int</td><td>int32</td><td>Uses variable-length encoding</td></tr>
<tr><td>int64</td><td>int64</td><td>long</td><td>int64</td><td>Uses variable-length encoding</td></tr>
<tr><td>uint32</td><td>uint32</td><td>int</td><td>uint32</td><td>Uses variable-length encoding</td></tr>
<tr><td>uint64</td><td>uint64</td><td>long</td><td>uint64</td><td>Uses variable-length encoding</td></tr>
<tr><td>sint32</td><td>int32</td><td>int</td><td>int32</td><td>Uses zigzag encoding</td></tr>
<tr><td>sint64</td><td>int64</td><td>long</td><td>int64</td><td>Uses zigzag encoding</td></tr>
<tr><td>fixed32</td><td>uint32</td><td>int</td><td>uint32</td><td>Always 4 bytes</td></tr>
<tr><td>fixed64</td><td>uint64</td><td>long</td><td>uint64</td><td>Always 8 bytes</td></tr>
<tr><td>sfixed32</td><td>int32</td><td>int</td><td>int32</td><td>Always 4 bytes</td></tr>
<tr><td>sfixed64</td><td>int64</td><td>long</td><td>int64</td><td>Always 8 bytes</td></tr>
<tr><td>bool</td><td>bool</td><td>boolean</td><td>bool</td><td></td></tr>
<tr><td>string</td><td>string</td><td>String</td><td>string</td><td>UTF-8 encoded</td></tr>
<tr><td>bytes</td><td>[]byte</td><td>ByteString</td><td>string</td><td></td></tr>
</tbody></table>
</div>
<h3 id="repeated-fields"><a class="header" href="#repeated-fields">Repeated Fields</a></h3>
<pre><code class="language-protobuf">message SearchResponse {
  repeated Result results = 1;
}
</code></pre>
<p>Creates an array/list of the specified type.</p>
<h3 id="nested-messages"><a class="header" href="#nested-messages">Nested Messages</a></h3>
<pre><code class="language-protobuf">message Address {
  string street = 1;
  string city = 2;
  string country = 3;
}

message Person {
  string name = 1;
  Address address = 2;
}
</code></pre>
<p>Messages can contain other messages as fields.</p>
<h3 id="oneof-fields"><a class="header" href="#oneof-fields">Oneof Fields</a></h3>
<pre><code class="language-protobuf">message Person {
  string name = 1;
  oneof contact_info {
    string email = 2;
    string phone = 3;
  }
}
</code></pre>
<p>Only one of the specified fields can be set at a time.</p>
<h3 id="maps"><a class="header" href="#maps">Maps</a></h3>
<pre><code class="language-protobuf">message Config {
  map&lt;string, string&gt; settings = 1;
}
</code></pre>
<p>Creates a key-value map structure.</p>
<h2 id="service-patterns"><a class="header" href="#service-patterns">Service Patterns</a></h2>
<h3 id="unary-rpc"><a class="header" href="#unary-rpc">Unary RPC</a></h3>
<pre><code class="language-protobuf">service Calculator {
  rpc Add(AddRequest) returns (AddResponse);
}
</code></pre>
<p>Standard request-response pattern.</p>
<h3 id="server-streaming"><a class="header" href="#server-streaming">Server Streaming</a></h3>
<pre><code class="language-protobuf">service NotificationService {
  rpc Subscribe(SubscribeRequest) returns (stream Notification);
}
</code></pre>
<p>Server sends multiple responses for a single request.</p>
<h3 id="client-streaming"><a class="header" href="#client-streaming">Client Streaming</a></h3>
<pre><code class="language-protobuf">service UploadService {
  rpc Upload(stream UploadChunk) returns (UploadResponse);
}
</code></pre>
<p>Client sends multiple requests, server responds once.</p>
<h3 id="bidirectional-streaming"><a class="header" href="#bidirectional-streaming">Bidirectional Streaming</a></h3>
<pre><code class="language-protobuf">service ChatService {
  rpc Chat(stream ChatMessage) returns (stream ChatMessage);
}
</code></pre>
<p>Both client and server can send messages independently.</p>
<h2 id="proto-file-organization-1"><a class="header" href="#proto-file-organization-1">Proto File Organization</a></h2>
<h3 id="directory-structure-2"><a class="header" href="#directory-structure-2">Directory Structure</a></h3>
<pre><code>proto/
‚îú‚îÄ‚îÄ user/
‚îÇ   ‚îú‚îÄ‚îÄ v1/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ user.proto
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ user_service.proto
‚îÇ   ‚îî‚îÄ‚îÄ v2/
‚îÇ       ‚îú‚îÄ‚îÄ user.proto
‚îÇ       ‚îî‚îÄ‚îÄ user_service.proto
‚îú‚îÄ‚îÄ payment/
‚îÇ   ‚îú‚îÄ‚îÄ payment.proto
‚îÇ   ‚îî‚îÄ‚îÄ payment_service.proto
‚îî‚îÄ‚îÄ common/
    ‚îú‚îÄ‚îÄ types.proto
    ‚îî‚îÄ‚îÄ errors.proto
</code></pre>
<h3 id="versioning"><a class="header" href="#versioning">Versioning</a></h3>
<pre><code class="language-protobuf">// user/v1/user.proto
syntax = "proto3";
package myapp.user.v1;

// Version-specific message
message User {
  string id = 1;
  string name = 2;
  string email = 3;
}
</code></pre>
<pre><code class="language-protobuf">// user/v2/user.proto
syntax = "proto3";
package myapp.user.v2;

// Extended version with new fields
message User {
  string id = 1;
  string name = 2;
  string email = 3;
  string phone = 4;  // New field
  repeated string tags = 5;  // New field
}
</code></pre>
<h2 id="mockforge-integration"><a class="header" href="#mockforge-integration">MockForge Integration</a></h2>
<h3 id="automatic-discovery"><a class="header" href="#automatic-discovery">Automatic Discovery</a></h3>
<p>MockForge automatically discovers <code>.proto</code> files in the configured directory:</p>
<pre><code class="language-bash"># Default proto directory
mockforge serve --grpc-port 50051

# Custom proto directory
MOCKFORGE_PROTO_DIR=my-protos mockforge serve --grpc-port 50051
</code></pre>
<h3 id="service-registration"><a class="header" href="#service-registration">Service Registration</a></h3>
<p>MockForge automatically registers all discovered services:</p>
<pre><code class="language-bash"># List available services
grpcurl -plaintext localhost:50051 list

# Output:
# grpc.reflection.v1alpha.ServerReflection
# myapp.user.UserService
# myapp.payment.PaymentService
</code></pre>
<h3 id="dynamic-response-generation-2"><a class="header" href="#dynamic-response-generation-2">Dynamic Response Generation</a></h3>
<p>MockForge generates responses based on proto message schemas:</p>
<pre><code class="language-protobuf">message UserResponse {
  string user_id = 1;    // Generates UUID
  string name = 2;       // Generates random name
  string email = 3;      // Generates valid email
  int64 created_at = 4;  // Generates timestamp
  UserStatus status = 5; // Random enum value
}
</code></pre>
<h3 id="template-support"><a class="header" href="#template-support">Template Support</a></h3>
<p>Use MockForge templates for custom responses:</p>
<pre><code class="language-protobuf">message UserResponse {
  string user_id = 1;    // {{uuid}}
  string name = 2;       // {{request.user_id == "123" ? "John Doe" : "Jane Smith"}}
  string email = 3;      // {{name | replace(" ", ".") | lower}}@example.com
  int64 created_at = 4;  // {{now}}
  UserStatus status = 5; // ACTIVE
}
</code></pre>
<h2 id="best-practices-13"><a class="header" href="#best-practices-13">Best Practices</a></h2>
<h3 id="naming-conventions"><a class="header" href="#naming-conventions">Naming Conventions</a></h3>
<ol>
<li><strong>Packages</strong>: Use lowercase with dots (e.g., <code>myapp.user.v1</code>)</li>
<li><strong>Services</strong>: Use PascalCase with ‚ÄúService‚Äù suffix (e.g., <code>UserService</code>)</li>
<li><strong>Messages</strong>: Use PascalCase (e.g., <code>UserProfile</code>)</li>
<li><strong>Fields</strong>: Use snake_case (e.g., <code>user_id</code>, <code>created_at</code>)</li>
<li><strong>Enums</strong>: Use PascalCase for type, SCREAMING_SNAKE_CASE for values</li>
</ol>
<h3 id="field-numbering"><a class="header" href="#field-numbering">Field Numbering</a></h3>
<ol>
<li><strong>Reserve numbers</strong>: Don‚Äôt reuse field numbers from deleted fields</li>
<li><strong>Start from 1</strong>: Field numbers start from 1</li>
<li><strong>Gap for extensions</strong>: Leave gaps for future extensions</li>
<li><strong>Document reservations</strong>: Comment reserved field numbers</li>
</ol>
<pre><code class="language-protobuf">message User {
  string user_id = 1;
  string name = 2;
  string email = 3;
  // reserved 4, 5, 6;  // Reserved for future use
  int64 created_at = 7;
}
</code></pre>
<h3 id="import-organization"><a class="header" href="#import-organization">Import Organization</a></h3>
<ol>
<li><strong>Standard imports</strong>: Import well-known protobuf types first</li>
<li><strong>Local imports</strong>: Import project-specific proto files</li>
<li><strong>Relative paths</strong>: Use relative paths for local imports</li>
</ol>
<pre><code class="language-protobuf">syntax = "proto3";

import "google/protobuf/timestamp.proto";
import "google/protobuf/empty.proto";

import "common/types.proto";
import "user/profile.proto";

package myapp.user;
</code></pre>
<h3 id="documentation"><a class="header" href="#documentation">Documentation</a></h3>
<ol>
<li><strong>Service comments</strong>: Document what each service does</li>
<li><strong>Method comments</strong>: Explain each RPC method</li>
<li><strong>Field comments</strong>: Describe field purposes and constraints</li>
<li><strong>Enum comments</strong>: Document enum value meanings</li>
</ol>
<pre><code class="language-protobuf">// User management service
service UserService {
  // Get a user by ID
  rpc GetUser(GetUserRequest) returns (User);

  // List users with pagination
  rpc ListUsers(ListUsersRequest) returns (ListUsersResponse);
}

message User {
  string user_id = 1;  // Unique identifier for the user
  string email = 2;    // User's email address (must be valid)
  UserStatus status = 3; // Current account status
}

enum UserStatus {
  UNKNOWN = 0;   // Default value
  ACTIVE = 1;    // Account is active
  INACTIVE = 2;  // Account is deactivated
  SUSPENDED = 3; // Account is temporarily suspended
}
</code></pre>
<h2 id="migration-and-evolution"><a class="header" href="#migration-and-evolution">Migration and Evolution</a></h2>
<h3 id="adding-fields"><a class="header" href="#adding-fields">Adding Fields</a></h3>
<pre><code class="language-protobuf">// Original
message User {
  string user_id = 1;
  string name = 2;
}

// Extended (backwards compatible)
message User {
  string user_id = 1;
  string name = 2;
  string email = 3;      // New field
  bool active = 4;       // New field
}
</code></pre>
<h3 id="reserved-fields"><a class="header" href="#reserved-fields">Reserved Fields</a></h3>
<pre><code class="language-protobuf">message User {
  reserved 5, 6, 7;        // Reserved for future use
  reserved "old_field";    // Reserved field name

  string user_id = 1;
  string name = 2;
  string email = 3;
}
</code></pre>
<h3 id="versioning-strategy"><a class="header" href="#versioning-strategy">Versioning Strategy</a></h3>
<ol>
<li><strong>Package versioning</strong>: Include version in package name</li>
<li><strong>Service evolution</strong>: Extend services with new methods</li>
<li><strong>Deprecation notices</strong>: Mark deprecated fields</li>
<li><strong>Breaking changes</strong>: Create new service versions</li>
</ol>
<h2 id="validation"><a class="header" href="#validation">Validation</a></h2>
<h3 id="proto-file-validation"><a class="header" href="#proto-file-validation">Proto File Validation</a></h3>
<pre><code class="language-bash"># Validate proto syntax
protoc --proto_path=. --error_format=json myproto.proto

# Generate descriptors
protoc --proto_path=. --descriptor_set_out=descriptor.pb myproto.proto
</code></pre>
<h3 id="mockforge-integration-testing"><a class="header" href="#mockforge-integration-testing">MockForge Integration Testing</a></h3>
<pre><code class="language-bash"># Test proto compilation
MOCKFORGE_PROTO_DIR=my-protos cargo build

# Verify service discovery
mockforge serve --grpc-port 50051 &amp;
sleep 2
grpcurl -plaintext localhost:50051 list
</code></pre>
<h3 id="cross-language-compatibility"><a class="header" href="#cross-language-compatibility">Cross-Language Compatibility</a></h3>
<pre><code class="language-bash"># Generate code for multiple languages
protoc --proto_path=. \
  --go_out=. \
  --java_out=. \
  --python_out=. \
  --cpp_out=. \
  myproto.proto
</code></pre>
<h2 id="troubleshooting-26"><a class="header" href="#troubleshooting-26">Troubleshooting</a></h2>
<h3 id="common-proto-issues"><a class="header" href="#common-proto-issues">Common Proto Issues</a></h3>
<p><strong>Import resolution</strong>: Ensure all imported proto files are available in the proto path</p>
<p><strong>Field conflicts</strong>: Check for duplicate field numbers or names within messages</p>
<p><strong>Circular imports</strong>: Avoid circular dependencies between proto files</p>
<p><strong>Syntax errors</strong>: Use <code>protoc</code> to validate proto file syntax</p>
<h3 id="mockforge-specific-issues"><a class="header" href="#mockforge-specific-issues">MockForge-Specific Issues</a></h3>
<p><strong>Services not discovered</strong>: Check proto directory configuration and file permissions</p>
<p><strong>Invalid responses</strong>: Verify proto message definitions match expected schemas</p>
<p><strong>Compilation failures</strong>: Check for proto syntax errors and missing dependencies</p>
<p><strong>Template errors</strong>: Ensure template variables are properly escaped in proto comments</p>
<h3 id="debug-commands-1"><a class="header" href="#debug-commands-1">Debug Commands</a></h3>
<pre><code class="language-bash"># Check proto file discovery
find proto/ -name "*.proto" -type f

# Validate proto files
for file in $(find proto/ -name "*.proto"); do
  echo "Validating $file..."
  protoc --proto_path=. --error_format=json "$file" &gt; /dev/null
done

# Test service compilation
MOCKFORGE_PROTO_DIR=proto/ cargo check -p mockforge-grpc

# Inspect generated code
cargo doc --open --package mockforge-grpc
</code></pre>
<p>Protocol Buffers provide a robust foundation for gRPC service definitions. By following these guidelines and leveraging MockForge‚Äôs dynamic discovery capabilities, you can create well-structured, maintainable, and testable gRPC services.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="streaming"><a class="header" href="#streaming">Streaming</a></h1>
<p>gRPC supports four fundamental communication patterns, with three involving streaming. MockForge provides comprehensive support for all streaming patterns, enabling realistic testing of real-time and batch data scenarios.</p>
<h2 id="streaming-patterns"><a class="header" href="#streaming-patterns">Streaming Patterns</a></h2>
<h3 id="unary-request--response-1"><a class="header" href="#unary-request--response-1">Unary (Request ‚Üí Response)</a></h3>
<p>Standard request-response pattern - one message in, one message out.</p>
<h3 id="server-streaming-request--stream-of-responses-1"><a class="header" href="#server-streaming-request--stream-of-responses-1">Server Streaming (Request ‚Üí Stream of Responses)</a></h3>
<p>Single request initiates a stream of responses from server to client.</p>
<h3 id="client-streaming-stream-of-requests--response-1"><a class="header" href="#client-streaming-stream-of-requests--response-1">Client Streaming (Stream of Requests ‚Üí Response)</a></h3>
<p>Client sends multiple messages, server responds once with aggregated result.</p>
<h3 id="bidirectional-streaming-stream--stream-1"><a class="header" href="#bidirectional-streaming-stream--stream-1">Bidirectional Streaming (Stream ‚Üî Stream)</a></h3>
<p>Both client and server can send messages independently and simultaneously.</p>
<h2 id="server-streaming-1"><a class="header" href="#server-streaming-1">Server Streaming</a></h2>
<h3 id="basic-server-streaming"><a class="header" href="#basic-server-streaming">Basic Server Streaming</a></h3>
<pre><code class="language-protobuf">service NotificationService {
  rpc Subscribe(SubscribeRequest) returns (stream Notification);
}

message SubscribeRequest {
  repeated string topics = 1;
  SubscriptionType type = 2;
}

message Notification {
  string topic = 1;
  string message = 2;
  google.protobuf.Timestamp timestamp = 3;
  Severity severity = 4;
}

enum SubscriptionType {
  REALTIME = 0;
  BATCH = 1;
}

enum Severity {
  INFO = 0;
  WARNING = 1;
  ERROR = 2;
  CRITICAL = 3;
}
</code></pre>
<h3 id="mockforge-configuration"><a class="header" href="#mockforge-configuration">MockForge Configuration</a></h3>
<p>Server streaming generates multiple responses based on configuration:</p>
<pre><code class="language-jsonl">// Basic server streaming - fixed number of responses
{"ts":0,"dir":"out","text":"{\"topic\":\"system\",\"message\":\"Connected\",\"severity\":\"INFO\"}"}
{"ts":1000,"dir":"out","text":"{\"topic\":\"user\",\"message\":\"New user registered\",\"severity\":\"INFO\"}"}
{"ts":2000,"dir":"out","text":"{\"topic\":\"payment\",\"message\":\"Payment processed\",\"severity\":\"INFO\"}"}
{"ts":3000,"dir":"out","text":"{\"topic\":\"system\",\"message\":\"Maintenance scheduled\",\"severity\":\"WARNING\"}"}
</code></pre>
<h3 id="dynamic-server-streaming"><a class="header" href="#dynamic-server-streaming">Dynamic Server Streaming</a></h3>
<pre><code class="language-jsonl">// Template-based dynamic responses
{"ts":0,"dir":"out","text":"{\"topic\":\"{{request.topics[0]}}\",\"message\":\"Subscribed to {{request.topics.length}} topics\",\"timestamp\":\"{{now}}\"}"}
{"ts":1000,"dir":"out","text":"{\"topic\":\"{{randFromArray request.topics}}\",\"message\":\"{{randParagraph}}\",\"timestamp\":\"{{now}}\"}"}
{"ts":2000,"dir":"out","text":"{\"topic\":\"{{randFromArray request.topics}}\",\"message\":\"{{randSentence}}\",\"timestamp\":\"{{now}}\"}"}
{"ts":5000,"dir":"out","text":"{\"topic\":\"system\",\"message\":\"Stream ending\",\"timestamp\":\"{{now}}\"}"}
</code></pre>
<h3 id="testing-server-streaming"><a class="header" href="#testing-server-streaming">Testing Server Streaming</a></h3>
<h4 id="using-grpcurl"><a class="header" href="#using-grpcurl">Using grpcurl</a></h4>
<pre><code class="language-bash"># Test server streaming
grpcurl -plaintext -d '{"topics": ["user", "payment"], "type": "REALTIME"}' \
  localhost:50051 myapp.NotificationService/Subscribe
</code></pre>
<h4 id="using-nodejs"><a class="header" href="#using-nodejs">Using Node.js</a></h4>
<pre><code class="language-javascript">const grpc = require('@grpc/grpc-js');
const protoLoader = require('@grpc/proto-loader');

const packageDefinition = protoLoader.loadSync('proto/notification.proto');
const proto = grpc.loadPackageDefinition(packageDefinition);

const client = new proto.myapp.NotificationService(
  'localhost:50051',
  grpc.credentials.createInsecure()
);

const call = client.Subscribe({
  topics: ['user', 'payment'],
  type: 'REALTIME'
});

call.on('data', (notification) =&gt; {
  console.log('Notification:', notification);
});

call.on('end', () =&gt; {
  console.log('Stream ended');
});

call.on('error', (error) =&gt; {
  console.error('Error:', error);
});
</code></pre>
<h2 id="client-streaming-1"><a class="header" href="#client-streaming-1">Client Streaming</a></h2>
<h3 id="basic-client-streaming"><a class="header" href="#basic-client-streaming">Basic Client Streaming</a></h3>
<pre><code class="language-protobuf">service UploadService {
  rpc UploadFile(stream FileChunk) returns (UploadResponse);
}

message FileChunk {
  bytes data = 1;
  int32 sequence = 2;
  bool is_last = 3;
}

message UploadResponse {
  string file_id = 1;
  int64 total_size = 2;
  string checksum = 3;
  UploadStatus status = 4;
}

enum UploadStatus {
  SUCCESS = 0;
  FAILED = 1;
  PARTIAL = 2;
}
</code></pre>
<h3 id="mockforge-configuration-1"><a class="header" href="#mockforge-configuration-1">MockForge Configuration</a></h3>
<p>Client streaming processes multiple incoming messages and returns a single response:</p>
<pre><code class="language-jsonl">// Client streaming - processes multiple chunks
{"ts":0,"dir":"in","text":".*","response":"{\"file_id\":\"{{uuid}}\",\"total_size\":1024,\"status\":\"SUCCESS\"}"}
</code></pre>
<h3 id="advanced-client-streaming"><a class="header" href="#advanced-client-streaming">Advanced Client Streaming</a></h3>
<pre><code class="language-jsonl">// Process chunks and maintain state
{"ts":0,"dir":"in","text":"{\"sequence\":0}","response":"Chunk 0 received","state":"uploading","chunks":1}
{"ts":0,"dir":"in","text":"{\"sequence\":1}","response":"Chunk 1 received","chunks":"{{request.ws.state.chunks + 1}}"}
{"ts":0,"dir":"in","text":"{\"is_last\":true}","response":"{\"file_id\":\"{{uuid}}\",\"total_size\":\"{{request.ws.state.chunks * 1024}}\",\"status\":\"SUCCESS\"}"}
</code></pre>
<h3 id="testing-client-streaming"><a class="header" href="#testing-client-streaming">Testing Client Streaming</a></h3>
<h4 id="using-grpcurl-1"><a class="header" href="#using-grpcurl-1">Using grpcurl</a></h4>
<pre><code class="language-bash"># Send multiple messages for client streaming
echo '{"data": "chunk1", "sequence": 0}' | \
grpcurl -plaintext -d @ localhost:50051 myapp.UploadService/UploadFile

echo '{"data": "chunk2", "sequence": 1}' | \
grpcurl -plaintext -d @ localhost:50051 myapp.UploadService/UploadFile

echo '{"data": "chunk3", "sequence": 2, "is_last": true}' | \
grpcurl -plaintext -d @ localhost:50051 myapp.UploadService/UploadFile
</code></pre>
<h4 id="using-python-1"><a class="header" href="#using-python-1">Using Python</a></h4>
<pre><code class="language-python">import grpc
from upload_pb2 import FileChunk
from upload_pb2_grpc import UploadServiceStub

def generate_chunks():
    # Simulate file chunks
    chunks = [
        b"chunk1",
        b"chunk2",
        b"chunk3"
    ]

    for i, chunk in enumerate(chunks):
        yield FileChunk(
            data=chunk,
            sequence=i,
            is_last=(i == len(chunks) - 1)
        )

channel = grpc.insecure_channel('localhost:50051')
stub = UploadServiceStub(channel)

response = stub.UploadFile(generate_chunks())
print(f"Upload result: {response}")
</code></pre>
<h2 id="bidirectional-streaming-1"><a class="header" href="#bidirectional-streaming-1">Bidirectional Streaming</a></h2>
<h3 id="basic-bidirectional-streaming"><a class="header" href="#basic-bidirectional-streaming">Basic Bidirectional Streaming</a></h3>
<pre><code class="language-protobuf">service ChatService {
  rpc Chat(stream ChatMessage) returns (stream ChatMessage);
}

message ChatMessage {
  string user_id = 1;
  string content = 2;
  MessageType type = 3;
  google.protobuf.Timestamp timestamp = 4;
}

enum MessageType {
  TEXT = 0;
  JOIN = 1;
  LEAVE = 2;
  SYSTEM = 3;
}
</code></pre>
<h3 id="mockforge-configuration-2"><a class="header" href="#mockforge-configuration-2">MockForge Configuration</a></h3>
<p>Bidirectional streaming handles both incoming and outgoing messages:</p>
<pre><code class="language-jsonl">// Welcome message on connection
{"ts":0,"dir":"out","text":"{\"user_id\":\"system\",\"content\":\"Welcome to chat!\",\"type\":\"SYSTEM\"}"}

// Handle join messages
{"ts":0,"dir":"in","text":"{\"type\":\"JOIN\"}","response":"{\"user_id\":\"system\",\"content\":\"{{request.ws.message.user_id}} joined the chat\",\"type\":\"SYSTEM\"}"}

// Handle text messages
{"ts":0,"dir":"in","text":"{\"type\":\"TEXT\"}","response":"{\"user_id\":\"{{request.ws.message.user_id}}\",\"content\":\"{{request.ws.message.content}}\",\"type\":\"TEXT\"}"}

// Handle leave messages
{"ts":0,"dir":"in","text":"{\"type\":\"LEAVE\"}","response":"{\"user_id\":\"system\",\"content\":\"{{request.ws.message.user_id}} left the chat\",\"type\":\"SYSTEM\"}"}

// Periodic system messages
{"ts":30000,"dir":"out","text":"{\"user_id\":\"system\",\"content\":\"Server uptime: {{randInt 1 24}} hours\",\"type\":\"SYSTEM\"}"}
</code></pre>
<h3 id="advanced-bidirectional-patterns"><a class="header" href="#advanced-bidirectional-patterns">Advanced Bidirectional Patterns</a></h3>
<pre><code class="language-jsonl">// State-aware responses
{"ts":0,"dir":"in","text":".*","condition":"{{!request.ws.state.authenticated}}","response":"Please authenticate first"}
{"ts":0,"dir":"in","text":"AUTH","response":"Authenticated","state":"authenticated"}

{"ts":0,"dir":"in","text":".*","condition":"{{request.ws.state.authenticated}}","response":"{{request.ws.message}}"}

{"ts":0,"dir":"in","text":"HELP","response":"Available commands: MSG, QUIT, STATUS"}
{"ts":0,"dir":"in","text":"STATUS","response":"Connected users: {{randInt 1 50}}"}
{"ts":0,"dir":"in","text":"QUIT","response":"Goodbye!","close":true}
</code></pre>
<h3 id="testing-bidirectional-streaming"><a class="header" href="#testing-bidirectional-streaming">Testing Bidirectional Streaming</a></h3>
<h4 id="using-nodejs-1"><a class="header" href="#using-nodejs-1">Using Node.js</a></h4>
<pre><code class="language-javascript">const grpc = require('@grpc/grpc-js');
const protoLoader = require('@grpc/proto-loader');

const packageDefinition = protoLoader.loadSync('proto/chat.proto');
const proto = grpc.loadPackageDefinition(packageDefinition);

const client = new proto.myapp.ChatService(
  'localhost:50051',
  grpc.credentials.createInsecure()
);

const call = client.Chat();

// Handle incoming messages
call.on('data', (message) =&gt; {
  console.log('Received:', message);
});

// Send messages
setInterval(() =&gt; {
  call.write({
    user_id: 'user123',
    content: 'Hello from client',
    type: 'TEXT'
  });
}, 2000);

// Send join message
call.write({
  user_id: 'user123',
  content: 'Joined chat',
  type: 'JOIN'
});

// Handle stream end
call.on('end', () =&gt; {
  console.log('Stream ended');
});

// Close after 30 seconds
setTimeout(() =&gt; {
  call.write({
    user_id: 'user123',
    content: 'Leaving chat',
    type: 'LEAVE'
  });
  call.end();
}, 30000);
</code></pre>
<h2 id="streaming-configuration"><a class="header" href="#streaming-configuration">Streaming Configuration</a></h2>
<h3 id="environment-variables-9"><a class="header" href="#environment-variables-9">Environment Variables</a></h3>
<pre><code class="language-bash"># Streaming behavior
MOCKFORGE_GRPC_STREAM_TIMEOUT=30000        # Stream timeout in ms
MOCKFORGE_GRPC_MAX_STREAM_MESSAGES=1000    # Max messages per stream
MOCKFORGE_GRPC_STREAM_BUFFER_SIZE=1024     # Buffer size for streaming

# Response timing
MOCKFORGE_GRPC_LATENCY_MIN_MS=10          # Minimum response latency
MOCKFORGE_GRPC_LATENCY_MAX_MS=100         # Maximum response latency
</code></pre>
<h3 id="stream-control-templates"><a class="header" href="#stream-control-templates">Stream Control Templates</a></h3>
<pre><code class="language-jsonl">// Conditional streaming
{"ts":0,"dir":"out","text":"Starting stream","condition":"{{request.stream_enabled}}"}
{"ts":1000,"dir":"out","text":"Stream data","condition":"{{request.ws.state.active}}"}
{"ts":0,"dir":"out","text":"Stream ended","condition":"{{request.ws.message.type === 'END'}}","close":true}

// Dynamic intervals
{"ts":"{{randInt 1000 5000}}","dir":"out","text":"Random interval message"}
{"ts":"{{request.interval || 2000}}","dir":"out","text":"Custom interval message"}
</code></pre>
<h2 id="performance-considerations-1"><a class="header" href="#performance-considerations-1">Performance Considerations</a></h2>
<h3 id="memory-management"><a class="header" href="#memory-management">Memory Management</a></h3>
<pre><code class="language-jsonl">// Limit message history
{"ts":0,"dir":"in","text":".*","condition":"{{(request.ws.state.messageCount || 0) &lt; 100}}","response":"Message received","messageCount":"{{(request.ws.state.messageCount || 0) + 1}}"}
{"ts":0,"dir":"in","text":".*","condition":"{{(request.ws.state.messageCount || 0) &gt;= 100}}","response":"Message limit reached"}
</code></pre>
<h3 id="connection-limits-1"><a class="header" href="#connection-limits-1">Connection Limits</a></h3>
<pre><code class="language-jsonl">// Global connection tracking (requires custom implementation)
{"ts":0,"dir":"out","text":"Connection {{request.ws.connectionId}} established"}
{"ts":300000,"dir":"out","text":"Connection timeout","close":true}
</code></pre>
<h3 id="load-balancing"><a class="header" href="#load-balancing">Load Balancing</a></h3>
<pre><code class="language-jsonl">// Simulate load balancer behavior
{"ts":"{{randInt 100 1000}}","dir":"out","text":"Response from server {{randInt 1 3}}"}
{"ts":"{{randInt 2000 5000}}","dir":"out","text":"Health check from server {{randInt 1 3}}"}
</code></pre>
<h2 id="error-handling-in-streams"><a class="header" href="#error-handling-in-streams">Error Handling in Streams</a></h2>
<h3 id="stream-errors"><a class="header" href="#stream-errors">Stream Errors</a></h3>
<pre><code class="language-jsonl">// Handle invalid messages
{"ts":0,"dir":"in","text":"","response":"Empty message not allowed"}
{"ts":0,"dir":"in","text":".{500,}","response":"Message too long (max 500 chars)"}

// Simulate network errors
{"ts":5000,"dir":"out","text":"Network error occurred","error":true,"close":true}
</code></pre>
<h3 id="recovery-patterns"><a class="header" href="#recovery-patterns">Recovery Patterns</a></h3>
<pre><code class="language-jsonl">// Automatic reconnection
{"ts":0,"dir":"out","text":"Connection lost, attempting reconnect..."}
{"ts":2000,"dir":"out","text":"Reconnected successfully"}
{"ts":100,"dir":"out","text":"Resuming stream from message {{request.ws.state.lastMessageId}}"}
</code></pre>
<h2 id="testing-strategies-1"><a class="header" href="#testing-strategies-1">Testing Strategies</a></h2>
<h3 id="unit-testing-streams"><a class="header" href="#unit-testing-streams">Unit Testing Streams</a></h3>
<pre><code class="language-javascript">// test-streaming.js
const { expect } = require('chai');

describe('gRPC Streaming', () =&gt; {
  it('should handle server streaming', (done) =&gt; {
    const call = client.subscribeNotifications({ topics: ['test'] });

    let messageCount = 0;
    call.on('data', (notification) =&gt; {
      messageCount++;
      expect(notification).to.have.property('topic');
      expect(notification).to.have.property('message');
    });

    call.on('end', () =&gt; {
      expect(messageCount).to.be.greaterThan(0);
      done();
    });

    // End test after 5 seconds
    setTimeout(() =&gt; call.cancel(), 5000);
  });

  it('should handle client streaming', (done) =&gt; {
    const call = client.uploadFile((error, response) =&gt; {
      expect(error).to.be.null;
      expect(response).to.have.property('file_id');
      expect(response.status).to.equal('SUCCESS');
      done();
    });

    // Send test chunks
    call.write({ data: Buffer.from('test'), sequence: 0 });
    call.write({ data: Buffer.from('data'), sequence: 1, is_last: true });
    call.end();
  });
});
</code></pre>
<h3 id="load-testing-3"><a class="header" href="#load-testing-3">Load Testing</a></h3>
<pre><code class="language-bash">#!/bin/bash
# load-test-streams.sh

CONCURRENT_STREAMS=10
DURATION=60

echo "Load testing $CONCURRENT_STREAMS concurrent streams for ${DURATION}s"

for i in $(seq 1 $CONCURRENT_STREAMS); do
  node stream-client.js &amp;
done

# Wait for test duration
sleep $DURATION

# Kill all clients
pkill -f stream-client.js

echo "Load test completed"
</code></pre>
<h2 id="best-practices-14"><a class="header" href="#best-practices-14">Best Practices</a></h2>
<h3 id="stream-design"><a class="header" href="#stream-design">Stream Design</a></h3>
<ol>
<li><strong>Appropriate Patterns</strong>: Choose the right streaming pattern for your use case</li>
<li><strong>Message Size</strong>: Keep individual messages reasonably sized</li>
<li><strong>Heartbeat Messages</strong>: Include periodic keepalive messages for long-running streams</li>
<li><strong>Error Recovery</strong>: Implement proper error handling and recovery mechanisms</li>
</ol>
<h3 id="performance-optimization-3"><a class="header" href="#performance-optimization-3">Performance Optimization</a></h3>
<ol>
<li><strong>Buffering</strong>: Use appropriate buffer sizes for your throughput requirements</li>
<li><strong>Compression</strong>: Enable compression for large message streams</li>
<li><strong>Connection Reuse</strong>: Reuse connections when possible</li>
<li><strong>Resource Limits</strong>: Set appropriate limits on concurrent streams and message rates</li>
</ol>
<h3 id="monitoring-and-debugging"><a class="header" href="#monitoring-and-debugging">Monitoring and Debugging</a></h3>
<ol>
<li><strong>Stream Metrics</strong>: Monitor stream duration, message counts, and error rates</li>
<li><strong>Logging</strong>: Enable detailed logging for debugging streaming issues</li>
<li><strong>Tracing</strong>: Implement request tracing across stream messages</li>
<li><strong>Health Checks</strong>: Regular health checks for long-running streams</li>
</ol>
<h3 id="client-compatibility"><a class="header" href="#client-compatibility">Client Compatibility</a></h3>
<ol>
<li><strong>Protocol Versions</strong>: Ensure compatibility with different gRPC versions</li>
<li><strong>Language Support</strong>: Test with multiple client language implementations</li>
<li><strong>Network Conditions</strong>: Test under various network conditions (latency, packet loss)</li>
<li><strong>Browser Support</strong>: Consider WebSocket fallback for web clients</li>
</ol>
<h2 id="troubleshooting-27"><a class="header" href="#troubleshooting-27">Troubleshooting</a></h2>
<h3 id="common-streaming-issues"><a class="header" href="#common-streaming-issues">Common Streaming Issues</a></h3>
<p><strong>Stream doesn‚Äôt start</strong>: Check proto file definitions and service registration</p>
<p><strong>Messages not received</strong>: Verify message encoding and template syntax</p>
<p><strong>Stream hangs</strong>: Check for proper stream termination and timeout settings</p>
<p><strong>Performance degradation</strong>: Monitor resource usage and adjust buffer sizes</p>
<p><strong>Client disconnects</strong>: Implement proper heartbeat and reconnection logic</p>
<h3 id="debug-commands-2"><a class="header" href="#debug-commands-2">Debug Commands</a></h3>
<pre><code class="language-bash"># Monitor active streams
grpcurl -plaintext localhost:50051 list

# Check stream status
netstat -tlnp | grep :50051

# View stream logs
tail -f mockforge.log | grep -E "(stream|grpc)"

# Test basic connectivity
grpcurl -plaintext localhost:50051 grpc.reflection.v1alpha.ServerReflection/ServerReflectionInfo
</code></pre>
<h3 id="performance-profiling"><a class="header" href="#performance-profiling">Performance Profiling</a></h3>
<pre><code class="language-bash"># Profile gRPC performance
cargo flamegraph --bin mockforge-cli -- serve --grpc-port 50051

# Monitor system resources
htop -p $(pgrep mockforge)

# Network monitoring
iftop -i lo
</code></pre>
<p>Streaming patterns enable powerful real-time communication scenarios. MockForge‚Äôs comprehensive streaming support allows you to create sophisticated mock environments that accurately simulate production streaming services for thorough testing and development.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="advanced-data-synthesis"><a class="header" href="#advanced-data-synthesis">Advanced Data Synthesis</a></h1>
<p>MockForge provides sophisticated data synthesis capabilities that go beyond simple random data generation. The advanced data synthesis system combines intelligent field inference, deterministic seeding, relationship-aware generation, and cross-endpoint validation to create realistic, coherent, and reproducible test data.</p>
<h2 id="overview-7"><a class="header" href="#overview-7">Overview</a></h2>
<p>The advanced data synthesis system consists of four main components:</p>
<ol>
<li><strong>Smart Mock Generator</strong> - Intelligent field-based mock data generation with deterministic seeding</li>
<li><strong>Schema Graph Extraction</strong> - Automatic discovery of relationships from protobuf schemas</li>
<li><strong>RAG-Driven Synthesis</strong> - Domain-aware data generation using Retrieval-Augmented Generation</li>
<li><strong>Validation Framework</strong> - Cross-endpoint consistency and integrity validation</li>
</ol>
<p>These components work together to provide enterprise-grade test data generation that maintains referential integrity across your entire gRPC service ecosystem.</p>
<h2 id="smart-mock-generator"><a class="header" href="#smart-mock-generator">Smart Mock Generator</a></h2>
<p>The Smart Mock Generator provides intelligent mock data generation based on field names, types, and patterns. It automatically detects the intent behind field names and generates appropriate realistic data.</p>
<h3 id="field-name-intelligence"><a class="header" href="#field-name-intelligence">Field Name Intelligence</a></h3>
<p>The generator automatically infers appropriate data types based on field names:</p>
<div class="table-wrapper"><table><thead><tr><th>Field Pattern</th><th>Generated Data Type</th><th>Example Values</th></tr></thead><tbody>
<tr><td><code>email</code>, <code>email_address</code></td><td>Realistic email addresses</td><td><code>user@example.com</code>, <code>alice.smith@company.org</code></td></tr>
<tr><td><code>phone</code>, <code>mobile</code>, <code>phone_number</code></td><td>Formatted phone numbers</td><td><code>+1-555-0123</code>, <code>(555) 123-4567</code></td></tr>
<tr><td><code>id</code>, <code>user_id</code>, <code>order_id</code></td><td>Sequential or UUID-based IDs</td><td><code>user_001</code>, <code>550e8400-e29b-41d4-a716-446655440000</code></td></tr>
<tr><td><code>name</code>, <code>first_name</code>, <code>last_name</code></td><td>Realistic names</td><td><code>John Doe</code>, <code>Alice</code>, <code>Johnson</code></td></tr>
<tr><td><code>created_at</code>, <code>updated_at</code>, <code>timestamp</code></td><td>ISO timestamps</td><td><code>2023-10-15T14:30:00Z</code></td></tr>
<tr><td><code>latitude</code>, <code>longitude</code></td><td>Geographic coordinates</td><td><code>40.7128</code>, <code>-74.0060</code></td></tr>
<tr><td><code>url</code>, <code>website</code></td><td>Valid URLs</td><td><code>https://example.com</code></td></tr>
<tr><td><code>token</code>, <code>api_key</code></td><td>Security tokens</td><td><code>sk_live_4eC39HqLyjWDarjtT1zdp7dc</code></td></tr>
</tbody></table>
</div>
<h3 id="deterministic-generation"><a class="header" href="#deterministic-generation">Deterministic Generation</a></h3>
<p>For reproducible test fixtures, the Smart Mock Generator supports deterministic seeding:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_grpc::reflection::smart_mock_generator::{SmartMockGenerator, SmartMockConfig};

// Create a deterministic generator with a fixed seed
let mut generator = SmartMockGenerator::new_with_seed(
    SmartMockConfig::default(),
    12345 // seed value
);

// Generate reproducible data
let uuid1 = generator.generate_uuid();
let email = generator.generate_random_string(10);

// Reset to regenerate same data
generator.reset();
let uuid2 = generator.generate_uuid(); // Same as uuid1
<span class="boring">}</span></code></pre></pre>
<p>This ensures that your tests produce consistent results across different runs and environments.</p>
<h2 id="schema-graph-extraction"><a class="header" href="#schema-graph-extraction">Schema Graph Extraction</a></h2>
<p>The schema graph extraction system analyzes your protobuf definitions to automatically discover relationships and foreign key patterns between entities.</p>
<h3 id="foreign-key-detection"><a class="header" href="#foreign-key-detection">Foreign Key Detection</a></h3>
<p>The system uses naming conventions to detect foreign key relationships:</p>
<pre><code class="language-protobuf">message Order {
  string id = 1;
  string user_id = 2;     // ‚Üí Detected as foreign key to User
  string customer_ref = 3; // ‚Üí Detected as reference to Customer  
  int64 timestamp = 4;
}

message User {
  string id = 1;          // ‚Üí Detected as primary key
  string name = 2;
  string email = 3;
}
</code></pre>
<p><strong>Common Foreign Key Patterns:</strong></p>
<ul>
<li><code>user_id</code> ‚Üí references <code>User</code> entity</li>
<li><code>orderId</code> ‚Üí references <code>Order</code> entity</li>
<li><code>customer_ref</code> ‚Üí references <code>Customer</code> entity</li>
</ul>
<h3 id="relationship-types"><a class="header" href="#relationship-types">Relationship Types</a></h3>
<p>The system identifies various relationship types:</p>
<ul>
<li><strong>Foreign Key</strong>: Direct ID references (<code>user_id</code> ‚Üí <code>User</code>)</li>
<li><strong>Embedded</strong>: Nested message types within other messages</li>
<li><strong>One-to-Many</strong>: Repeated field relationships</li>
<li><strong>Composition</strong>: Ownership relationships between entities</li>
</ul>
<h2 id="rag-driven-data-synthesis"><a class="header" href="#rag-driven-data-synthesis">RAG-Driven Data Synthesis</a></h2>
<p>RAG (Retrieval-Augmented Generation) enables context-aware data generation using domain knowledge from documentation, examples, and business rules.</p>
<h3 id="configuration-6"><a class="header" href="#configuration-6">Configuration</a></h3>
<pre><code class="language-yaml">grpc:
  data_synthesis:
    rag:
      enabled: true
      api_endpoint: "https://api.openai.com/v1/chat/completions"
      model: "gpt-3.5-turbo" 
      embedding_model: "text-embedding-ada-002"
      similarity_threshold: 0.7
      max_documents: 5
    context_sources:
      - id: "user_docs"
        type: "documentation"
        path: "./docs/user_guide.md"
        weight: 1.0
      - id: "examples"
        type: "examples"
        path: "./examples/sample_data.json" 
        weight: 0.8
</code></pre>
<h3 id="business-rule-extraction"><a class="header" href="#business-rule-extraction">Business Rule Extraction</a></h3>
<p>The RAG system automatically extracts business rules from your documentation:</p>
<ul>
<li><strong>Email Validation</strong>: ‚ÄúEmail fields must follow valid email format‚Äù</li>
<li><strong>Phone Formatting</strong>: ‚ÄúPhone numbers should be in international format‚Äù</li>
<li><strong>ID Requirements</strong>: ‚ÄúUser IDs must be alphanumeric and 8 characters long‚Äù</li>
<li><strong>Relationship Constraints</strong>: ‚ÄúOrders must reference valid existing users‚Äù</li>
</ul>
<h3 id="domain-aware-generation"><a class="header" href="#domain-aware-generation">Domain-Aware Generation</a></h3>
<p>Instead of generic random data, RAG generates contextually appropriate values:</p>
<pre><code class="language-protobuf">message User {
  string role = 1; // Context: "admin", "user", "moderator" 
  string department = 2; // Context: "engineering", "marketing", "sales"
  string location = 3; // Context: "San Francisco", "New York", "London"
}
</code></pre>
<h2 id="cross-endpoint-validation"><a class="header" href="#cross-endpoint-validation">Cross-Endpoint Validation</a></h2>
<p>The validation framework ensures data coherence across different endpoints and validates referential integrity.</p>
<h3 id="validation-rules"><a class="header" href="#validation-rules">Validation Rules</a></h3>
<p>The framework supports multiple types of validation rules:</p>
<p><strong>Built-in Validations:</strong></p>
<ul>
<li>Foreign key existence validation</li>
<li>Field format validation (email, phone, URL)</li>
<li>Range validation for numeric fields</li>
<li>Unique constraint validation</li>
</ul>
<p><strong>Custom Validation Rules:</strong></p>
<pre><code class="language-yaml">grpc:
  data_synthesis:
    validation:
      enabled: true
      strict_mode: false
      custom_rules:
        - name: "email_format"
          applies_to: ["User", "Customer"]
          fields: ["email"]
          type: "format"
          pattern: "^[^@\\s]+@[^@\\s]+\\.[^@\\s]+$"
          error: "Invalid email format"
        - name: "age_range" 
          applies_to: ["User"]
          fields: ["age"]
          type: "range"
          min: 0
          max: 120
          error: "Age must be between 0 and 120"
</code></pre>
<h3 id="referential-integrity"><a class="header" href="#referential-integrity">Referential Integrity</a></h3>
<p>The validator automatically checks that:</p>
<ul>
<li>Foreign key references point to existing entities</li>
<li>Required relationships are satisfied</li>
<li>Cross-service data dependencies are maintained</li>
<li>Business constraints are enforced</li>
</ul>
<h2 id="configuration-7"><a class="header" href="#configuration-7">Configuration</a></h2>
<h3 id="environment-variables-10"><a class="header" href="#environment-variables-10">Environment Variables</a></h3>
<pre><code class="language-bash"># Enable advanced data synthesis
MOCKFORGE_DATA_SYNTHESIS_ENABLED=true

# Deterministic generation  
MOCKFORGE_DATA_SYNTHESIS_SEED=12345
MOCKFORGE_DATA_SYNTHESIS_DETERMINISTIC=true

# RAG configuration
MOCKFORGE_RAG_ENABLED=true
MOCKFORGE_RAG_API_KEY=your-api-key
MOCKFORGE_RAG_MODEL=gpt-3.5-turbo

# Validation settings
MOCKFORGE_VALIDATION_ENABLED=true
MOCKFORGE_VALIDATION_STRICT_MODE=false
</code></pre>
<h3 id="configuration-file-3"><a class="header" href="#configuration-file-3">Configuration File</a></h3>
<pre><code class="language-yaml">grpc:
  port: 50051
  proto_dir: "proto/"
  data_synthesis:
    enabled: true
    smart_generator:
      field_inference: true
      use_faker: true
      deterministic: true
      seed: 42
      max_depth: 5
    rag:
      enabled: true
      api_endpoint: "https://api.openai.com/v1/chat/completions"
      api_key: "${RAG_API_KEY}"
      model: "gpt-3.5-turbo"
      embedding_model: "text-embedding-ada-002"  
      similarity_threshold: 0.7
      max_context_length: 2000
      cache_contexts: true
    validation:
      enabled: true
      strict_mode: false
      max_validation_depth: 3
      cache_results: true
    schema_extraction:
      extract_relationships: true
      detect_foreign_keys: true
      confidence_threshold: 0.8
</code></pre>
<h2 id="example-usage-1"><a class="header" href="#example-usage-1">Example Usage</a></h2>
<h3 id="basic-smart-generation"><a class="header" href="#basic-smart-generation">Basic Smart Generation</a></h3>
<pre><code class="language-bash"># Start MockForge with advanced data synthesis
MOCKFORGE_DATA_SYNTHESIS_ENABLED=true \
MOCKFORGE_DATA_SYNTHESIS_SEED=12345 \
mockforge serve --grpc-port 50051
</code></pre>
<h3 id="with-rag-enhancement"><a class="header" href="#with-rag-enhancement">With RAG Enhancement</a></h3>
<pre><code class="language-bash"># Start with RAG-powered domain awareness
MOCKFORGE_DATA_SYNTHESIS_ENABLED=true \
MOCKFORGE_RAG_ENABLED=true \
MOCKFORGE_RAG_API_KEY=your-api-key \
MOCKFORGE_VALIDATION_ENABLED=true \
mockforge serve --grpc-port 50051
</code></pre>
<h3 id="testing-deterministic-generation"><a class="header" href="#testing-deterministic-generation">Testing Deterministic Generation</a></h3>
<pre><code class="language-bash"># Generate data twice with same seed - should be identical
grpcurl -plaintext -d '{"user_id": "123"}' \
  localhost:50051 com.example.UserService/GetUser

# Reset and call again - will generate same response
grpcurl -plaintext -d '{"user_id": "123"}' \
  localhost:50051 com.example.UserService/GetUser
</code></pre>
<h2 id="best-practices-15"><a class="header" href="#best-practices-15">Best Practices</a></h2>
<h3 id="deterministic-testing"><a class="header" href="#deterministic-testing">Deterministic Testing</a></h3>
<ul>
<li>Use fixed seeds in CI/CD pipelines for reproducible tests</li>
<li>Reset generators between test cases for consistency</li>
<li>Document seed values used in critical test scenarios</li>
</ul>
<h3 id="schema-design-for-synthesis"><a class="header" href="#schema-design-for-synthesis">Schema Design for Synthesis</a></h3>
<ul>
<li>Use consistent naming conventions for foreign keys (<code>user_id</code>, <code>customer_ref</code>)</li>
<li>Add comments to proto files describing business rules</li>
<li>Consider field naming that indicates data type (<code>email_address</code> vs <code>contact</code>)</li>
</ul>
<h3 id="rag-integration"><a class="header" href="#rag-integration">RAG Integration</a></h3>
<ul>
<li>Provide high-quality domain documentation as context sources</li>
<li>Use specific, actionable descriptions in documentation</li>
<li>Monitor API costs and implement appropriate caching</li>
</ul>
<h3 id="validation-strategy"><a class="header" href="#validation-strategy">Validation Strategy</a></h3>
<ul>
<li>Start with lenient validation and gradually add stricter rules</li>
<li>Use warnings for potential issues, errors for critical problems</li>
<li>Provide helpful error messages with suggested fixes</li>
</ul>
<h2 id="advanced-scenarios"><a class="header" href="#advanced-scenarios">Advanced Scenarios</a></h2>
<h3 id="multi-service-data-coherence"><a class="header" href="#multi-service-data-coherence">Multi-Service Data Coherence</a></h3>
<p>When mocking multiple related gRPC services, ensure data coherence:</p>
<pre><code class="language-bash"># Start user service
MOCKFORGE_DATA_SYNTHESIS_SEED=100 \
mockforge serve --grpc-port 50051 --proto-dir user-proto &amp;

# Start order service with same seed for consistency  
MOCKFORGE_DATA_SYNTHESIS_SEED=100 \
mockforge serve --grpc-port 50052 --proto-dir order-proto &amp;
</code></pre>
<h3 id="custom-field-overrides"><a class="header" href="#custom-field-overrides">Custom Field Overrides</a></h3>
<p>Override specific fields with custom values:</p>
<pre><code class="language-yaml">grpc:
  data_synthesis:
    field_overrides:
      "admin_email": "admin@company.com"
      "api_version": "v2.1"
      "environment": "testing"
</code></pre>
<h3 id="business-rule-templates"><a class="header" href="#business-rule-templates">Business Rule Templates</a></h3>
<p>Define reusable business rule templates:</p>
<pre><code class="language-yaml">grpc:
  data_synthesis:
    rule_templates:
      - name: "financial_data"
        applies_to: ["Invoice", "Payment", "Transaction"]
        rules:
          - field_pattern: "*_amount"
            type: "range" 
            min: 0.01
            max: 10000.00
          - field_pattern: "*_currency"
            type: "enum"
            values: ["USD", "EUR", "GBP"]
</code></pre>
<h2 id="troubleshooting-28"><a class="header" href="#troubleshooting-28">Troubleshooting</a></h2>
<h3 id="common-issues-6"><a class="header" href="#common-issues-6">Common Issues</a></h3>
<p><strong>Generated data not realistic enough</strong></p>
<ul>
<li>Enable RAG synthesis with domain documentation</li>
<li>Check field naming conventions for better inference</li>
<li>Add custom business rules for specific constraints</li>
</ul>
<p><strong>Non-deterministic behavior</strong></p>
<ul>
<li>Ensure <code>deterministic: true</code> and provide a <code>seed</code> value</li>
<li>Reset generators between test runs</li>
<li>Check for external randomness sources</li>
</ul>
<p><strong>Validation failures</strong></p>
<ul>
<li>Review foreign key naming conventions</li>
<li>Ensure referenced entities are generated before referencing ones</li>
<li>Check custom validation rule patterns</li>
</ul>
<p><strong>RAG not working</strong></p>
<ul>
<li>Verify API credentials and endpoints</li>
<li>Check context source file paths and permissions</li>
<li>Monitor API rate limits and error responses</li>
</ul>
<h3 id="debug-commands-3"><a class="header" href="#debug-commands-3">Debug Commands</a></h3>
<pre><code class="language-bash"># Test data synthesis configuration
mockforge validate-config

# Show detected schema relationships
mockforge analyze-schema --proto-dir proto/

# Test deterministic generation
MOCKFORGE_DATA_SYNTHESIS_DEBUG=true \
mockforge serve --grpc-port 50051
</code></pre>
<p>Advanced data synthesis transforms MockForge from a simple mocking tool into a comprehensive test data management platform, enabling realistic, consistent, and validated test scenarios across your entire service architecture.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="graphql-mocking"><a class="header" href="#graphql-mocking">GraphQL Mocking</a></h1>
<p>MockForge provides comprehensive GraphQL API mocking capabilities, allowing you to create realistic GraphQL endpoints with schema-driven response generation, introspection support, and custom resolvers.</p>
<h2 id="overview-8"><a class="header" href="#overview-8">Overview</a></h2>
<p>MockForge‚Äôs GraphQL support includes:</p>
<ul>
<li><strong>Schema-Driven Mocking</strong>: Generate responses based on GraphQL schema definitions</li>
<li><strong>Introspection Support</strong>: Full GraphQL introspection query support</li>
<li><strong>Custom Resolvers</strong>: Implement custom logic for specific fields</li>
<li><strong>Query Validation</strong>: Validate incoming GraphQL queries against schema</li>
<li><strong>Subscription Support</strong>: Mock GraphQL subscriptions with real-time updates</li>
<li><strong>Schema Stitching</strong>: Combine multiple schemas into unified endpoints</li>
<li><strong>Performance Simulation</strong>: Configurable latency and complexity limits</li>
</ul>
<h2 id="getting-started"><a class="header" href="#getting-started">Getting Started</a></h2>
<h3 id="basic-setup-1"><a class="header" href="#basic-setup-1">Basic Setup</a></h3>
<p>Enable GraphQL mocking in your MockForge configuration:</p>
<pre><code class="language-yaml"># config.yaml
graphql:
  enabled: true
  endpoint: "/graphql"
  schema_file: "schema.graphql"
  introspection: true
  playground: true
  
server:
  http_port: 3000
</code></pre>
<p>Start MockForge with GraphQL support:</p>
<pre><code class="language-bash">mockforge serve --config config.yaml
</code></pre>
<p>Access your GraphQL endpoint:</p>
<ul>
<li><strong>GraphQL Endpoint</strong>: <code>http://localhost:3000/graphql</code></li>
<li><strong>GraphQL Playground</strong>: <code>http://localhost:3000/graphql/playground</code></li>
</ul>
<h3 id="schema-definition"><a class="header" href="#schema-definition">Schema Definition</a></h3>
<p>Create a GraphQL schema file:</p>
<pre><code class="language-graphql"># schema.graphql
type User {
  id: ID!
  name: String!
  email: String!
  age: Int
  posts: [Post!]!
  profile: UserProfile
}

type Post {
  id: ID!
  title: String!
  content: String!
  published: Boolean!
  author: User!
  createdAt: String!
  tags: [String!]!
}

type UserProfile {
  bio: String
  website: String
  location: String
  avatarUrl: String
}

type Query {
  users: [User!]!
  user(id: ID!): User
  posts: [Post!]!
  post(id: ID!): Post
  searchUsers(query: String!): [User!]!
}

type Mutation {
  createUser(input: CreateUserInput!): User!
  updateUser(id: ID!, input: UpdateUserInput!): User!
  deleteUser(id: ID!): Boolean!
  createPost(input: CreatePostInput!): Post!
}

type Subscription {
  userCreated: User!
  postPublished: Post!
  userOnline(userId: ID!): Boolean!
}

input CreateUserInput {
  name: String!
  email: String!
  age: Int
}

input UpdateUserInput {
  name: String
  email: String
  age: Int
}

input CreatePostInput {
  title: String!
  content: String!
  authorId: ID!
  tags: [String!]
}
</code></pre>
<h2 id="configuration-options-1"><a class="header" href="#configuration-options-1">Configuration Options</a></h2>
<h3 id="basic-configuration-2"><a class="header" href="#basic-configuration-2">Basic Configuration</a></h3>
<pre><code class="language-yaml">graphql:
  # Enable GraphQL support
  enabled: true
  
  # GraphQL endpoint path
  endpoint: "/graphql"
  
  # Schema configuration
  schema_file: "schema.graphql"
  schema_url: "https://api.example.com/schema"  # Alternative: fetch from URL
  
  # Development features
  introspection: true
  playground: true
  playground_endpoint: "/graphql/playground"
  
  # Response generation
  mock_responses: true
  default_list_length: 5
  
  # Validation
  validate_queries: true
  max_query_depth: 10
  max_query_complexity: 1000
</code></pre>
<h3 id="advanced-configuration-3"><a class="header" href="#advanced-configuration-3">Advanced Configuration</a></h3>
<pre><code class="language-yaml">graphql:
  # Performance settings
  performance:
    enable_query_complexity_analysis: true
    max_query_depth: 15
    max_query_complexity: 1000
    timeout_ms: 30000
    
  # Caching
  caching:
    enabled: true
    ttl_seconds: 300
    max_cache_size: 1000
    
  # Custom resolvers
  resolvers:
    directory: "./graphql/resolvers"
    auto_load: true
    
  # Subscription settings
  subscriptions:
    enabled: true
    transport: "websocket"
    heartbeat_interval: 30
    
  # Error handling
  errors:
    include_stack_trace: true
    include_extensions: true
    custom_error_codes: true
</code></pre>
<h2 id="response-generation"><a class="header" href="#response-generation">Response Generation</a></h2>
<h3 id="automatic-response-generation-2"><a class="header" href="#automatic-response-generation-2">Automatic Response Generation</a></h3>
<p>MockForge automatically generates realistic responses based on your schema:</p>
<pre><code class="language-graphql"># Query
query GetUsers {
  users {
    id
    name
    email
    age
    posts {
      title
      published
    }
  }
}
</code></pre>
<pre><code class="language-json">{
  "data": {
    "users": [
      {
        "id": "1a2b3c4d",
        "name": "Alice Johnson",
        "email": "alice.johnson@example.com",
        "age": 29,
        "posts": [
          {
            "title": "Getting Started with GraphQL",
            "published": true
          },
          {
            "title": "Advanced Query Techniques",
            "published": false
          }
        ]
      },
      {
        "id": "2b3c4d5e",
        "name": "Bob Smith",
        "email": "bob.smith@example.com",
        "age": 34,
        "posts": [
          {
            "title": "Building Scalable APIs",
            "published": true
          }
        ]
      }
    ]
  }
}
</code></pre>
<h3 id="template-based-responses"><a class="header" href="#template-based-responses">Template-Based Responses</a></h3>
<p>Use templates for more control over response data:</p>
<pre><code class="language-yaml"># graphql/responses/user.yaml
query: "query GetUser($id: ID!)"
response:
  data:
    user:
      id: "{{args.id}}"
      name: "{{faker.name.fullName}}"
      email: "{{faker.internet.email}}"
      age: "{{randInt 18 65}}"
      profile:
        bio: "{{faker.lorem.sentence}}"
        website: "{{faker.internet.url}}"
        location: "{{faker.address.city}}, {{faker.address.state}}"
        avatarUrl: "https://api.dicebear.com/7.x/avataaars/svg?seed={{uuid}}"
</code></pre>
<h3 id="custom-field-resolvers"><a class="header" href="#custom-field-resolvers">Custom Field Resolvers</a></h3>
<p>Create custom resolvers for specific fields:</p>
<pre><code class="language-javascript">// graphql/resolvers/user.js
module.exports = {
  User: {
    // Custom resolver for posts field
    posts: (parent, args, context) =&gt; {
      return context.dataSources.posts.getByAuthorId(parent.id);
    },
    
    // Computed field
    fullName: (parent) =&gt; {
      return `${parent.firstName} ${parent.lastName}`;
    },
    
    // Async resolver with external data
    socialStats: async (parent, args, context) =&gt; {
      return await context.dataSources.social.getStats(parent.id);
    }
  },
  
  Query: {
    // Custom query resolver
    searchUsers: (parent, args, context) =&gt; {
      const { query, limit = 10 } = args;
      return context.dataSources.users.search(query, limit);
    }
  },
  
  Mutation: {
    // Custom mutation resolver
    createUser: (parent, args, context) =&gt; {
      const { input } = args;
      const user = {
        id: uuid(),
        ...input,
        createdAt: new Date().toISOString()
      };
      
      context.dataSources.users.create(user);
      
      // Trigger subscription
      context.pubsub.publish('USER_CREATED', { userCreated: user });
      
      return user;
    }
  }
};
</code></pre>
<h2 id="data-sources"><a class="header" href="#data-sources">Data Sources</a></h2>
<h3 id="csv-data-source"><a class="header" href="#csv-data-source">CSV Data Source</a></h3>
<p>Connect GraphQL resolvers to CSV data:</p>
<pre><code class="language-yaml"># config.yaml
graphql:
  data_sources:
    users:
      type: "csv"
      file: "data/users.csv"
      key_field: "id"
    
    posts:
      type: "csv"
      file: "data/posts.csv"
      key_field: "id"
      relationships:
        author_id: "users.id"
</code></pre>
<pre><code class="language-csv"># data/users.csv
id,name,email,age
1,Alice Johnson,alice@example.com,29
2,Bob Smith,bob@example.com,34
3,Carol Davis,carol@example.com,27
</code></pre>
<h3 id="rest-api-data-source"><a class="header" href="#rest-api-data-source">REST API Data Source</a></h3>
<p>Fetch data from external REST APIs:</p>
<pre><code class="language-yaml">graphql:
  data_sources:
    users:
      type: "rest"
      base_url: "https://jsonplaceholder.typicode.com"
      endpoints:
        getAll: "/users"
        getById: "/users/{id}"
        create: 
          method: "POST"
          url: "/users"
    
    posts:
      type: "rest"
      base_url: "https://jsonplaceholder.typicode.com"
      endpoints:
        getAll: "/posts"
        getByUserId: "/posts?userId={userId}"
</code></pre>
<h3 id="database-data-source"><a class="header" href="#database-data-source">Database Data Source</a></h3>
<p>Connect to databases for realistic data:</p>
<pre><code class="language-yaml">graphql:
  data_sources:
    database:
      type: "postgresql"
      connection_string: "postgresql://user:pass@localhost/mockdb"
      tables:
        users:
          table: "users"
          key_field: "id"
        posts:
          table: "posts"
          key_field: "id"
          relationships:
            author_id: "users.id"
</code></pre>
<h2 id="subscriptions"><a class="header" href="#subscriptions">Subscriptions</a></h2>
<h3 id="websocket-subscriptions"><a class="header" href="#websocket-subscriptions">WebSocket Subscriptions</a></h3>
<p>Enable real-time GraphQL subscriptions:</p>
<pre><code class="language-yaml">graphql:
  subscriptions:
    enabled: true
    transport: "websocket"
    endpoint: "/graphql/ws"
    heartbeat_interval: 30
    connection_timeout: 60
</code></pre>
<h3 id="subscription-resolvers"><a class="header" href="#subscription-resolvers">Subscription Resolvers</a></h3>
<pre><code class="language-javascript">// graphql/resolvers/subscriptions.js
module.exports = {
  Subscription: {
    userCreated: {
      subscribe: (parent, args, context) =&gt; {
        return context.pubsub.asyncIterator('USER_CREATED');
      }
    },
    
    postPublished: {
      subscribe: (parent, args, context) =&gt; {
        return context.pubsub.asyncIterator('POST_PUBLISHED');
      }
    },
    
    userOnline: {
      subscribe: (parent, args, context) =&gt; {
        const { userId } = args;
        return context.pubsub.asyncIterator(`USER_ONLINE_${userId}`);
      }
    }
  }
};
</code></pre>
<h3 id="triggering-subscriptions"><a class="header" href="#triggering-subscriptions">Triggering Subscriptions</a></h3>
<p>Trigger subscriptions from mutations or external events:</p>
<pre><code class="language-javascript">// In mutation resolver
createPost: (parent, args, context) =&gt; {
  const post = createNewPost(args.input);
  
  // Trigger subscription
  context.pubsub.publish('POST_PUBLISHED', { 
    postPublished: post 
  });
  
  return post;
}
</code></pre>
<h2 id="schema-stitching"><a class="header" href="#schema-stitching">Schema Stitching</a></h2>
<p>Combine multiple GraphQL schemas:</p>
<pre><code class="language-yaml">graphql:
  schema_stitching:
    enabled: true
    schemas:
      - name: "users"
        file: "schemas/users.graphql"
        endpoint: "http://users-service/graphql"
      
      - name: "posts"
        file: "schemas/posts.graphql"
        endpoint: "http://posts-service/graphql"
      
      - name: "comments"
        file: "schemas/comments.graphql"
        endpoint: "http://comments-service/graphql"
    
    # Type extensions for stitching
    extensions:
      - |
        extend type User {
          posts: [Post]
        }
      - |
        extend type Post {
          comments: [Comment]
        }
</code></pre>
<h2 id="error-handling-2"><a class="header" href="#error-handling-2">Error Handling</a></h2>
<h3 id="custom-error-responses-1"><a class="header" href="#custom-error-responses-1">Custom Error Responses</a></h3>
<p>Configure custom error handling:</p>
<pre><code class="language-yaml">graphql:
  errors:
    # Include detailed error information
    include_stack_trace: true
    include_extensions: true
    
    # Custom error codes
    custom_error_codes:
      INVALID_INPUT: 400
      UNAUTHORIZED: 401
      FORBIDDEN: 403
      NOT_FOUND: 404
      RATE_LIMITED: 429
</code></pre>
<h3 id="error-response-format"><a class="header" href="#error-response-format">Error Response Format</a></h3>
<pre><code class="language-json">{
  "errors": [
    {
      "message": "User not found",
      "locations": [
        {
          "line": 2,
          "column": 3
        }
      ],
      "path": ["user"],
      "extensions": {
        "code": "NOT_FOUND",
        "userId": "invalid-id",
        "timestamp": "2024-01-01T00:00:00Z"
      }
    }
  ],
  "data": {
    "user": null
  }
}
</code></pre>
<h2 id="performance--optimization"><a class="header" href="#performance--optimization">Performance &amp; Optimization</a></h2>
<h3 id="query-complexity-analysis"><a class="header" href="#query-complexity-analysis">Query Complexity Analysis</a></h3>
<p>Prevent expensive queries:</p>
<pre><code class="language-yaml">graphql:
  performance:
    enable_query_complexity_analysis: true
    max_query_depth: 10
    max_query_complexity: 1000
    complexity_scalarCost: 1
    complexity_objectCost: 2
    complexity_listFactor: 10
    complexity_introspectionCost: 100
</code></pre>
<h3 id="caching"><a class="header" href="#caching">Caching</a></h3>
<p>Cache responses for improved performance:</p>
<pre><code class="language-yaml">graphql:
  caching:
    enabled: true
    ttl_seconds: 300
    max_cache_size: 1000
    cache_key_strategy: "query_and_variables"
    
    # Cache per resolver
    resolver_cache:
      "Query.users": 600  # Cache for 10 minutes
      "Query.posts": 300  # Cache for 5 minutes
</code></pre>
<h3 id="latency-simulation"><a class="header" href="#latency-simulation">Latency Simulation</a></h3>
<p>Simulate real-world latency:</p>
<pre><code class="language-yaml">graphql:
  latency:
    enabled: true
    default_delay_ms: 100
    
    # Per-field latency
    field_delays:
      "Query.users": 200
      "User.posts": 150
      "Post.comments": 100
    
    # Random latency ranges
    random_delay:
      min_ms: 50
      max_ms: 500
</code></pre>
<h2 id="testing--development"><a class="header" href="#testing--development">Testing &amp; Development</a></h2>
<h3 id="graphql-playground"><a class="header" href="#graphql-playground">GraphQL Playground</a></h3>
<p>The built-in GraphQL Playground provides:</p>
<ul>
<li><strong>Interactive Query Editor</strong>: Write and test GraphQL queries</li>
<li><strong>Schema Documentation</strong>: Browse your schema structure</li>
<li><strong>Query Variables</strong>: Test with different variable values</li>
<li><strong>Response Headers</strong>: View response metadata</li>
<li><strong>Subscription Testing</strong>: Test real-time subscriptions</li>
</ul>
<h3 id="query-examples"><a class="header" href="#query-examples">Query Examples</a></h3>
<p>Test your GraphQL API with these examples:</p>
<pre><code class="language-graphql"># Simple query
query GetAllUsers {
  users {
    id
    name
    email
  }
}

# Query with variables
query GetUser($userId: ID!) {
  user(id: $userId) {
    id
    name
    email
    posts {
      title
      published
    }
  }
}

# Mutation
mutation CreateUser($input: CreateUserInput!) {
  createUser(input: $input) {
    id
    name
    email
  }
}

# Subscription
subscription UserUpdates {
  userCreated {
    id
    name
    email
  }
}
</code></pre>
<h3 id="integration-with-http-mocking"><a class="header" href="#integration-with-http-mocking">Integration with HTTP Mocking</a></h3>
<p>Combine GraphQL with REST API mocking:</p>
<pre><code class="language-yaml"># config.yaml
http:
  enabled: true
  spec: "openapi.yaml"

graphql:
  enabled: true
  schema_file: "schema.graphql"
  
# Use REST endpoints in GraphQL resolvers
graphql:
  data_sources:
    rest_api:
      type: "rest"
      base_url: "http://localhost:3000"  # MockForge HTTP server
      endpoints:
        users: "/api/users"
        posts: "/api/posts"
</code></pre>
<h2 id="best-practices-16"><a class="header" href="#best-practices-16">Best Practices</a></h2>
<h3 id="schema-design"><a class="header" href="#schema-design">Schema Design</a></h3>
<ol>
<li><strong>Use Descriptive Names</strong>: Choose clear, self-documenting field names</li>
<li><strong>Follow Conventions</strong>: Use camelCase for fields, PascalCase for types</li>
<li><strong>Document Your Schema</strong>: Add descriptions to types and fields</li>
<li><strong>Version Carefully</strong>: Use field deprecation instead of breaking changes</li>
</ol>
<h3 id="performance"><a class="header" href="#performance">Performance</a></h3>
<ol>
<li><strong>Implement Caching</strong>: Cache expensive resolver operations</li>
<li><strong>Limit Query Depth</strong>: Prevent deeply nested queries</li>
<li><strong>Use DataLoaders</strong>: Batch and cache data fetching</li>
<li><strong>Monitor Complexity</strong>: Track query complexity metrics</li>
</ol>
<h3 id="testing-3"><a class="header" href="#testing-3">Testing</a></h3>
<ol>
<li><strong>Test Query Variations</strong>: Test different query structures and variables</li>
<li><strong>Validate Error Cases</strong>: Ensure proper error handling</li>
<li><strong>Test Subscriptions</strong>: Verify real-time functionality</li>
<li><strong>Performance Testing</strong>: Test with realistic query loads</li>
</ol>
<h2 id="troubleshooting-29"><a class="header" href="#troubleshooting-29">Troubleshooting</a></h2>
<h3 id="common-issues-7"><a class="header" href="#common-issues-7">Common Issues</a></h3>
<h4 id="schema-loading-errors"><a class="header" href="#schema-loading-errors">Schema Loading Errors</a></h4>
<pre><code class="language-bash"># Validate GraphQL schema
mockforge graphql validate --schema schema.graphql

# Check schema syntax
graphql-schema-linter schema.graphql
</code></pre>
<h4 id="resolver-errors"><a class="header" href="#resolver-errors">Resolver Errors</a></h4>
<pre><code class="language-bash"># Enable debug logging
RUST_LOG=mockforge_graphql=debug mockforge serve

# Test individual resolvers
mockforge graphql test-resolver Query.users
</code></pre>
<h4 id="subscription-issues"><a class="header" href="#subscription-issues">Subscription Issues</a></h4>
<pre><code class="language-bash"># Test WebSocket connection
wscat -c ws://localhost:3000/graphql/ws

# Check subscription resolver
mockforge graphql test-subscription userCreated
</code></pre>
<p>This comprehensive GraphQL support makes MockForge a powerful tool for mocking modern GraphQL APIs with realistic data and behavior.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="websocket-mocking"><a class="header" href="#websocket-mocking">WebSocket Mocking</a></h1>
<p>MockForge provides comprehensive WebSocket connection mocking with support for both scripted replay scenarios and interactive real-time communication. This enables testing of WebSocket-based applications, real-time APIs, and event-driven systems.</p>
<h2 id="websocket-mocking-modes"><a class="header" href="#websocket-mocking-modes">WebSocket Mocking Modes</a></h2>
<p>MockForge supports two primary WebSocket mocking approaches:</p>
<h3 id="1-replay-mode-scripted"><a class="header" href="#1-replay-mode-scripted">1. Replay Mode (Scripted)</a></h3>
<p>Pre-recorded message sequences that play back on schedule, simulating server behavior with precise timing control.</p>
<h3 id="2-interactive-mode-real-time"><a class="header" href="#2-interactive-mode-real-time">2. Interactive Mode (Real-time)</a></h3>
<p>Dynamic responses based on client messages, enabling complex interactive scenarios and stateful communication.</p>
<h2 id="configuration-8"><a class="header" href="#configuration-8">Configuration</a></h2>
<h3 id="basic-websocket-setup"><a class="header" href="#basic-websocket-setup">Basic WebSocket Setup</a></h3>
<pre><code class="language-bash"># Start MockForge with WebSocket support
mockforge serve --ws-port 3001 --ws-replay-file ws-scenario.jsonl
</code></pre>
<h3 id="environment-variables-11"><a class="header" href="#environment-variables-11">Environment Variables</a></h3>
<pre><code class="language-bash"># WebSocket configuration
MOCKFORGE_WS_ENABLED=true                    # Enable WebSocket support (default: false)
MOCKFORGE_WS_PORT=3001                       # WebSocket server port
MOCKFORGE_WS_BIND=0.0.0.0                    # Bind address
MOCKFORGE_WS_REPLAY_FILE=path/to/file.jsonl  # Path to replay file
MOCKFORGE_WS_PATH=/ws                         # WebSocket endpoint path (default: /ws)
MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true      # Enable template processing
</code></pre>
<h3 id="command-line-options-1"><a class="header" href="#command-line-options-1">Command Line Options</a></h3>
<pre><code class="language-bash">mockforge serve \
  --ws-port 3001 \
  --ws-replay-file examples/ws-demo.jsonl \
  --ws-path /websocket
</code></pre>
<h2 id="replay-mode"><a class="header" href="#replay-mode">Replay Mode</a></h2>
<p>Replay mode uses JSONL-formatted files to define scripted message sequences with precise timing control.</p>
<h3 id="replay-file-format"><a class="header" href="#replay-file-format">Replay File Format</a></h3>
<p>Each line in the replay file is a JSON object with the following structure:</p>
<pre><code class="language-json">{
  "ts": 0,
  "dir": "out",
  "text": "Hello, client!",
  "waitFor": "^CLIENT_READY$"
}
</code></pre>
<h3 id="field-definitions"><a class="header" href="#field-definitions">Field Definitions</a></h3>
<ul>
<li><strong><code>ts</code></strong> (number, required): Timestamp offset in milliseconds from connection start</li>
<li><strong><code>dir</code></strong> (string, required): Message direction
<ul>
<li><code>"out"</code> - Message sent from server to client</li>
<li><code>"in"</code> - Expected message from client (for validation)</li>
</ul>
</li>
<li><strong><code>text</code></strong> (string, required): Message content (supports templates)</li>
<li><strong><code>waitFor</code></strong> (string, optional): Regular expression to wait for before proceeding</li>
</ul>
<h3 id="basic-replay-example"><a class="header" href="#basic-replay-example">Basic Replay Example</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"Welcome to MockForge WebSocket server","waitFor":"^HELLO$"}
{"ts":1000,"dir":"out","text":"Connection established"}
{"ts":2000,"dir":"out","text":"Sending data: 42"}
{"ts":3000,"dir":"out","text":"Goodbye"}
</code></pre>
<h3 id="advanced-replay-features"><a class="header" href="#advanced-replay-features">Advanced Replay Features</a></h3>
<h4 id="template-support-1"><a class="header" href="#template-support-1">Template Support</a></h4>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"Session {{uuid}} started at {{now}}"}
{"ts":1000,"dir":"out","text":"Random value: {{randInt 1 100}}"}
{"ts":2000,"dir":"out","text":"Future event at {{now+5m}}"}
</code></pre>
<h4 id="interactive-elements"><a class="header" href="#interactive-elements">Interactive Elements</a></h4>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"Please authenticate","waitFor":"^AUTH .+$"}
{"ts":100,"dir":"out","text":"Authentication successful"}
{"ts":200,"dir":"out","text":"Choose option (A/B/C)","waitFor":"^(A|B|C)$"}
</code></pre>
<h4 id="complex-message-structures"><a class="header" href="#complex-message-structures">Complex Message Structures</a></h4>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"{\"type\":\"welcome\",\"user\":{\"id\":\"{{uuid}}\",\"name\":\"John\"}}"}
{"ts":1000,"dir":"out","text":"{\"type\":\"data\",\"payload\":{\"items\":[{\"id\":1,\"value\":\"{{randInt 10 99}}\"},{\"id\":2,\"value\":\"{{randInt 100 999}}\"}]}}"}
</code></pre>
<h3 id="replay-file-management"><a class="header" href="#replay-file-management">Replay File Management</a></h3>
<h4 id="creating-replay-files"><a class="header" href="#creating-replay-files">Creating Replay Files</a></h4>
<pre><code class="language-bash"># Record from live WebSocket connection
# (Feature in development - manual creation for now)

# Create from application logs
# Extract WebSocket messages and convert to JSONL format

# Generate programmatically
node -e "
const fs = require('fs');
const messages = [
  {ts: 0, dir: 'out', text: 'HELLO', waitFor: '^HI$'},
  {ts: 1000, dir: 'out', text: 'DATA: 42'}
];
fs.writeFileSync('replay.jsonl', messages.map(JSON.stringify).join('\n'));
"
</code></pre>
<h4 id="validation-1"><a class="header" href="#validation-1">Validation</a></h4>
<pre><code class="language-bash"># Validate replay file syntax
node -e "
const fs = require('fs');
const lines = fs.readFileSync('replay.jsonl', 'utf8').split('\n');
lines.forEach((line, i) =&gt; {
  if (line.trim()) {
    try {
      const msg = JSON.parse(line);
      if (!msg.ts || !msg.dir || !msg.text) {
        console.log(\`Line \${i+1}: Missing required fields\`);
      }
    } catch (e) {
      console.log(\`Line \${i+1}: Invalid JSON\`);
    }
  }
});
console.log('Validation complete');
"
</code></pre>
<h2 id="interactive-mode"><a class="header" href="#interactive-mode">Interactive Mode</a></h2>
<p>Interactive mode enables dynamic responses based on client messages, supporting complex conversational patterns and state management.</p>
<h3 id="basic-interactive-setup"><a class="header" href="#basic-interactive-setup">Basic Interactive Setup</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"What is your name?","waitFor":"^NAME .+$"}
{"ts":100,"dir":"out","text":"Hello {{request.ws.lastMessage.match(/^NAME (.+)$/)[1]}}!"}
</code></pre>
<h3 id="state-management-1"><a class="header" href="#state-management-1">State Management</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"Welcome! Type 'START' to begin","waitFor":"^START$"}
{"ts":100,"dir":"out","text":"Game started. Score: 0","state":"playing"}
{"ts":200,"dir":"out","text":"Choose: ROCK/PAPER/SCISSORS","waitFor":"^(ROCK|PAPER|SCISSORS)$"}
{"ts":300,"dir":"out","text":"You chose {{request.ws.lastMessage}}. I chose ROCK. You win!","waitFor":"^PLAY_AGAIN$"}
</code></pre>
<h3 id="conditional-logic-1"><a class="header" href="#conditional-logic-1">Conditional Logic</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"Enter command","waitFor":".+","condition":"{{request.ws.message.length &gt; 0}}"}
{"ts":100,"dir":"out","text":"Processing: {{request.ws.message}}"}
{"ts":200,"dir":"out","text":"Command completed"}
</code></pre>
<h2 id="testing-websocket-connections"><a class="header" href="#testing-websocket-connections">Testing WebSocket Connections</a></h2>
<h3 id="using-websocket-clients"><a class="header" href="#using-websocket-clients">Using WebSocket Clients</a></h3>
<h4 id="nodejs-client"><a class="header" href="#nodejs-client">Node.js Client</a></h4>
<pre><code class="language-javascript">const WebSocket = require('ws');

const ws = new WebSocket('ws://localhost:3001/ws');

ws.on('open', () =&gt; {
  console.log('Connected to MockForge WebSocket');
  ws.send('CLIENT_READY');
});

ws.on('message', (data) =&gt; {
  const message = data.toString();
  console.log('Received:', message);

  // Auto-respond to common prompts
  if (message.includes('ACK')) {
    ws.send('ACK');
  }
  if (message.includes('CONFIRMED')) {
    ws.send('CONFIRMED');
  }
  if (message.includes('AUTH')) {
    ws.send('AUTH token123');
  }
});

ws.on('close', () =&gt; {
  console.log('Connection closed');
});

ws.on('error', (err) =&gt; {
  console.error('WebSocket error:', err);
});
</code></pre>
<h4 id="browser-javascript"><a class="header" href="#browser-javascript">Browser JavaScript</a></h4>
<pre><code class="language-javascript">const ws = new WebSocket('ws://localhost:3001/ws');

ws.onopen = () =&gt; {
  console.log('Connected');
  ws.send('CLIENT_READY');
};

ws.onmessage = (event) =&gt; {
  console.log('Received:', event.data);
  // Handle server messages
};

ws.onclose = () =&gt; {
  console.log('Connection closed');
};
</code></pre>
<h4 id="command-line-tools"><a class="header" href="#command-line-tools">Command Line Tools</a></h4>
<pre><code class="language-bash"># Using websocat
websocat ws://localhost:3001/ws

# Using curl (WebSocket support experimental)
curl --include \
     --no-buffer \
     --header "Connection: Upgrade" \
     --header "Upgrade: websocket" \
     --header "Sec-WebSocket-Key: x3JJHMbDL1EzLkh9GBhXDw==" \
     --header "Sec-WebSocket-Version: 13" \
     ws://localhost:3001/ws
</code></pre>
<h3 id="automated-testing-3"><a class="header" href="#automated-testing-3">Automated Testing</a></h3>
<pre><code class="language-bash">#!/bin/bash
# test-websocket.sh

echo "Testing WebSocket connection..."

# Test with Node.js
node -e "
const WebSocket = require('ws');
const ws = new WebSocket('ws://localhost:3001/ws');

ws.on('open', () =&gt; {
  console.log('‚úì Connection established');
  ws.send('CLIENT_READY');
});

ws.on('message', (data) =&gt; {
  console.log('‚úì Message received:', data.toString());
  ws.close();
});

ws.on('close', () =&gt; {
  console.log('‚úì Connection closed successfully');
  process.exit(0);
});

ws.on('error', (err) =&gt; {
  console.error('‚úó WebSocket error:', err);
  process.exit(1);
});

// Timeout after 10 seconds
setTimeout(() =&gt; {
  console.error('‚úó Test timeout');
  process.exit(1);
}, 10000);
"
</code></pre>
<h2 id="advanced-features-2"><a class="header" href="#advanced-features-2">Advanced Features</a></h2>
<h3 id="connection-pooling"><a class="header" href="#connection-pooling">Connection Pooling</a></h3>
<pre><code class="language-bash"># Support multiple concurrent connections
MOCKFORGE_WS_MAX_CONNECTIONS=100
MOCKFORGE_WS_CONNECTION_TIMEOUT=30000
</code></pre>
<h3 id="message-filtering"><a class="header" href="#message-filtering">Message Filtering</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"in","text":".*","filter":"{{request.ws.message.startsWith('VALID_')}}"}
{"ts":100,"dir":"out","text":"Valid message received"}
</code></pre>
<h3 id="error-simulation-1"><a class="header" href="#error-simulation-1">Error Simulation</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"Error occurred","error":"true","code":1006}
{"ts":100,"dir":"out","text":"Connection will close","close":"true"}
</code></pre>
<h3 id="binary-message-support"><a class="header" href="#binary-message-support">Binary Message Support</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"AQIDBAU=","binary":"true"}
{"ts":1000,"dir":"out","text":"Binary data sent"}
</code></pre>
<h2 id="integration-patterns-2"><a class="header" href="#integration-patterns-2">Integration Patterns</a></h2>
<h3 id="real-time-applications"><a class="header" href="#real-time-applications">Real-time Applications</a></h3>
<ul>
<li><strong>Chat Applications</strong>: Mock user conversations and bot responses</li>
<li><strong>Live Updates</strong>: Simulate real-time data feeds and notifications</li>
<li><strong>Gaming</strong>: Mock multiplayer game state and player interactions</li>
</ul>
<h3 id="api-testing"><a class="header" href="#api-testing">API Testing</a></h3>
<ul>
<li><strong>WebSocket APIs</strong>: Test GraphQL subscriptions and real-time queries</li>
<li><strong>Event Streams</strong>: Mock server-sent events and push notifications</li>
<li><strong>Live Dashboards</strong>: Simulate real-time metrics and monitoring data</li>
</ul>
<h3 id="development-workflows"><a class="header" href="#development-workflows">Development Workflows</a></h3>
<ul>
<li><strong>Frontend Development</strong>: Mock WebSocket backends during UI development</li>
<li><strong>Integration Testing</strong>: Test WebSocket handling in microservices</li>
<li><strong>Load Testing</strong>: Simulate thousands of concurrent WebSocket connections</li>
</ul>
<h2 id="best-practices-17"><a class="header" href="#best-practices-17">Best Practices</a></h2>
<h3 id="replay-file-organization"><a class="header" href="#replay-file-organization">Replay File Organization</a></h3>
<ol>
<li><strong>Modular Files</strong>: Break complex scenarios into smaller, focused replay files</li>
<li><strong>Version Control</strong>: Keep replay files in Git for collaboration</li>
<li><strong>Documentation</strong>: Comment complex scenarios with clear descriptions</li>
<li><strong>Validation</strong>: Always validate replay files before deployment</li>
</ol>
<h3 id="performance-considerations-2"><a class="header" href="#performance-considerations-2">Performance Considerations</a></h3>
<ol>
<li><strong>Message Volume</strong>: Limit concurrent connections based on system resources</li>
<li><strong>Memory Usage</strong>: Monitor memory usage with large replay files</li>
<li><strong>Timing Accuracy</strong>: Consider system clock precision for time-sensitive scenarios</li>
<li><strong>Connection Limits</strong>: Set appropriate connection pool sizes</li>
</ol>
<h3 id="security-considerations-4"><a class="header" href="#security-considerations-4">Security Considerations</a></h3>
<ol>
<li><strong>Input Validation</strong>: Validate all client messages in interactive mode</li>
<li><strong>Rate Limiting</strong>: Implement connection rate limits for production</li>
<li><strong>Authentication</strong>: Mock authentication handshakes appropriately</li>
<li><strong>Data Sanitization</strong>: Avoid exposing sensitive data in replay files</li>
</ol>
<h3 id="debugging-tips"><a class="header" href="#debugging-tips">Debugging Tips</a></h3>
<ol>
<li><strong>Verbose Logging</strong>: Enable detailed WebSocket logging for troubleshooting</li>
<li><strong>Connection Monitoring</strong>: Track connection lifecycle and message flow</li>
<li><strong>Replay Debugging</strong>: Step through replay files manually</li>
<li><strong>Client Compatibility</strong>: Test with multiple WebSocket client libraries</li>
</ol>
<h2 id="troubleshooting-30"><a class="header" href="#troubleshooting-30">Troubleshooting</a></h2>
<h3 id="common-issues-8"><a class="header" href="#common-issues-8">Common Issues</a></h3>
<p><strong>Connection fails</strong>: Check that WebSocket port is not blocked by firewall</p>
<p><strong>Messages not received</strong>: Verify replay file path and JSONL format</p>
<p><strong>Templates not expanding</strong>: Ensure <code>MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true</code></p>
<p><strong>Timing issues</strong>: Check system clock and timestamp calculations</p>
<h3 id="debug-commands-4"><a class="header" href="#debug-commands-4">Debug Commands</a></h3>
<pre><code class="language-bash"># Check WebSocket port
netstat -tlnp | grep :3001

# Monitor connections
ss -tlnp | grep :3001

# Test basic connectivity
curl -I http://localhost:3001/health  # If HTTP health endpoint exists
</code></pre>
<h3 id="log-analysis-1"><a class="header" href="#log-analysis-1">Log Analysis</a></h3>
<pre><code class="language-bash"># View WebSocket logs
tail -f mockforge.log | grep -i websocket

# Count connections
grep "WebSocket connection" mockforge.log | wc -l

# Find errors
grep -i "websocket.*error" mockforge.log
</code></pre>
<p>For detailed implementation guides, see:</p>
<ul>
<li><a href="user-guide/websocket-mocking/replay.html">Replay Mode</a> - Advanced scripted scenarios</li>
<li><a href="user-guide/websocket-mocking/interactive.html">Interactive Mode</a> - Dynamic real-time communication</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="replay-mode-1"><a class="header" href="#replay-mode-1">Replay Mode</a></h1>
<p>Replay mode provides precise, scripted WebSocket message sequences that execute on a predetermined schedule. This mode is ideal for testing deterministic scenarios, reproducing specific interaction patterns, and validating client behavior against known server responses.</p>
<h2 id="core-concepts"><a class="header" href="#core-concepts">Core Concepts</a></h2>
<h3 id="message-timeline"><a class="header" href="#message-timeline">Message Timeline</a></h3>
<p>Replay files define a sequence of messages that execute based on timestamps relative to connection establishment. Each message has a precise timing offset ensuring consistent playback.</p>
<h3 id="deterministic-execution"><a class="header" href="#deterministic-execution">Deterministic Execution</a></h3>
<p>Replay scenarios execute identically each time, making them perfect for:</p>
<ul>
<li>Automated testing</li>
<li>Regression testing</li>
<li>Client behavior validation</li>
<li>Demo environments</li>
</ul>
<h2 id="replay-file-structure"><a class="header" href="#replay-file-structure">Replay File Structure</a></h2>
<h3 id="jsonl-format"><a class="header" href="#jsonl-format">JSONL Format</a></h3>
<p>Replay files use JSON Lines format where each line contains a complete JSON object representing a single message or directive.</p>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"Welcome message"}
{"ts":1000,"dir":"out","text":"Data update","waitFor":"^ACK$"}
{"ts":2000,"dir":"out","text":"Connection closing"}
</code></pre>
<h3 id="message-object-schema"><a class="header" href="#message-object-schema">Message Object Schema</a></h3>
<pre><code class="language-typescript">interface ReplayMessage {
  ts: number;           // Timestamp offset in milliseconds
  dir: "out" | "in";    // Message direction
  text: string;         // Message content
  waitFor?: string;     // Optional regex pattern to wait for
  binary?: boolean;     // Binary message flag
  close?: boolean;      // Close connection after this message
  error?: boolean;      // Send as error frame
}
</code></pre>
<h2 id="basic-replay-examples"><a class="header" href="#basic-replay-examples">Basic Replay Examples</a></h2>
<h3 id="simple-chat-simulation"><a class="header" href="#simple-chat-simulation">Simple Chat Simulation</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"Chat server connected. Welcome!"}
{"ts":500,"dir":"out","text":"Type 'hello' to start chatting","waitFor":"^hello$"}
{"ts":100,"dir":"out","text":"Hello! How can I help you today?"}
{"ts":2000,"dir":"out","text":"Are you still there?","waitFor":".*"}
{"ts":500,"dir":"out","text":"Thanks for chatting! Goodbye."}
</code></pre>
<h3 id="api-status-monitoring"><a class="header" href="#api-status-monitoring">API Status Monitoring</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"{\"type\":\"status\",\"message\":\"Monitor connected\"}"}
{"ts":1000,"dir":"out","text":"{\"type\":\"metrics\",\"cpu\":45,\"memory\":67}"}
{"ts":2000,"dir":"out","text":"{\"type\":\"metrics\",\"cpu\":42,\"memory\":68}"}
{"ts":3000,"dir":"out","text":"{\"type\":\"metrics\",\"cpu\":47,\"memory\":66}"}
{"ts":4000,"dir":"out","text":"{\"type\":\"alert\",\"level\":\"warning\",\"message\":\"High CPU usage\"}"}
</code></pre>
<h3 id="game-state-synchronization"><a class="header" href="#game-state-synchronization">Game State Synchronization</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"{\"action\":\"game_start\",\"player_id\":\"{{uuid}}\",\"game_id\":\"{{uuid}}\"}"}
{"ts":1000,"dir":"out","text":"{\"action\":\"state_update\",\"position\":{\"x\":10,\"y\":20},\"score\":0}"}
{"ts":2000,"dir":"out","text":"{\"action\":\"enemy_spawn\",\"enemy_id\":\"{{uuid}}\",\"position\":{\"x\":50,\"y\":30}}"}
{"ts":1500,"dir":"out","text":"{\"action\":\"powerup\",\"type\":\"speed\",\"position\":{\"x\":25,\"y\":15}}"}
{"ts":3000,"dir":"out","text":"{\"action\":\"game_over\",\"final_score\":1250,\"reason\":\"timeout\"}"}
</code></pre>
<h2 id="advanced-replay-techniques"><a class="header" href="#advanced-replay-techniques">Advanced Replay Techniques</a></h2>
<h3 id="conditional-branching"><a class="header" href="#conditional-branching">Conditional Branching</a></h3>
<p>While replay mode is inherently linear, you can simulate branching using multiple replay files and external logic:</p>
<pre><code class="language-jsonl">// File: login-success.jsonl
{"ts":0,"dir":"out","text":"Login successful","waitFor":"^ready$"}
{"ts":100,"dir":"out","text":"Welcome to your dashboard"}

// File: login-failed.jsonl
{"ts":0,"dir":"out","text":"Invalid credentials"}
{"ts":500,"dir":"out","text":"Connection will close","close":true}
</code></pre>
<h3 id="template-integration"><a class="header" href="#template-integration">Template Integration</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"Session {{uuid}} established at {{now}}"}
{"ts":1000,"dir":"out","text":"Your lucky number is: {{randInt 1 100}}"}
{"ts":2000,"dir":"out","text":"Next maintenance window: {{now+24h}}"}
{"ts":3000,"dir":"out","text":"Server load: {{randInt 20 80}}%"}
</code></pre>
<h3 id="binary-message-support-1"><a class="header" href="#binary-message-support-1">Binary Message Support</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNkYPhfDwAChwGA60e6kgAAAABJRU5ErkJggg==","binary":true}
{"ts":1000,"dir":"out","text":"Image sent successfully"}
</code></pre>
<h3 id="error-simulation-2"><a class="header" href="#error-simulation-2">Error Simulation</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"Connection established"}
{"ts":5000,"dir":"out","text":"Internal server error","error":true}
{"ts":1000,"dir":"out","text":"Attempting reconnection..."}
{"ts":2000,"dir":"out","text":"Reconnection failed","close":true}
</code></pre>
<h2 id="creating-replay-files-1"><a class="header" href="#creating-replay-files-1">Creating Replay Files</a></h2>
<h3 id="manual-creation"><a class="header" href="#manual-creation">Manual Creation</a></h3>
<pre><code class="language-bash"># Create a new replay file
cat &gt; chat-replay.jsonl &lt;&lt; 'EOF'
{"ts":0,"dir":"out","text":"Welcome to support chat!"}
{"ts":1000,"dir":"out","text":"How can I help you today?","waitFor":".*"}
{"ts":500,"dir":"out","text":"Thanks for your question. Let me check..."}
{"ts":2000,"dir":"out","text":"I found the solution! Here's what you need to do:"}
{"ts":1000,"dir":"out","text":"1. Go to settings\n2. Click preferences\n3. Enable feature X"}
{"ts":3000,"dir":"out","text":"Does this solve your issue?","waitFor":"^(yes|no)$"}
{"ts":500,"dir":"out","text":"Great! Glad I could help. Have a nice day!"}
EOF
</code></pre>
<h3 id="from-application-logs"><a class="header" href="#from-application-logs">From Application Logs</a></h3>
<pre><code class="language-bash">#!/bin/bash
# extract-websocket-logs.sh

# Extract WebSocket messages from application logs
grep "WEBSOCKET_MSG" app.log | \
  # Parse log entries and convert to JSONL
  awk '{
    # Extract timestamp, direction, and message
    match($0, /([0-9]+).*dir=([^ ]*).*msg=(.*)/, arr)
    printf "{\"ts\":%d,\"dir\":\"%s\",\"text\":\"%s\"}\n", arr[1], arr[2], arr[3]
  }' &gt; replay-from-logs.jsonl
</code></pre>
<h3 id="programmatic-generation"><a class="header" href="#programmatic-generation">Programmatic Generation</a></h3>
<pre><code class="language-javascript">// generate-replay.js
const fs = require('fs');

function generateHeartbeatReplay(interval = 30000, duration = 300000) {
  const messages = [];
  const messageCount = duration / interval;

  for (let i = 0; i &lt; messageCount; i++) {
    messages.push({
      ts: i * interval,
      dir: "out",
      text: JSON.stringify({
        type: "heartbeat",
        timestamp: `{{now+${i * interval}ms}}`,
        sequence: i + 1
      })
    });
  }

  fs.writeFileSync('heartbeat-replay.jsonl',
    messages.map(JSON.stringify).join('\n'));
}

generateHeartbeatReplay();
</code></pre>
<pre><code class="language-python"># generate-replay.py
import json
import random

def generate_data_stream(count=100, interval=1000):
    messages = []
    for i in range(count):
        messages.append({
            "ts": i * interval,
            "dir": "out",
            "text": json.dumps({
                "type": "data_point",
                "id": f"{{{{uuid}}}}",
                "value": random.randint(1, 100),
                "timestamp": f"{{{{now+{i * interval}ms}}}}}"
            })
        })
    return messages

# Write to file
with open('data-stream-replay.jsonl', 'w') as f:
    for msg in generate_data_stream():
        f.write(json.dumps(msg) + '\n')
</code></pre>
<h2 id="validation-and-testing"><a class="header" href="#validation-and-testing">Validation and Testing</a></h2>
<h3 id="replay-file-validation"><a class="header" href="#replay-file-validation">Replay File Validation</a></h3>
<pre><code class="language-bash"># Validate JSONL syntax
node -e "
const fs = require('fs');
const lines = fs.readFileSync('replay.jsonl', 'utf8').split('\n');
let valid = true;

lines.forEach((line, i) =&gt; {
  if (line.trim()) {
    try {
      const msg = JSON.parse(line);
      if (!msg.ts || !msg.dir || !msg.text) {
        console.log(\`Line \${i+1}: Missing required fields\`);
        valid = false;
      }
      if (typeof msg.ts !== 'number' || msg.ts &lt; 0) {
        console.log(\`Line \${i+1}: Invalid timestamp\`);
        valid = false;
      }
      if (!['in', 'out'].includes(msg.dir)) {
        console.log(\`Line \${i+1}: Invalid direction\`);
        valid = false;
      }
    } catch (e) {
      console.log(\`Line \${i+1}: Invalid JSON - \${e.message}\`);
      valid = false;
    }
  }
});

console.log(valid ? '‚úì Replay file is valid' : '‚úó Replay file has errors');
"
</code></pre>
<h3 id="timing-analysis"><a class="header" href="#timing-analysis">Timing Analysis</a></h3>
<pre><code class="language-bash"># Analyze replay timing
node -e "
const fs = require('fs');
const messages = fs.readFileSync('replay.jsonl', 'utf8')
  .split('\n')
  .filter(line =&gt; line.trim())
  .map(line =&gt; JSON.parse(line));

const timings = messages.map((msg, i) =&gt; ({
  index: i + 1,
  ts: msg.ts,
  interval: i &gt; 0 ? msg.ts - messages[i-1].ts : 0
}));

console.log('Timing Analysis:');
timings.forEach(t =&gt; {
  console.log(\`Message \${t.index}: \${t.ts}ms (interval: \${t.interval}ms)\`);
});

const totalDuration = Math.max(...messages.map(m =&gt; m.ts));
console.log(\`Total duration: \${totalDuration}ms (\${(totalDuration/1000).toFixed(1)}s)\`);
"
</code></pre>
<h3 id="functional-testing"><a class="header" href="#functional-testing">Functional Testing</a></h3>
<pre><code class="language-bash">#!/bin/bash
# test-replay.sh

REPLAY_FILE=$1
WS_URL="ws://localhost:3001/ws"

echo "Testing replay file: $REPLAY_FILE"

# Validate file exists and is readable
if [ ! -f "$REPLAY_FILE" ]; then
  echo "‚úó Replay file not found"
  exit 1
fi

# Basic syntax check
if ! node -e "
  const fs = require('fs');
  const content = fs.readFileSync('$REPLAY_FILE', 'utf8');
  const lines = content.split('\n').filter(l =&gt; l.trim());
  lines.forEach((line, i) =&gt; {
    try {
      JSON.parse(line);
    } catch (e) {
      console.error(\`Line \${i+1}: \${e.message}\`);
      process.exit(1);
    }
  });
  console.log(\`‚úì Valid JSONL: \${lines.length} messages\`);
"; then
  echo "‚úó Syntax validation failed"
  exit 1
fi

echo "‚úì Replay file validation passed"
echo "Ready to test with: mockforge serve --ws-replay-file $REPLAY_FILE"
</code></pre>
<h2 id="best-practices-18"><a class="header" href="#best-practices-18">Best Practices</a></h2>
<h3 id="file-organization"><a class="header" href="#file-organization">File Organization</a></h3>
<ol>
<li>
<p><strong>Descriptive Names</strong>: Use clear, descriptive filenames</p>
<pre><code>user-authentication-flow.jsonl
real-time-data-stream.jsonl
error-handling-scenarios.jsonl
</code></pre>
</li>
<li>
<p><strong>Modular Scenarios</strong>: Break complex interactions into focused files</p>
<pre><code>login-flow.jsonl
main-interaction.jsonl
logout-flow.jsonl
</code></pre>
</li>
<li>
<p><strong>Version Control</strong>: Keep replay files in Git with meaningful commit messages</p>
</li>
</ol>
<h3 id="performance-optimization-4"><a class="header" href="#performance-optimization-4">Performance Optimization</a></h3>
<ol>
<li><strong>Message Batching</strong>: Group related messages with minimal intervals</li>
<li><strong>Memory Management</strong>: Monitor memory usage with large replay files</li>
<li><strong>Connection Limits</strong>: Consider concurrent connection impact</li>
</ol>
<h3 id="maintenance"><a class="header" href="#maintenance">Maintenance</a></h3>
<ol>
<li><strong>Regular Updates</strong>: Keep replay files synchronized with application changes</li>
<li><strong>Documentation</strong>: Comment complex scenarios inline</li>
<li><strong>Versioning</strong>: Tag replay files with application versions</li>
</ol>
<h3 id="debugging"><a class="header" href="#debugging">Debugging</a></h3>
<ol>
<li><strong>Verbose Logging</strong>: Enable detailed WebSocket logging during development</li>
<li><strong>Step-through Testing</strong>: Test replay files incrementally</li>
<li><strong>Timing Verification</strong>: Validate message timing against expectations</li>
</ol>
<h2 id="common-patterns"><a class="header" href="#common-patterns">Common Patterns</a></h2>
<h3 id="authentication-flow"><a class="header" href="#authentication-flow">Authentication Flow</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"Please authenticate","waitFor":"^AUTH .+$"}
{"ts":100,"dir":"out","text":"Authenticating..."}
{"ts":500,"dir":"out","text":"Authentication successful"}
{"ts":200,"dir":"out","text":"Welcome back, user!"}
</code></pre>
<h3 id="streaming-data"><a class="header" href="#streaming-data">Streaming Data</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"{\"type\":\"stream_start\",\"stream_id\":\"{{uuid}}\"}"}
{"ts":100,"dir":"out","text":"{\"type\":\"data\",\"value\":{{randInt 1 100}}}"}
{"ts":100,"dir":"out","text":"{\"type\":\"data\",\"value\":{{randInt 1 100}}}"}
{"ts":100,"dir":"out","text":"{\"type\":\"data\",\"value\":{{randInt 1 100}}}"}
{"ts":5000,"dir":"out","text":"{\"type\":\"stream_end\",\"total_messages\":3}"}
</code></pre>
<h3 id="error-recovery"><a class="header" href="#error-recovery">Error Recovery</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"System operational"}
{"ts":30000,"dir":"out","text":"Warning: High load detected"}
{"ts":10000,"dir":"out","text":"Error: Service unavailable","error":true}
{"ts":5000,"dir":"out","text":"Attempting recovery..."}
{"ts":10000,"dir":"out","text":"Recovery successful"}
{"ts":1000,"dir":"out","text":"System back to normal"}
</code></pre>
<h2 id="integration-with-cicd"><a class="header" href="#integration-with-cicd">Integration with CI/CD</a></h2>
<h3 id="automated-testing-4"><a class="header" href="#automated-testing-4">Automated Testing</a></h3>
<pre><code class="language-yaml"># .github/workflows/test.yml
name: WebSocket Tests
on: [push, pull_request]

jobs:
  websocket-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
      - name: Install dependencies
        run: npm install ws
      - name: Start MockForge
        run: |
          cargo install mockforge-cli
          mockforge serve --ws-replay-file examples/ws-demo.jsonl &amp;
          sleep 2
      - name: Run WebSocket tests
        run: node test-websocket.js
</code></pre>
<h3 id="performance-benchmarking"><a class="header" href="#performance-benchmarking">Performance Benchmarking</a></h3>
<pre><code class="language-bash">#!/bin/bash
# benchmark-replay.sh

CONCURRENT_CONNECTIONS=100
DURATION=60

echo "Benchmarking WebSocket replay with $CONCURRENT_CONNECTIONS connections for ${DURATION}s"

# Start MockForge
mockforge serve --ws-replay-file benchmark-replay.jsonl &amp;
SERVER_PID=$!
sleep 2

# Run benchmark
node benchmark-websocket.js $CONCURRENT_CONNECTIONS $DURATION

# Cleanup
kill $SERVER_PID
</code></pre>
<p>This comprehensive approach to replay mode ensures reliable, deterministic WebSocket testing scenarios that can be easily created, validated, and maintained as part of your testing infrastructure.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="interactive-mode-1"><a class="header" href="#interactive-mode-1">Interactive Mode</a></h1>
<p>Interactive mode enables dynamic, real-time WebSocket communication where MockForge responds intelligently to client messages. Unlike replay mode‚Äôs predetermined sequences, interactive mode supports complex conversational patterns, state management, and adaptive responses based on client input.</p>
<h2 id="core-concepts-1"><a class="header" href="#core-concepts-1">Core Concepts</a></h2>
<h3 id="dynamic-response-logic"><a class="header" href="#dynamic-response-logic">Dynamic Response Logic</a></h3>
<p>Interactive mode evaluates client messages and generates contextually appropriate responses using conditional logic, pattern matching, and state tracking.</p>
<h3 id="state-management-2"><a class="header" href="#state-management-2">State Management</a></h3>
<p>Connections maintain state across messages, enabling complex interactions like authentication flows, game mechanics, and multi-step processes.</p>
<h3 id="message-processing-pipeline"><a class="header" href="#message-processing-pipeline">Message Processing Pipeline</a></h3>
<ol>
<li><strong>Receive</strong> client message</li>
<li><strong>Parse</strong> and validate input</li>
<li><strong>Evaluate</strong> conditions and state</li>
<li><strong>Generate</strong> appropriate response</li>
<li><strong>Update</strong> connection state</li>
</ol>
<h2 id="basic-interactive-setup-1"><a class="header" href="#basic-interactive-setup-1">Basic Interactive Setup</a></h2>
<h3 id="simple-echo-server"><a class="header" href="#simple-echo-server">Simple Echo Server</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"Echo server ready. Send me a message!"}
{"ts":0,"dir":"in","text":".*","response":"You said: {{request.ws.message}}"}
</code></pre>
<h3 id="command-processor"><a class="header" href="#command-processor">Command Processor</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"Available commands: HELP, TIME, ECHO &lt;message&gt;, QUIT"}
{"ts":0,"dir":"in","text":"^HELP$","response":"Commands: HELP, TIME, ECHO &lt;msg&gt;, QUIT"}
{"ts":0,"dir":"in","text":"^TIME$","response":"Current time: {{now}}"}
{"ts":0,"dir":"in","text":"^ECHO (.+)$","response":"Echo: {{request.ws.message.match(/^ECHO (.+)$/)[1]}}"}
{"ts":0,"dir":"in","text":"^QUIT$","response":"Goodbye!","close":true}
</code></pre>
<h2 id="advanced-interactive-patterns"><a class="header" href="#advanced-interactive-patterns">Advanced Interactive Patterns</a></h2>
<h3 id="authentication-flow-1"><a class="header" href="#authentication-flow-1">Authentication Flow</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"Welcome! Please login with: LOGIN &lt;username&gt; &lt;password&gt;"}
{"ts":0,"dir":"in","text":"^LOGIN (\\w+) (\\w+)$","response":"Authenticating {{request.ws.message.match(/^LOGIN (\\w+) (\\w+)$/)[1]}}...","state":"authenticating"}
{"ts":1000,"dir":"out","text":"Login successful! Welcome, {{request.ws.state.username}}!","condition":"{{request.ws.state.authenticating}}"}
{"ts":0,"dir":"out","text":"Login failed. Try again.","condition":"{{!request.ws.state.authenticating}}"}
</code></pre>
<h3 id="state-based-conversations"><a class="header" href="#state-based-conversations">State-Based Conversations</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"Welcome to the survey bot. What's your name?","state":"awaiting_name"}
{"ts":0,"dir":"in","text":".+","response":"Nice to meet you, {{request.ws.message}}! How old are you?","state":"awaiting_age","condition":"{{request.ws.state.awaiting_name}}"}
{"ts":0,"dir":"in","text":"^\\d+$","response":"Thanks! You're {{request.ws.message}} years old. Survey complete!","state":"complete","condition":"{{request.ws.state.awaiting_age}}"}
{"ts":0,"dir":"in","text":".*","response":"Please enter a valid age (numbers only).","condition":"{{request.ws.state.awaiting_age}}"}
</code></pre>
<h3 id="game-mechanics"><a class="header" href="#game-mechanics">Game Mechanics</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"Welcome to Number Guessing Game! I'm thinking of a number between 1-100.","state":"playing","game":{"target":42,"attempts":0}}
{"ts":0,"dir":"in","text":"^GUESS (\\d+)$","condition":"{{request.ws.state.playing}}","response":"{{#if (eq (parseInt request.ws.message.match(/^GUESS (\\d+)$/) [1]) request.ws.state.game.target)}}You won in {{request.ws.state.game.attempts + 1}} attempts!{{else}}{{#if (gt (parseInt request.ws.message.match(/^GUESS (\\d+)$/) [1]) request.ws.state.game.target)}}Too high!{{else}}Too low!{{/if}} Try again.{{/if}}","state":"{{#if (eq (parseInt request.ws.message.match(/^GUESS (\\d+)$/) [1]) request.ws.state.game.target)}}won{{else}}playing{{/if}}","game":{"target":"{{request.ws.state.game.target}}","attempts":"{{request.ws.state.game.attempts + 1}}"}}
</code></pre>
<h2 id="message-processing-syntax"><a class="header" href="#message-processing-syntax">Message Processing Syntax</a></h2>
<h3 id="input-patterns"><a class="header" href="#input-patterns">Input Patterns</a></h3>
<p>Interactive mode uses regex patterns to match client messages:</p>
<pre><code class="language-jsonl">// Exact match
{"dir":"in","text":"hello","response":"Hi there!"}

// Case-insensitive match
{"dir":"in","text":"(?i)hello","response":"Hi there!"}

// Pattern with capture groups
{"dir":"in","text":"^NAME (.+)$","response":"Hello, {{request.ws.message.match(/^NAME (.+)$/)[1]}}!"}

// Optional elements
{"dir":"in","text":"^(HELP|help|\\?)$","response":"Available commands: ..."}
</code></pre>
<h3 id="response-templates"><a class="header" href="#response-templates">Response Templates</a></h3>
<p>Responses support the full MockForge template system:</p>
<pre><code class="language-jsonl">{"dir":"in","text":".*","response":"Message received at {{now}}: {{request.ws.message}} (length: {{request.ws.message.length}})"}
</code></pre>
<h3 id="conditions"><a class="header" href="#conditions">Conditions</a></h3>
<p>Use template conditions to control when rules apply:</p>
<pre><code class="language-jsonl">{"dir":"in","text":".*","condition":"{{request.ws.state.authenticated}}","response":"Welcome back!"}
{"dir":"in","text":".*","condition":"{{!request.ws.state.authenticated}}","response":"Please authenticate first."}
</code></pre>
<h3 id="state-updates"><a class="header" href="#state-updates">State Updates</a></h3>
<p>Modify connection state based on interactions:</p>
<pre><code class="language-jsonl">// Set simple state
{"dir":"in","text":"START","response":"Starting...","state":"active"}

// Update complex state
{"dir":"in","text":"SCORE","response":"Current score: {{request.ws.state.score}}","state":"playing","score":"{{request.ws.state.score + 10}}"}
</code></pre>
<h2 id="advanced-features-3"><a class="header" href="#advanced-features-3">Advanced Features</a></h2>
<h3 id="multi-message-conversations"><a class="header" href="#multi-message-conversations">Multi-Message Conversations</a></h3>
<pre><code class="language-jsonl">// Step 1: Greeting
{"ts":0,"dir":"out","text":"Hello! What's your favorite color?"}
{"ts":0,"dir":"in","text":".+","response":"{{request.ws.message}} is a great choice! What's your favorite food?","state":"asked_color","color":"{{request.ws.message}}","next":"food"}

// Step 2: Follow-up
{"ts":0,"dir":"out","text":"Based on your preferences, I recommend: ...","condition":"{{request.ws.state.next === 'complete'}}"}
{"ts":0,"dir":"in","text":".+","condition":"{{request.ws.state.next === 'food'}}","response":"Perfect! You like {{request.ws.state.color}} and {{request.ws.message}}. Here's a recommendation...","state":"complete"}
</code></pre>
<h3 id="error-handling-3"><a class="header" href="#error-handling-3">Error Handling</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"Enter a command:"}
{"ts":0,"dir":"in","text":"","response":"Empty input not allowed. Try again."}
{"ts":0,"dir":"in","text":"^.{100,}$","response":"Input too long (max 99 characters). Please shorten."}
{"ts":0,"dir":"in","text":"^INVALID.*","response":"Unknown command. Type HELP for available commands."}
{"ts":0,"dir":"in","text":".*","response":"Processing: {{request.ws.message}}"}
</code></pre>
<h3 id="rate-limiting"><a class="header" href="#rate-limiting">Rate Limiting</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"in","text":".*","condition":"{{request.ws.state.messageCount &lt; 10}}","response":"Message {{request.ws.state.messageCount + 1}}: {{request.ws.message}}","messageCount":"{{request.ws.state.messageCount + 1}}"}
{"ts":0,"dir":"in","text":".*","condition":"{{request.ws.state.messageCount &gt;= 10}}","response":"Rate limit exceeded. Please wait."}
</code></pre>
<h3 id="session-management-1"><a class="header" href="#session-management-1">Session Management</a></h3>
<pre><code class="language-jsonl">// Initialize session
{"ts":0,"dir":"out","text":"Session started: {{uuid}}","sessionId":"{{uuid}}","startTime":"{{now}}","messageCount":0}

// Track activity
{"ts":0,"dir":"in","text":".*","response":"Received","messageCount":"{{request.ws.state.messageCount + 1}}","lastActivity":"{{now}}","condition":"{{request.ws.state.active}}"}
</code></pre>
<h2 id="template-functions-for-interactive-mode"><a class="header" href="#template-functions-for-interactive-mode">Template Functions for Interactive Mode</a></h2>
<h3 id="message-analysis"><a class="header" href="#message-analysis">Message Analysis</a></h3>
<pre><code class="language-jsonl">// Message properties
{"dir":"in","text":".*","response":"Length: {{request.ws.message.length}}, Uppercase: {{request.ws.message.toUpperCase()}}"}
</code></pre>
<h3 id="state-queries"><a class="header" href="#state-queries">State Queries</a></h3>
<pre><code class="language-jsonl">// Check state existence
{"condition":"{{request.ws.state.userId}}","response":"Logged in as: {{request.ws.state.userId}}"}
{"condition":"{{!request.ws.state.userId}}","response":"Please log in first."}

// State comparisons
{"condition":"{{request.ws.state.score &gt; 100}}","response":"High score achieved!"}
{"condition":"{{request.ws.state.level === 'expert'}}","response":"Expert mode enabled."}
</code></pre>
<h3 id="time-based-logic"><a class="header" href="#time-based-logic">Time-based Logic</a></h3>
<pre><code class="language-jsonl">// Session timeout
{"condition":"{{request.ws.state.lastActivity &amp;&amp; (now - request.ws.state.lastActivity) &gt; 300000}}","response":"Session expired. Please reconnect.","close":true}

// Time-based greetings
{"response":"{{#if (gte (now.getHours()) 18)}}Good evening!{{else if (gte (now.getHours()) 12)}}Good afternoon!{{else}}Good morning!{{/if}}"}
</code></pre>
<h2 id="creating-interactive-scenarios"><a class="header" href="#creating-interactive-scenarios">Creating Interactive Scenarios</a></h2>
<h3 id="from-scratch"><a class="header" href="#from-scratch">From Scratch</a></h3>
<pre><code class="language-bash"># Create a new interactive scenario
cat &gt; interactive-chat.jsonl &lt;&lt; 'EOF'
{"ts":0,"dir":"out","text":"ChatBot: Hello! How can I help you today?"}
{"ts":0,"dir":"in","text":"(?i).*help.*","response":"ChatBot: I can answer questions, tell jokes, or just chat. What would you like?"}
{"ts":0,"dir":"in","text":"(?i).*joke.*","response":"ChatBot: Why did the computer go to the doctor? It had a virus! üòÇ"}
{"ts":0,"dir":"in","text":"(?i).*bye.*","response":"ChatBot: Goodbye! Have a great day! üëã","close":true}
{"ts":0,"dir":"in","text":".*","response":"ChatBot: I'm not sure how to respond to that. Try asking for help!"}
EOF
</code></pre>
<h3 id="from-existing-logs"><a class="header" href="#from-existing-logs">From Existing Logs</a></h3>
<pre><code class="language-bash">#!/bin/bash
# convert-logs-to-interactive.sh

# Extract conversation patterns from logs
grep "USER:" chat.log | sed 's/.*USER: //' | sort | uniq &gt; user_patterns.txt
grep "BOT:" chat.log | sed 's/.*BOT: //' | sort | uniq &gt; bot_responses.txt

# Generate interactive rules
paste user_patterns.txt bot_responses.txt | while IFS=$'\t' read -r user bot; do
  echo "{\"dir\":\"in\",\"text\":\"$(echo "$user" | sed 's/[^a-zA-Z0-9]/\\&amp;/g')\",\"response\":\"$bot\"}"
done &gt; interactive-from-logs.jsonl
</code></pre>
<h3 id="testing-interactive-scenarios"><a class="header" href="#testing-interactive-scenarios">Testing Interactive Scenarios</a></h3>
<pre><code class="language-bash">#!/bin/bash
# test-interactive.sh

echo "Testing interactive WebSocket scenario..."

# Start MockForge with interactive file
mockforge serve --ws-replay-file interactive-test.jsonl &amp;
SERVER_PID=$!
sleep 2

# Test conversation flow
node -e "
const WebSocket = require('ws');
const ws = new WebSocket('ws://localhost:3001/ws');

const conversation = [
  'Hello',
  'Tell me a joke',
  'What can you do?',
  'Goodbye'
];

let step = 0;

ws.on('open', () =&gt; {
  console.log('Connected, starting conversation...');
  ws.send(conversation[step++]);
});

ws.on('message', (data) =&gt; {
  const response = data.toString();
  console.log('Bot:', response);

  if (step &lt; conversation.length) {
    setTimeout(() =&gt; {
      ws.send(conversation[step++]);
    }, 1000);
  } else {
    ws.close();
  }
});

ws.on('close', () =&gt; {
  console.log('Conversation complete');
  process.exit(0);
});

ws.on('error', (err) =&gt; {
  console.error('Error:', err);
  process.exit(1);
});
"

# Cleanup
kill $SERVER_PID
</code></pre>
<h2 id="best-practices-19"><a class="header" href="#best-practices-19">Best Practices</a></h2>
<h3 id="design-principles"><a class="header" href="#design-principles">Design Principles</a></h3>
<ol>
<li><strong>Clear Conversation Flow</strong>: Design conversations with clear paths and expectations</li>
<li><strong>Graceful Error Handling</strong>: Provide helpful responses for unexpected input</li>
<li><strong>State Consistency</strong>: Keep state updates predictable and logical</li>
<li><strong>Performance Awareness</strong>: Avoid complex regex or template processing</li>
</ol>
<h3 id="pattern-guidelines"><a class="header" href="#pattern-guidelines">Pattern Guidelines</a></h3>
<ol>
<li><strong>Specific to General</strong>: Order patterns from most specific to most general</li>
<li><strong>Anchored Regex</strong>: Use <code>^</code> and <code>$</code> to avoid partial matches</li>
<li><strong>Case Handling</strong>: Consider case sensitivity in user input</li>
<li><strong>Input Validation</strong>: Validate and sanitize user input</li>
</ol>
<h3 id="state-management-3"><a class="header" href="#state-management-3">State Management</a></h3>
<ol>
<li><strong>Minimal State</strong>: Store only necessary information in connection state</li>
<li><strong>State Validation</strong>: Verify state consistency across interactions</li>
<li><strong>State Cleanup</strong>: Clear state when conversations end</li>
<li><strong>State Persistence</strong>: Consider state requirements for reconnection scenarios</li>
</ol>
<h3 id="debugging-interactive-scenarios"><a class="header" href="#debugging-interactive-scenarios">Debugging Interactive Scenarios</a></h3>
<ol>
<li><strong>Verbose Logging</strong>: Enable detailed WebSocket logging</li>
<li><strong>State Inspection</strong>: Log state changes during conversations</li>
<li><strong>Pattern Testing</strong>: Test regex patterns independently</li>
<li><strong>Flow Tracing</strong>: Track conversation paths through state changes</li>
</ol>
<h2 id="common-patterns-1"><a class="header" href="#common-patterns-1">Common Patterns</a></h2>
<h3 id="customer-support-chat"><a class="header" href="#customer-support-chat">Customer Support Chat</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"Welcome to support! How can I help you? (Type your question or 'menu' for options)"}
{"ts":0,"dir":"in","text":"(?i)menu","response":"Options: 1) Password reset 2) Billing 3) Technical issue 4) Other","state":"menu"}
{"ts":0,"dir":"in","text":"(?i).*password.*","response":"I'll help you reset your password. What's your email address?","state":"password_reset","issue":"password"}
{"ts":0,"dir":"in","text":"(?i).*billing.*","response":"For billing questions, please visit our billing portal at billing.example.com","state":"billing"}
{"ts":0,"dir":"in","text":".*","response":"Thanks for your question: '{{request.ws.message}}'. A support agent will respond shortly. Your ticket ID is: {{uuid}}"}
</code></pre>
<h3 id="e-commerce-assistant"><a class="header" href="#e-commerce-assistant">E-commerce Assistant</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"Welcome to our store! What are you looking for?","state":"browsing"}
{"ts":0,"dir":"in","text":"(?i).*shirt.*","response":"We have various shirts: casual, formal, graphic. Which style interests you?","state":"shirt_selection","category":"shirts"}
{"ts":0,"dir":"in","text":"(?i).*size.*","response":"Available sizes: S, M, L, XL. Which size would you like?","state":"size_selection","condition":"{{request.ws.state.category}}"}
{"ts":0,"dir":"in","text":"(?i)(S|M|L|XL)","condition":"{{request.ws.state.size_selection}}","response":"Great! Adding {{request.ws.state.category}} in size {{request.ws.message.toUpperCase()}} to cart. Would you like to checkout or continue shopping?","state":"checkout_ready"}
</code></pre>
<h3 id="game-server"><a class="header" href="#game-server">Game Server</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"Welcome to the game server! Choose your character: WARRIOR, MAGE, ROGUE","state":"character_select"}
{"ts":0,"dir":"in","text":"(?i)^(warrior|mage|rogue)$","response":"Excellent choice! You selected {{request.ws.message.toUpperCase()}}. Your adventure begins now...","state":"playing","character":"{{request.ws.message.toLowerCase()}}","health":100,"level":1}
{"ts":0,"dir":"in","text":"(?i)stats","condition":"{{request.ws.state.playing}}","response":"Character: {{request.ws.state.character}}, Level: {{request.ws.state.level}}, Health: {{request.ws.state.health}}"}
{"ts":0,"dir":"in","text":"(?i)fight","condition":"{{request.ws.state.playing}}","response":"You encounter a monster! Roll for attack... {{randInt 1 20}}! {{#if (gte (randInt 1 20) 10)}}Victory!{{else}}Defeat!{{/if}}"}
</code></pre>
<h2 id="integration-examples"><a class="header" href="#integration-examples">Integration Examples</a></h2>
<h3 id="with-testing-frameworks"><a class="header" href="#with-testing-frameworks">With Testing Frameworks</a></h3>
<pre><code class="language-javascript">// test-interactive.js
const WebSocket = require('ws');

class InteractiveWebSocketTester {
  constructor(url) {
    this.url = url;
    this.ws = null;
  }

  async connect() {
    return new Promise((resolve, reject) =&gt; {
      this.ws = new WebSocket(this.url);
      this.ws.on('open', () =&gt; resolve());
      this.ws.on('error', reject);
    });
  }

  async sendAndExpect(message, expectedResponse) {
    return new Promise((resolve, reject) =&gt; {
      const timeout = setTimeout(() =&gt; reject(new Error('Timeout')), 5000);

      this.ws.send(message);
      this.ws.once('message', (data) =&gt; {
        clearTimeout(timeout);
        const response = data.toString();
        if (response === expectedResponse) {
          resolve(response);
        } else {
          reject(new Error(`Expected "${expectedResponse}", got "${response}"`));
        }
      });
    });
  }

  close() {
    if (this.ws) this.ws.close();
  }
}

module.exports = InteractiveWebSocketTester;
</code></pre>
<h3 id="load-testing-interactive-scenarios"><a class="header" href="#load-testing-interactive-scenarios">Load Testing Interactive Scenarios</a></h3>
<pre><code class="language-bash">#!/bin/bash
# load-test-interactive.sh

CONCURRENT_USERS=50
DURATION=300

echo "Load testing interactive WebSocket with $CONCURRENT_USERS concurrent users for ${DURATION}s"

# Start MockForge
mockforge serve --ws-replay-file interactive-load-test.jsonl &amp;
SERVER_PID=$!
sleep 2

# Run load test
node load-test-interactive.js $CONCURRENT_USERS $DURATION

# Generate report
echo "Generating performance report..."
node analyze-results.js

# Cleanup
kill $SERVER_PID
</code></pre>
<p>Interactive mode transforms MockForge from a simple message player into an intelligent conversation partner, enabling sophisticated testing scenarios that adapt to client behavior and maintain complex interaction state.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="plugin-system-1"><a class="header" href="#plugin-system-1">Plugin System</a></h1>
<p>MockForge features a powerful WebAssembly-based plugin system that allows you to extend functionality without modifying the core framework. Plugins run in a secure sandbox with resource limits and provide capabilities for custom response generation, authentication, data sources, and template extensions.</p>
<h2 id="overview-9"><a class="header" href="#overview-9">Overview</a></h2>
<p>The plugin system enables:</p>
<ul>
<li><strong>Custom Response Generators</strong>: Create specialized mock data and responses</li>
<li><strong>Authentication Providers</strong>: Implement JWT, OAuth2, and custom authentication schemes</li>
<li><strong>Data Source Connectors</strong>: Connect to CSV files, databases, and external APIs</li>
<li><strong>Template Extensions</strong>: Add custom template functions and filters</li>
<li><strong>Protocol Handlers</strong>: Extend support for custom protocols and formats</li>
</ul>
<h2 id="plugin-architecture"><a class="header" href="#plugin-architecture">Plugin Architecture</a></h2>
<h3 id="webassembly-runtime"><a class="header" href="#webassembly-runtime">WebAssembly Runtime</a></h3>
<p>Plugins are compiled to WebAssembly (WASM) and run in an isolated runtime environment:</p>
<ul>
<li><strong>Security Sandbox</strong>: Isolated execution prevents plugins from accessing unauthorized resources</li>
<li><strong>Resource Limits</strong>: CPU, memory, and execution time constraints</li>
<li><strong>Capability System</strong>: Fine-grained permissions control what plugins can access</li>
<li><strong>Cross-platform</strong>: WASM plugins work on any platform MockForge supports</li>
</ul>
<h3 id="plugin-types-1"><a class="header" href="#plugin-types-1">Plugin Types</a></h3>
<p>MockForge supports several plugin types:</p>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Description</th><th>Interface</th></tr></thead><tbody>
<tr><td><code>response</code></td><td>Generate custom response data</td><td><code>ResponseGenerator</code></td></tr>
<tr><td><code>auth</code></td><td>Handle authentication and authorization</td><td><code>AuthProvider</code></td></tr>
<tr><td><code>datasource</code></td><td>Connect to external data sources</td><td><code>DataSourceConnector</code></td></tr>
<tr><td><code>template</code></td><td>Add custom template functions</td><td><code>TemplateExtension</code></td></tr>
<tr><td><code>protocol</code></td><td>Support custom protocols</td><td><code>ProtocolHandler</code></td></tr>
</tbody></table>
</div>
<h2 id="installing-plugins"><a class="header" href="#installing-plugins">Installing Plugins</a></h2>
<h3 id="from-plugin-registry"><a class="header" href="#from-plugin-registry">From Plugin Registry</a></h3>
<pre><code class="language-bash"># Install plugin from registry
mockforge plugin install auth-jwt

# Install specific version
mockforge plugin install auth-jwt@1.2.0

# List available plugins
mockforge plugin search
</code></pre>
<h3 id="from-local-file"><a class="header" href="#from-local-file">From Local File</a></h3>
<pre><code class="language-bash"># Install from local WASM file
mockforge plugin install ./my-plugin.wasm

# Install with manifest
mockforge plugin install ./my-plugin/ --manifest plugin.yaml
</code></pre>
<h3 id="from-git-repository"><a class="header" href="#from-git-repository">From Git Repository</a></h3>
<pre><code class="language-bash"># Install from Git repository
mockforge plugin install https://github.com/example/mockforge-plugin-custom.git

# Install specific branch/tag
mockforge plugin install https://github.com/example/mockforge-plugin-custom.git#v1.0.0
</code></pre>
<h2 id="plugin-management"><a class="header" href="#plugin-management">Plugin Management</a></h2>
<h3 id="list-installed-plugins-1"><a class="header" href="#list-installed-plugins-1">List Installed Plugins</a></h3>
<pre><code class="language-bash"># List all installed plugins
mockforge plugin list

# Show detailed information
mockforge plugin list --verbose

# Filter by type
mockforge plugin list --type auth
</code></pre>
<h3 id="enabledisable-plugins"><a class="header" href="#enabledisable-plugins">Enable/Disable Plugins</a></h3>
<pre><code class="language-bash"># Enable plugin
mockforge plugin enable auth-jwt

# Disable plugin
mockforge plugin disable auth-jwt

# Enable plugin for specific workspace
mockforge plugin enable auth-jwt --workspace my-workspace
</code></pre>
<h3 id="update-plugins"><a class="header" href="#update-plugins">Update Plugins</a></h3>
<pre><code class="language-bash"># Update specific plugin
mockforge plugin update auth-jwt

# Update all plugins
mockforge plugin update --all

# Check for updates
mockforge plugin outdated
</code></pre>
<h3 id="remove-plugins"><a class="header" href="#remove-plugins">Remove Plugins</a></h3>
<pre><code class="language-bash"># Remove plugin
mockforge plugin remove auth-jwt

# Remove plugin and its data
mockforge plugin remove auth-jwt --purge
</code></pre>
<h2 id="plugin-configuration-1"><a class="header" href="#plugin-configuration-1">Plugin Configuration</a></h2>
<h3 id="global-configuration"><a class="header" href="#global-configuration">Global Configuration</a></h3>
<p>Configure plugins in your MockForge configuration file:</p>
<pre><code class="language-yaml">plugins:
  enabled: true
  directory: "~/.mockforge/plugins"
  runtime:
    memory_limit_mb: 64
    cpu_limit_percent: 10
    execution_timeout_ms: 5000
  
  # Plugin-specific configuration
  auth-jwt:
    enabled: true
    config:
      secret_key: "${JWT_SECRET}"
      algorithm: "HS256"
      expiration: 3600
  
  datasource-csv:
    enabled: true
    config:
      base_directory: "./data"
      cache_ttl: 300
</code></pre>
<h3 id="environment-variables-12"><a class="header" href="#environment-variables-12">Environment Variables</a></h3>
<pre><code class="language-bash"># Plugin system settings
export MOCKFORGE_PLUGINS_ENABLED=true
export MOCKFORGE_PLUGINS_DIRECTORY=~/.mockforge/plugins

# Runtime limits
export MOCKFORGE_PLUGIN_MEMORY_LIMIT=64
export MOCKFORGE_PLUGIN_CPU_LIMIT=10
export MOCKFORGE_PLUGIN_TIMEOUT=5000

# Plugin-specific settings
export JWT_SECRET=your-secret-key
export CSV_DATA_DIR=./test-data
</code></pre>
<h2 id="developing-plugins"><a class="header" href="#developing-plugins">Developing Plugins</a></h2>
<h3 id="plugin-manifest"><a class="header" href="#plugin-manifest">Plugin Manifest</a></h3>
<p>Every plugin requires a <code>plugin.yaml</code> manifest file:</p>
<pre><code class="language-yaml"># plugin.yaml
name: "auth-jwt"
version: "1.0.0"
description: "JWT authentication provider"
author: "Your Name &lt;email@example.com&gt;"
license: "MIT"
repository: "https://github.com/example/mockforge-plugin-auth-jwt"

# Plugin metadata
type: "auth"
category: "authentication"
tags: ["jwt", "auth", "security"]

# Runtime requirements
runtime:
  wasm_version: "0.1"
  memory_limit_mb: 32
  execution_timeout_ms: 1000

# Capabilities required
capabilities:
  - "network.http.client"
  - "storage.key_value"
  - "template.functions"

# Configuration schema
config_schema:
  type: "object"
  properties:
    secret_key:
      type: "string"
      description: "JWT signing secret"
      required: true
    algorithm:
      type: "string"
      enum: ["HS256", "HS384", "HS512", "RS256"]
      default: "HS256"
    expiration:
      type: "integer"
      description: "Token expiration in seconds"
      default: 3600
      minimum: 60

# Export information
exports:
  auth_provider: "JwtAuthProvider"
  template_functions:
    - "jwt_encode"
    - "jwt_decode"
    - "jwt_verify"
</code></pre>
<h3 id="rust-plugin-development"><a class="header" href="#rust-plugin-development">Rust Plugin Development</a></h3>
<p>Create a new Rust project for your plugin:</p>
<pre><code class="language-bash">cargo new --lib mockforge-plugin-custom
cd mockforge-plugin-custom
</code></pre>
<p>Add dependencies to <code>Cargo.toml</code>:</p>
<pre><code class="language-toml">[package]
name = "mockforge-plugin-custom"
version = "0.1.0"
edition = "2021"

[lib]
crate-type = ["cdylib"]

[dependencies]
mockforge-plugin-core = "0.1.0"
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
wasm-bindgen = "0.2"

[dependencies.web-sys]
version = "0.3"
features = [
  "console",
]
</code></pre>
<p>Implement your plugin in <code>src/lib.rs</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_plugin_core::{
    AuthProvider, AuthResult, PluginConfig, PluginError, PluginResult,
    export_auth_provider, export_template_functions
};
use serde::{Deserialize, Serialize};
use wasm_bindgen::prelude::*;

#[derive(Deserialize)]
struct JwtConfig {
    secret_key: String,
    algorithm: String,
    expiration: u64,
}

pub struct JwtAuthProvider {
    config: JwtConfig,
}

impl JwtAuthProvider {
    pub fn new(config: PluginConfig) -&gt; PluginResult&lt;Self&gt; {
        let jwt_config: JwtConfig = serde_json::from_value(config.into())?;
        Ok(Self { config: jwt_config })
    }
}

impl AuthProvider for JwtAuthProvider {
    fn authenticate(&amp;self, token: &amp;str) -&gt; PluginResult&lt;AuthResult&gt; {
        // Implement JWT validation logic
        match self.verify_jwt(token) {
            Ok(claims) =&gt; Ok(AuthResult::success(claims)),
            Err(e) =&gt; Ok(AuthResult::failure(e.to_string())),
        }
    }
    
    fn generate_token(&amp;self, user_id: &amp;str) -&gt; PluginResult&lt;String&gt; {
        // Implement JWT generation logic
        self.create_jwt(user_id)
    }
}

impl JwtAuthProvider {
    fn verify_jwt(&amp;self, token: &amp;str) -&gt; Result&lt;serde_json::Value, PluginError&gt; {
        // JWT verification implementation
        todo!("Implement JWT verification")
    }
    
    fn create_jwt(&amp;self, user_id: &amp;str) -&gt; PluginResult&lt;String&gt; {
        // JWT creation implementation
        todo!("Implement JWT creation")
    }
}

// Template functions
#[wasm_bindgen]
pub fn jwt_encode(payload: &amp;str, secret: &amp;str) -&gt; String {
    // Implement JWT encoding for templates
    todo!("Implement template JWT encoding")
}

#[wasm_bindgen]
pub fn jwt_decode(token: &amp;str) -&gt; String {
    // Implement JWT decoding for templates
    todo!("Implement template JWT decoding")
}

// Export plugin interfaces
export_auth_provider!(JwtAuthProvider);
export_template_functions! {
    "jwt_encode" =&gt; jwt_encode,
    "jwt_decode" =&gt; jwt_decode,
}
<span class="boring">}</span></code></pre></pre>
<h3 id="building-plugins"><a class="header" href="#building-plugins">Building Plugins</a></h3>
<p>Build your plugin to WebAssembly:</p>
<pre><code class="language-bash"># Install wasm-pack if not already installed
cargo install wasm-pack

# Build the plugin
wasm-pack build --target web --out-dir pkg

# The WASM file will be in pkg/mockforge_plugin_custom.wasm
</code></pre>
<h3 id="testing-plugins"><a class="header" href="#testing-plugins">Testing Plugins</a></h3>
<p>MockForge provides a testing framework for plugins:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod tests {
    use super::*;
    use mockforge_plugin_core::test_utils::*;

    #[test]
    fn test_jwt_authentication() {
        let config = test_config! {
            "secret_key": "test-secret",
            "algorithm": "HS256",
            "expiration": 3600
        };
        
        let provider = JwtAuthProvider::new(config).unwrap();
        
        // Test valid token
        let token = provider.generate_token("user123").unwrap();
        let result = provider.authenticate(&amp;token).unwrap();
        assert!(result.is_success());
        
        // Test invalid token
        let invalid_result = provider.authenticate("invalid.token.here").unwrap();
        assert!(invalid_result.is_failure());
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="plugin-examples"><a class="header" href="#plugin-examples">Plugin Examples</a></h2>
<p>MockForge includes several example plugins to demonstrate different capabilities:</p>
<h3 id="authentication-plugins-1"><a class="header" href="#authentication-plugins-1">Authentication Plugins</a></h3>
<h4 id="basic-authentication-auth-basic"><a class="header" href="#basic-authentication-auth-basic">Basic Authentication (<code>auth-basic</code>)</a></h4>
<pre><code class="language-yaml"># examples/plugins/auth-basic/plugin.yaml
name: "auth-basic"
type: "auth"
description: "HTTP Basic Authentication provider"

config_schema:
  type: "object"
  properties:
    users:
      type: "object"
      description: "Username to password mapping"
    realm:
      type: "string"
      default: "MockForge"
</code></pre>
<p>Usage in MockForge configuration:</p>
<pre><code class="language-yaml">plugins:
  auth-basic:
    enabled: true
    config:
      realm: "API Access"
      users:
        admin: "password123"
        user: "userpass"
</code></pre>
<h4 id="jwt-authentication-auth-jwt"><a class="header" href="#jwt-authentication-auth-jwt">JWT Authentication (<code>auth-jwt</code>)</a></h4>
<p>Advanced JWT authentication with support for multiple algorithms:</p>
<pre><code class="language-yaml"># examples/plugins/auth-jwt/plugin.yaml
name: "auth-jwt"
type: "auth"
description: "JWT authentication provider with multiple algorithm support"

capabilities:
  - "storage.key_value"
  - "template.functions"

config_schema:
  type: "object"
  properties:
    secret_key:
      type: "string"
      required: true
    algorithm:
      type: "string"
      enum: ["HS256", "HS384", "HS512", "RS256", "RS384", "RS512"]
      default: "HS256"
    issuer:
      type: "string"
      description: "JWT issuer claim"
    audience:
      type: "string"
      description: "JWT audience claim"
</code></pre>
<h3 id="data-source-plugins-1"><a class="header" href="#data-source-plugins-1">Data Source Plugins</a></h3>
<h4 id="csv-data-source-datasource-csv"><a class="header" href="#csv-data-source-datasource-csv">CSV Data Source (<code>datasource-csv</code>)</a></h4>
<p>Connect to CSV files as data sources:</p>
<pre><code class="language-yaml"># examples/plugins/datasource-csv/plugin.yaml
name: "datasource-csv"
type: "datasource"
description: "CSV file data source connector"

config_schema:
  type: "object"
  properties:
    base_directory:
      type: "string"
      description: "Base directory for CSV files"
      required: true
    cache_ttl:
      type: "integer"
      description: "Cache TTL in seconds"
      default: 300
    delimiter:
      type: "string"
      description: "CSV delimiter"
      default: ","
</code></pre>
<p>Usage in templates:</p>
<pre><code class="language-yaml">response:
  status: 200
  body:
    users: "{{datasource.csv('users.csv').random(5)}}"
    products: "{{datasource.csv('products.csv').filter('category', 'electronics')}}"
</code></pre>
<h3 id="template-plugins-2"><a class="header" href="#template-plugins-2">Template Plugins</a></h3>
<h4 id="crypto-functions-template-crypto"><a class="header" href="#crypto-functions-template-crypto">Crypto Functions (<code>template-crypto</code>)</a></h4>
<p>Add cryptographic template functions:</p>
<pre><code class="language-yaml"># examples/plugins/template-crypto/plugin.yaml
name: "template-crypto"
type: "template"
description: "Cryptographic template functions"

exports:
  template_functions:
    - "crypto_hash"
    - "crypto_hmac"
    - "crypto_encrypt"
    - "crypto_decrypt"
    - "crypto_random"
</code></pre>
<p>Template usage:</p>
<pre><code class="language-yaml">response:
  body:
    user_id: "{{uuid}}"
    password_hash: "{{crypto_hash(faker.password, 'sha256')}}"
    api_key: "{{crypto_random(32, 'hex')}}"
    signature: "{{crypto_hmac(request.body, env.API_SECRET, 'sha256')}}"
</code></pre>
<h3 id="response-plugins-2"><a class="header" href="#response-plugins-2">Response Plugins</a></h3>
<h4 id="graphql-response-generator-response-graphql"><a class="header" href="#graphql-response-generator-response-graphql">GraphQL Response Generator (<code>response-graphql</code>)</a></h4>
<p>Generate GraphQL responses from schema:</p>
<pre><code class="language-yaml"># examples/plugins/response-graphql/plugin.yaml
name: "response-graphql"
type: "response"
description: "GraphQL response generator"

config_schema:
  type: "object"
  properties:
    schema_file:
      type: "string"
      description: "Path to GraphQL schema file"
      required: true
    resolvers:
      type: "object"
      description: "Custom resolver configuration"
</code></pre>
<h2 id="security-considerations-5"><a class="header" href="#security-considerations-5">Security Considerations</a></h2>
<h3 id="capability-system"><a class="header" href="#capability-system">Capability System</a></h3>
<p>Plugins must declare required capabilities:</p>
<pre><code class="language-yaml"># plugin.yaml
capabilities:
  - "network.http.client"     # Make HTTP requests
  - "network.http.server"     # Handle HTTP requests
  - "storage.key_value"       # Access key-value storage
  - "storage.file.read"       # Read files
  - "storage.file.write"      # Write files
  - "template.functions"      # Register template functions
  - "crypto.random"           # Access random number generation
  - "crypto.hash"             # Access hashing functions
</code></pre>
<h3 id="resource-limits"><a class="header" href="#resource-limits">Resource Limits</a></h3>
<p>Configure resource limits per plugin:</p>
<pre><code class="language-yaml">plugins:
  my-plugin:
    runtime:
      memory_limit_mb: 64        # Maximum memory usage
      cpu_limit_percent: 5       # Maximum CPU usage
      execution_timeout_ms: 2000 # Maximum execution time
      network_timeout_ms: 1000   # Network request timeout
</code></pre>
<h3 id="sandboxing"><a class="header" href="#sandboxing">Sandboxing</a></h3>
<p>Plugins run in a secure sandbox that:</p>
<ul>
<li>Prevents access to the host file system outside permitted directories</li>
<li>Limits network access to declared endpoints</li>
<li>Restricts system calls and resource usage</li>
<li>Isolates plugin memory from the host process</li>
</ul>
<h2 id="best-practices-20"><a class="header" href="#best-practices-20">Best Practices</a></h2>
<h3 id="plugin-development-1"><a class="header" href="#plugin-development-1">Plugin Development</a></h3>
<ol>
<li><strong>Keep plugins focused</strong>: Each plugin should have a single, clear purpose</li>
<li><strong>Minimize resource usage</strong>: Use efficient algorithms and limit memory allocation</li>
<li><strong>Handle errors gracefully</strong>: Return meaningful error messages</li>
<li><strong>Document configuration</strong>: Provide clear schema and examples</li>
<li><strong>Test thoroughly</strong>: Include comprehensive tests for all functionality</li>
</ol>
<h3 id="plugin-usage"><a class="header" href="#plugin-usage">Plugin Usage</a></h3>
<ol>
<li><strong>Review plugin capabilities</strong>: Understand what permissions plugins require</li>
<li><strong>Monitor resource usage</strong>: Check plugin performance and resource consumption</li>
<li><strong>Keep plugins updated</strong>: Regularly update to get security fixes and improvements</li>
<li><strong>Use official plugins</strong>: Prefer plugins from trusted sources</li>
<li><strong>Test in development</strong>: Thoroughly test plugins before production use</li>
</ol>
<h3 id="security-1"><a class="header" href="#security-1">Security</a></h3>
<ol>
<li><strong>Audit plugin code</strong>: Review plugin source code when possible</li>
<li><strong>Limit capabilities</strong>: Only grant necessary permissions</li>
<li><strong>Monitor logs</strong>: Watch for suspicious plugin behavior</li>
<li><strong>Use resource limits</strong>: Prevent plugins from consuming excessive resources</li>
<li><strong>Isolate environments</strong>: Use separate plugin configurations for development and production</li>
</ol>
<h2 id="troubleshooting-31"><a class="header" href="#troubleshooting-31">Troubleshooting</a></h2>
<h3 id="common-issues-9"><a class="header" href="#common-issues-9">Common Issues</a></h3>
<h4 id="plugin-wont-load"><a class="header" href="#plugin-wont-load">Plugin Won‚Äôt Load</a></h4>
<pre><code class="language-bash"># Check plugin status
mockforge plugin status my-plugin

# Validate plugin manifest
mockforge plugin validate ./my-plugin/plugin.yaml

# Check logs for errors
mockforge logs --filter "plugin"
</code></pre>
<h4 id="runtime-errors"><a class="header" href="#runtime-errors">Runtime Errors</a></h4>
<pre><code class="language-bash"># Enable debug logging
RUST_LOG=mockforge_plugin_loader=debug mockforge serve

# Check resource limits
mockforge plugin stats my-plugin

# Validate configuration
mockforge plugin config validate my-plugin
</code></pre>
<h4 id="performance-issues-4"><a class="header" href="#performance-issues-4">Performance Issues</a></h4>
<pre><code class="language-bash"># Monitor plugin performance
mockforge plugin stats --watch

# Check memory usage
mockforge plugin stats --memory

# Profile plugin execution
mockforge plugin profile my-plugin
</code></pre>
<h3 id="debug-mode"><a class="header" href="#debug-mode">Debug Mode</a></h3>
<p>Enable debug mode for plugin development:</p>
<pre><code class="language-yaml">plugins:
  debug_mode: true
  verbose_logging: true
  enable_profiling: true
</code></pre>
<p>This comprehensive plugin system enables powerful extensibility while maintaining security and performance. Plugins can significantly extend MockForge‚Äôs capabilities for specialized use cases and integrations.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="security--encryption"><a class="header" href="#security--encryption">Security &amp; Encryption</a></h1>
<p>MockForge provides enterprise-grade security features including end-to-end encryption, secure key management, and comprehensive authentication systems to protect your mock data and configurations.</p>
<h2 id="overview-10"><a class="header" href="#overview-10">Overview</a></h2>
<p>MockForge‚Äôs security features include:</p>
<ul>
<li><strong>End-to-End Encryption</strong>: AES-256-GCM and ChaCha20-Poly1305 algorithms</li>
<li><strong>Hierarchical Key Management</strong>: Master keys, workspace keys, and session keys</li>
<li><strong>Auto-Encryption</strong>: Automatic encryption of sensitive configuration data</li>
<li><strong>Secure Storage</strong>: OS keychain integration and file-based key storage</li>
<li><strong>Template Encryption</strong>: Built-in encryption/decryption functions in templates</li>
<li><strong>Role-Based Access Control</strong>: Admin and viewer roles in the UI</li>
<li><strong>Plugin Security</strong>: Sandboxed plugin execution with capability controls</li>
</ul>
<h2 id="encryption-setup"><a class="header" href="#encryption-setup">Encryption Setup</a></h2>
<h3 id="initial-configuration"><a class="header" href="#initial-configuration">Initial Configuration</a></h3>
<p>Enable encryption when starting MockForge:</p>
<pre><code class="language-bash"># Enable encryption with environment variables
export MOCKFORGE_ENCRYPTION_ENABLED=true
export MOCKFORGE_ENCRYPTION_ALGORITHM=aes-256-gcm
export MOCKFORGE_KEY_STORE_PATH=~/.mockforge/keys

# Start MockForge with encryption
mockforge serve --config config.yaml
</code></pre>
<h3 id="configuration-file-4"><a class="header" href="#configuration-file-4">Configuration File</a></h3>
<p>Configure encryption in your YAML configuration:</p>
<pre><code class="language-yaml"># config.yaml
encryption:
  enabled: true
  algorithm: "aes-256-gcm"  # or "chacha20-poly1305"
  key_store:
    type: "file"  # or "os_keychain"
    path: "~/.mockforge/keys"
    auto_create: true
  
  # Auto-encryption rules
  auto_encrypt:
    enabled: true
    patterns:
      - "*.password"
      - "*.secret"
      - "*.key"
      - "*.token"
      - "auth.headers.*"
      - "database.connection_string"
  
  # Key rotation
  rotation:
    enabled: true
    interval_days: 30
    backup_count: 5
</code></pre>
<h2 id="key-management"><a class="header" href="#key-management">Key Management</a></h2>
<h3 id="key-hierarchy"><a class="header" href="#key-hierarchy">Key Hierarchy</a></h3>
<p>MockForge uses a hierarchical key system:</p>
<ol>
<li><strong>Master Key</strong>: Root encryption key stored securely</li>
<li><strong>Workspace Keys</strong>: Per-workspace encryption keys derived from master key</li>
<li><strong>Session Keys</strong>: Temporary keys for active sessions</li>
<li><strong>Data Keys</strong>: Keys for encrypting specific data elements</li>
</ol>
<h3 id="key-storage-options"><a class="header" href="#key-storage-options">Key Storage Options</a></h3>
<h4 id="file-based-storage"><a class="header" href="#file-based-storage">File-Based Storage</a></h4>
<p>Store keys in encrypted files on the local filesystem:</p>
<pre><code class="language-yaml">encryption:
  key_store:
    type: "file"
    path: "~/.mockforge/keys"
    permissions: "0600"  # Owner read/write only
    backup_enabled: true
    backup_path: "~/.mockforge/keys.backup"
</code></pre>
<h4 id="os-keychain-integration"><a class="header" href="#os-keychain-integration">OS Keychain Integration</a></h4>
<p>Use the operating system‚Äôs secure keychain:</p>
<pre><code class="language-yaml">encryption:
  key_store:
    type: "os_keychain"
    service_name: "mockforge"
    account_prefix: "workspace_"
</code></pre>
<p><strong>Supported Platforms:</strong></p>
<ul>
<li><strong>macOS</strong>: Uses Keychain Services</li>
<li><strong>Windows</strong>: Uses Windows Credential Manager</li>
<li><strong>Linux</strong>: Uses Secret Service API (GNOME Keyring, KWallet)</li>
</ul>
<h3 id="key-generation"><a class="header" href="#key-generation">Key Generation</a></h3>
<p>MockForge automatically generates keys when needed:</p>
<pre><code class="language-bash"># Initialize new key store
mockforge keys init --algorithm aes-256-gcm

# Generate workspace key
mockforge keys generate --workspace my-workspace

# Rotate all keys
mockforge keys rotate --all

# Export keys for backup (encrypted)
mockforge keys export --output keys-backup.enc
</code></pre>
<h3 id="key-rotation"><a class="header" href="#key-rotation">Key Rotation</a></h3>
<p>Implement automatic key rotation for enhanced security:</p>
<pre><code class="language-yaml">encryption:
  rotation:
    enabled: true
    interval_days: 30
    max_key_age_days: 90
    backup_old_keys: true
    notify_before_rotation_days: 7
</code></pre>
<h2 id="encryption-algorithms"><a class="header" href="#encryption-algorithms">Encryption Algorithms</a></h2>
<h3 id="aes-256-gcm-default"><a class="header" href="#aes-256-gcm-default">AES-256-GCM (Default)</a></h3>
<pre><code class="language-yaml">encryption:
  algorithm: "aes-256-gcm"
  config:
    key_size: 256
    iv_size: 12
    tag_size: 16
</code></pre>
<p><strong>Features:</strong></p>
<ul>
<li><strong>Performance</strong>: Optimized for speed on modern CPUs</li>
<li><strong>Security</strong>: NIST-approved, widely audited</li>
<li><strong>Authentication</strong>: Built-in message authentication</li>
<li><strong>Hardware Support</strong>: AES-NI acceleration on Intel/AMD</li>
</ul>
<h3 id="chacha20-poly1305"><a class="header" href="#chacha20-poly1305">ChaCha20-Poly1305</a></h3>
<pre><code class="language-yaml">encryption:
  algorithm: "chacha20-poly1305"
  config:
    key_size: 256
    nonce_size: 12
    tag_size: 16
</code></pre>
<p><strong>Features:</strong></p>
<ul>
<li><strong>Performance</strong>: Excellent on ARM and older CPUs</li>
<li><strong>Security</strong>: Modern, quantum-resistant design</li>
<li><strong>Authentication</strong>: Integrated Poly1305 MAC</li>
<li><strong>Simplicity</strong>: Fewer implementation pitfalls</li>
</ul>
<h2 id="auto-encryption"><a class="header" href="#auto-encryption">Auto-Encryption</a></h2>
<p>MockForge automatically encrypts sensitive data based on configurable patterns:</p>
<h3 id="configuration-patterns"><a class="header" href="#configuration-patterns">Configuration Patterns</a></h3>
<pre><code class="language-yaml">encryption:
  auto_encrypt:
    enabled: true
    patterns:
      # Password fields
      - "*.password"
      - "*.passwd"
      - "auth.password"
      
      # API keys and tokens
      - "*.api_key"
      - "*.secret_key"
      - "*.access_token"
      - "*.refresh_token"
      
      # Database connections
      - "database.password"
      - "database.connection_string"
      - "redis.password"
      
      # HTTP headers
      - "auth.headers.Authorization"
      - "auth.headers.X-API-Key"
      
      # Custom patterns
      - "custom.sensitive_data.*"
</code></pre>
<h3 id="field-level-encryption"><a class="header" href="#field-level-encryption">Field-Level Encryption</a></h3>
<p>Encrypt specific fields in your configurations:</p>
<pre><code class="language-yaml"># Original configuration
database:
  host: "localhost"
  port: 5432
  username: "user"
  password: "secret123"  # Will be auto-encrypted
  
auth:
  jwt_secret: "my-secret"  # Will be auto-encrypted
  
# After auto-encryption
database:
  host: "localhost"
  port: 5432
  username: "user"
  password: "{{encrypted:AES256:base64-encrypted-data}}"
  
auth:
  jwt_secret: "{{encrypted:AES256:base64-encrypted-data}}"
</code></pre>
<h2 id="template-encryption-functions"><a class="header" href="#template-encryption-functions">Template Encryption Functions</a></h2>
<p>Use encryption functions directly in your templates:</p>
<h3 id="encryption-functions-1"><a class="header" href="#encryption-functions-1">Encryption Functions</a></h3>
<pre><code class="language-yaml"># Encrypt data in templates
response:
  body:
    user_id: "{{uuid}}"
    encrypted_data: "{{encrypt('sensitive-data', 'workspace-key')}}"
    hashed_password: "{{hash('password123', 'sha256')}}"
    signed_token: "{{sign(user_data, 'signing-key')}}"
</code></pre>
<h3 id="decryption-functions"><a class="header" href="#decryption-functions">Decryption Functions</a></h3>
<pre><code class="language-yaml"># Decrypt data in templates
request:
  headers:
    Authorization: "Bearer {{decrypt(encrypted_token, 'workspace-key')}}"
  body:
    password: "{{decrypt(user.encrypted_password, 'user-key')}}"
</code></pre>
<h3 id="available-functions"><a class="header" href="#available-functions">Available Functions</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Function</th><th>Description</th><th>Example</th></tr></thead><tbody>
<tr><td><code>encrypt(data, key)</code></td><td>Encrypt data with specified key</td><td><code>{{encrypt('secret', 'my-key')}}</code></td></tr>
<tr><td><code>decrypt(data, key)</code></td><td>Decrypt data with specified key</td><td><code>{{decrypt(encrypted_data, 'my-key')}}</code></td></tr>
<tr><td><code>hash(data, algorithm)</code></td><td>Hash data with algorithm</td><td><code>{{hash('password', 'sha256')}}</code></td></tr>
<tr><td><code>hmac(data, key, algorithm)</code></td><td>Generate HMAC signature</td><td><code>{{hmac(message, 'secret', 'sha256')}}</code></td></tr>
<tr><td><code>sign(data, key)</code></td><td>Sign data with private key</td><td><code>{{sign(payload, 'private-key')}}</code></td></tr>
<tr><td><code>verify(data, signature, key)</code></td><td>Verify signature with public key</td><td><code>{{verify(data, sig, 'public-key')}}</code></td></tr>
</tbody></table>
</div>
<h2 id="mutual-tls-mtls"><a class="header" href="#mutual-tls-mtls">Mutual TLS (mTLS)</a></h2>
<p>MockForge supports <strong>Mutual TLS (mTLS)</strong> for enhanced security, requiring both server and client certificates for authentication.</p>
<h3 id="quick-start-7"><a class="header" href="#quick-start-7">Quick Start</a></h3>
<p>Enable mTLS in your configuration:</p>
<pre><code class="language-yaml">http:
  tls:
    enabled: true
    cert_file: "./certs/server.crt"
    key_file: "./certs/server.key"
    ca_file: "./certs/ca.crt"           # CA certificate for client verification
    require_client_cert: true            # Enable mTLS
</code></pre>
<h3 id="client-configuration"><a class="header" href="#client-configuration">Client Configuration</a></h3>
<p>Clients must provide a certificate signed by the CA:</p>
<pre><code class="language-bash"># Using cURL
curl --cert client.crt --key client.key --cacert ca.crt \
  https://localhost:3000/api/endpoint
</code></pre>
<h3 id="certificate-generation"><a class="header" href="#certificate-generation">Certificate Generation</a></h3>
<p>For development, use <code>mkcert</code>:</p>
<pre><code class="language-bash"># Install mkcert
brew install mkcert
mkcert -install

# Generate certificates
mkcert localhost 127.0.0.1 ::1
mkcert -client localhost 127.0.0.1 ::1
</code></pre>
<p>For production, use OpenSSL or a trusted Certificate Authority.</p>
<p><strong>Full Documentation:</strong> See <a href="user-guide/../../docs/mTLS_CONFIGURATION.html">mTLS Configuration Guide</a> for complete setup instructions, certificate generation, client examples, and troubleshooting.</p>
<h2 id="authentication--authorization"><a class="header" href="#authentication--authorization">Authentication &amp; Authorization</a></h2>
<h3 id="admin-ui-authentication"><a class="header" href="#admin-ui-authentication">Admin UI Authentication</a></h3>
<p>MockForge Admin UI v2 includes <strong>complete role-based authentication</strong> with JWT-based authentication:</p>
<pre><code class="language-yaml">admin:
  auth:
    enabled: true
    jwt_secret: "{{encrypted:your-jwt-secret}}"
    session_timeout: 86400  # 24 hours
    
    # Built-in users
    users:
      admin:
        password: "{{encrypted:admin-password}}"
        role: "admin"
      viewer:
        password: "{{encrypted:viewer-password}}"
        role: "viewer"
        
    # Custom authentication provider
    provider: "custom"
    provider_config:
      ldap_url: "ldap://company.com"
      oauth2_client_id: "mockforge-client"
</code></pre>
<h3 id="role-permissions"><a class="header" href="#role-permissions">Role Permissions</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Role</th><th>Permissions</th></tr></thead><tbody>
<tr><td><strong>Admin</strong></td><td>Full access to all features (workspace management, member management, all editing)</td></tr>
<tr><td><strong>Editor</strong></td><td>Create, edit, and delete mocks; view history; cannot manage workspace settings</td></tr>
<tr><td><strong>Viewer</strong></td><td>Read-only access to dashboard, logs, metrics, and mocks</td></tr>
</tbody></table>
</div>
<p><strong>Full Documentation:</strong> See <a href="user-guide/../../docs/RBAC_GUIDE.html">RBAC Guide</a> for complete role and permission details.</p>
<h3 id="custom-authentication"><a class="header" href="#custom-authentication">Custom Authentication</a></h3>
<p>Implement custom authentication via plugins:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Custom auth plugin
use mockforge_plugin_core::{AuthProvider, AuthResult};

pub struct LdapAuthProvider {
    ldap_url: String,
    base_dn: String,
}

impl AuthProvider for LdapAuthProvider {
    fn authenticate(&amp;self, username: &amp;str, password: &amp;str) -&gt; AuthResult {
        // LDAP authentication logic
        match self.ldap_authenticate(username, password) {
            Ok(user_info) =&gt; AuthResult::success(user_info),
            Err(e) =&gt; AuthResult::failure(e.to_string()),
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="plugin-security-1"><a class="header" href="#plugin-security-1">Plugin Security</a></h2>
<h3 id="capability-system-1"><a class="header" href="#capability-system-1">Capability System</a></h3>
<p>Plugins must declare required capabilities:</p>
<pre><code class="language-yaml"># plugin.yaml
capabilities:
  - "crypto.encrypt"      # Encryption functions
  - "crypto.decrypt"      # Decryption functions
  - "crypto.hash"         # Hashing functions
  - "crypto.random"       # Random number generation
  - "storage.encrypted"   # Encrypted storage access
  - "network.tls"         # TLS/SSL connections
</code></pre>
<h3 id="resource-limits-1"><a class="header" href="#resource-limits-1">Resource Limits</a></h3>
<p>Configure security limits for plugins:</p>
<pre><code class="language-yaml">plugins:
  security:
    memory_limit_mb: 64
    cpu_limit_percent: 5
    network_timeout_ms: 5000
    file_access_paths:
      - "/app/data"
      - "/tmp/plugin-cache"
    
    # Encryption access
    encryption_access:
      allowed_algorithms: ["aes-256-gcm"]
      key_access_patterns: ["workspace.*", "plugin.*"]
</code></pre>
<h3 id="sandboxing-1"><a class="header" href="#sandboxing-1">Sandboxing</a></h3>
<p>Plugins run in secure sandboxes that:</p>
<ul>
<li><strong>Isolate Memory</strong>: Separate memory space from host process</li>
<li><strong>Limit File Access</strong>: Restricted to declared paths only</li>
<li><strong>Control Network</strong>: Limited to specified endpoints</li>
<li><strong>Monitor Resources</strong>: CPU, memory, and execution time limits</li>
<li><strong>Audit Operations</strong>: Log all security-relevant operations</li>
</ul>
<h2 id="transport-security"><a class="header" href="#transport-security">Transport Security</a></h2>
<h3 id="tls-configuration"><a class="header" href="#tls-configuration">TLS Configuration</a></h3>
<p>Enable TLS for all network communication:</p>
<pre><code class="language-yaml"># Server TLS
server:
  tls:
    enabled: true
    cert_file: "/path/to/server.crt"
    key_file: "/path/to/server.key"
    min_version: "1.3"
    cipher_suites:
      - "TLS_AES_256_GCM_SHA384"
      - "TLS_CHACHA20_POLY1305_SHA256"

# Client TLS (for outbound requests)
client:
  tls:
    verify_certificates: true
    ca_bundle: "/path/to/ca-bundle.crt"
    client_cert: "/path/to/client.crt"
    client_key: "/path/to/client.key"
</code></pre>
<h3 id="certificate-management"><a class="header" href="#certificate-management">Certificate Management</a></h3>
<pre><code class="language-bash"># Generate self-signed certificates for development
mockforge certs generate --domain localhost --output ./certs/

# Use Let's Encrypt for production
mockforge certs letsencrypt --domain api.mockforge.dev --email admin@company.com

# Import existing certificates
mockforge certs import --cert server.crt --key server.key --ca ca.crt
</code></pre>
<h2 id="security-best-practices"><a class="header" href="#security-best-practices">Security Best Practices</a></h2>
<h3 id="configuration-security"><a class="header" href="#configuration-security">Configuration Security</a></h3>
<ol>
<li><strong>Encrypt Sensitive Data</strong>: Use auto-encryption for passwords and keys</li>
<li><strong>Secure Key Storage</strong>: Use OS keychain in production</li>
<li><strong>Regular Key Rotation</strong>: Implement automatic key rotation</li>
<li><strong>Least Privilege</strong>: Grant minimal necessary permissions</li>
<li><strong>Audit Logging</strong>: Enable comprehensive security logging</li>
</ol>
<h3 id="deployment-security"><a class="header" href="#deployment-security">Deployment Security</a></h3>
<ol>
<li><strong>Use TLS</strong>: Enable TLS for all network communication</li>
<li><strong>Network Isolation</strong>: Deploy in isolated network segments</li>
<li><strong>Access Control</strong>: Implement proper firewall rules</li>
<li><strong>Monitor Security</strong>: Set up security monitoring and alerting</li>
<li><strong>Regular Updates</strong>: Keep MockForge and dependencies updated</li>
</ol>
<h3 id="plugin-security-2"><a class="header" href="#plugin-security-2">Plugin Security</a></h3>
<ol>
<li><strong>Review Plugin Code</strong>: Audit plugin source code before installation</li>
<li><strong>Limit Capabilities</strong>: Grant only necessary plugin permissions</li>
<li><strong>Monitor Resources</strong>: Watch plugin resource usage</li>
<li><strong>Isolate Environments</strong>: Use separate configs for dev/prod</li>
<li><strong>Update Regularly</strong>: Keep plugins updated for security fixes</li>
</ol>
<h2 id="security-monitoring"><a class="header" href="#security-monitoring">Security Monitoring</a></h2>
<h3 id="audit-logging"><a class="header" href="#audit-logging">Audit Logging</a></h3>
<p>Enable comprehensive security logging:</p>
<pre><code class="language-yaml">logging:
  security:
    enabled: true
    level: "info"
    destinations:
      - type: "file"
        path: "/var/log/mockforge/security.log"
        format: "json"
      - type: "syslog"
        facility: "local0"
        tag: "mockforge-security"
    
    events:
      - "auth_success"
      - "auth_failure"
      - "key_access"
      - "encryption_operation"
      - "plugin_security_violation"
      - "configuration_change"
</code></pre>
<h3 id="security-metrics"><a class="header" href="#security-metrics">Security Metrics</a></h3>
<p>Monitor security-related metrics:</p>
<pre><code class="language-yaml">metrics:
  security:
    enabled: true
    metrics:
      - "auth_attempts_total"
      - "auth_failures_total"
      - "encryption_operations_total"
      - "key_rotations_total"
      - "plugin_security_violations_total"
</code></pre>
<h3 id="alerting"><a class="header" href="#alerting">Alerting</a></h3>
<p>Set up security alerts:</p>
<pre><code class="language-yaml">alerts:
  security:
    enabled: true
    rules:
      - name: "High Authentication Failures"
        condition: "auth_failures_rate &gt; 10/minute"
        action: "email_admin"
      
      - name: "Plugin Security Violation"
        condition: "plugin_security_violations &gt; 0"
        action: "disable_plugin"
      
      - name: "Encryption Key Access Anomaly"
        condition: "key_access_rate &gt; 100/minute"
        action: "alert_security_team"
</code></pre>
<h2 id="compliance--standards"><a class="header" href="#compliance--standards">Compliance &amp; Standards</a></h2>
<h3 id="standards-compliance"><a class="header" href="#standards-compliance">Standards Compliance</a></h3>
<p>MockForge security features comply with:</p>
<ul>
<li><strong>FIPS 140-2</strong>: Cryptographic standards compliance</li>
<li><strong>Common Criteria</strong>: Security evaluation criteria</li>
<li><strong>SOC 2 Type II</strong>: Security, availability, and confidentiality</li>
<li><strong>ISO 27001</strong>: Information security management</li>
</ul>
<h3 id="data-protection"><a class="header" href="#data-protection">Data Protection</a></h3>
<p>Features for data protection compliance:</p>
<ul>
<li><strong>Data Encryption</strong>: All sensitive data encrypted at rest and in transit</li>
<li><strong>Key Management</strong>: Secure key lifecycle management</li>
<li><strong>Access Controls</strong>: Role-based access and audit trails</li>
<li><strong>Data Minimization</strong>: Only collect and store necessary data</li>
<li><strong>Right to Deletion</strong>: Secure data deletion capabilities</li>
</ul>
<h2 id="audit-logging-1"><a class="header" href="#audit-logging-1">Audit Logging</a></h2>
<p>MockForge provides comprehensive audit logging for security and compliance:</p>
<ul>
<li><strong>Authentication Audit Logs</strong>: Track all authentication attempts (success/failure)</li>
<li><strong>Request Logs</strong>: Full request/response logging with metadata</li>
<li><strong>Collaboration History</strong>: Git-style version control for workspace changes</li>
<li><strong>Configuration Changes</strong>: Track all configuration modifications</li>
<li><strong>Plugin Activity</strong>: Monitor plugin execution and security events</li>
</ul>
<p><strong>Full Documentation:</strong> See <a href="user-guide/../../docs/AUDIT_TRAILS.html">Audit Trails Guide</a> for complete audit logging configuration and usage.</p>
<h2 id="troubleshooting-security"><a class="header" href="#troubleshooting-security">Troubleshooting Security</a></h2>
<h3 id="common-issues-10"><a class="header" href="#common-issues-10">Common Issues</a></h3>
<h4 id="encryption-not-working"><a class="header" href="#encryption-not-working">Encryption Not Working</a></h4>
<pre><code class="language-bash"># Check encryption status
mockforge encryption status

# Verify key store
mockforge keys list

# Test encryption/decryption
mockforge encrypt test-data --key workspace-key
</code></pre>
<h4 id="authentication-failures"><a class="header" href="#authentication-failures">Authentication Failures</a></h4>
<pre><code class="language-bash"># Check auth configuration
mockforge auth status

# Verify JWT secret
mockforge auth verify-jwt your-token

# Reset admin credentials
mockforge auth reset-admin
</code></pre>
<h4 id="key-store-issues"><a class="header" href="#key-store-issues">Key Store Issues</a></h4>
<pre><code class="language-bash"># Initialize key store
mockforge keys init --force

# Repair key store
mockforge keys repair

# Backup and restore
mockforge keys backup --output keys.backup
mockforge keys restore --input keys.backup
</code></pre>
<h3 id="debug-mode-1"><a class="header" href="#debug-mode-1">Debug Mode</a></h3>
<p>Enable security debug logging:</p>
<pre><code class="language-bash">RUST_LOG=mockforge_core::encryption=debug,mockforge_core::auth=debug mockforge serve
</code></pre>
<p>This comprehensive security system ensures that MockForge can be safely used in enterprise environments while protecting sensitive mock data and configurations.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="directory-synchronization"><a class="header" href="#directory-synchronization">Directory Synchronization</a></h1>
<p>MockForge‚Äôs sync daemon enables automatic synchronization between workspace files and MockForge‚Äôs internal storage, allowing you to work with your mock API definitions as files and keep them in version control.</p>
<h2 id="overview-11"><a class="header" href="#overview-11">Overview</a></h2>
<p>The sync daemon monitors a directory for <code>.yaml</code> and <code>.yml</code> files and automatically imports them into MockForge workspaces. This enables:</p>
<ul>
<li><strong>File-based workflows</strong>: Edit workspace files with your favorite text editor</li>
<li><strong>Version control</strong>: Keep workspace definitions in Git</li>
<li><strong>Team collaboration</strong>: Share workspaces via Git repositories</li>
<li><strong>Automated workflows</strong>: CI/CD integration and automated deployment</li>
<li><strong>Real-time feedback</strong>: See exactly what‚Äôs being synced as it happens</li>
</ul>
<h2 id="how-it-works-2"><a class="header" href="#how-it-works-2">How It Works</a></h2>
<p>The sync daemon provides bidirectional synchronization:</p>
<ol>
<li><strong>Monitors Directory</strong>: Watches for file changes in the specified workspace directory</li>
<li><strong>Detects Changes</strong>: Identifies created, modified, and deleted <code>.yaml</code>/<code>.yml</code> files</li>
<li><strong>Imports Automatically</strong>: Parses and imports valid MockRequest files into workspaces</li>
<li><strong>Provides Feedback</strong>: Shows clear, real-time output of all sync operations</li>
</ol>
<h3 id="what-gets-synced"><a class="header" href="#what-gets-synced">What Gets Synced</a></h3>
<ul>
<li><strong>File Types</strong>: Only <code>.yaml</code> and <code>.yml</code> files</li>
<li><strong>File Format</strong>: Files must be valid MockRequest YAML</li>
<li><strong>Subdirectories</strong>: Monitors all subdirectories recursively</li>
<li><strong>Exclusions</strong>: Skips hidden files (starting with <code>.</code>)</li>
</ul>
<h2 id="getting-started-1"><a class="header" href="#getting-started-1">Getting Started</a></h2>
<h3 id="starting-the-sync-daemon"><a class="header" href="#starting-the-sync-daemon">Starting the Sync Daemon</a></h3>
<p>Use the CLI to start the sync daemon:</p>
<pre><code class="language-bash"># Basic usage
mockforge sync --workspace-dir ./my-workspace

# Short form
mockforge sync -w ./my-workspace

# With custom configuration
mockforge sync --workspace-dir ./workspace --config sync-config.yaml
</code></pre>
<h3 id="what-youll-see"><a class="header" href="#what-youll-see">What You‚Äôll See</a></h3>
<p>When you start the sync daemon:</p>
<pre><code>üîÑ Starting MockForge Sync Daemon...
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
üìÅ Workspace directory: ./my-workspace

‚ÑπÔ∏è  What the sync daemon does:
   ‚Ä¢ Monitors the workspace directory for .yaml/.yml file changes
   ‚Ä¢ Automatically imports new or modified request files
   ‚Ä¢ Syncs changes bidirectionally between files and workspace
   ‚Ä¢ Skips hidden files (starting with .)

üîç Monitoring for file changes...
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

‚úÖ Sync daemon started successfully!
üí° Press Ctrl+C to stop
</code></pre>
<h3 id="real-time-feedback"><a class="header" href="#real-time-feedback">Real-time Feedback</a></h3>
<p>As files change, you‚Äôll see detailed output:</p>
<pre><code>üîÑ Detected 1 file change in workspace 'default'
  ‚ûï Created: new-endpoint.yaml
     ‚úÖ Successfully imported

üîÑ Detected 2 file changes in workspace 'default'
  üìù Modified: user-api.yaml
     ‚úÖ Successfully updated
  üóëÔ∏è  Deleted: old-endpoint.yaml
     ‚ÑπÔ∏è  Auto-deletion from workspace is disabled
</code></pre>
<h2 id="directory-organization"><a class="header" href="#directory-organization">Directory Organization</a></h2>
<p>You can organize your workspace files however you like. The sync daemon monitors all subdirectories recursively:</p>
<pre><code>my-workspace/
‚îú‚îÄ‚îÄ api-v1/
‚îÇ   ‚îú‚îÄ‚îÄ users.yaml
‚îÇ   ‚îú‚îÄ‚îÄ products.yaml
‚îÇ   ‚îî‚îÄ‚îÄ orders.yaml
‚îú‚îÄ‚îÄ api-v2/
‚îÇ   ‚îú‚îÄ‚îÄ users.yaml
‚îÇ   ‚îî‚îÄ‚îÄ graphql.yaml
‚îú‚îÄ‚îÄ internal/
‚îÇ   ‚îî‚îÄ‚îÄ admin.yaml
‚îî‚îÄ‚îÄ shared/
    ‚îî‚îÄ‚îÄ auth.yaml
</code></pre>
<p>All <code>.yaml</code> and <code>.yml</code> files will be monitored and imported automatically.</p>
<h2 id="file-format"><a class="header" href="#file-format">File Format</a></h2>
<p>Each file should contain a valid MockRequest in YAML format:</p>
<pre><code class="language-yaml">id: "get-users"
name: "Get Users"
method: "GET"
path: "/api/users"
headers:
  Content-Type: "application/json"
response_status: 200
response_body: |
  [
    {"id": 1, "name": "Alice"},
    {"id": 2, "name": "Bob"}
  ]
</code></pre>
<h2 id="usage-examples"><a class="header" href="#usage-examples">Usage Examples</a></h2>
<h3 id="git-integration"><a class="header" href="#git-integration">Git Integration</a></h3>
<p>Keep your workspaces in version control:</p>
<pre><code class="language-bash"># 1. Create a Git repository for your workspaces
mkdir api-mocks
cd api-mocks
git init

# 2. Start the sync daemon
mockforge sync --workspace-dir .

# 3. Create or edit workspace files
vim user-endpoints.yaml

# 4. Commit and push changes
git add .
git commit -m "Add user endpoints"
git push origin main

# 5. Team members can pull changes
# The sync daemon will automatically import updates
</code></pre>
<h3 id="development-workflow-2"><a class="header" href="#development-workflow-2">Development Workflow</a></h3>
<p>Use the sync daemon during active development:</p>
<pre><code class="language-bash"># Terminal 1: Start sync daemon
mockforge sync --workspace-dir ./workspaces

# Terminal 2: Edit files
vim ./workspaces/new-feature.yaml

# Changes are automatically imported
# You'll see real-time feedback in Terminal 1
</code></pre>
<h3 id="cicd-integration-6"><a class="header" href="#cicd-integration-6">CI/CD Integration</a></h3>
<p>Automate workspace deployment:</p>
<pre><code class="language-bash">#!/bin/bash
# deploy-mocks.sh

# Pull latest workspace definitions from Git
git pull origin main

# Start sync daemon in background
mockforge sync --workspace-dir ./workspaces &amp;
SYNC_PID=$!

# Wait for initial sync
sleep 5

# Start MockForge server
mockforge serve --config mockforge.yaml

# Cleanup on exit
trap "kill $SYNC_PID" EXIT
</code></pre>
<h2 id="best-practices-21"><a class="header" href="#best-practices-21">Best Practices</a></h2>
<h3 id="1-use-version-control"><a class="header" href="#1-use-version-control">1. Use Version Control</a></h3>
<p>Keep workspace files in Git for team collaboration:</p>
<pre><code class="language-bash"># Create a .gitignore to exclude temporary files
echo ".DS_Store" &gt;&gt; .gitignore
echo "*.swp" &gt;&gt; .gitignore
echo "*.tmp" &gt;&gt; .gitignore

# Commit workspace definitions
git add *.yaml
git commit -m "Add workspace definitions"
</code></pre>
<h3 id="2-organize-files-logically"><a class="header" href="#2-organize-files-logically">2. Organize Files Logically</a></h3>
<p>Structure your workspace files for clarity:</p>
<pre><code>workspaces/
‚îú‚îÄ‚îÄ production/         # Production endpoints
‚îÇ   ‚îú‚îÄ‚îÄ users-api.yaml
‚îÇ   ‚îî‚îÄ‚îÄ orders-api.yaml
‚îú‚îÄ‚îÄ staging/           # Staging endpoints
‚îÇ   ‚îî‚îÄ‚îÄ beta-features.yaml
‚îî‚îÄ‚îÄ development/       # Development/experimental
    ‚îî‚îÄ‚îÄ new-feature.yaml
</code></pre>
<h3 id="3-use-descriptive-filenames"><a class="header" href="#3-use-descriptive-filenames">3. Use Descriptive Filenames</a></h3>
<p>Name files based on what they contain:</p>
<pre><code>‚úÖ Good:
   - user-authentication.yaml
   - product-catalog-api.yaml
   - payment-processing.yaml

‚ùå Bad:
   - endpoint1.yaml
   - test.yaml
   - temp.yaml
</code></pre>
<h3 id="4-keep-sync-daemon-running"><a class="header" href="#4-keep-sync-daemon-running">4. Keep Sync Daemon Running</a></h3>
<p>Run the sync daemon continuously during development:</p>
<pre><code class="language-bash"># Use a terminal multiplexer like tmux
tmux new -s mockforge-sync
mockforge sync --workspace-dir ./workspaces

# Detach with Ctrl+B then D
# Reattach with: tmux attach -t mockforge-sync
</code></pre>
<h3 id="5-monitor-sync-output"><a class="header" href="#5-monitor-sync-output">5. Monitor Sync Output</a></h3>
<p>Pay attention to the sync daemon‚Äôs output:</p>
<ul>
<li>‚úÖ <strong>Green checkmarks</strong>: Files imported successfully</li>
<li>‚ö†Ô∏è <strong>Warning icons</strong>: Import failed, check file format</li>
<li>üîÑ <strong>Change notifications</strong>: Shows what‚Äôs being synced</li>
<li>‚ùå <strong>Error messages</strong>: Indicate issues that need fixing</li>
</ul>
<h3 id="6-handle-errors-promptly"><a class="header" href="#6-handle-errors-promptly">6. Handle Errors Promptly</a></h3>
<p>When you see errors, fix them immediately:</p>
<pre><code>‚ùå Detected error:
  üìù Modified: broken-endpoint.yaml
     ‚ö†Ô∏è  Failed to import: File is not a recognized format

Action: Check the file syntax and fix YAML formatting
</code></pre>
<h2 id="troubleshooting-32"><a class="header" href="#troubleshooting-32">Troubleshooting</a></h2>
<h3 id="files-not-being-imported"><a class="header" href="#files-not-being-imported">Files Not Being Imported</a></h3>
<p><strong>Check file extension:</strong></p>
<pre><code class="language-bash"># Only .yaml and .yml files are monitored
ls -la workspaces/
# Ensure files end with .yaml or .yml
</code></pre>
<p><strong>Verify file format:</strong></p>
<pre><code class="language-bash"># Files must be valid MockRequest YAML
cat workspaces/my-file.yaml
# Check for proper YAML syntax and required fields
</code></pre>
<p><strong>Check for hidden files:</strong></p>
<pre><code class="language-bash"># Hidden files (starting with .) are ignored
# Rename: .hidden.yaml ‚Üí visible.yaml
mv .hidden.yaml visible.yaml
</code></pre>
<h3 id="permission-errors"><a class="header" href="#permission-errors">Permission Errors</a></h3>
<pre><code class="language-bash"># Ensure MockForge can read the directory
chmod 755 workspaces/
chmod 644 workspaces/*.yaml

# Check ownership
ls -la workspaces/
</code></pre>
<h3 id="changes-not-detected"><a class="header" href="#changes-not-detected">Changes Not Detected</a></h3>
<p><strong>Verify sync daemon is running:</strong></p>
<pre><code class="language-bash"># Check if the process is still active
ps aux | grep "mockforge sync"
</code></pre>
<p><strong>Check filesystem notifications:</strong></p>
<pre><code class="language-bash"># Some network filesystems don't support notifications
# Try editing locally instead of over NFS/SMB
</code></pre>
<p><strong>Restart sync daemon:</strong></p>
<pre><code class="language-bash"># Stop with Ctrl+C, then restart
mockforge sync --workspace-dir ./workspaces
</code></pre>
<h3 id="yaml-syntax-errors"><a class="header" href="#yaml-syntax-errors">YAML Syntax Errors</a></h3>
<p>When files fail to import due to syntax errors:</p>
<pre><code class="language-bash"># Use a YAML validator
yamllint workspaces/problematic-file.yaml

# Common issues:
# - Incorrect indentation
# - Missing quotes around special characters
# - Invalid escape sequences
</code></pre>
<h3 id="debug-logging"><a class="header" href="#debug-logging">Debug Logging</a></h3>
<p>Enable detailed logging to see what‚Äôs happening:</p>
<pre><code class="language-bash"># Enable debug logs for sync watcher
RUST_LOG=mockforge_core::sync_watcher=debug mockforge sync --workspace-dir ./workspaces

# Enable trace-level logs for maximum detail
RUST_LOG=mockforge_core::sync_watcher=trace mockforge sync --workspace-dir ./workspaces

# Log to a file
RUST_LOG=mockforge_core::sync_watcher=debug mockforge sync --workspace-dir ./workspaces 2&gt;&amp;1 | tee sync.log
</code></pre>
<h3 id="getting-help"><a class="header" href="#getting-help">Getting Help</a></h3>
<p>If you‚Äôre still having issues:</p>
<ol>
<li>Check the sync daemon output for error messages</li>
<li>Enable debug logging to see detailed information</li>
<li>Verify file format matches MockRequest YAML structure</li>
<li>Check file permissions and ownership</li>
<li>Try with a minimal test file to isolate the issue</li>
</ol>
<p>Example minimal test file:</p>
<pre><code class="language-yaml"># test-endpoint.yaml
id: "test"
name: "Test Endpoint"
method: "GET"
path: "/test"
response_status: 200
response_body: '{"status": "ok"}'
</code></pre>
<p>Save this file in your workspace directory and verify it gets imported successfully.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="admin-ui"><a class="header" href="#admin-ui">Admin UI</a></h1>
<p><img src="user-guide/../../assets/mockforge-logo.png" alt="MockForge Logo" /></p>
<p>MockForge Admin UI is a modern React-based dashboard that provides comprehensive administrative capabilities for your MockForge instances. Built with Shadcn UI components and designed for power users, it eliminates the need for manual file editing while providing enhanced functionality and user experience.</p>
<h2 id="overview-12"><a class="header" href="#overview-12">Overview</a></h2>
<p>The Admin UI replaces the legacy static HTML interface with a rich, interactive React application that offers:</p>
<ul>
<li><strong>Service Management</strong>: Enable/disable services and routes with granular control</li>
<li><strong>Fixture Management</strong>: Visual editing, diffing, and organization of mock data</li>
<li><strong>Live Monitoring</strong>: Real-time logs and performance metrics</li>
<li><strong>Authentication</strong>: Secure role-based access control</li>
<li><strong>Advanced Search</strong>: Full-text search across services, fixtures, and logs</li>
<li><strong>Bulk Operations</strong>: Manage multiple services simultaneously</li>
</ul>
<h2 id="getting-started-2"><a class="header" href="#getting-started-2">Getting Started</a></h2>
<h3 id="enabling-the-admin-ui"><a class="header" href="#enabling-the-admin-ui">Enabling the Admin UI</a></h3>
<p>The Admin UI is enabled by default when starting MockForge with the admin interface:</p>
<pre><code class="language-bash">mockforge serve --admin-ui
</code></pre>
<p>Access the interface at <code>http://localhost:9080/admin</code> (or your configured admin port).</p>
<h3 id="authentication-1"><a class="header" href="#authentication-1">Authentication</a></h3>
<p>The Admin UI includes secure authentication with two built-in roles:</p>
<h4 id="admin-role"><a class="header" href="#admin-role">Admin Role</a></h4>
<ul>
<li><strong>Username</strong>: <code>admin</code></li>
<li><strong>Password</strong>: <code>admin123</code></li>
<li><strong>Permissions</strong>: Full access to all features</li>
</ul>
<h4 id="viewer-role"><a class="header" href="#viewer-role">Viewer Role</a></h4>
<ul>
<li><strong>Username</strong>: <code>viewer</code></li>
<li><strong>Password</strong>: <code>viewer123</code></li>
<li><strong>Permissions</strong>: Read-only access to dashboard, logs, and metrics</li>
</ul>
<h3 id="first-login"><a class="header" href="#first-login">First Login</a></h3>
<ol>
<li>Navigate to the admin URL</li>
<li>Enter your credentials or click ‚ÄúDemo Admin‚Äù for quick access</li>
<li>The interface will load with role-appropriate navigation</li>
</ol>
<h2 id="core-features"><a class="header" href="#core-features">Core Features</a></h2>
<h3 id="dashboard"><a class="header" href="#dashboard">Dashboard</a></h3>
<p>The dashboard provides an overview of your MockForge instance:</p>
<ul>
<li><strong>System Status</strong>: CPU, memory usage, uptime, and active threads</li>
<li><strong>Server Status</strong>: HTTP, WebSocket, and gRPC server health</li>
<li><strong>Recent Requests</strong>: Latest API calls with response times and status codes</li>
<li><strong>Quick Stats</strong>: Total routes, fixtures, and active connections</li>
</ul>
<h3 id="service-management"><a class="header" href="#service-management">Service Management</a></h3>
<p>Manage your mock services without editing configuration files:</p>
<h4 id="service-controls"><a class="header" href="#service-controls">Service Controls</a></h4>
<ul>
<li><strong>Service Toggle</strong>: Enable/disable entire services</li>
<li><strong>Route Toggle</strong>: Granular control over individual endpoints</li>
<li><strong>Bulk Operations</strong>: Enable/disable multiple services at once</li>
<li><strong>Tag Filtering</strong>: Filter services by tags for organized management</li>
</ul>
<h4 id="service-information"><a class="header" href="#service-information">Service Information</a></h4>
<ul>
<li>Request counts and error rates per route</li>
<li>Response time averages</li>
<li>HTTP method indicators (GET, POST, PUT, DELETE)</li>
<li>gRPC service paths</li>
</ul>
<pre><code class="language-typescript">// Example: Toggle a service programmatically
const { updateService } = useServiceStore();
updateService('user-service', { enabled: false });
</code></pre>
<h3 id="fixture-management-1"><a class="header" href="#fixture-management-1">Fixture Management</a></h3>
<p>Complete fixture lifecycle management through the web interface:</p>
<h4 id="file-operations"><a class="header" href="#file-operations">File Operations</a></h4>
<ul>
<li><strong>Tree View</strong>: Hierarchical organization of fixture files</li>
<li><strong>Drag &amp; Drop</strong>: Move fixtures between folders</li>
<li><strong>Inline Rename</strong>: Click to edit fixture names</li>
<li><strong>Rich Editor</strong>: Monaco-style editing with syntax highlighting</li>
</ul>
<h4 id="content-management"><a class="header" href="#content-management">Content Management</a></h4>
<ul>
<li><strong>Real-time Editing</strong>: Live preview of fixture content</li>
<li><strong>Version Control</strong>: Track changes with version numbers</li>
<li><strong>Auto-save</strong>: Ctrl+S keyboard shortcut for quick saves</li>
<li><strong>File Metadata</strong>: Size, modification dates, and route associations</li>
</ul>
<h4 id="visual-diff"><a class="header" href="#visual-diff">Visual Diff</a></h4>
<ul>
<li><strong>Change Detection</strong>: Automatic diff generation on content changes</li>
<li><strong>Side-by-side View</strong>: Color-coded comparison of old vs new content</li>
<li><strong>Change Statistics</strong>: Count of added, removed, and modified lines</li>
<li><strong>Diff History</strong>: Review previous changes with timestamps</li>
</ul>
<h3 id="live-logs"><a class="header" href="#live-logs">Live Logs</a></h3>
<p>Monitor your MockForge instance in real-time:</p>
<h4 id="log-streaming"><a class="header" href="#log-streaming">Log Streaming</a></h4>
<ul>
<li><strong>Real-time Updates</strong>: Live log feed with configurable refresh intervals</li>
<li><strong>Auto-scroll</strong>: Smart scrolling with pause/resume controls</li>
<li><strong>Connection Status</strong>: Visual indicators for WebSocket health</li>
</ul>
<h4 id="advanced-filtering"><a class="header" href="#advanced-filtering">Advanced Filtering</a></h4>
<ul>
<li><strong>Method Filter</strong>: Filter by HTTP methods (GET, POST, etc.)</li>
<li><strong>Status Code Filter</strong>: Focus on specific response codes</li>
<li><strong>Path Search</strong>: Full-text search across request paths</li>
<li><strong>Time Range</strong>: Filter logs by time windows (1h, 6h, 24h, 7d)</li>
</ul>
<h4 id="log-details"><a class="header" href="#log-details">Log Details</a></h4>
<ul>
<li><strong>Request Inspection</strong>: Click any log entry for detailed view</li>
<li><strong>Headers &amp; Timing</strong>: Complete request/response metadata</li>
<li><strong>Error Analysis</strong>: Detailed error messages and stack traces</li>
<li><strong>Export Options</strong>: Download filtered logs for analysis</li>
</ul>
<h3 id="performance-metrics"><a class="header" href="#performance-metrics">Performance Metrics</a></h3>
<p>Comprehensive performance monitoring and analysis:</p>
<h4 id="latency-analysis"><a class="header" href="#latency-analysis">Latency Analysis</a></h4>
<ul>
<li><strong>Histogram Visualization</strong>: Response time distribution across buckets</li>
<li><strong>Percentile Metrics</strong>: P50, P95, and P99 latency measurements</li>
<li><strong>Service Comparison</strong>: Compare performance across different services</li>
<li><strong>Color-coded Buckets</strong>: Visual indicators for fast (green), medium (yellow), and slow (red) responses</li>
</ul>
<h4 id="failure-analysis"><a class="header" href="#failure-analysis">Failure Analysis</a></h4>
<ul>
<li><strong>Success/Failure Ratios</strong>: Pie chart visualization of request outcomes</li>
<li><strong>Status Code Distribution</strong>: Bar chart of HTTP response codes</li>
<li><strong>Error Rate Tracking</strong>: Percentage of failed requests over time</li>
<li><strong>SLA Monitoring</strong>: Visual indicators for SLA compliance</li>
</ul>
<h4 id="real-time-updates"><a class="header" href="#real-time-updates">Real-time Updates</a></h4>
<ul>
<li><strong>Auto-refresh</strong>: Metrics update every 30 seconds</li>
<li><strong>Manual Refresh</strong>: Force immediate data refresh</li>
<li><strong>Performance Alerts</strong>: Automatic warnings for high error rates or latency</li>
</ul>
<h2 id="advanced-features-4"><a class="header" href="#advanced-features-4">Advanced Features</a></h2>
<p>The Admin UI provides access to many advanced MockForge features:</p>
<ul>
<li><strong>Chaos Lab</strong>: Interactive network condition simulation with real-time latency visualization</li>
<li><strong>Reality Slider</strong>: Unified control for adjusting mock environment realism</li>
<li><strong>Scenario State Machine Editor</strong>: Visual flow editor for creating state machines</li>
<li><strong>Time Travel Controls</strong>: Virtual clock controls for temporal simulation</li>
<li><strong>Contract Diff Dashboard</strong>: Visualize and analyze API contract mismatches</li>
<li><strong>Voice Interface</strong>: Create APIs using natural language commands</li>
</ul>
<p>For detailed documentation on these features, see the <a href="user-guide/advanced-features.html">Advanced Features</a> section.</p>
<h3 id="authentication--authorization-1"><a class="header" href="#authentication--authorization-1">Authentication &amp; Authorization</a></h3>
<h4 id="jwt-based-security"><a class="header" href="#jwt-based-security">JWT-based Security</a></h4>
<ul>
<li><strong>Token Authentication</strong>: Secure JWT tokens with automatic refresh</li>
<li><strong>Session Persistence</strong>: Login state survives browser refresh</li>
<li><strong>Auto-logout</strong>: Automatic logout on token expiration</li>
</ul>
<h4 id="role-based-access-control"><a class="header" href="#role-based-access-control">Role-based Access Control</a></h4>
<ul>
<li><strong>Admin Features</strong>: Full read/write access to all functionality</li>
<li><strong>Viewer Restrictions</strong>: Read-only access to monitoring features</li>
<li><strong>Navigation Adaptation</strong>: Menu items adjust based on user role</li>
<li><strong>Permission Guards</strong>: Graceful handling of unauthorized access</li>
</ul>
<h3 id="search--filtering"><a class="header" href="#search--filtering">Search &amp; Filtering</a></h3>
<h4 id="global-search"><a class="header" href="#global-search">Global Search</a></h4>
<ul>
<li><strong>Service Search</strong>: Find services by name, route paths, or tags</li>
<li><strong>Fixture Search</strong>: Search fixture names, paths, and content</li>
<li><strong>Log Search</strong>: Full-text search across log messages and metadata</li>
</ul>
<h4 id="advanced-filters"><a class="header" href="#advanced-filters">Advanced Filters</a></h4>
<ul>
<li><strong>Tag-based Filtering</strong>: Group services by functional tags</li>
<li><strong>Time-based Filtering</strong>: Filter data by time ranges</li>
<li><strong>Status Filtering</strong>: Focus on specific response codes or error states</li>
<li><strong>Persistent Filters</strong>: Maintain filter state across navigation</li>
</ul>
<h3 id="bulk-operations"><a class="header" href="#bulk-operations">Bulk Operations</a></h3>
<h4 id="service-management-1"><a class="header" href="#service-management-1">Service Management</a></h4>
<pre><code class="language-bash"># Enable all services in a tag group
services.filter(s =&gt; s.tags.includes('api'))
  .forEach(s =&gt; updateService(s.id, { enabled: true }));
</code></pre>
<h4 id="fixture-operations"><a class="header" href="#fixture-operations">Fixture Operations</a></h4>
<ul>
<li><strong>Batch Selection</strong>: Select multiple fixtures for operations</li>
<li><strong>Bulk Rename</strong>: Apply naming patterns to multiple files</li>
<li><strong>Mass Delete</strong>: Remove multiple fixtures with confirmation</li>
</ul>
<h3 id="validation-management"><a class="header" href="#validation-management">Validation Management</a></h3>
<p>The Admin UI provides comprehensive validation controls for OpenAPI request validation:</p>
<h4 id="validation-mode-control"><a class="header" href="#validation-mode-control">Validation Mode Control</a></h4>
<ul>
<li><strong>Global Mode Toggle</strong>: Switch between <code>off</code>, <code>warn</code>, and <code>enforce</code> validation modes</li>
<li><strong>Per-Route Overrides</strong>: Set custom validation rules for specific endpoints</li>
<li><strong>Real-time Application</strong>: Changes take effect immediately without server restart</li>
</ul>
<h4 id="validation-monitoring"><a class="header" href="#validation-monitoring">Validation Monitoring</a></h4>
<ul>
<li><strong>Error Statistics</strong>: View validation failure rates and error types</li>
<li><strong>Route-specific Metrics</strong>: See which endpoints are failing validation</li>
<li><strong>Error Details</strong>: Inspect detailed validation error messages</li>
</ul>
<h4 id="advanced-validation-features"><a class="header" href="#advanced-validation-features">Advanced Validation Features</a></h4>
<ul>
<li><strong>Aggregate Error Reporting</strong>: Combine multiple validation errors into single responses</li>
<li><strong>Response Validation</strong>: Validate response payloads against OpenAPI schemas</li>
<li><strong>Admin Route Exclusion</strong>: Skip validation for admin UI routes when configured</li>
</ul>
<pre><code class="language-typescript">// Example: Update validation mode programmatically
const { updateValidation } = useValidationStore();
updateValidation({
  mode: 'warn',
  aggregate_errors: true,
  overrides: {
    'GET /health': 'off',
    'POST /api/users': 'enforce'
  }
});
</code></pre>
<h2 id="configuration-9"><a class="header" href="#configuration-9">Configuration</a></h2>
<h3 id="environment-variables-13"><a class="header" href="#environment-variables-13">Environment Variables</a></h3>
<p>Configure Admin UI behavior through environment variables:</p>
<pre><code class="language-bash"># Enable Admin UI (default: true)
MOCKFORGE_ADMIN_UI_ENABLED=true

# Admin UI port (default: 9080)
MOCKFORGE_ADMIN_PORT=9080

# Authentication settings
MOCKFORGE_ADMIN_AUTH_ENABLED=true
MOCKFORGE_ADMIN_JWT_SECRET=your-secret-key

# Session timeout (default: 24h)
MOCKFORGE_ADMIN_SESSION_TIMEOUT=86400
</code></pre>
<h3 id="custom-authentication-1"><a class="header" href="#custom-authentication-1">Custom Authentication</a></h3>
<p>Replace the default authentication with your own system:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Custom auth provider
pub struct CustomAuthProvider {
    // Your authentication implementation
}

impl AuthProvider for CustomAuthProvider {
    fn authenticate(&amp;self, username: &amp;str, password: &amp;str) -&gt; Result&lt;User&gt; {
        // Your authentication logic
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="theming"><a class="header" href="#theming">Theming</a></h3>
<p>The Admin UI supports light and dark themes with CSS custom properties:</p>
<pre><code class="language-css">:root {
  --background: 0 0% 100%;
  --foreground: 222.2 84% 4.9%;
  --primary: 221.2 83.2% 53.3%;
  /* ... additional theme variables */
}

.dark {
  --background: 222.2 84% 4.9%;
  --foreground: 210 40% 98%;
  /* ... dark theme overrides */
}
</code></pre>
<h2 id="api-integration"><a class="header" href="#api-integration">API Integration</a></h2>
<h3 id="rest-endpoints"><a class="header" href="#rest-endpoints">REST Endpoints</a></h3>
<p>The Admin UI communicates with MockForge through RESTful APIs:</p>
<pre><code class="language-http"># Service management
GET    /api/v2/services
PUT    /api/v2/services/{id}
POST   /api/v2/services/bulk

# Fixture management
GET    /api/v2/fixtures
POST   /api/v2/fixtures
PUT    /api/v2/fixtures/{id}
DELETE /api/v2/fixtures/{id}

# Authentication
POST   /api/v2/auth/login
POST   /api/v2/auth/refresh
POST   /api/v2/auth/logout

# Logs and metrics
GET    /api/v2/logs
GET    /api/v2/metrics/latency
GET    /api/v2/metrics/failures
</code></pre>
<h3 id="websocket-endpoints"><a class="header" href="#websocket-endpoints">WebSocket Endpoints</a></h3>
<p>Real-time features use WebSocket connections:</p>
<pre><code class="language-http"># Live log streaming
WS /api/v2/logs/stream

# Metrics updates
WS /api/v2/metrics/stream

# Configuration changes
WS /api/v2/config/stream
</code></pre>
<h2 id="troubleshooting-33"><a class="header" href="#troubleshooting-33">Troubleshooting</a></h2>
<h3 id="common-issues-11"><a class="header" href="#common-issues-11">Common Issues</a></h3>
<h4 id="authentication-problems"><a class="header" href="#authentication-problems">Authentication Problems</a></h4>
<pre><code class="language-bash"># Check JWT secret configuration
MOCKFORGE_ADMIN_JWT_SECRET=your-secret-key

# Verify admin credentials
curl -X POST http://localhost:9080/api/v2/auth/login \
  -H "Content-Type: application/json" \
  -d '{"username":"admin","password":"admin123"}'
</code></pre>
<h4 id="websocket-connection-issues"><a class="header" href="#websocket-connection-issues">WebSocket Connection Issues</a></h4>
<pre><code class="language-bash"># Check WebSocket endpoint
wscat -c ws://localhost:9080/api/v2/logs/stream

# Verify proxy configuration if behind reverse proxy
ProxyPass /api/v2/ ws://localhost:9080/api/v2/
</code></pre>
<h4 id="performance-issues-5"><a class="header" href="#performance-issues-5">Performance Issues</a></h4>
<pre><code class="language-bash"># Enable performance monitoring
MOCKFORGE_ADMIN_METRICS_ENABLED=true

# Increase memory limits for large datasets
MOCKFORGE_ADMIN_MEMORY_LIMIT=512MB
</code></pre>
<h3 id="debug-mode-2"><a class="header" href="#debug-mode-2">Debug Mode</a></h3>
<p>Enable debug logging for troubleshooting:</p>
<pre><code class="language-bash">MOCKFORGE_LOG_LEVEL=debug mockforge serve --admin-ui
</code></pre>
<h3 id="browser-compatibility"><a class="header" href="#browser-compatibility">Browser Compatibility</a></h3>
<p>The Admin UI requires modern browsers with support for:</p>
<ul>
<li>ES2020 features</li>
<li>WebSocket API</li>
<li>CSS Grid and Flexbox</li>
<li>Local Storage</li>
</ul>
<h2 id="best-practices-22"><a class="header" href="#best-practices-22">Best Practices</a></h2>
<h3 id="security-2"><a class="header" href="#security-2">Security</a></h3>
<ul>
<li>Change default admin credentials in production</li>
<li>Use HTTPS for admin interface in production</li>
<li>Configure appropriate session timeouts</li>
<li>Regularly rotate JWT secrets</li>
</ul>
<h3 id="performance-1"><a class="header" href="#performance-1">Performance</a></h3>
<ul>
<li>Use filtering to limit large datasets</li>
<li>Enable auto-scroll only when monitoring actively</li>
<li>Clear old logs periodically to improve performance</li>
<li>Monitor memory usage with large fixture files</li>
</ul>
<h3 id="organization-1"><a class="header" href="#organization-1">Organization</a></h3>
<ul>
<li>Use descriptive service and fixture names</li>
<li>Organize fixtures in logical folder structures</li>
<li>Apply consistent tagging to services</li>
<li>Document fixture purposes in comments</li>
</ul>
<h2 id="examples-8"><a class="header" href="#examples-8">Examples</a></h2>
<h3 id="service-management-workflow"><a class="header" href="#service-management-workflow">Service Management Workflow</a></h3>
<pre><code class="language-typescript">// 1. Filter services by tag
const apiServices = services.filter(s =&gt; s.tags.includes('api'));

// 2. Enable all API services
apiServices.forEach(service =&gt; {
  updateService(service.id, { enabled: true });
});

// 3. Disable specific routes within services
apiServices.forEach(service =&gt; {
  service.routes
    .filter(route =&gt; route.path.includes('/internal'))
    .forEach(route =&gt; {
      const routeId = `${route.method}-${route.path}`;
      toggleRoute(service.id, routeId, false);
    });
});
</code></pre>
<h3 id="fixture-management-workflow"><a class="header" href="#fixture-management-workflow">Fixture Management Workflow</a></h3>
<pre><code class="language-typescript">// 1. Create new fixture
const newFixture = {
  id: 'user-profile-success',
  name: 'user-profile.json',
  path: 'http/get/users/profile/user-profile.json',
  content: JSON.stringify({
    id: '{{uuid}}',
    name: '{{faker.name.fullName}}',
    email: '{{faker.internet.email}}',
    created_at: '{{now}}'
  }, null, 2)
};

// 2. Add to store
addFixture(newFixture);

// 3. Associate with route
updateFixture(newFixture.id, {
  ...newFixture.content,
  route_path: '/api/users/profile',
  method: 'GET'
});
</code></pre>
<p>This comprehensive guide covers all aspects of the MockForge Admin UI, from basic usage to advanced configuration and troubleshooting. The interface provides a complete administrative solution that eliminates the need for manual file editing while offering enhanced functionality and user experience.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="ide-integration"><a class="header" href="#ide-integration">IDE Integration</a></h1>
<p>MockForge provides first-class IDE integration to enhance your development workflow. This guide covers the VS Code extension and its features.</p>
<h2 id="vs-code-extension"><a class="header" href="#vs-code-extension">VS Code Extension</a></h2>
<p>The MockForge VS Code extension brings the power of MockForge directly into your editor, providing real-time mock management, validation, and preview capabilities.</p>
<h3 id="installation-4"><a class="header" href="#installation-4">Installation</a></h3>
<p>Install the extension from the <a href="https://marketplace.visualstudio.com/items?itemName=saasy-solutions.mockforge-vscode">VS Code Marketplace</a>:</p>
<ol>
<li>Open VS Code</li>
<li>Go to Extensions (Ctrl+Shift+X / Cmd+Shift+X)</li>
<li>Search for ‚ÄúMockForge‚Äù</li>
<li>Click Install</li>
</ol>
<p>Or install via command line:</p>
<pre><code class="language-bash">code --install-extension saasy-solutions.mockforge-vscode
</code></pre>
<h3 id="configuration-10"><a class="header" href="#configuration-10">Configuration</a></h3>
<p>Configure the extension in VS Code settings:</p>
<pre><code class="language-json">{
  "mockforge.serverUrl": "http://localhost:3000",
  "mockforge.autoConnect": true,
  "mockforge.showNotifications": true,
  "mockforge.inlinePreview.enabled": true
}
</code></pre>
<p><strong>Settings:</strong></p>
<ul>
<li><code>mockforge.serverUrl</code>: MockForge server URL (default: <code>http://localhost:3000</code>)</li>
<li><code>mockforge.autoConnect</code>: Automatically connect on startup (default: <code>true</code>)</li>
<li><code>mockforge.showNotifications</code>: Show notifications for mock changes (default: <code>true</code>)</li>
<li><code>mockforge.inlinePreview.enabled</code>: Enable inline preview of mock responses (default: <code>true</code>)</li>
</ul>
<h2 id="features-3"><a class="header" href="#features-3">Features</a></h2>
<h3 id="peek-mock-response"><a class="header" href="#peek-mock-response">Peek Mock Response</a></h3>
<p>Hover over API endpoint references in your code to see mock responses inline.</p>
<p><strong>Supported Patterns:</strong></p>
<ul>
<li><code>fetch('/api/users')</code></li>
<li><code>axios.get('/api/products')</code></li>
<li><code>http.get('/api/orders')</code></li>
<li>Endpoint paths in <code>mockforge.yaml</code> files</li>
</ul>
<p><strong>Usage:</strong></p>
<ol>
<li>Hover over any API endpoint reference in your code</li>
<li>See the mock response (headers and body) in a tooltip</li>
<li>Click ‚ÄúOpen in Playground‚Äù to test the endpoint interactively</li>
</ol>
<p><strong>Example:</strong></p>
<pre><code class="language-typescript">// Hover over this endpoint to see the mock response
const response = await fetch('/api/users');
</code></pre>
<p>The hover tooltip will show:</p>
<ul>
<li>Response headers</li>
<li>Response body (formatted JSON)</li>
<li>Link to open in MockForge Playground</li>
</ul>
<h3 id="config-validation-1"><a class="header" href="#config-validation-1">Config Validation</a></h3>
<p>Get real-time validation for your <code>mockforge.yaml</code> files with inline error reporting.</p>
<p><strong>Features:</strong></p>
<ul>
<li>Inline error reporting with accurate line/column positions</li>
<li>Validates against JSON Schema generated from MockForge config types</li>
<li>Supports multiple config types:
<ul>
<li>Main config (<code>mockforge.yaml</code>)</li>
<li>Reality config (<code>reality/*.yaml</code>)</li>
<li>Persona config (<code>personas/*.yaml</code>)</li>
<li>Blueprint config (<code>blueprint.yaml</code>)</li>
</ul>
</li>
<li>Auto-detects schema type based on file name and location</li>
<li>Helpful error messages for:
<ul>
<li>Missing required fields</li>
<li>Type mismatches</li>
<li>Invalid enum values</li>
<li>Format errors (email, uri, etc.)</li>
<li>Pattern mismatches</li>
</ul>
</li>
</ul>
<p><strong>Example:</strong></p>
<pre><code class="language-yaml"># mockforge.yaml
reality:
  level: invalid_level  # ‚ùå Error: Invalid reality level
</code></pre>
<p>The extension will show an inline error:</p>
<pre><code>Invalid reality level: invalid_level. Valid values: static, light, moderate, high, chaos
</code></pre>
<h3 id="mocks-explorer"><a class="header" href="#mocks-explorer">Mocks Explorer</a></h3>
<p>Visual tree view of all your mocks with real-time WebSocket updates.</p>
<p><strong>Features:</strong></p>
<ul>
<li>Browse all mocks in a tree view</li>
<li>Color-coded by HTTP method (GET, POST, PUT, DELETE, etc.)</li>
<li>Real-time updates when mocks change</li>
<li>Context menu actions:
<ul>
<li>Edit Mock</li>
<li>Delete Mock</li>
<li>Toggle Mock (enable/disable)</li>
<li>View Details</li>
</ul>
</li>
</ul>
<p><strong>Usage:</strong></p>
<ol>
<li>Open the MockForge sidebar (click the MockForge icon in the activity bar)</li>
<li>Browse your mocks in the ‚ÄúMocks Explorer‚Äù view</li>
<li>Click on a mock to see details</li>
<li>Right-click for context menu actions</li>
</ol>
<h3 id="server-control"><a class="header" href="#server-control">Server Control</a></h3>
<p>Monitor your MockForge server status and statistics.</p>
<p><strong>Features:</strong></p>
<ul>
<li>Connection status indicator</li>
<li>Server version and port</li>
<li>Uptime and request count</li>
<li>Active mocks count</li>
<li>Quick actions to start/stop/restart server</li>
</ul>
<p><strong>Usage:</strong></p>
<ol>
<li>Open the ‚ÄúServer Control‚Äù panel in the MockForge sidebar</li>
<li>View server statistics</li>
<li>Use quick actions to manage the server</li>
</ol>
<h3 id="playground-integration-1"><a class="header" href="#playground-integration-1">Playground Integration</a></h3>
<p>Quick access to MockForge Playground from hover tooltips.</p>
<p><strong>Usage:</strong></p>
<ol>
<li>Hover over an API endpoint reference</li>
<li>Click ‚ÄúOpen in Playground‚Äù in the tooltip</li>
<li>The MockForge Admin UI playground opens in your browser</li>
<li>The endpoint method and path are pre-filled</li>
</ol>
<h2 id="workflow-integration"><a class="header" href="#workflow-integration">Workflow Integration</a></h2>
<h3 id="development-workflow-3"><a class="header" href="#development-workflow-3">Development Workflow</a></h3>
<ol>
<li><strong>Start MockForge server</strong>: <code>mockforge start</code></li>
<li><strong>Open VS Code</strong>: The extension auto-connects</li>
<li><strong>Edit config files</strong>: Get real-time validation</li>
<li><strong>Hover over endpoints</strong>: See mock responses inline</li>
<li><strong>Test in Playground</strong>: Click ‚ÄúOpen in Playground‚Äù from hover tooltips</li>
</ol>
<h3 id="config-validation-workflow"><a class="header" href="#config-validation-workflow">Config Validation Workflow</a></h3>
<ol>
<li><strong>Edit <code>mockforge.yaml</code></strong>: Start typing your configuration</li>
<li><strong>See inline errors</strong>: Validation happens in real-time</li>
<li><strong>Fix errors</strong>: Follow the error messages to correct issues</li>
<li><strong>Generate schemas</strong> (optional): Run <code>mockforge schema generate</code> to create local schemas</li>
</ol>
<h3 id="mock-management-workflow"><a class="header" href="#mock-management-workflow">Mock Management Workflow</a></h3>
<ol>
<li><strong>View mocks</strong>: Open Mocks Explorer</li>
<li><strong>Create mock</strong>: Click ‚Äú+‚Äù icon or use command palette</li>
<li><strong>Edit mock</strong>: Right-click ‚Üí Edit Mock</li>
<li><strong>Test mock</strong>: Hover over endpoint reference to see response</li>
<li><strong>Open in Playground</strong>: Click link in hover tooltip</li>
</ol>
<h2 id="troubleshooting-34"><a class="header" href="#troubleshooting-34">Troubleshooting</a></h2>
<h3 id="extension-not-connecting-1"><a class="header" href="#extension-not-connecting-1">Extension Not Connecting</a></h3>
<ol>
<li>Check that MockForge server is running</li>
<li>Verify <code>mockforge.serverUrl</code> setting is correct</li>
<li>Check VS Code output panel for connection errors</li>
<li>Try restarting the extension: Command Palette ‚Üí ‚ÄúMockForge: Restart Extension‚Äù</li>
</ol>
<h3 id="validation-not-working-2"><a class="header" href="#validation-not-working-2">Validation Not Working</a></h3>
<ol>
<li>Ensure you have a <code>mockforge.yaml</code> file open</li>
<li>Check that schemas are available:
<ul>
<li>Look for <code>schemas/</code> directory in workspace</li>
<li>Or run <code>mockforge schema generate</code> to create schemas</li>
</ul>
</li>
<li>Check VS Code output panel for validation errors</li>
</ol>
<h3 id="hover-preview-not-showing"><a class="header" href="#hover-preview-not-showing">Hover Preview Not Showing</a></h3>
<ol>
<li>Ensure <code>mockforge.inlinePreview.enabled</code> is <code>true</code></li>
<li>Check that MockForge server is connected</li>
<li>Verify the endpoint path matches a configured mock</li>
<li>Try hovering over different endpoint patterns</li>
</ol>
<h2 id="related-documentation-6"><a class="header" href="#related-documentation-6">Related Documentation</a></h2>
<ul>
<li><a href="user-guide/../../../vscode-extension/README.html">VS Code Extension README</a></li>
<li><a href="user-guide/../configuration/files.html">Configuration Files</a></li>
<li><a href="user-guide/../getting-started/getting-started.html">Getting Started</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="advanced-features-5"><a class="header" href="#advanced-features-5">Advanced Features</a></h1>
<p>MockForge includes a comprehensive set of advanced features that enable sophisticated mocking scenarios, intelligent behavior simulation, and production-like testing environments. This section provides an overview of all advanced features with links to detailed documentation.</p>
<h2 id="overview-13"><a class="header" href="#overview-13">Overview</a></h2>
<p>MockForge‚Äôs advanced features are organized into several categories:</p>
<ul>
<li><strong>Simulation &amp; State Management</strong>: Virtual Backend Reality (VBR), Temporal Simulation, Scenario State Machines, World State Engine</li>
<li><strong>Intelligence &amp; Automation</strong>: MockAI, Generative Schema Mode, AI Contract Diff, API Architecture Critique, System Generation, Behavioral Simulation</li>
<li><strong>Chaos &amp; Realism</strong>: Chaos Lab, Reality Slider, Reality Profiles Marketplace, Behavioral Economics Engine, Performance Mode</li>
<li><strong>Collaboration &amp; Cloud</strong>: Cloud Workspaces, Data Scenario Marketplace, MockOps Pipelines, Federation, Analytics Dashboard</li>
<li><strong>Developer Experience</strong>: ForgeConnect SDK, Zero-Config Mode, Snapshot Diff, Mock-Oriented Development</li>
<li><strong>Experimental Features</strong>: Deceptive Deploys, Voice + LLM Interface, Reality Continuum, Smart Personas</li>
</ul>
<h2 id="simulation--state-management"><a class="header" href="#simulation--state-management">Simulation &amp; State Management</a></h2>
<h3 id="virtual-backend-reality-vbr-engine"><a class="header" href="#virtual-backend-reality-vbr-engine">Virtual Backend Reality (VBR) Engine</a></h3>
<p>The VBR Engine provides a virtual ‚Äúdatabase‚Äù layer that automatically generates CRUD operations from OpenAPI specifications. It supports relationship mapping, data persistence, and state management.</p>
<p><strong>Key Features:</strong></p>
<ul>
<li>Automatic CRUD generation from OpenAPI specs</li>
<li>Support for 1:N and N:N relationships</li>
<li>Multiple storage backends (JSON, SQLite, in-memory)</li>
<li>Data seeding and state snapshots</li>
<li>Realistic ID generation</li>
</ul>
<p><strong>Learn More:</strong> <a href="user-guide/vbr-engine.html">VBR Engine Documentation</a></p>
<h3 id="temporal-simulation-time-travel"><a class="header" href="#temporal-simulation-time-travel">Temporal Simulation (Time Travel)</a></h3>
<p>Temporal Simulation allows you to control time in your mock environment, enabling time-based data mutations, scheduled events, and time-travel debugging.</p>
<p><strong>Key Features:</strong></p>
<ul>
<li>Virtual clock abstraction</li>
<li>Time advancement controls</li>
<li>Data mutation rules triggered by time</li>
<li>Scheduler for simulated cron events</li>
<li>UI controls for time travel</li>
</ul>
<p><strong>Learn More:</strong> <a href="user-guide/temporal-simulation.html">Temporal Simulation Documentation</a></p>
<h3 id="scenario-state-machines-20"><a class="header" href="#scenario-state-machines-20">Scenario State Machines 2.0</a></h3>
<p>Advanced state machine system for modeling complex workflows and multi-step scenarios with visual flow editing and conditional transitions.</p>
<p><strong>Key Features:</strong></p>
<ul>
<li>Visual flow editor for state transitions</li>
<li>Conditional transitions with if/else logic</li>
<li>Reusable sub-scenarios</li>
<li>Real-time preview of active state</li>
<li>Programmatic state manipulation</li>
</ul>
<p><strong>Learn More:</strong> <a href="user-guide/scenario-state-machines.html">Scenario State Machines Documentation</a></p>
<h2 id="intelligence--automation"><a class="header" href="#intelligence--automation">Intelligence &amp; Automation</a></h2>
<h3 id="mockai-intelligent-mocking"><a class="header" href="#mockai-intelligent-mocking">MockAI (Intelligent Mocking)</a></h3>
<p>MockAI uses artificial intelligence to generate contextually appropriate, realistic API responses. It learns from OpenAPI specifications and example payloads.</p>
<p><strong>Key Features:</strong></p>
<ul>
<li>Trainable rule engine from examples or schema</li>
<li>Context-aware conditional logic generation</li>
<li>LLM-based dynamic response option</li>
<li>Automatic fake data consistency</li>
<li>Realistic validation error simulation</li>
</ul>
<p><strong>Learn More:</strong> <a href="user-guide/mockai.html">MockAI Documentation</a></p>
<h3 id="generative-schema-mode"><a class="header" href="#generative-schema-mode">Generative Schema Mode</a></h3>
<p>Generate complete API ecosystems from JSON payloads, automatically creating routes, schemas, and entity relationships.</p>
<p><strong>Key Features:</strong></p>
<ul>
<li>Complete ‚ÄúJSON ‚Üí entire API ecosystem‚Äù generation</li>
<li>Auto-route generation with realistic CRUD mapping</li>
<li>One-click environment creation from JSON payloads</li>
<li>Entity relation inference</li>
<li>Schema merging from multiple examples</li>
</ul>
<p><strong>Learn More:</strong> <a href="user-guide/generative-schema.html">Generative Schema Mode Documentation</a></p>
<h3 id="ai-contract-diff"><a class="header" href="#ai-contract-diff">AI Contract Diff</a></h3>
<p>Automatically detect and analyze differences between API contracts and live requests, providing contextual recommendations for mismatches.</p>
<p><strong>Key Features:</strong></p>
<ul>
<li>Contract diff analysis between schema and live requests</li>
<li>Contextual recommendations for mismatches</li>
<li>Inline schema correction proposals</li>
<li>CI/CD integration (contract verification step)</li>
<li>Dashboard visualization of mismatches</li>
</ul>
<p><strong>Learn More:</strong> <a href="user-guide/ai-contract-diff.html">AI Contract Diff Documentation</a></p>
<h3 id="api-architecture-critique"><a class="header" href="#api-architecture-critique">API Architecture Critique</a></h3>
<p>LLM-powered analysis of API schemas to detect anti-patterns, redundancies, naming issues, emotional tone problems, and restructuring recommendations.</p>
<p><strong>Key Features:</strong></p>
<ul>
<li>Anti-pattern detection</li>
<li>Redundancy detection</li>
<li>Naming quality assessment</li>
<li>Emotional tone analysis</li>
<li>Restructuring recommendations</li>
</ul>
<p><strong>Learn More:</strong> <a href="user-guide/../ai/api-architecture-critique.html">API Architecture Critique Documentation</a></p>
<h3 id="system-generation"><a class="header" href="#system-generation">System Generation</a></h3>
<p>Generate complete backend systems from natural language descriptions, including endpoints, personas, lifecycles, WebSocket topics, and more.</p>
<p><strong>Key Features:</strong></p>
<ul>
<li>20-30 REST endpoints from description</li>
<li>4-5 personas based on roles</li>
<li>6-10 lifecycle states</li>
<li>WebSocket topics</li>
<li>Full OpenAPI spec</li>
<li>CI pipeline templates</li>
</ul>
<p><strong>Learn More:</strong> <a href="user-guide/../ai/system-generation.html">System Generation Documentation</a></p>
<h3 id="behavioral-simulation"><a class="header" href="#behavioral-simulation">Behavioral Simulation</a></h3>
<p>Model users as narrative agents that react to app state, form intentions, respond to errors, and trigger multi-step interactions.</p>
<p><strong>Key Features:</strong></p>
<ul>
<li>Narrative agents</li>
<li>React to app state</li>
<li>Form intentions (shop, browse, buy, abandon)</li>
<li>Respond to errors</li>
<li>Multi-step interactions</li>
</ul>
<p><strong>Learn More:</strong> <a href="user-guide/../ai/behavioral-simulation.html">Behavioral Simulation Documentation</a></p>
<h2 id="chaos--realism"><a class="header" href="#chaos--realism">Chaos &amp; Realism</a></h2>
<h3 id="chaos-lab"><a class="header" href="#chaos-lab">Chaos Lab</a></h3>
<p>Interactive network condition simulation with real-time latency visualization, network profiles, and error pattern scripting.</p>
<p><strong>Key Features:</strong></p>
<ul>
<li>Real-time latency visualization</li>
<li>Network profile management (slow 3G, flaky Wi-Fi, etc.)</li>
<li>Error pattern scripting (burst, random, sequential)</li>
<li>Profile export/import</li>
<li>CLI integration</li>
</ul>
<p><strong>Learn More:</strong> <a href="user-guide/chaos-lab.html">Chaos Lab Documentation</a></p>
<h3 id="reality-slider"><a class="header" href="#reality-slider">Reality Slider</a></h3>
<p>Unified control mechanism that adjusts mock environment realism from simple static stubs to full production-level chaos.</p>
<p><strong>Key Features:</strong></p>
<ul>
<li>Configurable realism levels (1‚Äì5)</li>
<li>Automated toggling of chaos, latency, and MockAI behaviors</li>
<li>Persistent slider state per environment</li>
<li>Export/import of realism presets</li>
<li>Keyboard shortcuts for quick changes</li>
</ul>
<p><strong>Learn More:</strong> <a href="user-guide/reality-slider.html">Reality Slider Documentation</a></p>
<h3 id="reality-profiles-marketplace"><a class="header" href="#reality-profiles-marketplace">Reality Profiles Marketplace</a></h3>
<p>Pre-tuned ‚Äúrealism packs‚Äù that bundle personas, scenarios, chaos rules, latency curves, error distributions, and protocol behaviors into ready-to-use packages.</p>
<p><strong>Key Features:</strong></p>
<ul>
<li>E-Commerce Peak Season Pack</li>
<li>Fintech Fraud Pack</li>
<li>Healthcare HL7/Insurance Edge Cases Pack</li>
<li>IoT Device Fleet Chaos Pack</li>
<li>Custom pack creation</li>
</ul>
<p><strong>Learn More:</strong> <a href="user-guide/advanced-features/reality-profiles-marketplace.html">Reality Profiles Marketplace Documentation</a></p>
<h3 id="behavioral-economics-engine"><a class="header" href="#behavioral-economics-engine">Behavioral Economics Engine</a></h3>
<p>Makes mocks react to real-world pressures like latency, load, pricing changes, fraud suspicion, and customer segments.</p>
<p><strong>Key Features:</strong></p>
<ul>
<li>Cart conversion drops if latency &gt; 400ms</li>
<li>Bank declines transactions if prior balance checks failed</li>
<li>User churn increases after multiple 500s</li>
<li>Declarative and scriptable rules</li>
</ul>
<p><strong>Learn More:</strong> <a href="user-guide/advanced-features/behavioral-economics.html">Behavioral Economics Engine Documentation</a></p>
<h3 id="world-state-engine"><a class="header" href="#world-state-engine">World State Engine</a></h3>
<p>Unified visualization of all MockForge state systems‚Äîlike a ‚Äúminiature game engine for your backend.‚Äù</p>
<p><strong>Key Features:</strong></p>
<ul>
<li>Unified state aggregation from all subsystems</li>
<li>Graph visualization</li>
<li>Real-time updates</li>
<li>Time travel</li>
<li>Query interface</li>
</ul>
<p><strong>Learn More:</strong> <a href="user-guide/advanced-features/world-state-engine.html">World State Engine Documentation</a></p>
<h3 id="performance-mode"><a class="header" href="#performance-mode">Performance Mode</a></h3>
<p>Lightweight load simulation for running scenarios at N RPS, simulating bottlenecks, and recording latencies.</p>
<p><strong>Key Features:</strong></p>
<ul>
<li>Run scenarios at n RPS</li>
<li>Simulate bottlenecks</li>
<li>Record latencies</li>
<li>Observe response changes under load</li>
</ul>
<p><strong>Learn More:</strong> <a href="user-guide/advanced-features/performance-mode.html">Performance Mode Documentation</a></p>
<h3 id="drift-learning"><a class="header" href="#drift-learning">Drift Learning</a></h3>
<p>Mocks learn from recorded traffic patterns and adapt their behavior over time.</p>
<p><strong>Key Features:</strong></p>
<ul>
<li>Traffic pattern learning from recorded requests</li>
<li>Persona behavior adaptation</li>
<li>Configurable learning modes (behavioral, statistical, hybrid)</li>
<li>Opt-in per endpoint/persona learning</li>
</ul>
<p><strong>Learn More:</strong> <a href="user-guide/advanced-features/drift-learning.html">Drift Learning Documentation</a></p>
<h2 id="collaboration--cloud"><a class="header" href="#collaboration--cloud">Collaboration &amp; Cloud</a></h2>
<h3 id="cloud-workspaces"><a class="header" href="#cloud-workspaces">Cloud Workspaces</a></h3>
<p>Multi-user collaborative editing with real-time state synchronization, version control, and role-based permissions.</p>
<p><strong>Key Features:</strong></p>
<ul>
<li>User authentication and access control</li>
<li>Multi-user environment editing</li>
<li>State synchronization between clients</li>
<li>Git-style version control for mocks and data</li>
<li>Role-based permissions (Owner, Editor, Viewer)</li>
</ul>
<p><strong>Learn More:</strong> <a href="user-guide/cloud-workspaces.html">Cloud Workspaces Documentation</a></p>
<h3 id="data-scenario-marketplace"><a class="header" href="#data-scenario-marketplace">Data Scenario Marketplace</a></h3>
<p>Marketplace for downloadable mock templates with tags, ratings, versioning, and one-click import/export.</p>
<p><strong>Key Features:</strong></p>
<ul>
<li>Marketplace for downloadable mock templates</li>
<li>Tags, ratings, and versioning</li>
<li>One-click import/export</li>
<li>Domain-specific packs (e-commerce, fintech, IoT)</li>
<li>Automatic schema and route alignment</li>
</ul>
<p><strong>Learn More:</strong> <a href="user-guide/scenario-marketplace.html">Scenario Marketplace Documentation</a></p>
<h3 id="mockops-pipelines"><a class="header" href="#mockops-pipelines">MockOps Pipelines</a></h3>
<p>GitHub Actions-like automation for mock lifecycle management with event-driven pipelines.</p>
<p><strong>Key Features:</strong></p>
<ul>
<li>Schema change ‚Üí auto-regenerate SDK</li>
<li>Scenario published ‚Üí auto-promote to test ‚Üí notify teams</li>
<li>Drift threshold exceeded ‚Üí auto-generate Git PR</li>
<li>Event-driven automation</li>
</ul>
<p><strong>Learn More:</strong> <a href="user-guide/../cloud/mockops-pipelines.html">MockOps Pipelines Documentation</a></p>
<h3 id="multi-workspace-federation"><a class="header" href="#multi-workspace-federation">Multi-Workspace Federation</a></h3>
<p>Compose multiple mock workspaces into one federated ‚Äúvirtual system‚Äù for large organizations with microservices.</p>
<p><strong>Key Features:</strong></p>
<ul>
<li>Service boundary definition</li>
<li>Compose workspaces into virtual systems</li>
<li>System-wide scenarios</li>
<li>Per-service reality level control</li>
</ul>
<p><strong>Learn More:</strong> <a href="user-guide/../cloud/federation.html">Federation Documentation</a></p>
<h3 id="analytics-dashboard"><a class="header" href="#analytics-dashboard">Analytics Dashboard</a></h3>
<p>Leadership insight into coverage, risk, and usage with heatmaps, CI tracking, and coverage analysis.</p>
<p><strong>Key Features:</strong></p>
<ul>
<li>Scenario usage heatmaps</li>
<li>Persona CI hit tracking</li>
<li>Endpoint coverage analysis</li>
<li>Reality level staleness detection</li>
<li>Drift percentage tracking</li>
</ul>
<p><strong>Learn More:</strong> <a href="user-guide/../cloud/analytics-dashboard.html">Analytics Dashboard Documentation</a></p>
<h2 id="developer-experience"><a class="header" href="#developer-experience">Developer Experience</a></h2>
<h3 id="forgeconnect-sdk"><a class="header" href="#forgeconnect-sdk">ForgeConnect SDK</a></h3>
<p>Browser extension and SDK for capturing network traffic, auto-generating mocks, and integrating with popular frameworks.</p>
<p><strong>Key Features:</strong></p>
<ul>
<li>Browser extension to capture network traffic</li>
<li>Auto-mock generation for unhandled requests</li>
<li>Local mock preview in browser</li>
<li>SDK for framework bindings (React, Vue, Angular)</li>
<li>Auth passthrough support for OAuth flows</li>
</ul>
<p><strong>Learn More:</strong> <a href="user-guide/forgeconnect-sdk.html">ForgeConnect SDK Documentation</a></p>
<h3 id="zero-config-mode-runtime-daemon"><a class="header" href="#zero-config-mode-runtime-daemon">Zero-Config Mode (Runtime Daemon)</a></h3>
<p>The ‚Äúinvisible mock server‚Äù experience‚Äîautomatically creates mocks, generates types, and sets up scenarios when you hit non-existent endpoints.</p>
<p><strong>Key Features:</strong></p>
<ul>
<li>Auto-detection of 404 responses</li>
<li>Automatic mock creation</li>
<li>Type generation</li>
<li>Client stub generation</li>
<li>OpenAPI schema updates</li>
</ul>
<p><strong>Learn More:</strong> <a href="user-guide/../devx/zero-config-mode.html">Zero-Config Mode Documentation</a></p>
<h3 id="snapshot-diff"><a class="header" href="#snapshot-diff">Snapshot Diff</a></h3>
<p>Side-by-side visualization for comparing mock behavior between environments, personas, scenarios, or reality levels.</p>
<p><strong>Key Features:</strong></p>
<ul>
<li>Compare test vs prod</li>
<li>Compare personas</li>
<li>Compare reality levels</li>
<li>Side-by-side visualization</li>
</ul>
<p><strong>Learn More:</strong> <a href="user-guide/../devx/snapshot-diff.html">Snapshot Diff Documentation</a></p>
<h3 id="mock-oriented-development-mod"><a class="header" href="#mock-oriented-development-mod">Mock-Oriented Development (MOD)</a></h3>
<p>A software development methodology that places mocks at the center of the development workflow.</p>
<p><strong>Key Features:</strong></p>
<ul>
<li>Mock-first design</li>
<li>Contract-driven development</li>
<li>Reality progression</li>
<li>Scenario-driven testing</li>
</ul>
<p><strong>Learn More:</strong> <a href="user-guide/../devx/mock-oriented-development.html">MOD Documentation</a></p>
<h2 id="experimental-features"><a class="header" href="#experimental-features">Experimental Features</a></h2>
<h3 id="deceptive-deploys"><a class="header" href="#deceptive-deploys">Deceptive Deploys</a></h3>
<p>Deploy mock APIs that look identical to production endpoints, perfect for demos, PoCs, and client presentations.</p>
<p><strong>Key Features:</strong></p>
<ul>
<li>Production-like headers and response patterns</li>
<li>Production-like CORS configuration</li>
<li>Production-like rate limiting</li>
<li>OAuth flow simulation</li>
<li>Auto-tunnel deployment</li>
</ul>
<p><strong>Learn More:</strong> <a href="user-guide/deceptive-deploys.html">Deceptive Deploys Documentation</a></p>
<h3 id="voice--llm-interface"><a class="header" href="#voice--llm-interface">Voice + LLM Interface</a></h3>
<p>Generate OpenAPI specifications and mock APIs from natural language voice commands.</p>
<p><strong>Key Features:</strong></p>
<ul>
<li>Voice command parsing with LLM</li>
<li>OpenAPI spec generation from voice commands</li>
<li>Conversational mode for multi-turn interactions</li>
<li>Single-shot mode for complete commands</li>
<li>CLI and Web UI integration</li>
</ul>
<p><strong>Learn More:</strong> <a href="user-guide/voice-llm-interface.html">Voice + LLM Interface Documentation</a></p>
<h3 id="reality-continuum"><a class="header" href="#reality-continuum">Reality Continuum</a></h3>
<p>Gradually transition from mock to real backend data by intelligently blending responses from both sources.</p>
<p><strong>Key Features:</strong></p>
<ul>
<li>Dynamic blending of mock and real responses</li>
<li>Time-based progression with virtual clock integration</li>
<li>Per-route, group-level, and global blend ratios</li>
<li>Multiple merge strategies</li>
<li>Fallback handling for failures</li>
</ul>
<p><strong>Learn More:</strong> <a href="user-guide/reality-continuum.html">Reality Continuum Documentation</a></p>
<h3 id="smart-personas"><a class="header" href="#smart-personas">Smart Personas</a></h3>
<p>Generate coherent, consistent mock data using persona profiles with unique backstories and deterministic generation.</p>
<p><strong>Key Features:</strong></p>
<ul>
<li>Persona profile system with unique IDs and domains</li>
<li>Coherent backstories with template-based generation</li>
<li>Persona relationships (connections between personas)</li>
<li>Deterministic data generation (same persona = same data)</li>
<li>Domain-specific persona templates</li>
</ul>
<p><strong>Learn More:</strong> <a href="user-guide/smart-personas.html">Smart Personas Documentation</a></p>
<h2 id="getting-started-3"><a class="header" href="#getting-started-3">Getting Started</a></h2>
<p>To get started with advanced features:</p>
<ol>
<li><strong>Review the feature documentation</strong> linked above for detailed information</li>
<li><strong>Check configuration examples</strong> in the <a href="user-guide/../configuration/files.html">Configuration Guide</a></li>
<li><strong>Try the tutorials</strong> in the <a href="user-guide/../tutorials/README.html">Tutorials section</a></li>
<li><strong>Explore examples</strong> in the <code>examples/</code> directory</li>
</ol>
<h2 id="feature-comparison"><a class="header" href="#feature-comparison">Feature Comparison</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Feature</th><th>Use Case</th><th>Complexity</th></tr></thead><tbody>
<tr><td>VBR Engine</td><td>Stateful CRUD operations</td><td>Medium</td></tr>
<tr><td>Temporal Simulation</td><td>Time-based testing</td><td>Medium</td></tr>
<tr><td>MockAI</td><td>Intelligent responses</td><td>High</td></tr>
<tr><td>Chaos Lab</td><td>Resilience testing</td><td>Low</td></tr>
<tr><td>Reality Slider</td><td>Quick realism adjustment</td><td>Low</td></tr>
<tr><td>Cloud Workspaces</td><td>Team collaboration</td><td>Medium</td></tr>
<tr><td>ForgeConnect SDK</td><td>Browser-based development</td><td>Low</td></tr>
</tbody></table>
</div>
<h2 id="best-practices-23"><a class="header" href="#best-practices-23">Best Practices</a></h2>
<ol>
<li><strong>Start Simple</strong>: Begin with basic features (Chaos Lab, Reality Slider) before moving to advanced features</li>
<li><strong>Read Documentation</strong>: Each feature has detailed documentation with examples</li>
<li><strong>Use Examples</strong>: Check the <code>examples/</code> directory for working configurations</li>
<li><strong>Test Incrementally</strong>: Enable features one at a time to understand their impact</li>
<li><strong>Monitor Performance</strong>: Some features (like MockAI) may add latency</li>
</ol>
<h2 id="related-documentation-7"><a class="header" href="#related-documentation-7">Related Documentation</a></h2>
<ul>
<li><a href="user-guide/advanced-behavior.html">Advanced Behavior and Simulation</a> - Basic advanced features</li>
<li><a href="user-guide/../configuration/files.html">Configuration Guide</a> - How to configure features</li>
<li><a href="user-guide/../api/rust.html">API Reference</a> - Programmatic API access</li>
<li><a href="user-guide/../tutorials/README.html">Tutorials</a> - Step-by-step guides</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="virtual-backend-reality-vbr-engine-1"><a class="header" href="#virtual-backend-reality-vbr-engine-1">Virtual Backend Reality (VBR) Engine</a></h1>
<p>The Virtual Backend Reality (VBR) Engine provides a virtual ‚Äúdatabase‚Äù layer that automatically generates CRUD operations from OpenAPI specifications. It enables stateful mocking with relationship management, data persistence, and realistic data generation.</p>
<h2 id="overview-14"><a class="header" href="#overview-14">Overview</a></h2>
<p>The VBR Engine transforms MockForge from a simple request/response mock server into a stateful backend simulator. Instead of returning static responses, VBR maintains a virtual database that supports:</p>
<ul>
<li><strong>Automatic CRUD operations</strong> from OpenAPI specs</li>
<li><strong>Relationship mapping</strong> (1:N and N:N)</li>
<li><strong>Data persistence</strong> across server restarts</li>
<li><strong>State snapshots</strong> for point-in-time recovery</li>
<li><strong>Realistic ID generation</strong> with customizable patterns</li>
</ul>
<h2 id="quick-start-8"><a class="header" href="#quick-start-8">Quick Start</a></h2>
<h3 id="from-openapi-specification"><a class="header" href="#from-openapi-specification">From OpenAPI Specification</a></h3>
<p>The easiest way to get started is to generate a VBR engine from an OpenAPI specification:</p>
<pre><code class="language-bash"># Start server with VBR from OpenAPI spec
mockforge serve --spec api.yaml --vbr-enabled
</code></pre>
<p>Or in your configuration:</p>
<pre><code class="language-yaml">vbr:
  enabled: true
  openapi_spec: "./api.yaml"
  backend: "sqlite"  # or "json", "memory"
  storage_path: "./vbr-data"
</code></pre>
<h3 id="programmatic-usage"><a class="header" href="#programmatic-usage">Programmatic Usage</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_vbr::VbrEngine;

// Create engine from OpenAPI spec
let (engine, result) = VbrEngine::from_openapi_file(config, "./api-spec.yaml").await?;

// Or create manually
let mut engine = VbrEngine::new(config).await?;
<span class="boring">}</span></code></pre></pre>
<h2 id="features-4"><a class="header" href="#features-4">Features</a></h2>
<h3 id="automatic-crud-generation"><a class="header" href="#automatic-crud-generation">Automatic CRUD Generation</a></h3>
<p>VBR automatically detects CRUD operations from your OpenAPI specification:</p>
<ul>
<li><strong>GET /users</strong> ‚Üí List all users</li>
<li><strong>GET /users/{id}</strong> ‚Üí Get user by ID</li>
<li><strong>POST /users</strong> ‚Üí Create new user</li>
<li><strong>PUT /users/{id}</strong> ‚Üí Update user</li>
<li><strong>DELETE /users/{id}</strong> ‚Üí Delete user</li>
</ul>
<p>Primary keys are auto-detected (fields named <code>id</code>, <code>uuid</code>, etc.), and foreign keys are inferred from field names ending in <code>_id</code>.</p>
<h3 id="relationship-mapping"><a class="header" href="#relationship-mapping">Relationship Mapping</a></h3>
<h4 id="one-to-many-1n"><a class="header" href="#one-to-many-1n">One-to-Many (1:N)</a></h4>
<p>VBR automatically detects foreign key relationships:</p>
<pre><code class="language-yaml"># OpenAPI spec
components:
  schemas:
    User:
      properties:
        id: { type: integer }
        name: { type: string }
    
    Post:
      properties:
        id: { type: integer }
        user_id: { type: integer }  # Foreign key detected
        title: { type: string }
</code></pre>
<p>This creates a relationship where one User can have many Posts. Access related resources:</p>
<pre><code class="language-bash"># Get all posts for a user
GET /vbr-api/users/1/posts
</code></pre>
<h4 id="many-to-many-nn"><a class="header" href="#many-to-many-nn">Many-to-Many (N:N)</a></h4>
<p>Define many-to-many relationships explicitly:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_vbr::ManyToManyDefinition;

let m2m = ManyToManyDefinition::new("User".to_string(), "Role".to_string());
schema.with_many_to_many(m2m);
<span class="boring">}</span></code></pre></pre>
<p>This creates a junction table automatically (e.g., <code>user_role</code>) and enables:</p>
<pre><code class="language-bash"># Get all roles for a user
GET /vbr-api/users/1/roles

# Get all users with a role
GET /vbr-api/roles/1/users
</code></pre>
<h3 id="data-seeding"><a class="header" href="#data-seeding">Data Seeding</a></h3>
<p>Seed your virtual database with initial data:</p>
<h4 id="from-file"><a class="header" href="#from-file">From File</a></h4>
<pre><code class="language-bash"># Seed from JSON file
mockforge vbr seed --file seed-data.json

# Seed from YAML file
mockforge vbr seed --file seed-data.yaml
</code></pre>
<p><strong>Seed file format:</strong></p>
<pre><code class="language-json">{
  "users": [
    {"id": 1, "name": "Alice", "email": "alice@example.com"},
    {"id": 2, "name": "Bob", "email": "bob@example.com"}
  ],
  "posts": [
    {"id": 1, "user_id": 1, "title": "First Post"},
    {"id": 2, "user_id": 1, "title": "Second Post"}
  ]
}
</code></pre>
<h4 id="programmatic-seeding"><a class="header" href="#programmatic-seeding">Programmatic Seeding</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Seed a single entity
engine.seed_entity("users", vec![
    json!({"name": "Alice", "email": "alice@example.com"}),
    json!({"name": "Bob", "email": "bob@example.com"}),
]).await?;

// Seed all entities from file
engine.seed_from_file("./seed-data.json").await?;

// Clear entity data
engine.clear_entity("users").await?;

// Clear all data
engine.reset().await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="id-generation"><a class="header" href="#id-generation">ID Generation</a></h3>
<p>VBR supports multiple ID generation strategies:</p>
<h4 id="pattern-based-ids"><a class="header" href="#pattern-based-ids">Pattern-Based IDs</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>.with_auto_generation("id", AutoGenerationRule::Pattern("USR-{increment:06}".to_string()))
<span class="boring">}</span></code></pre></pre>
<p><strong>Template variables:</strong></p>
<ul>
<li><code>{increment}</code> or <code>{increment:06}</code> - Auto-incrementing with optional padding</li>
<li><code>{timestamp}</code> - Unix timestamp</li>
<li><code>{random}</code> or <code>{random:8}</code> - Random alphanumeric (default length 8)</li>
<li><code>{uuid}</code> - UUID v4</li>
</ul>
<h4 id="realistic-ids-stripe-style"><a class="header" href="#realistic-ids-stripe-style">Realistic IDs (Stripe-style)</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>.with_auto_generation("id", AutoGenerationRule::Realistic {
    prefix: "cus".to_string(),
    length: 14
})
<span class="boring">}</span></code></pre></pre>
<p>Generates IDs like: <code>cus_abc123def456</code></p>
<h3 id="state-snapshots"><a class="header" href="#state-snapshots">State Snapshots</a></h3>
<p>Create point-in-time snapshots of your virtual database:</p>
<h4 id="create-snapshot"><a class="header" href="#create-snapshot">Create Snapshot</a></h4>
<pre><code class="language-bash"># Via CLI
mockforge vbr snapshot create --name initial --description "Initial state"

# Via API
curl -X POST http://localhost:3000/vbr-api/snapshots \
  -H "Content-Type: application/json" \
  -d '{"name": "initial", "description": "Initial state"}'
</code></pre>
<h4 id="restore-snapshot"><a class="header" href="#restore-snapshot">Restore Snapshot</a></h4>
<pre><code class="language-bash"># Via CLI
mockforge vbr snapshot restore --name initial

# Via API
curl -X POST http://localhost:3000/vbr-api/snapshots/initial/restore
</code></pre>
<h4 id="list-snapshots"><a class="header" href="#list-snapshots">List Snapshots</a></h4>
<pre><code class="language-bash"># Via CLI
mockforge vbr snapshot list

# Via API
curl http://localhost:3000/vbr-api/snapshots
</code></pre>
<h4 id="delete-snapshot"><a class="header" href="#delete-snapshot">Delete Snapshot</a></h4>
<pre><code class="language-bash"># Via CLI
mockforge vbr snapshot delete --name initial

# Via API
curl -X DELETE http://localhost:3000/vbr-api/snapshots/initial
</code></pre>
<h3 id="time-based-expiry"><a class="header" href="#time-based-expiry">Time-Based Expiry</a></h3>
<p>Configure records to expire after a certain time:</p>
<pre><code class="language-yaml">vbr:
  entities:
    - name: sessions
      ttl_seconds: 3600  # Expire after 1 hour
      aging_enabled: true
</code></pre>
<p>Records older than the TTL are automatically removed.</p>
<h2 id="storage-backends-1"><a class="header" href="#storage-backends-1">Storage Backends</a></h2>
<p>VBR supports multiple storage backends:</p>
<h3 id="sqlite-recommended"><a class="header" href="#sqlite-recommended">SQLite (Recommended)</a></h3>
<p>Persistent storage with full SQL support:</p>
<pre><code class="language-yaml">vbr:
  backend: "sqlite"
  storage_path: "./vbr-data.db"
</code></pre>
<p><strong>Advantages:</strong></p>
<ul>
<li>Full SQL query support</li>
<li>ACID transactions</li>
<li>Efficient for large datasets</li>
<li>Easy to inspect with SQL tools</li>
</ul>
<h3 id="json"><a class="header" href="#json">JSON</a></h3>
<p>File-based storage for simple use cases:</p>
<pre><code class="language-yaml">vbr:
  backend: "json"
  storage_path: "./vbr-data.json"
</code></pre>
<p><strong>Advantages:</strong></p>
<ul>
<li>Human-readable</li>
<li>Easy to version control</li>
<li>Simple backup/restore</li>
</ul>
<h3 id="in-memory"><a class="header" href="#in-memory">In-Memory</a></h3>
<p>Fast, non-persistent storage:</p>
<pre><code class="language-yaml">vbr:
  backend: "memory"
</code></pre>
<p><strong>Advantages:</strong></p>
<ul>
<li>Fastest performance</li>
<li>No disk I/O</li>
<li>Perfect for testing</li>
</ul>
<p><strong>Note:</strong> Data is lost on server restart.</p>
<h2 id="api-endpoints"><a class="header" href="#api-endpoints">API Endpoints</a></h2>
<p>VBR automatically creates REST API endpoints for all entities:</p>
<h3 id="entity-operations"><a class="header" href="#entity-operations">Entity Operations</a></h3>
<pre><code class="language-http"># List all entities
GET /vbr-api/{entity}

# Get entity by ID
GET /vbr-api/{entity}/{id}

# Create entity
POST /vbr-api/{entity}
Content-Type: application/json

{
  "name": "Alice",
  "email": "alice@example.com"
}

# Update entity
PUT /vbr-api/{entity}/{id}
Content-Type: application/json

{
  "name": "Alice Updated"
}

# Delete entity
DELETE /vbr-api/{entity}/{id}
</code></pre>
<h3 id="relationship-operations"><a class="header" href="#relationship-operations">Relationship Operations</a></h3>
<pre><code class="language-http"># Get related entities (1:N)
GET /vbr-api/{entity}/{id}/{relationship}

# Get related entities (N:N)
GET /vbr-api/{entity}/{id}/{relationship}
</code></pre>
<h3 id="snapshot-operations"><a class="header" href="#snapshot-operations">Snapshot Operations</a></h3>
<pre><code class="language-http"># Create snapshot
POST /vbr-api/snapshots
Content-Type: application/json

{
  "name": "snapshot1",
  "description": "Optional description"
}

# List snapshots
GET /vbr-api/snapshots

# Get snapshot metadata
GET /vbr-api/snapshots/{name}

# Restore snapshot
POST /vbr-api/snapshots/{name}/restore

# Delete snapshot
DELETE /vbr-api/snapshots/{name}
</code></pre>
<h3 id="database-management"><a class="header" href="#database-management">Database Management</a></h3>
<pre><code class="language-http"># Reset entire database
POST /vbr-api/reset

# Reset specific entity
POST /vbr-api/reset/{entity}
</code></pre>
<h2 id="configuration-11"><a class="header" href="#configuration-11">Configuration</a></h2>
<h3 id="full-configuration-example"><a class="header" href="#full-configuration-example">Full Configuration Example</a></h3>
<pre><code class="language-yaml">vbr:
  enabled: true
  
  # OpenAPI spec for auto-generation
  openapi_spec: "./api.yaml"
  
  # Storage backend
  backend: "sqlite"  # sqlite, json, memory
  storage_path: "./vbr-data"
  
  # Entity configuration
  entities:
    - name: users
      primary_key: "id"
      auto_generation:
        id: "pattern:USR-{increment:06}"
      ttl_seconds: null  # No expiry
      aging_enabled: false
    
    - name: sessions
      primary_key: "id"
      ttl_seconds: 3600  # Expire after 1 hour
      aging_enabled: true
  
  # Relationships
  relationships:
    - type: "one_to_many"
      from: "users"
      to: "posts"
      foreign_key: "user_id"
    
    - type: "many_to_many"
      from: "users"
      to: "roles"
      junction_table: "user_role"
  
  # Snapshot configuration
  snapshots:
    enabled: true
    directory: "./snapshots"
    max_snapshots: 10
</code></pre>
<h2 id="use-cases-1"><a class="header" href="#use-cases-1">Use Cases</a></h2>
<h3 id="development-environment"><a class="header" href="#development-environment">Development Environment</a></h3>
<p>Create a realistic development environment without a real database:</p>
<pre><code class="language-yaml">vbr:
  enabled: true
  backend: "sqlite"
  openapi_spec: "./api.yaml"
</code></pre>
<h3 id="integration-testing-2"><a class="header" href="#integration-testing-2">Integration Testing</a></h3>
<p>Use VBR for integration tests with deterministic data:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Setup
let engine = VbrEngine::from_openapi_file(config, "./api.yaml").await?;
engine.seed_from_file("./test-data.json").await?;

// Run tests
// ...

// Cleanup
engine.reset().await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="demo-environments"><a class="header" href="#demo-environments">Demo Environments</a></h3>
<p>Create snapshots for consistent demo environments:</p>
<pre><code class="language-bash"># Setup demo data
mockforge vbr seed --file demo-data.json

# Create snapshot
mockforge vbr snapshot create --name demo

# Later, restore for consistent demos
mockforge vbr snapshot restore --name demo
</code></pre>
<h2 id="best-practices-24"><a class="header" href="#best-practices-24">Best Practices</a></h2>
<ol>
<li><strong>Use SQLite for Production</strong>: SQLite provides the best balance of performance and features</li>
<li><strong>Seed Initial Data</strong>: Use seed files for consistent starting states</li>
<li><strong>Create Snapshots</strong>: Save important states for quick restoration</li>
<li><strong>Configure TTL</strong>: Use time-based expiry for session-like data</li>
<li><strong>Version Control Seed Files</strong>: Keep seed data in version control</li>
<li><strong>Use Realistic IDs</strong>: Pattern-based IDs make data look more realistic</li>
</ol>
<h2 id="troubleshooting-35"><a class="header" href="#troubleshooting-35">Troubleshooting</a></h2>
<h3 id="primary-key-not-detected"><a class="header" href="#primary-key-not-detected">Primary Key Not Detected</a></h3>
<p>If VBR doesn‚Äôt detect your primary key, specify it explicitly:</p>
<pre><code class="language-yaml">vbr:
  entities:
    - name: users
      primary_key: "user_id"  # Explicit primary key
</code></pre>
<h3 id="foreign-key-not-detected"><a class="header" href="#foreign-key-not-detected">Foreign Key Not Detected</a></h3>
<p>If foreign key relationships aren‚Äôt detected, define them explicitly:</p>
<pre><code class="language-yaml">vbr:
  relationships:
    - type: "one_to_many"
      from: "users"
      to: "posts"
      foreign_key: "author_id"  # Custom foreign key name
</code></pre>
<h3 id="snapshot-restore-fails"><a class="header" href="#snapshot-restore-fails">Snapshot Restore Fails</a></h3>
<p>Ensure the snapshot directory exists and has write permissions:</p>
<pre><code class="language-bash">mkdir -p ./snapshots
chmod 755 ./snapshots
</code></pre>
<h2 id="related-documentation-8"><a class="header" href="#related-documentation-8">Related Documentation</a></h2>
<ul>
<li><a href="user-guide/temporal-simulation.html">Temporal Simulation</a> - Time-based data mutations</li>
<li><a href="user-guide/scenario-state-machines.html">Scenario State Machines</a> - State machine integration</li>
<li><a href="user-guide/../configuration/files.html">Configuration Guide</a> - Complete configuration reference</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="temporal-simulation-time-travel-1"><a class="header" href="#temporal-simulation-time-travel-1">Temporal Simulation (Time Travel)</a></h1>
<p>Temporal Simulation allows you to control time in your mock environment, enabling time-based data mutations, scheduled events, and time-travel debugging. Test time-dependent behavior without waiting for real time to pass.</p>
<h2 id="overview-15"><a class="header" href="#overview-15">Overview</a></h2>
<p>Time travel in MockForge works through a <strong>virtual clock</strong> that can be:</p>
<ul>
<li><strong>Enabled/disabled</strong> at runtime</li>
<li><strong>Set</strong> to any specific point in time</li>
<li><strong>Advanced</strong> by arbitrary durations instantly</li>
<li><strong>Scaled</strong> to run faster or slower than real time</li>
</ul>
<p>When time travel is enabled, all time-related features use the virtual clock instead of the system clock.</p>
<h2 id="quick-start-9"><a class="header" href="#quick-start-9">Quick Start</a></h2>
<h3 id="enable-time-travel"><a class="header" href="#enable-time-travel">Enable Time Travel</a></h3>
<pre><code class="language-yaml"># config.yaml
core:
  time_travel:
    enabled: true
    initial_time: "2025-01-01T00:00:00Z"
    scale_factor: 1.0
    enable_scheduling: true
</code></pre>
<h3 id="control-time-via-cli"><a class="header" href="#control-time-via-cli">Control Time via CLI</a></h3>
<pre><code class="language-bash"># Get time travel status
mockforge time status

# Enable time travel at a specific time
mockforge time enable --time "2025-01-01T00:00:00Z"

# Advance time by 1 month (instantly!)
mockforge time advance 1month

# Advance time by 2 hours
mockforge time advance 2h

# Set time to a specific point
mockforge time set "2025-06-01T12:00:00Z"

# Reset to real time
mockforge time reset
</code></pre>
<h3 id="use-time-based-templates"><a class="header" href="#use-time-based-templates">Use Time-Based Templates</a></h3>
<p>Time-aware template tokens automatically use the virtual clock:</p>
<pre><code class="language-json">{
  "timestamp": "{{now}}",
  "expires_at": "{{now+1h}}",
  "created_at": "{{now-30m}}"
}
</code></pre>
<h2 id="virtual-clock"><a class="header" href="#virtual-clock">Virtual Clock</a></h2>
<p>The virtual clock is the core of temporal simulation. It provides:</p>
<h3 id="basic-operations"><a class="header" href="#basic-operations">Basic Operations</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_core::time_travel::VirtualClock;

let clock = VirtualClock::new();

// Enable and set time
clock.enable_and_set(DateTime::parse_from_rfc3339("2025-01-01T00:00:00Z")?);

// Advance time
clock.advance(Duration::from_secs(3600)); // Advance 1 hour

// Get current virtual time
let now = clock.now();

// Disable (return to real time)
clock.disable();
<span class="boring">}</span></code></pre></pre>
<h3 id="time-scale"><a class="header" href="#time-scale">Time Scale</a></h3>
<p>Run time faster or slower than real time:</p>
<pre><code class="language-bash"># Run at 2x speed
mockforge time scale 2.0

# Run at 0.5x speed (half speed)
mockforge time scale 0.5
</code></pre>
<h2 id="cron-scheduler"><a class="header" href="#cron-scheduler">Cron Scheduler</a></h2>
<p>Schedule recurring events using cron expressions:</p>
<h3 id="create-cron-job"><a class="header" href="#create-cron-job">Create Cron Job</a></h3>
<pre><code class="language-bash"># Via CLI
mockforge time cron create \
  --schedule "0 */6 * * *" \
  --action "callback" \
  --callback-url "http://localhost:3000/api/cleanup"

# Via API
curl -X POST http://localhost:9080/__mockforge/time-travel/cron \
  -H "Content-Type: application/json" \
  -d '{
    "schedule": "0 */6 * * *",
    "action": {
      "type": "callback",
      "url": "http://localhost:3000/api/cleanup"
    },
    "enabled": true
  }'
</code></pre>
<h3 id="cron-expression-format"><a class="header" href="#cron-expression-format">Cron Expression Format</a></h3>
<pre><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ minute (0 - 59)
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ hour (0 - 23)
‚îÇ ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ day of month (1 - 31)
‚îÇ ‚îÇ ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ month (1 - 12)
‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ day of week (0 - 6) (Sunday to Saturday)
‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ
* * * * *
</code></pre>
<p><strong>Examples:</strong></p>
<ul>
<li><code>0 */6 * * *</code> - Every 6 hours</li>
<li><code>0 0 * * *</code> - Daily at midnight</li>
<li><code>*/15 * * * *</code> - Every 15 minutes</li>
<li><code>0 9 * * 1-5</code> - Weekdays at 9 AM</li>
</ul>
<h3 id="list-cron-jobs"><a class="header" href="#list-cron-jobs">List Cron Jobs</a></h3>
<pre><code class="language-bash"># Via CLI
mockforge time cron list

# Via API
curl http://localhost:9080/__mockforge/time-travel/cron
</code></pre>
<h2 id="mutation-rules"><a class="header" href="#mutation-rules">Mutation Rules</a></h2>
<p>Automatically mutate data based on time triggers:</p>
<h3 id="interval-based-mutations"><a class="header" href="#interval-based-mutations">Interval-Based Mutations</a></h3>
<p>Mutate data at regular intervals:</p>
<pre><code class="language-bash"># Create mutation rule
mockforge time mutation create \
  --entity "orders" \
  --trigger "interval:1h" \
  --operation "update_status" \
  --field "status" \
  --value "shipped"

# Via API
curl -X POST http://localhost:9080/__mockforge/time-travel/mutations \
  -H "Content-Type: application/json" \
  -d '{
    "entity": "orders",
    "trigger": {
      "type": "interval",
      "duration": "1h"
    },
    "operation": {
      "type": "update_status",
      "field": "status",
      "value": "shipped"
    }
  }'
</code></pre>
<h3 id="time-based-mutations"><a class="header" href="#time-based-mutations">Time-Based Mutations</a></h3>
<p>Mutate data at specific times:</p>
<pre><code class="language-json">{
  "entity": "tokens",
  "trigger": {
    "type": "at_time",
    "time": "2025-01-01T12:00:00Z"
  },
  "operation": {
    "type": "set",
    "field": "expired",
    "value": true
  }
}
</code></pre>
<h3 id="field-threshold-mutations"><a class="header" href="#field-threshold-mutations">Field Threshold Mutations</a></h3>
<p>Mutate when a field reaches a threshold:</p>
<pre><code class="language-json">{
  "entity": "orders",
  "trigger": {
    "type": "field_threshold",
    "field": "age_days",
    "operator": "&gt;=",
    "value": 30
  },
  "operation": {
    "type": "set",
    "field": "status",
    "value": "archived"
  }
}
</code></pre>
<h2 id="scheduled-responses"><a class="header" href="#scheduled-responses">Scheduled Responses</a></h2>
<p>Schedule responses to be sent at specific times:</p>
<pre><code class="language-bash"># Schedule a response for 30 minutes from now
curl -X POST http://localhost:9080/__mockforge/time-travel/schedule \
  -H "Content-Type: application/json" \
  -d '{
    "trigger_time": "+30m",
    "path": "/api/notifications",
    "method": "POST",
    "body": {"event": "token_expired"},
    "status": 401
  }'
</code></pre>
<h2 id="vbr-integration"><a class="header" href="#vbr-integration">VBR Integration</a></h2>
<p>Temporal simulation integrates with the VBR Engine for time-based data mutations:</p>
<h3 id="snapshot-with-time-travel"><a class="header" href="#snapshot-with-time-travel">Snapshot with Time Travel</a></h3>
<p>Create snapshots that include time travel state:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_vbr::VbrEngine;

// Create snapshot with time travel state
engine.create_snapshot_with_time_travel(
    "snapshot1",
    Some("Description".to_string()),
    "./snapshots",
    &amp;clock
).await?;

// Restore snapshot with time travel state
engine.restore_snapshot_with_time_travel(
    "snapshot1",
    "./snapshots",
    &amp;clock
).await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="mutation-rules-in-vbr"><a class="header" href="#mutation-rules-in-vbr">Mutation Rules in VBR</a></h3>
<p>VBR automatically executes mutation rules based on virtual time:</p>
<pre><code class="language-yaml">vbr:
  entities:
    - name: orders
      mutation_rules:
        - trigger: "interval:1h"
          operation: "update_status"
          field: "status"
          value: "processing"
</code></pre>
<h2 id="admin-api"><a class="header" href="#admin-api">Admin API</a></h2>
<h3 id="time-travel-status"><a class="header" href="#time-travel-status">Time Travel Status</a></h3>
<pre><code class="language-http">GET /__mockforge/time-travel/status
</code></pre>
<p>Response:</p>
<pre><code class="language-json">{
  "enabled": true,
  "virtual_time": "2025-01-15T10:30:00Z",
  "real_time": "2025-01-01T10:30:00Z",
  "scale_factor": 1.0
}
</code></pre>
<h3 id="advance-time"><a class="header" href="#advance-time">Advance Time</a></h3>
<pre><code class="language-http">POST /__mockforge/time-travel/advance
Content-Type: application/json

{
  "duration": "2h"  # or "1month", "30m", etc.
}
</code></pre>
<h3 id="set-time"><a class="header" href="#set-time">Set Time</a></h3>
<pre><code class="language-http">PUT /__mockforge/time-travel/time
Content-Type: application/json

{
  "time": "2025-06-01T12:00:00Z"
}
</code></pre>
<h3 id="enabledisable"><a class="header" href="#enabledisable">Enable/Disable</a></h3>
<pre><code class="language-http">POST /__mockforge/time-travel/enable
Content-Type: application/json

{
  "time": "2025-01-01T00:00:00Z"  # Optional initial time
}
</code></pre>
<pre><code class="language-http">POST /__mockforge/time-travel/disable
</code></pre>
<h2 id="cli-commands"><a class="header" href="#cli-commands">CLI Commands</a></h2>
<h3 id="time-control"><a class="header" href="#time-control">Time Control</a></h3>
<pre><code class="language-bash"># Status
mockforge time status

# Enable
mockforge time enable [--time "2025-01-01T00:00:00Z"]

# Disable
mockforge time disable

# Advance
mockforge time advance &lt;duration&gt;  # e.g., "1month", "2h", "30m"

# Set
mockforge time set &lt;time&gt;  # ISO 8601 format

# Scale
mockforge time scale &lt;factor&gt;  # e.g., 2.0 for 2x speed

# Reset
mockforge time reset
</code></pre>
<h3 id="cron-jobs"><a class="header" href="#cron-jobs">Cron Jobs</a></h3>
<pre><code class="language-bash"># List
mockforge time cron list

# Create
mockforge time cron create --schedule "&lt;cron&gt;" --action "&lt;action&gt;"

# Get
mockforge time cron get &lt;id&gt;

# Update
mockforge time cron update &lt;id&gt; --enabled false

# Delete
mockforge time cron delete &lt;id&gt;
</code></pre>
<h3 id="mutation-rules-1"><a class="header" href="#mutation-rules-1">Mutation Rules</a></h3>
<pre><code class="language-bash"># List
mockforge time mutation list

# Create
mockforge time mutation create --entity "&lt;entity&gt;" --trigger "&lt;trigger&gt;" --operation "&lt;operation&gt;"

# Get
mockforge time mutation get &lt;id&gt;

# Update
mockforge time mutation update &lt;id&gt; --enabled false

# Delete
mockforge time mutation delete &lt;id&gt;
</code></pre>
<h2 id="use-cases-2"><a class="header" href="#use-cases-2">Use Cases</a></h2>
<h3 id="token-expiration"><a class="header" href="#token-expiration">Token Expiration</a></h3>
<p>Test token expiration without waiting:</p>
<pre><code class="language-bash"># Create token that expires in 1 hour
mockforge time enable --time "2025-01-01T00:00:00Z"

# Advance 1 hour
mockforge time advance 1h

# Token is now expired
</code></pre>
<h3 id="session-timeouts"><a class="header" href="#session-timeouts">Session Timeouts</a></h3>
<p>Test session timeout behavior:</p>
<pre><code class="language-yaml">vbr:
  entities:
    - name: sessions
      ttl_seconds: 3600  # 1 hour
      aging_enabled: true
</code></pre>
<h3 id="scheduled-events"><a class="header" href="#scheduled-events">Scheduled Events</a></h3>
<p>Test scheduled notifications:</p>
<pre><code class="language-bash"># Schedule notification for 1 day from now
mockforge time cron create \
  --schedule "0 0 * * *" \
  --action "callback" \
  --callback-url "http://localhost:3000/api/send-daily-report"
</code></pre>
<h3 id="data-aging"><a class="header" href="#data-aging">Data Aging</a></h3>
<p>Test data that changes over time:</p>
<pre><code class="language-bash"># Create mutation rule to age orders
mockforge time mutation create \
  --entity "orders" \
  --trigger "interval:1d" \
  --operation "increment" \
  --field "age_days"
</code></pre>
<h2 id="best-practices-25"><a class="header" href="#best-practices-25">Best Practices</a></h2>
<ol>
<li><strong>Start with Simple Scenarios</strong>: Begin with basic time advancement before using cron or mutations</li>
<li><strong>Use Snapshots</strong>: Save important time states for quick restoration</li>
<li><strong>Test Edge Cases</strong>: Test behavior at midnight, month boundaries, etc.</li>
<li><strong>Monitor Performance</strong>: Time-based features add minimal overhead</li>
<li><strong>Combine with VBR</strong>: Use VBR entities with time-based mutations for realistic scenarios</li>
</ol>
<h2 id="troubleshooting-36"><a class="header" href="#troubleshooting-36">Troubleshooting</a></h2>
<h3 id="time-not-advancing"><a class="header" href="#time-not-advancing">Time Not Advancing</a></h3>
<ul>
<li>Ensure time travel is enabled: <code>mockforge time status</code></li>
<li>Check that scheduling is enabled in configuration</li>
<li>Verify cron jobs are enabled</li>
</ul>
<h3 id="mutations-not-executing"><a class="header" href="#mutations-not-executing">Mutations Not Executing</a></h3>
<ul>
<li>Check mutation rule is enabled</li>
<li>Verify trigger conditions are met</li>
<li>Review server logs for errors</li>
</ul>
<h3 id="cron-jobs-not-running"><a class="header" href="#cron-jobs-not-running">Cron Jobs Not Running</a></h3>
<ul>
<li>Ensure cron scheduler background task is running</li>
<li>Check cron expression is valid</li>
<li>Verify job is enabled</li>
</ul>
<h2 id="related-documentation-9"><a class="header" href="#related-documentation-9">Related Documentation</a></h2>
<ul>
<li><a href="user-guide/vbr-engine.html">VBR Engine</a> - State management with time-based mutations</li>
<li><a href="user-guide/scenario-state-machines.html">Scenario State Machines</a> - Time-based state transitions</li>
<li><a href="user-guide/../configuration/files.html">Configuration Guide</a> - Complete configuration reference</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="scenario-state-machines-20-1"><a class="header" href="#scenario-state-machines-20-1">Scenario State Machines 2.0</a></h1>
<p>Scenario State Machines 2.0 provides a visual flow editor for modeling complex workflows and multi-step scenarios. Create state machines with conditional transitions, reusable sub-scenarios, and real-time state tracking.</p>
<h2 id="overview-16"><a class="header" href="#overview-16">Overview</a></h2>
<p>State machines enable you to model complex API behaviors that depend on previous interactions:</p>
<ul>
<li><strong>Visual Flow Editor</strong>: Drag-and-drop interface for creating state machines</li>
<li><strong>Conditional Transitions</strong>: If/else logic for state transitions</li>
<li><strong>Reusable Sub-Scenarios</strong>: Compose complex workflows from simpler components</li>
<li><strong>Real-Time Preview</strong>: See active state and available transitions</li>
<li><strong>VBR Integration</strong>: Synchronize state with VBR entities</li>
</ul>
<h2 id="quick-start-10"><a class="header" href="#quick-start-10">Quick Start</a></h2>
<h3 id="create-a-state-machine"><a class="header" href="#create-a-state-machine">Create a State Machine</a></h3>
<ol>
<li>Navigate to <strong>State Machines</strong> in the Admin UI</li>
<li>Click <strong>Create New State Machine</strong></li>
<li>Add states and transitions using the visual editor</li>
<li>Configure conditions for transitions</li>
<li>Save the state machine</li>
</ol>
<h3 id="basic-example-order-workflow"><a class="header" href="#basic-example-order-workflow">Basic Example: Order Workflow</a></h3>
<pre><code class="language-yaml">name: order_workflow
initial_state: pending
states:
  - name: pending
    response:
      status_code: 200
      body: '{"order_id": "{{resource_id}}", "status": "pending"}'
  
  - name: processing
    response:
      status_code: 200
      body: '{"order_id": "{{resource_id}}", "status": "processing"}'
  
  - name: shipped
    response:
      status_code: 200
      body: '{"order_id": "{{resource_id}}", "status": "shipped"}'

transitions:
  - from: pending
    to: processing
    condition: 'method == "PUT" &amp;&amp; path == "/api/orders/{id}/process"'
  
  - from: processing
    to: shipped
    condition: 'method == "PUT" &amp;&amp; path == "/api/orders/{id}/ship"'
</code></pre>
<h2 id="visual-editor"><a class="header" href="#visual-editor">Visual Editor</a></h2>
<p>The visual editor provides a React Flow-based interface for creating state machines:</p>
<h3 id="adding-states"><a class="header" href="#adding-states">Adding States</a></h3>
<ol>
<li>Click <strong>Add State</strong> button</li>
<li>Configure state name and response</li>
<li>Position state on canvas</li>
<li>Connect states with transitions</li>
</ol>
<h3 id="creating-transitions"><a class="header" href="#creating-transitions">Creating Transitions</a></h3>
<ol>
<li>Drag from one state to another</li>
<li>Configure transition condition</li>
<li>Set transition metadata (optional)</li>
</ol>
<h3 id="editing-states"><a class="header" href="#editing-states">Editing States</a></h3>
<ul>
<li>Double-click a state to edit</li>
<li>Right-click for context menu</li>
<li>Drag to reposition</li>
</ul>
<h2 id="conditional-transitions"><a class="header" href="#conditional-transitions">Conditional Transitions</a></h2>
<p>Transitions can include conditions that determine when they execute:</p>
<h3 id="method-based-conditions"><a class="header" href="#method-based-conditions">Method-Based Conditions</a></h3>
<pre><code class="language-yaml">transitions:
  - from: pending
    to: processing
    condition: 'method == "POST" &amp;&amp; path == "/api/orders/{id}/process"'
</code></pre>
<h3 id="header-based-conditions"><a class="header" href="#header-based-conditions">Header-Based Conditions</a></h3>
<pre><code class="language-yaml">transitions:
  - from: pending
    to: processing
    condition: 'header["X-Admin"] == "true"'
</code></pre>
<h3 id="body-based-conditions"><a class="header" href="#body-based-conditions">Body-Based Conditions</a></h3>
<pre><code class="language-yaml">transitions:
  - from: pending
    to: processing
    condition: 'body.status == "ready"'
</code></pre>
<h3 id="complex-conditions"><a class="header" href="#complex-conditions">Complex Conditions</a></h3>
<pre><code class="language-yaml">transitions:
  - from: pending
    to: processing
    condition: '(method == "PUT" || method == "PATCH") &amp;&amp; body.amount &gt; 100'
</code></pre>
<h2 id="sub-scenarios"><a class="header" href="#sub-scenarios">Sub-Scenarios</a></h2>
<p>Create reusable sub-scenarios that can be embedded in larger workflows:</p>
<h3 id="define-sub-scenario"><a class="header" href="#define-sub-scenario">Define Sub-Scenario</a></h3>
<pre><code class="language-yaml">name: payment_processing
states:
  - name: initiated
  - name: processing
  - name: completed
  - name: failed

transitions:
  - from: initiated
    to: processing
    condition: 'method == "POST" &amp;&amp; path == "/api/payments"'
</code></pre>
<h3 id="use-sub-scenario"><a class="header" href="#use-sub-scenario">Use Sub-Scenario</a></h3>
<pre><code class="language-yaml">name: order_workflow
states:
  - name: pending
  - name: payment
    sub_scenario: payment_processing
  - name: completed

transitions:
  - from: pending
    to: payment
    condition: 'method == "POST" &amp;&amp; path == "/api/orders/{id}/pay"'
  
  - from: payment
    to: completed
    condition: 'sub_scenario_state == "completed"'
</code></pre>
<h2 id="vbr-integration-1"><a class="header" href="#vbr-integration-1">VBR Integration</a></h2>
<p>Synchronize state machine state with VBR entities:</p>
<h3 id="configure-vbr-entity"><a class="header" href="#configure-vbr-entity">Configure VBR Entity</a></h3>
<pre><code class="language-yaml">vbr:
  entities:
    - name: orders
      state_machine: order_workflow
      state_field: status
</code></pre>
<h3 id="state-synchronization"><a class="header" href="#state-synchronization">State Synchronization</a></h3>
<p>When a state transition occurs, the corresponding VBR entity is updated:</p>
<pre><code class="language-bash"># Transition order to processing
PUT /api/orders/123/process

# VBR entity automatically updated
GET /vbr-api/orders/123
# Response: {"id": 123, "status": "processing", ...}
</code></pre>
<h2 id="api-endpoints-1"><a class="header" href="#api-endpoints-1">API Endpoints</a></h2>
<h3 id="state-machine-crud"><a class="header" href="#state-machine-crud">State Machine CRUD</a></h3>
<pre><code class="language-http"># Create state machine
POST /__mockforge/state-machines
Content-Type: application/json

{
  "name": "order_workflow",
  "initial_state": "pending",
  "states": [...],
  "transitions": [...]
}

# List state machines
GET /__mockforge/state-machines

# Get state machine
GET /__mockforge/state-machines/{id}

# Update state machine
PUT /__mockforge/state-machines/{id}

# Delete state machine
DELETE /__mockforge/state-machines/{id}
</code></pre>
<h3 id="state-instances"><a class="header" href="#state-instances">State Instances</a></h3>
<pre><code class="language-http"># Create state instance
POST /__mockforge/state-machines/{id}/instances
Content-Type: application/json

{
  "resource_id": "order-123",
  "initial_state": "pending"
}

# List instances
GET /__mockforge/state-machines/{id}/instances

# Get instance
GET /__mockforge/state-machines/{id}/instances/{instance_id}

# Transition instance
POST /__mockforge/state-machines/{id}/instances/{instance_id}/transition
Content-Type: application/json

{
  "to_state": "processing",
  "condition_override": null
}
</code></pre>
<h3 id="current-state"><a class="header" href="#current-state">Current State</a></h3>
<pre><code class="language-http"># Get current state
GET /__mockforge/state-machines/{id}/instances/{instance_id}/state

# Get next possible states
GET /__mockforge/state-machines/{id}/instances/{instance_id}/next-states
</code></pre>
<h3 id="importexport"><a class="header" href="#importexport">Import/Export</a></h3>
<pre><code class="language-http"># Export state machine
GET /__mockforge/state-machines/{id}/export

# Import state machine
POST /__mockforge/state-machines/import
Content-Type: application/json

{
  "name": "order_workflow",
  "definition": {...}
}
</code></pre>
<h2 id="real-time-updates-1"><a class="header" href="#real-time-updates-1">Real-Time Updates</a></h2>
<p>State machines support real-time updates via WebSocket:</p>
<h3 id="websocket-events"><a class="header" href="#websocket-events">WebSocket Events</a></h3>
<pre><code class="language-json">{
  "type": "state_machine_transition",
  "state_machine_id": "uuid",
  "instance_id": "uuid",
  "from_state": "pending",
  "to_state": "processing",
  "timestamp": "2025-01-15T10:30:00Z"
}
</code></pre>
<h3 id="subscribe-to-updates"><a class="header" href="#subscribe-to-updates">Subscribe to Updates</a></h3>
<pre><code class="language-javascript">const ws = new WebSocket('ws://localhost:9080/ws');
ws.onmessage = (event) =&gt; {
  const data = JSON.parse(event.data);
  if (data.type === 'state_machine_transition') {
    console.log('State transition:', data);
  }
};
</code></pre>
<h2 id="undoredo"><a class="header" href="#undoredo">Undo/Redo</a></h2>
<p>The visual editor supports undo/redo operations:</p>
<ul>
<li><strong>Undo</strong>: <code>Ctrl+Z</code> or <code>Cmd+Z</code></li>
<li><strong>Redo</strong>: <code>Ctrl+Shift+Z</code> or <code>Cmd+Shift+Z</code></li>
<li><strong>History</strong>: View edit history in editor</li>
</ul>
<h2 id="use-cases-3"><a class="header" href="#use-cases-3">Use Cases</a></h2>
<h3 id="order-processing-workflow"><a class="header" href="#order-processing-workflow">Order Processing Workflow</a></h3>
<p>Model a complete order lifecycle:</p>
<pre><code class="language-yaml">states:
  - pending
  - payment_pending
  - payment_processing
  - payment_completed
  - payment_failed
  - processing
  - shipped
  - delivered
  - cancelled
</code></pre>
<h3 id="user-onboarding"><a class="header" href="#user-onboarding">User Onboarding</a></h3>
<p>Track user onboarding progress:</p>
<pre><code class="language-yaml">states:
  - signup
  - email_verification
  - profile_setup
  - onboarding_complete
</code></pre>
<h3 id="approval-workflows"><a class="header" href="#approval-workflows">Approval Workflows</a></h3>
<p>Model multi-step approval processes:</p>
<pre><code class="language-yaml">states:
  - draft
  - submitted
  - review
  - approved
  - rejected
</code></pre>
<h2 id="best-practices-26"><a class="header" href="#best-practices-26">Best Practices</a></h2>
<ol>
<li><strong>Start Simple</strong>: Begin with basic state machines before adding complexity</li>
<li><strong>Use Sub-Scenarios</strong>: Break complex workflows into reusable components</li>
<li><strong>Test Transitions</strong>: Verify all transitions work as expected</li>
<li><strong>Document Conditions</strong>: Keep transition conditions well-documented</li>
<li><strong>Version Control</strong>: Export and version control state machine definitions</li>
</ol>
<h2 id="troubleshooting-37"><a class="header" href="#troubleshooting-37">Troubleshooting</a></h2>
<h3 id="state-not-transitioning"><a class="header" href="#state-not-transitioning">State Not Transitioning</a></h3>
<ul>
<li>Verify transition condition is correct</li>
<li>Check that request matches condition</li>
<li>Review server logs for errors</li>
</ul>
<h3 id="sub-scenario-not-executing"><a class="header" href="#sub-scenario-not-executing">Sub-Scenario Not Executing</a></h3>
<ul>
<li>Ensure sub-scenario is properly defined</li>
<li>Verify input/output mapping is correct</li>
<li>Check sub-scenario state transitions</li>
</ul>
<h3 id="vbr-sync-issues"><a class="header" href="#vbr-sync-issues">VBR Sync Issues</a></h3>
<ul>
<li>Verify VBR entity configuration</li>
<li>Check state field name matches</li>
<li>Review VBR entity state</li>
</ul>
<h2 id="related-documentation-10"><a class="header" href="#related-documentation-10">Related Documentation</a></h2>
<ul>
<li><a href="user-guide/vbr-engine.html">VBR Engine</a> - State persistence</li>
<li><a href="user-guide/temporal-simulation.html">Temporal Simulation</a> - Time-based state transitions</li>
<li><a href="user-guide/admin-ui.html">Admin UI</a> - Visual editor usage</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="mockai-intelligent-mocking-1"><a class="header" href="#mockai-intelligent-mocking-1">MockAI (Intelligent Mocking)</a></h1>
<p>MockAI is MockForge‚Äôs intelligent mock generation system that uses AI to create contextually appropriate, realistic API responses. It automatically learns from OpenAPI specifications and example payloads to generate intelligent behavior.</p>
<h2 id="overview-17"><a class="header" href="#overview-17">Overview</a></h2>
<p>MockAI provides:</p>
<ul>
<li><strong>Auto-Generated Rules</strong>: Automatically infers behavioral rules from OpenAPI specs or example payloads</li>
<li><strong>Context-Aware Responses</strong>: Maintains session state and conversation history across requests</li>
<li><strong>Mutation Detection</strong>: Intelligently detects create, update, and delete operations from request changes</li>
<li><strong>Validation Error Generation</strong>: Generates realistic, context-aware validation error responses</li>
<li><strong>Pagination Intelligence</strong>: Automatically generates realistic pagination metadata and responses</li>
<li><strong>Session Persistence</strong>: Tracks state across multiple requests within a session</li>
</ul>
<h2 id="quick-start-11"><a class="header" href="#quick-start-11">Quick Start</a></h2>
<h3 id="enable-mockai"><a class="header" href="#enable-mockai">Enable MockAI</a></h3>
<pre><code class="language-yaml"># config.yaml
mockai:
  enabled: true
  auto_learn: true
  mutation_detection: true
  ai_validation_errors: true
  intelligent_pagination: true
</code></pre>
<h3 id="start-server"><a class="header" href="#start-server">Start Server</a></h3>
<pre><code class="language-bash">mockforge serve --config config.yaml --spec api.yaml
</code></pre>
<p>MockAI will automatically:</p>
<ul>
<li>Learn from your OpenAPI specification</li>
<li>Generate intelligent responses</li>
<li>Track session state</li>
<li>Handle mutations and pagination</li>
</ul>
<h2 id="configuration-12"><a class="header" href="#configuration-12">Configuration</a></h2>
<h3 id="basic-configuration-3"><a class="header" href="#basic-configuration-3">Basic Configuration</a></h3>
<pre><code class="language-yaml">mockai:
  enabled: true
  auto_learn: true
  mutation_detection: true
  ai_validation_errors: true
  intelligent_pagination: true
  intelligent_behavior:
    behavior_model:
      provider: "ollama"  # or "openai", "anthropic"
      model: "llama3.2"
      base_url: "http://localhost:11434"
</code></pre>
<h3 id="llm-provider-configuration"><a class="header" href="#llm-provider-configuration">LLM Provider Configuration</a></h3>
<h4 id="ollama-local-free"><a class="header" href="#ollama-local-free">Ollama (Local, Free)</a></h4>
<pre><code class="language-yaml">mockai:
  intelligent_behavior:
    behavior_model:
      provider: "ollama"
      model: "llama3.2"
      base_url: "http://localhost:11434"
</code></pre>
<h4 id="openai"><a class="header" href="#openai">OpenAI</a></h4>
<pre><code class="language-yaml">mockai:
  intelligent_behavior:
    behavior_model:
      provider: "openai"
      model: "gpt-3.5-turbo"
      api_key: "${OPENAI_API_KEY}"
      temperature: 0.7
      max_tokens: 1000
</code></pre>
<h4 id="anthropic"><a class="header" href="#anthropic">Anthropic</a></h4>
<pre><code class="language-yaml">mockai:
  intelligent_behavior:
    behavior_model:
      provider: "anthropic"
      model: "claude-3-sonnet-20240229"
      api_key: "${ANTHROPIC_API_KEY}"
</code></pre>
<h3 id="performance-tuning-4"><a class="header" href="#performance-tuning-4">Performance Tuning</a></h3>
<pre><code class="language-yaml">mockai:
  intelligent_behavior:
    performance:
      max_history_length: 100
      cache_enabled: true
      cache_ttl_seconds: 3600
      timeout_seconds: 30
</code></pre>
<h2 id="cli-commands-1"><a class="header" href="#cli-commands-1">CLI Commands</a></h2>
<h3 id="enabledisable-mockai"><a class="header" href="#enabledisable-mockai">Enable/Disable MockAI</a></h3>
<pre><code class="language-bash"># Enable globally
mockforge mockai enable

# Enable for specific endpoints
mockforge mockai enable --endpoints "/users" "/products"

# Disable globally
mockforge mockai disable

# Disable for specific endpoints
mockforge mockai disable --endpoints "/admin/*"
</code></pre>
<h3 id="check-status"><a class="header" href="#check-status">Check Status</a></h3>
<pre><code class="language-bash">mockforge mockai status
</code></pre>
<h3 id="learn-from-examples"><a class="header" href="#learn-from-examples">Learn from Examples</a></h3>
<pre><code class="language-bash"># Learn from example request/response pairs
mockforge mockai learn --examples examples.json
</code></pre>
<h3 id="generate-response"><a class="header" href="#generate-response">Generate Response</a></h3>
<pre><code class="language-bash"># Generate a response for a request
mockforge mockai generate \
  --method POST \
  --path "/users" \
  --body '{"name": "John"}'
</code></pre>
<h2 id="session-management-2"><a class="header" href="#session-management-2">Session Management</a></h2>
<p>MockAI automatically tracks sessions to maintain context across requests:</p>
<h3 id="session-identification"><a class="header" href="#session-identification">Session Identification</a></h3>
<p>Sessions are identified by:</p>
<ul>
<li><strong>Header</strong>: <code>X-Session-ID: &lt;session-id&gt;</code></li>
<li><strong>Cookie</strong>: <code>mockforge_session=&lt;session-id&gt;</code></li>
</ul>
<p>If no session ID is provided, MockAI generates a new one automatically.</p>
<h3 id="example-with-session"><a class="header" href="#example-with-session">Example with Session</a></h3>
<pre><code class="language-bash"># First request - creates session
curl http://localhost:3000/users

# Response includes session ID in Set-Cookie header
# Subsequent requests use the same session

# Second request with session
curl -H "X-Session-ID: my-session-123" \
     http://localhost:3000/users
</code></pre>
<h2 id="mutation-detection"><a class="header" href="#mutation-detection">Mutation Detection</a></h2>
<p>MockAI automatically detects mutations (create, update, delete) by comparing request bodies:</p>
<h3 id="create-detection"><a class="header" href="#create-detection">Create Detection</a></h3>
<pre><code class="language-bash"># First request - creates a new resource
curl -X POST http://localhost:3000/users \
     -H "Content-Type: application/json" \
     -d '{"name": "John", "email": "john@example.com"}'

# MockAI detects this as a create operation
# Response includes generated ID and created timestamp
</code></pre>
<h3 id="update-detection"><a class="header" href="#update-detection">Update Detection</a></h3>
<pre><code class="language-bash"># Second request with changes - detected as update
curl -X POST http://localhost:3000/users \
     -H "Content-Type: application/json" \
     -H "X-Session-ID: my-session-123" \
     -d '{"name": "John Doe", "email": "john@example.com"}'

# MockAI detects changes and treats as update
# Response reflects updated values
</code></pre>
<h2 id="validation-errors-1"><a class="header" href="#validation-errors-1">Validation Errors</a></h2>
<p>MockAI generates realistic validation errors when requests don‚Äôt match schemas:</p>
<h3 id="missing-required-field"><a class="header" href="#missing-required-field">Missing Required Field</a></h3>
<pre><code class="language-bash">curl -X POST http://localhost:3000/users \
     -H "Content-Type: application/json" \
     -d '{"email": "invalid"}'  # Missing "name" field
</code></pre>
<p>Response:</p>
<pre><code class="language-json">{
  "error": "Validation failed",
  "details": [
    {
      "field": "name",
      "message": "Field 'name' is required"
    },
    {
      "field": "email",
      "message": "Invalid email format"
    }
  ]
}
</code></pre>
<h2 id="pagination"><a class="header" href="#pagination">Pagination</a></h2>
<p>MockAI automatically handles pagination requests:</p>
<h3 id="paginated-request"><a class="header" href="#paginated-request">Paginated Request</a></h3>
<pre><code class="language-bash">curl "http://localhost:3000/users?page=1&amp;limit=10"
</code></pre>
<p>Response:</p>
<pre><code class="language-json">{
  "data": [...],
  "pagination": {
    "page": 1,
    "limit": 10,
    "total": 100,
    "total_pages": 10,
    "has_next": true,
    "has_prev": false
  }
}
</code></pre>
<h2 id="programmatic-usage-1"><a class="header" href="#programmatic-usage-1">Programmatic Usage</a></h2>
<h3 id="create-mockai-from-openapi"><a class="header" href="#create-mockai-from-openapi">Create MockAI from OpenAPI</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_core::intelligent_behavior::{IntelligentBehaviorConfig, MockAI};
use mockforge_core::openapi::OpenApiSpec;

// Load OpenAPI spec
let spec = OpenApiSpec::from_file("api.yaml").await?;

// Create MockAI with default config
let config = IntelligentBehaviorConfig::default();
let mockai = MockAI::from_openapi(&amp;spec, config).await?;

// Process a request
let request = Request {
    method: "POST".to_string(),
    path: "/users".to_string(),
    body: Some(json!({"name": "John"})),
    query_params: HashMap::new(),
    headers: HashMap::new(),
};

let response = mockai.process_request(&amp;request).await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="learn-from-examples-1"><a class="header" href="#learn-from-examples-1">Learn from Examples</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_core::intelligent_behavior::rule_generator::ExamplePair;

let examples = vec![
    ExamplePair {
        method: "POST".to_string(),
        path: "/users".to_string(),
        request: Some(json!({"name": "John"})),
        response: Some(json!({"id": 1, "name": "John"})),
    },
];

mockai.learn_from_example(examples[0]).await?;
<span class="boring">}</span></code></pre></pre>
<h2 id="use-cases-4"><a class="header" href="#use-cases-4">Use Cases</a></h2>
<h3 id="rapid-prototyping"><a class="header" href="#rapid-prototyping">Rapid Prototyping</a></h3>
<p>Generate realistic API responses without writing fixtures:</p>
<pre><code class="language-yaml">mockai:
  enabled: true
  auto_learn: true
</code></pre>
<h3 id="testing-error-handling"><a class="header" href="#testing-error-handling">Testing Error Handling</a></h3>
<p>Generate realistic validation errors:</p>
<pre><code class="language-yaml">mockai:
  enabled: true
  ai_validation_errors: true
</code></pre>
<h3 id="session-based-testing"><a class="header" href="#session-based-testing">Session-Based Testing</a></h3>
<p>Test multi-step workflows with session persistence:</p>
<pre><code class="language-bash"># Step 1: Create session
curl -X POST http://localhost:3000/sessions

# Step 2: Use session in subsequent requests
curl -H "X-Session-ID: &lt;session-id&gt;" \
     http://localhost:3000/users
</code></pre>
<h2 id="best-practices-27"><a class="header" href="#best-practices-27">Best Practices</a></h2>
<ol>
<li><strong>Start with Defaults</strong>: Begin with default configuration and adjust as needed</li>
<li><strong>Use Local LLMs</strong>: For faster responses, use Ollama or similar local providers</li>
<li><strong>Monitor Performance</strong>: Track response times and adjust <code>timeout_seconds</code> accordingly</li>
<li><strong>Session Management</strong>: Use consistent session IDs across related requests</li>
<li><strong>Example Quality</strong>: Provide high-quality examples for better rule generation</li>
</ol>
<h2 id="troubleshooting-38"><a class="header" href="#troubleshooting-38">Troubleshooting</a></h2>
<h3 id="mockai-not-responding"><a class="header" href="#mockai-not-responding">MockAI Not Responding</a></h3>
<ol>
<li>
<p>Check if MockAI is enabled:</p>
<pre><code class="language-bash">mockforge mockai status
</code></pre>
</li>
<li>
<p>Verify LLM provider is accessible:</p>
<pre><code class="language-bash"># For Ollama
curl http://localhost:11434/api/tags
</code></pre>
</li>
<li>
<p>Check logs for errors:</p>
<pre><code class="language-bash">mockforge serve --log-level debug
</code></pre>
</li>
</ol>
<h3 id="session-not-persisting"><a class="header" href="#session-not-persisting">Session Not Persisting</a></h3>
<ul>
<li>Ensure session ID is sent in headers or cookies</li>
<li>Check session timeout settings</li>
<li>Verify session storage is not being cleared</li>
</ul>
<h3 id="slow-responses"><a class="header" href="#slow-responses">Slow Responses</a></h3>
<ul>
<li>Use a smaller/faster model</li>
<li>Enable caching</li>
<li>Reduce <code>max_history_length</code></li>
<li>Use a local LLM provider (Ollama)</li>
</ul>
<h2 id="limitations"><a class="header" href="#limitations">Limitations</a></h2>
<ul>
<li>Query parameter extraction currently requires middleware enhancement</li>
<li>Session contexts are stored in memory (not persisted to disk)</li>
<li>Large OpenAPI specs may take longer to initialize</li>
</ul>
<h2 id="related-documentation-11"><a class="header" href="#related-documentation-11">Related Documentation</a></h2>
<ul>
<li><a href="user-guide/reality-slider.html">Reality Slider</a> - Control MockAI via reality levels</li>
<li><a href="user-guide/../configuration/files.html">Configuration Guide</a> - Complete configuration reference</li>
<li><a href="user-guide/http-mocking/openapi.html">OpenAPI Integration</a> - OpenAPI specification support</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="generative-schema-mode-1"><a class="header" href="#generative-schema-mode-1">Generative Schema Mode</a></h1>
<p>Generative Schema Mode enables you to generate complete API ecosystems from JSON payloads. Simply provide example JSON data, and MockForge automatically creates routes, schemas, and entity relationships for a fully functional mock API.</p>
<h2 id="overview-18"><a class="header" href="#overview-18">Overview</a></h2>
<p>Generative Schema Mode transforms example JSON payloads into:</p>
<ul>
<li><strong>Complete OpenAPI specifications</strong> with all endpoints</li>
<li><strong>Automatic CRUD routes</strong> for each entity</li>
<li><strong>Entity relationship inference</strong> from data structure</li>
<li><strong>One-click environment creation</strong> ready for deployment</li>
<li><strong>Preview and edit</strong> generated schemas before deployment</li>
</ul>
<h2 id="quick-start-12"><a class="header" href="#quick-start-12">Quick Start</a></h2>
<h3 id="generate-from-json-file"><a class="header" href="#generate-from-json-file">Generate from JSON File</a></h3>
<pre><code class="language-bash"># Generate API ecosystem from JSON payloads
mockforge generate --from-json examples.json --output ./generated-api

# Or from multiple files
mockforge generate --from-json file1.json file2.json --output ./generated-api
</code></pre>
<h3 id="generate-from-json-payloads"><a class="header" href="#generate-from-json-payloads">Generate from JSON Payloads</a></h3>
<pre><code class="language-bash"># Generate from inline JSON
mockforge generate --from-json '{"users": [{"id": 1, "name": "Alice"}]}' --output ./api
</code></pre>
<h3 id="one-click-environment-creation"><a class="header" href="#one-click-environment-creation">One-Click Environment Creation</a></h3>
<pre><code class="language-bash"># Generate and start server in one command
mockforge generate --from-json data.json --serve --port 3000
</code></pre>
<h2 id="how-it-works-3"><a class="header" href="#how-it-works-3">How It Works</a></h2>
<h3 id="1-entity-inference"><a class="header" href="#1-entity-inference">1. Entity Inference</a></h3>
<p>MockForge analyzes JSON payloads to infer entity structures:</p>
<p><strong>Input JSON:</strong></p>
<pre><code class="language-json">{
  "users": [
    {"id": 1, "name": "Alice", "email": "alice@example.com"},
    {"id": 2, "name": "Bob", "email": "bob@example.com"}
  ],
  "posts": [
    {"id": 1, "user_id": 1, "title": "First Post", "content": "..."},
    {"id": 2, "user_id": 1, "title": "Second Post", "content": "..."}
  ]
}
</code></pre>
<p><strong>Inferred Entities:</strong></p>
<ul>
<li><code>User</code> entity with fields: <code>id</code>, <code>name</code>, <code>email</code></li>
<li><code>Post</code> entity with fields: <code>id</code>, <code>user_id</code>, <code>title</code>, <code>content</code></li>
<li>Relationship: <code>User</code> has many <code>Post</code> (via <code>user_id</code>)</li>
</ul>
<h3 id="2-route-generation"><a class="header" href="#2-route-generation">2. Route Generation</a></h3>
<p>Automatically generates CRUD routes for each entity:</p>
<p><strong>Generated Routes:</strong></p>
<ul>
<li><code>GET /users</code> - List all users</li>
<li><code>GET /users/{id}</code> - Get user by ID</li>
<li><code>POST /users</code> - Create user</li>
<li><code>PUT /users/{id}</code> - Update user</li>
<li><code>DELETE /users/{id}</code> - Delete user</li>
</ul>
<p>Same routes generated for <code>posts</code>.</p>
<h3 id="3-schema-building"><a class="header" href="#3-schema-building">3. Schema Building</a></h3>
<p>Creates complete OpenAPI 3.0 specification:</p>
<pre><code class="language-yaml">openapi: 3.0.0
info:
  title: Generated API
  version: 1.0.0
paths:
  /users:
    get:
      summary: List users
      responses:
        '200':
          description: List of users
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: '#/components/schemas/User'
components:
  schemas:
    User:
      type: object
      properties:
        id:
          type: integer
        name:
          type: string
        email:
          type: string
          format: email
</code></pre>
<h2 id="configuration-13"><a class="header" href="#configuration-13">Configuration</a></h2>
<h3 id="generation-options"><a class="header" href="#generation-options">Generation Options</a></h3>
<pre><code class="language-yaml">generative_schema:
  enabled: true
  
  # API metadata
  title: "My Generated API"
  version: "1.0.0"
  
  # Naming rules
  naming_rules:
    entity_case: "PascalCase"  # PascalCase, camelCase, snake_case
    route_case: "kebab-case"   # kebab-case, snake_case, camelCase
    pluralization: "standard"  # standard, none, custom
    
  # Generation options
  generate_crud: true
  infer_relationships: true
  merge_schemas: true
</code></pre>
<h3 id="naming-rules"><a class="header" href="#naming-rules">Naming Rules</a></h3>
<p>Customize how entities and routes are named:</p>
<pre><code class="language-yaml">naming_rules:
  # Entity naming
  entity_case: "PascalCase"  # User, OrderItem
  entity_suffix: ""           # Optional suffix
  
  # Route naming
  route_case: "kebab-case"    # /api/users, /api/order-items
  route_prefix: "/api"        # Route prefix
  
  # Pluralization
  pluralization: "standard"   # users, orders
  custom_plurals:
    person: "people"
    child: "children"
</code></pre>
<h2 id="cli-commands-2"><a class="header" href="#cli-commands-2">CLI Commands</a></h2>
<h3 id="generate-from-json"><a class="header" href="#generate-from-json">Generate from JSON</a></h3>
<pre><code class="language-bash"># Basic generation
mockforge generate --from-json data.json

# With output directory
mockforge generate --from-json data.json --output ./generated

# With options
mockforge generate \
  --from-json data.json \
  --title "My API" \
  --version "1.0.0" \
  --output ./generated
</code></pre>
<h3 id="preview-before-generation"><a class="header" href="#preview-before-generation">Preview Before Generation</a></h3>
<pre><code class="language-bash"># Preview generated schema without creating files
mockforge generate --from-json data.json --preview
</code></pre>
<h3 id="generate-and-serve"><a class="header" href="#generate-and-serve">Generate and Serve</a></h3>
<pre><code class="language-bash"># Generate and start server
mockforge generate --from-json data.json --serve --port 3000
</code></pre>
<h2 id="programmatic-usage-2"><a class="header" href="#programmatic-usage-2">Programmatic Usage</a></h2>
<h3 id="generate-ecosystem"><a class="header" href="#generate-ecosystem">Generate Ecosystem</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_core::generative_schema::{
    EcosystemGenerator, GenerationOptions, NamingRules
};
use serde_json::json;

// Example payloads
let payloads = vec![
    json!({
        "users": [
            {"id": 1, "name": "Alice", "email": "alice@example.com"}
        ]
    })
];

// Generation options
let options = GenerationOptions {
    title: Some("My API".to_string()),
    version: Some("1.0.0".to_string()),
    naming_rules: NamingRules::default(),
    generate_crud: true,
    output_dir: Some("./generated".into()),
};

// Generate ecosystem
let result = EcosystemGenerator::generate_from_json(payloads, options).await?;

// Access generated spec
let spec = result.spec;
let entities = result.entities;
let routes = result.routes;
<span class="boring">}</span></code></pre></pre>
<h2 id="entity-relationship-inference"><a class="header" href="#entity-relationship-inference">Entity Relationship Inference</a></h2>
<p>MockForge automatically detects relationships from JSON structure:</p>
<h3 id="one-to-many-1n-1"><a class="header" href="#one-to-many-1n-1">One-to-Many (1:N)</a></h3>
<p>Detected from foreign key patterns:</p>
<pre><code class="language-json">{
  "users": [{"id": 1, "name": "Alice"}],
  "posts": [{"id": 1, "user_id": 1, "title": "Post"}]
}
</code></pre>
<p><strong>Detected Relationship:</strong></p>
<ul>
<li><code>User</code> has many <code>Post</code> (via <code>user_id</code>)</li>
</ul>
<h3 id="many-to-many-nn-1"><a class="header" href="#many-to-many-nn-1">Many-to-Many (N:N)</a></h3>
<p>Detected from junction patterns:</p>
<pre><code class="language-json">{
  "users": [{"id": 1, "name": "Alice"}],
  "roles": [{"id": 1, "name": "admin"}],
  "user_roles": [
    {"user_id": 1, "role_id": 1}
  ]
}
</code></pre>
<p><strong>Detected Relationship:</strong></p>
<ul>
<li><code>User</code> has many <code>Role</code> through <code>user_roles</code></li>
</ul>
<h2 id="schema-merging"><a class="header" href="#schema-merging">Schema Merging</a></h2>
<p>When generating from multiple JSON files, schemas are intelligently merged:</p>
<pre><code class="language-bash"># Generate from multiple files
mockforge generate \
  --from-json users.json posts.json comments.json \
  --output ./generated
</code></pre>
<p><strong>Merging Strategy:</strong></p>
<ul>
<li>Common fields are preserved</li>
<li>New fields are added</li>
<li>Type conflicts are resolved (prefer more specific types)</li>
<li>Relationships are merged</li>
</ul>
<h2 id="preview-and-edit"><a class="header" href="#preview-and-edit">Preview and Edit</a></h2>
<p>Before deploying, preview and edit the generated schema:</p>
<h3 id="preview-generated-schema"><a class="header" href="#preview-generated-schema">Preview Generated Schema</a></h3>
<pre><code class="language-bash"># Preview in terminal
mockforge generate --from-json data.json --preview

# Preview in browser (opens generated OpenAPI spec)
mockforge generate --from-json data.json --preview --open-browser
</code></pre>
<h3 id="edit-before-deployment"><a class="header" href="#edit-before-deployment">Edit Before Deployment</a></h3>
<pre><code class="language-bash"># Generate and open in editor
mockforge generate --from-json data.json --output ./generated --edit

# Manually edit generated/openapi.yaml, then deploy
mockforge serve --spec ./generated/openapi.yaml
</code></pre>
<h2 id="integration-with-vbr"><a class="header" href="#integration-with-vbr">Integration with VBR</a></h2>
<p>Generated schemas can be automatically integrated with VBR:</p>
<pre><code class="language-bash"># Generate with VBR integration
mockforge generate \
  --from-json data.json \
  --vbr-enabled \
  --output ./generated
</code></pre>
<p>This creates:</p>
<ul>
<li>VBR entity definitions</li>
<li>Relationship mappings</li>
<li>Seed data from JSON</li>
</ul>
<h2 id="use-cases-5"><a class="header" href="#use-cases-5">Use Cases</a></h2>
<h3 id="rapid-prototyping-1"><a class="header" href="#rapid-prototyping-1">Rapid Prototyping</a></h3>
<p>Quickly create mock APIs from example data:</p>
<pre><code class="language-bash"># Generate API from sample responses
mockforge generate --from-json sample-responses.json --serve
</code></pre>
<h3 id="api-design"><a class="header" href="#api-design">API Design</a></h3>
<p>Design APIs by example:</p>
<pre><code class="language-bash"># Create API from design mockups
mockforge generate --from-json design-mockups.json --output ./api-design
</code></pre>
<h3 id="testing-data-generation"><a class="header" href="#testing-data-generation">Testing Data Generation</a></h3>
<p>Generate test APIs with realistic data:</p>
<pre><code class="language-bash"># Generate API with test data
mockforge generate --from-json test-data.json --output ./test-api
</code></pre>
<h2 id="best-practices-28"><a class="header" href="#best-practices-28">Best Practices</a></h2>
<ol>
<li><strong>Provide Complete Examples</strong>: Include all fields you want in the generated schema</li>
<li><strong>Use Consistent Naming</strong>: Consistent naming in JSON helps with entity inference</li>
<li><strong>Include Relationships</strong>: Show relationships in JSON for automatic detection</li>
<li><strong>Preview Before Deploy</strong>: Always preview generated schemas before deployment</li>
<li><strong>Version Control</strong>: Commit generated schemas to version control</li>
</ol>
<h2 id="troubleshooting-39"><a class="header" href="#troubleshooting-39">Troubleshooting</a></h2>
<h3 id="entities-not-detected"><a class="header" href="#entities-not-detected">Entities Not Detected</a></h3>
<ul>
<li>Ensure JSON has a clear structure (arrays of objects)</li>
<li>Use consistent field names</li>
<li>Include ID fields for relationship detection</li>
</ul>
<h3 id="routes-not-generated"><a class="header" href="#routes-not-generated">Routes Not Generated</a></h3>
<ul>
<li>Check that <code>generate_crud</code> is enabled</li>
<li>Verify entity names are valid</li>
<li>Review naming rules configuration</li>
</ul>
<h3 id="relationships-not-inferred"><a class="header" href="#relationships-not-inferred">Relationships Not Inferred</a></h3>
<ul>
<li>Use standard foreign key naming (<code>entity_id</code>)</li>
<li>Include junction tables for many-to-many</li>
<li>Provide complete relationship data in JSON</li>
</ul>
<h2 id="related-documentation-12"><a class="header" href="#related-documentation-12">Related Documentation</a></h2>
<ul>
<li><a href="user-guide/vbr-engine.html">VBR Engine</a> - State management for generated entities</li>
<li><a href="user-guide/http-mocking/openapi.html">OpenAPI Integration</a> - Working with generated OpenAPI specs</li>
<li><a href="user-guide/../configuration/files.html">Configuration Guide</a> - Complete configuration reference</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="ai-contract-diff-1"><a class="header" href="#ai-contract-diff-1">AI Contract Diff</a></h1>
<p>AI Contract Diff automatically detects and analyzes differences between API contracts (OpenAPI specifications) and live requests. It provides contextual recommendations for mismatches and generates correction proposals to keep your contracts in sync with reality.</p>
<h2 id="overview-19"><a class="header" href="#overview-19">Overview</a></h2>
<p>AI Contract Diff helps you:</p>
<ul>
<li><strong>Detect Contract Drift</strong>: Find discrepancies between your OpenAPI spec and actual API usage</li>
<li><strong>Get AI-Powered Recommendations</strong>: Understand why mismatches occur and how to fix them</li>
<li><strong>Generate Correction Patches</strong>: Automatically create JSON Patch files to update your specs</li>
<li><strong>Integrate with CI/CD</strong>: Automatically verify contracts in your pipeline</li>
<li><strong>Visualize Mismatches</strong>: Dashboard visualization of contract differences</li>
</ul>
<h2 id="quick-start-13"><a class="header" href="#quick-start-13">Quick Start</a></h2>
<h3 id="analyze-a-request"><a class="header" href="#analyze-a-request">Analyze a Request</a></h3>
<pre><code class="language-bash"># Analyze a captured request against an OpenAPI spec
mockforge contract-diff analyze \
  --spec api.yaml \
  --request-id &lt;capture-id&gt;

# Or analyze from file
mockforge contract-diff analyze \
  --spec api.yaml \
  --request-file request.json
</code></pre>
<h3 id="compare-two-specs"><a class="header" href="#compare-two-specs">Compare Two Specs</a></h3>
<pre><code class="language-bash"># Compare two OpenAPI specifications
mockforge contract-diff compare \
  --spec1 api-v1.yaml \
  --spec2 api-v2.yaml
</code></pre>
<h3 id="generate-correction-patch"><a class="header" href="#generate-correction-patch">Generate Correction Patch</a></h3>
<pre><code class="language-bash"># Generate JSON Patch file for corrections
mockforge contract-diff generate-patch \
  --spec api.yaml \
  --request-id &lt;capture-id&gt; \
  --output patch.json
</code></pre>
<h2 id="how-it-works-4"><a class="header" href="#how-it-works-4">How It Works</a></h2>
<h3 id="1-request-capture"><a class="header" href="#1-request-capture">1. Request Capture</a></h3>
<p>MockForge automatically captures requests for contract analysis:</p>
<pre><code class="language-yaml"># config.yaml
core:
  contract_diff:
    enabled: true
    auto_capture: true
    capture_all: false  # Only capture mismatches
</code></pre>
<h3 id="2-contract-analysis"><a class="header" href="#2-contract-analysis">2. Contract Analysis</a></h3>
<p>When a request is captured, it‚Äôs analyzed against your OpenAPI specification:</p>
<ul>
<li><strong>Path Matching</strong>: Verify request path matches spec</li>
<li><strong>Method Validation</strong>: Check HTTP method is defined</li>
<li><strong>Header Validation</strong>: Compare request headers with spec</li>
<li><strong>Query Parameter Validation</strong>: Verify query params match</li>
<li><strong>Body Validation</strong>: Validate request body against schema</li>
</ul>
<h3 id="3-mismatch-detection"><a class="header" href="#3-mismatch-detection">3. Mismatch Detection</a></h3>
<p>The analyzer identifies several types of mismatches:</p>
<ul>
<li><strong>Missing Endpoint</strong>: Request path not in spec</li>
<li><strong>Invalid Method</strong>: HTTP method not allowed</li>
<li><strong>Missing Header</strong>: Required header not present</li>
<li><strong>Invalid Parameter</strong>: Query param doesn‚Äôt match spec</li>
<li><strong>Schema Mismatch</strong>: Request body doesn‚Äôt match schema</li>
<li><strong>Type Mismatch</strong>: Value type doesn‚Äôt match spec</li>
</ul>
<h3 id="4-ai-recommendations"><a class="header" href="#4-ai-recommendations">4. AI Recommendations</a></h3>
<p>AI-powered recommendations explain mismatches:</p>
<pre><code class="language-json">{
  "mismatch": {
    "type": "missing_field",
    "field": "email",
    "location": "request.body"
  },
  "recommendation": {
    "message": "The 'email' field is required but missing from the request. Add it to the request body or mark it as optional in the schema.",
    "confidence": 0.95,
    "suggested_fix": "Add 'email' field to request body or update schema to make it optional"
  }
}
</code></pre>
<h3 id="5-correction-proposals"><a class="header" href="#5-correction-proposals">5. Correction Proposals</a></h3>
<p>Generate JSON Patch files to fix mismatches:</p>
<pre><code class="language-json">[
  {
    "op": "add",
    "path": "/paths/~1users/post/requestBody/content/application~1json/schema/required",
    "value": ["email"]
  }
]
</code></pre>
<h2 id="configuration-14"><a class="header" href="#configuration-14">Configuration</a></h2>
<h3 id="basic-configuration-4"><a class="header" href="#basic-configuration-4">Basic Configuration</a></h3>
<pre><code class="language-yaml">core:
  contract_diff:
    enabled: true
    auto_capture: true
    capture_all: false
    spec_path: "./api.yaml"
</code></pre>
<h3 id="ai-provider-configuration"><a class="header" href="#ai-provider-configuration">AI Provider Configuration</a></h3>
<pre><code class="language-yaml">core:
  contract_diff:
    ai_provider: "ollama"  # or "openai", "anthropic"
    ai_model: "llama3.2"
    ai_base_url: "http://localhost:11434"
    ai_api_key: "${AI_API_KEY}"  # For OpenAI/Anthropic
</code></pre>
<h3 id="webhook-configuration"><a class="header" href="#webhook-configuration">Webhook Configuration</a></h3>
<pre><code class="language-yaml">core:
  contract_diff:
    webhooks:
      - url: "https://example.com/webhook"
        events: ["mismatch", "high_severity"]
        secret: "${WEBHOOK_SECRET}"
</code></pre>
<h2 id="cli-commands-3"><a class="header" href="#cli-commands-3">CLI Commands</a></h2>
<h3 id="analyze-request"><a class="header" href="#analyze-request">Analyze Request</a></h3>
<pre><code class="language-bash"># Analyze captured request
mockforge contract-diff analyze \
  --spec api.yaml \
  --request-id &lt;capture-id&gt;

# Analyze from file
mockforge contract-diff analyze \
  --spec api.yaml \
  --request-file request.json

# With AI recommendations
mockforge contract-diff analyze \
  --spec api.yaml \
  --request-id &lt;capture-id&gt; \
  --ai-enabled \
  --ai-provider ollama
</code></pre>
<h3 id="compare-specs"><a class="header" href="#compare-specs">Compare Specs</a></h3>
<pre><code class="language-bash"># Compare two OpenAPI specs
mockforge contract-diff compare \
  --spec1 api-v1.yaml \
  --spec2 api-v2.yaml

# Output to file
mockforge contract-diff compare \
  --spec1 api-v1.yaml \
  --spec2 api-v2.yaml \
  --output diff.json
</code></pre>
<h3 id="generate-patch"><a class="header" href="#generate-patch">Generate Patch</a></h3>
<pre><code class="language-bash"># Generate correction patch
mockforge contract-diff generate-patch \
  --spec api.yaml \
  --request-id &lt;capture-id&gt; \
  --output patch.json

# Apply patch automatically
mockforge contract-diff generate-patch \
  --spec api.yaml \
  --request-id &lt;capture-id&gt; \
  --apply
</code></pre>
<h3 id="apply-patch"><a class="header" href="#apply-patch">Apply Patch</a></h3>
<pre><code class="language-bash"># Apply patch to spec
mockforge contract-diff apply-patch \
  --spec api.yaml \
  --patch patch.json \
  --output api-updated.yaml
</code></pre>
<h2 id="api-endpoints-2"><a class="header" href="#api-endpoints-2">API Endpoints</a></h2>
<h3 id="upload-request"><a class="header" href="#upload-request">Upload Request</a></h3>
<pre><code class="language-http">POST /__mockforge/contract-diff/upload
Content-Type: application/json

{
  "method": "POST",
  "path": "/users",
  "headers": {"Content-Type": "application/json"},
  "query_params": {},
  "body": {"name": "Alice", "email": "alice@example.com"}
}
</code></pre>
<h3 id="get-captured-requests"><a class="header" href="#get-captured-requests">Get Captured Requests</a></h3>
<pre><code class="language-http">GET /__mockforge/contract-diff/captures?limit=10&amp;offset=0
</code></pre>
<h3 id="analyze-request-1"><a class="header" href="#analyze-request-1">Analyze Request</a></h3>
<pre><code class="language-http">POST /__mockforge/contract-diff/captures/{id}/analyze
Content-Type: application/json

{
  "spec_path": "./api.yaml"
}
</code></pre>
<h3 id="generate-patch-1"><a class="header" href="#generate-patch-1">Generate Patch</a></h3>
<pre><code class="language-http">POST /__mockforge/contract-diff/captures/{id}/patch
Content-Type: application/json

{
  "spec_path": "./api.yaml"
}
</code></pre>
<h3 id="get-statistics"><a class="header" href="#get-statistics">Get Statistics</a></h3>
<pre><code class="language-http">GET /__mockforge/contract-diff/statistics
</code></pre>
<h2 id="dashboard-1"><a class="header" href="#dashboard-1">Dashboard</a></h2>
<p>The Contract Diff dashboard provides:</p>
<ul>
<li><strong>Statistics Overview</strong>: Total captures, analyzed requests, mismatch counts</li>
<li><strong>Captured Requests List</strong>: Browse and filter captured requests</li>
<li><strong>Analysis Results</strong>: View mismatches, recommendations, and confidence scores</li>
<li><strong>Patch Generation</strong>: Generate and download correction patches</li>
</ul>
<p>Access via: <strong>Admin UI ‚Üí Contract Diff</strong></p>
<h2 id="cicd-integration-7"><a class="header" href="#cicd-integration-7">CI/CD Integration</a></h2>
<h3 id="github-actions-1"><a class="header" href="#github-actions-1">GitHub Actions</a></h3>
<pre><code class="language-yaml">name: Contract Diff Analysis

on:
  pull_request:
    paths:
      - 'api.yaml'
      - '**/*.yaml'

jobs:
  contract-diff:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Analyze contracts
        run: |
          mockforge contract-diff analyze \
            --spec api.yaml \
            --request-id ${{ github.event.pull_request.number }}
      
      - name: Generate patch
        run: |
          mockforge contract-diff generate-patch \
            --spec api.yaml \
            --request-id ${{ github.event.pull_request.number }} \
            --output patch.json
      
      - name: Upload patch
        uses: actions/upload-artifact@v3
        with:
          name: contract-patch
          path: patch.json
</code></pre>
<h3 id="gitlab-ci-1"><a class="header" href="#gitlab-ci-1">GitLab CI</a></h3>
<pre><code class="language-yaml">contract-diff:
  script:
    - mockforge contract-diff analyze --spec api.yaml --request-id $CI_PIPELINE_ID
    - mockforge contract-diff generate-patch --spec api.yaml --request-id $CI_PIPELINE_ID --output patch.json
  artifacts:
    paths:
      - patch.json
</code></pre>
<h2 id="use-cases-6"><a class="header" href="#use-cases-6">Use Cases</a></h2>
<h3 id="contract-validation"><a class="header" href="#contract-validation">Contract Validation</a></h3>
<p>Ensure your API spec matches actual usage:</p>
<pre><code class="language-bash"># Run analysis on all captured requests
for id in $(mockforge contract-diff list-captures --ids); do
  mockforge contract-diff analyze --spec api.yaml --request-id $id
done
</code></pre>
<h3 id="spec-maintenance"><a class="header" href="#spec-maintenance">Spec Maintenance</a></h3>
<p>Keep specs up-to-date automatically:</p>
<pre><code class="language-bash"># Generate patches for all mismatches
mockforge contract-diff generate-patch \
  --spec api.yaml \
  --request-id &lt;capture-id&gt; \
  --output patches/

# Review and apply patches
mockforge contract-diff apply-patch \
  --spec api.yaml \
  --patch patches/patch-1.json \
  --output api-updated.yaml
</code></pre>
<h3 id="api-versioning"><a class="header" href="#api-versioning">API Versioning</a></h3>
<p>Compare API versions:</p>
<pre><code class="language-bash"># Compare v1 and v2
mockforge contract-diff compare \
  --spec1 api-v1.yaml \
  --spec2 api-v2.yaml \
  --output version-diff.json
</code></pre>
<h2 id="best-practices-29"><a class="header" href="#best-practices-29">Best Practices</a></h2>
<ol>
<li><strong>Enable Auto-Capture</strong>: Automatically capture requests for analysis</li>
<li><strong>Regular Analysis</strong>: Run analysis regularly to catch drift early</li>
<li><strong>Review Recommendations</strong>: Always review AI recommendations before applying</li>
<li><strong>Version Control Patches</strong>: Commit patches to version control</li>
<li><strong>CI/CD Integration</strong>: Automate contract validation in your pipeline</li>
</ol>
<h2 id="troubleshooting-40"><a class="header" href="#troubleshooting-40">Troubleshooting</a></h2>
<h3 id="no-mismatches-detected"><a class="header" href="#no-mismatches-detected">No Mismatches Detected</a></h3>
<ul>
<li>Verify OpenAPI spec is valid</li>
<li>Check that request path matches spec</li>
<li>Ensure method is defined in spec</li>
</ul>
<h3 id="ai-recommendations-not-available"><a class="header" href="#ai-recommendations-not-available">AI Recommendations Not Available</a></h3>
<ul>
<li>Check AI provider is configured</li>
<li>Verify API key is set (for OpenAI/Anthropic)</li>
<li>Ensure Ollama is running (for local provider)</li>
</ul>
<h3 id="patch-generation-fails"><a class="header" href="#patch-generation-fails">Patch Generation Fails</a></h3>
<ul>
<li>Verify spec path is correct</li>
<li>Check that mismatches exist</li>
<li>Review patch generation logs</li>
</ul>
<h2 id="related-documentation-13"><a class="header" href="#related-documentation-13">Related Documentation</a></h2>
<ul>
<li><a href="user-guide/http-mocking/openapi.html">OpenAPI Integration</a> - Working with OpenAPI specs</li>
<li><a href="user-guide/../configuration/files.html">Configuration Guide</a> - Complete configuration reference</li>
<li><a href="user-guide/../contributing/release.html">CI/CD Integration</a> - Pipeline integration</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="chaos-lab-1"><a class="header" href="#chaos-lab-1">Chaos Lab</a></h1>
<p>Chaos Lab is an interactive module that enables you to simulate various real-world network conditions and errors directly from the UI. Test application resilience, debug network-related issues, and validate error handling logic.</p>
<h2 id="overview-20"><a class="header" href="#overview-20">Overview</a></h2>
<p>Chaos Lab provides:</p>
<ul>
<li><strong>Real-time latency visualization</strong> - Visual graph showing request latency over time</li>
<li><strong>Network profile management</strong> - Predefined and custom profiles for common network conditions</li>
<li><strong>Error pattern scripting</strong> - Configure burst, random, or sequential error injection</li>
<li><strong>Profile export/import</strong> - Share and version control chaos configurations</li>
<li><strong>CLI integration</strong> - Apply profiles and manage configurations from the command line</li>
</ul>
<h2 id="quick-start-14"><a class="header" href="#quick-start-14">Quick Start</a></h2>
<h3 id="using-the-ui"><a class="header" href="#using-the-ui">Using the UI</a></h3>
<ol>
<li>Navigate to the <strong>Chaos Engineering</strong> page in the MockForge Admin UI</li>
<li>Use the <strong>Network Profiles</strong> section to apply predefined conditions (slow 3G, flaky Wi-Fi, etc.)</li>
<li>Monitor real-time latency in the <strong>Latency Metrics</strong> graph</li>
<li>Configure error patterns in the <strong>Error Pattern Editor</strong></li>
</ol>
<h3 id="using-the-cli"><a class="header" href="#using-the-cli">Using the CLI</a></h3>
<pre><code class="language-bash"># Apply a network profile
mockforge serve --chaos-profile slow_3g

# List available profiles
mockforge chaos profile list

# Export a profile
mockforge chaos profile export slow_3g --format json --output profile.json

# Import a profile
mockforge chaos profile import --file profile.json
</code></pre>
<h2 id="features-5"><a class="header" href="#features-5">Features</a></h2>
<h3 id="real-time-latency-graph"><a class="header" href="#real-time-latency-graph">Real-Time Latency Graph</a></h3>
<p>The latency graph displays request latency over time with:</p>
<ul>
<li><strong>Time-series visualization</strong> - See latency trends in real-time</li>
<li><strong>Statistics overlay</strong> - Min, max, average, P95, P99 percentiles</li>
<li><strong>Auto-refresh</strong> - Updates every 500ms for live monitoring</li>
<li><strong>Configurable history</strong> - View last 100 samples by default</li>
</ul>
<p><strong>Usage:</strong></p>
<ul>
<li>Enable latency injection in the Quick Controls section</li>
<li>The graph automatically populates as requests are made</li>
<li>Hover over data points to see exact latency values</li>
</ul>
<h3 id="network-profiles"><a class="header" href="#network-profiles">Network Profiles</a></h3>
<p>Network profiles are pre-configured chaos settings that simulate specific network conditions:</p>
<h4 id="built-in-profiles"><a class="header" href="#built-in-profiles">Built-in Profiles</a></h4>
<ul>
<li><strong>slow_3g</strong> - Simulates slow 3G connection (high latency, low bandwidth)</li>
<li><strong>flaky_wifi</strong> - Intermittent connection issues with packet loss</li>
<li><strong>high_latency</strong> - Consistent high latency for all requests</li>
<li><strong>unstable_connection</strong> - Random connection drops and timeouts</li>
</ul>
<h4 id="custom-profiles"><a class="header" href="#custom-profiles">Custom Profiles</a></h4>
<p>Create your own profiles:</p>
<ol>
<li>Configure chaos settings in the Quick Controls</li>
<li>Use the Profile Exporter to save your configuration</li>
<li>Import it later or share with your team</li>
</ol>
<p><strong>Applying Profiles:</strong></p>
<pre><code class="language-bash"># Via UI
Click "Apply Profile" on any profile card

# Via CLI
mockforge chaos profile apply slow_3g
</code></pre>
<h3 id="error-pattern-editor"><a class="header" href="#error-pattern-editor">Error Pattern Editor</a></h3>
<p>Configure sophisticated error injection patterns:</p>
<h4 id="burst-pattern"><a class="header" href="#burst-pattern">Burst Pattern</a></h4>
<p>Inject multiple errors within a time window:</p>
<pre><code class="language-json">{
  "type": "burst",
  "count": 5,
  "interval_ms": 1000
}
</code></pre>
<p>This injects 5 errors within 1 second, then waits for the next interval.</p>
<h4 id="random-pattern"><a class="header" href="#random-pattern">Random Pattern</a></h4>
<p>Inject errors with a probability:</p>
<pre><code class="language-json">{
  "type": "random",
  "probability": 0.1
}
</code></pre>
<p>Each request has a 10% chance of receiving an error.</p>
<h4 id="sequential-pattern"><a class="header" href="#sequential-pattern">Sequential Pattern</a></h4>
<p>Inject errors in a specific order:</p>
<pre><code class="language-json">{
  "type": "sequential",
  "sequence": [500, 502, 503, 504]
}
</code></pre>
<p>Errors are injected in the specified order, then the sequence repeats.</p>
<p><strong>Usage:</strong></p>
<ol>
<li>Enable Fault Injection in Quick Controls</li>
<li>Open the Error Pattern Editor</li>
<li>Select pattern type and configure parameters</li>
<li>Click ‚ÄúSave Pattern‚Äù</li>
</ol>
<h3 id="profile-exportimport"><a class="header" href="#profile-exportimport">Profile Export/Import</a></h3>
<p>Export and import chaos configurations for:</p>
<ul>
<li><strong>Version control</strong> - Track chaos configurations in git</li>
<li><strong>Team sharing</strong> - Share tested configurations</li>
<li><strong>CI/CD integration</strong> - Apply profiles in automated tests</li>
<li><strong>Backup</strong> - Save working configurations</li>
</ul>
<p><strong>Export Format:</strong></p>
<pre><code class="language-json">{
  "name": "custom_profile",
  "description": "Custom network condition",
  "chaos_config": {
    "latency": {
      "enabled": true,
      "fixed_delay_ms": 500,
      "probability": 1.0
    },
    "fault_injection": {
      "enabled": true,
      "http_errors": [500, 502, 503],
      "http_error_probability": 0.1
    }
  },
  "tags": ["custom", "testing"],
  "builtin": false
}
</code></pre>
<p><strong>Import:</strong></p>
<ul>
<li>Via UI: Use the Profile Exporter component</li>
<li>Via CLI: <code>mockforge chaos profile import --file profile.json</code></li>
</ul>
<h2 id="api-endpoints-3"><a class="header" href="#api-endpoints-3">API Endpoints</a></h2>
<h3 id="latency-metrics"><a class="header" href="#latency-metrics">Latency Metrics</a></h3>
<pre><code class="language-http">GET /api/chaos/metrics/latency
</code></pre>
<p>Returns time-series latency data:</p>
<pre><code class="language-json">{
  "samples": [
    {
      "timestamp": "2024-01-01T12:00:00Z",
      "latency_ms": 150
    }
  ]
}
</code></pre>
<pre><code class="language-http">GET /api/chaos/metrics/latency/stats
</code></pre>
<p>Returns aggregated statistics:</p>
<pre><code class="language-json">{
  "avg_latency_ms": 145.5,
  "min_latency_ms": 100,
  "max_latency_ms": 200,
  "total_requests": 100,
  "p50_ms": 140,
  "p95_ms": 180,
  "p99_ms": 195
}
</code></pre>
<h3 id="profile-management"><a class="header" href="#profile-management">Profile Management</a></h3>
<pre><code class="language-http">GET /api/chaos/profiles
</code></pre>
<p>List all available profiles.</p>
<pre><code class="language-http">GET /api/chaos/profiles/{name}
</code></pre>
<p>Get a specific profile.</p>
<pre><code class="language-http">POST /api/chaos/profiles/{name}/apply
</code></pre>
<p>Apply a profile to the current configuration.</p>
<pre><code class="language-http">POST /api/chaos/profiles
</code></pre>
<p>Create a custom profile.</p>
<pre><code class="language-http">DELETE /api/chaos/profiles/{name}
</code></pre>
<p>Delete a custom profile.</p>
<pre><code class="language-http">GET /api/chaos/profiles/{name}/export?format=json
</code></pre>
<p>Export a profile.</p>
<pre><code class="language-http">POST /api/chaos/profiles/import
</code></pre>
<p>Import a profile.</p>
<h3 id="error-pattern-configuration"><a class="header" href="#error-pattern-configuration">Error Pattern Configuration</a></h3>
<p>Update error patterns via the fault injection config endpoint:</p>
<pre><code class="language-http">PUT /api/chaos/config/faults
</code></pre>
<pre><code class="language-json">{
  "enabled": true,
  "http_errors": [500, 502, 503],
  "error_pattern": {
    "type": "burst",
    "count": 5,
    "interval_ms": 1000
  }
}
</code></pre>
<h2 id="cli-commands-4"><a class="header" href="#cli-commands-4">CLI Commands</a></h2>
<h3 id="profile-management-1"><a class="header" href="#profile-management-1">Profile Management</a></h3>
<pre><code class="language-bash"># List all profiles
mockforge chaos profile list

# Apply a profile
mockforge chaos profile apply slow_3g

# Export a profile
mockforge chaos profile export slow_3g --format json --output profile.json

# Import a profile
mockforge chaos profile import --file profile.json
</code></pre>
<h3 id="server-startup"><a class="header" href="#server-startup">Server Startup</a></h3>
<pre><code class="language-bash"># Start server with a profile applied
mockforge serve --chaos-profile slow_3g --spec openapi.json
</code></pre>
<h2 id="use-cases-7"><a class="header" href="#use-cases-7">Use Cases</a></h2>
<h3 id="testing-resilience"><a class="header" href="#testing-resilience">Testing Resilience</a></h3>
<ol>
<li>Apply a ‚Äúflaky_wifi‚Äù profile</li>
<li>Monitor your application‚Äôs retry logic</li>
<li>Verify error handling and recovery</li>
</ol>
<h3 id="debugging-network-issues"><a class="header" href="#debugging-network-issues">Debugging Network Issues</a></h3>
<ol>
<li>Reproduce reported network conditions</li>
<li>Use the latency graph to identify patterns</li>
<li>Test fixes under controlled conditions</li>
</ol>
<h3 id="load-testing-preparation"><a class="header" href="#load-testing-preparation">Load Testing Preparation</a></h3>
<ol>
<li>Create profiles matching production network conditions</li>
<li>Export profiles for CI/CD pipelines</li>
<li>Apply profiles during automated tests</li>
</ol>
<h3 id="team-collaboration-1"><a class="header" href="#team-collaboration-1">Team Collaboration</a></h3>
<ol>
<li>Export tested chaos configurations</li>
<li>Share profiles via version control</li>
<li>Standardize testing across environments</li>
</ol>
<h2 id="best-practices-30"><a class="header" href="#best-practices-30">Best Practices</a></h2>
<h3 id="profile-naming"><a class="header" href="#profile-naming">Profile Naming</a></h3>
<ul>
<li>Use descriptive names: <code>production_like_network</code>, <code>mobile_edge_conditions</code></li>
<li>Include tags for categorization: <code>["mobile", "edge", "testing"]</code></li>
<li>Document profile purpose in the description field</li>
</ul>
<h3 id="error-pattern-design"><a class="header" href="#error-pattern-design">Error Pattern Design</a></h3>
<ul>
<li>Start with low probabilities (0.05-0.1) and increase gradually</li>
<li>Use burst patterns to test rate limiting and circuit breakers</li>
<li>Use sequential patterns to test specific error code handling</li>
</ul>
<h3 id="monitoring"><a class="header" href="#monitoring">Monitoring</a></h3>
<ul>
<li>Always monitor the latency graph when chaos is active</li>
<li>Set up alerts for unexpected latency spikes</li>
<li>Review statistics regularly to understand impact</li>
</ul>
<h3 id="version-control"><a class="header" href="#version-control">Version Control</a></h3>
<ul>
<li>Export profiles before making changes</li>
<li>Commit profiles to version control</li>
<li>Tag profiles with application versions</li>
</ul>
<h2 id="troubleshooting-41"><a class="header" href="#troubleshooting-41">Troubleshooting</a></h2>
<h3 id="latency-graph-not-updating"><a class="header" href="#latency-graph-not-updating">Latency Graph Not Updating</a></h3>
<ul>
<li>Ensure latency injection is enabled</li>
<li>Check that requests are being made to the server</li>
<li>Verify the API endpoint is accessible: <code>GET /api/chaos/metrics/latency</code></li>
</ul>
<h3 id="profile-not-applying"><a class="header" href="#profile-not-applying">Profile Not Applying</a></h3>
<ul>
<li>Verify profile name is correct: <code>mockforge chaos profile list</code></li>
<li>Check server logs for errors</li>
<li>Ensure chaos engineering is enabled in configuration</li>
</ul>
<h3 id="error-pattern-not-working"><a class="header" href="#error-pattern-not-working">Error Pattern Not Working</a></h3>
<ul>
<li>Verify fault injection is enabled</li>
<li>Check error pattern configuration is valid JSON</li>
<li>Ensure HTTP error codes are configured: <code>http_errors: [500, 502, 503]</code></li>
</ul>
<h2 id="configuration-15"><a class="header" href="#configuration-15">Configuration</a></h2>
<p>Chaos Lab settings can be configured in <code>mockforge.yaml</code>:</p>
<pre><code class="language-yaml">observability:
  chaos:
    enabled: true
    latency:
      enabled: true
      fixed_delay_ms: 200
      probability: 0.5
    fault_injection:
      enabled: true
      http_errors: [500, 502, 503]
      http_error_probability: 0.1
      error_pattern:
        type: random
        probability: 0.1
</code></pre>
<h2 id="integration-with-test-automation"><a class="header" href="#integration-with-test-automation">Integration with Test Automation</a></h2>
<h3 id="cicd-integration-8"><a class="header" href="#cicd-integration-8">CI/CD Integration</a></h3>
<pre><code class="language-yaml"># Example GitHub Actions workflow
- name: Test with chaos profile
  run: |
    mockforge serve --chaos-profile slow_3g &amp;
    sleep 5
    pytest tests/
    mockforge chaos profile apply none
</code></pre>
<h3 id="test-scripts"><a class="header" href="#test-scripts">Test Scripts</a></h3>
<pre><code class="language-bash">#!/bin/bash
# Apply profile and run tests
mockforge chaos profile apply flaky_wifi --base-url http://localhost:3000
npm test
mockforge chaos profile apply none --base-url http://localhost:3000
</code></pre>
<h2 id="performance-considerations-3"><a class="header" href="#performance-considerations-3">Performance Considerations</a></h2>
<ul>
<li>Latency metrics are stored in memory (last 100 samples)</li>
<li>Profile application is instant (no server restart required)</li>
<li>Error pattern evaluation adds minimal overhead (&lt; 1ms per request)</li>
<li>Real-time graph updates every 500ms (configurable)</li>
</ul>
<h2 id="limitations-1"><a class="header" href="#limitations-1">Limitations</a></h2>
<ul>
<li>Latency samples are limited to the last 100 requests</li>
<li>Custom profiles are stored in memory (not persisted across restarts)</li>
<li>Error patterns apply globally (not per-endpoint)</li>
<li>MockAI integration requires MockAI to be enabled</li>
</ul>
<h2 id="related-documentation-14"><a class="header" href="#related-documentation-14">Related Documentation</a></h2>
<ul>
<li><a href="user-guide/reality-slider.html">Reality Slider</a> - Unified realism control</li>
<li><a href="user-guide/advanced-behavior.html">Advanced Behavior</a> - Basic chaos features</li>
<li><a href="user-guide/../configuration/files.html">Configuration Guide</a> - Complete configuration reference</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="reality-slider-1"><a class="header" href="#reality-slider-1">Reality Slider</a></h1>
<p>The Reality Slider is a unified control mechanism that adjusts the realism of your mock environment from simple static stubs to full production-level chaos. It coordinates three key subsystems: Chaos Engineering, Latency Simulation, and MockAI.</p>
<h2 id="overview-21"><a class="header" href="#overview-21">Overview</a></h2>
<p>By adjusting a single slider from 1 to 5, you can instantly transform your mock environment to match different testing scenarios without manually configuring each subsystem.</p>
<h2 id="reality-levels"><a class="header" href="#reality-levels">Reality Levels</a></h2>
<h3 id="level-1-static-stubs"><a class="header" href="#level-1-static-stubs">Level 1: Static Stubs</a></h3>
<p><strong>Use Case</strong>: Fast, predictable responses for basic functionality testing</p>
<ul>
<li><strong>Chaos</strong>: Disabled</li>
<li><strong>Latency</strong>: 0ms (instant responses)</li>
<li><strong>MockAI</strong>: Disabled</li>
<li><strong>Best For</strong>: Unit tests, rapid prototyping, simple integration checks</li>
</ul>
<h3 id="level-2-light-simulation"><a class="header" href="#level-2-light-simulation">Level 2: Light Simulation</a></h3>
<p><strong>Use Case</strong>: Minimal realism with basic intelligence</p>
<ul>
<li><strong>Chaos</strong>: Disabled</li>
<li><strong>Latency</strong>: 10-50ms (minimal network delay)</li>
<li><strong>MockAI</strong>: Basic AI (simple response generation)</li>
<li><strong>Best For</strong>: Frontend development, basic API testing, quick demos</li>
</ul>
<h3 id="level-3-moderate-realism-default"><a class="header" href="#level-3-moderate-realism-default">Level 3: Moderate Realism (Default)</a></h3>
<p><strong>Use Case</strong>: Balanced realism for most development scenarios</p>
<ul>
<li><strong>Chaos</strong>: 5% error rate, 10% delay probability</li>
<li><strong>Latency</strong>: 50-200ms (moderate network conditions)</li>
<li><strong>MockAI</strong>: Full AI enabled (intelligent responses, relationship awareness)</li>
<li><strong>Best For</strong>: Integration testing, development environments, staging-like behavior</li>
</ul>
<h3 id="level-4-high-realism"><a class="header" href="#level-4-high-realism">Level 4: High Realism</a></h3>
<p><strong>Use Case</strong>: Production-like conditions with increased complexity</p>
<ul>
<li><strong>Chaos</strong>: 10% error rate, 20% delay probability</li>
<li><strong>Latency</strong>: 100-500ms (realistic network conditions)</li>
<li><strong>MockAI</strong>: Full AI + session state management</li>
<li><strong>Best For</strong>: Pre-production testing, realistic user flows, stress testing preparation</li>
</ul>
<h3 id="level-5-production-chaos"><a class="header" href="#level-5-production-chaos">Level 5: Production Chaos</a></h3>
<p><strong>Use Case</strong>: Maximum realism for resilience testing</p>
<ul>
<li><strong>Chaos</strong>: 15% error rate, 30% delay probability</li>
<li><strong>Latency</strong>: 200-2000ms (production-like network conditions)</li>
<li><strong>MockAI</strong>: Full AI + mutations + advanced features</li>
<li><strong>Best For</strong>: Chaos engineering, resilience testing, production simulation</li>
</ul>
<h2 id="usage-1"><a class="header" href="#usage-1">Usage</a></h2>
<h3 id="ui-usage"><a class="header" href="#ui-usage">UI Usage</a></h3>
<h4 id="dashboard-2"><a class="header" href="#dashboard-2">Dashboard</a></h4>
<p>The Reality Slider is available on the Dashboard page:</p>
<ol>
<li>Navigate to <strong>Dashboard</strong> in the admin UI</li>
<li>Find the <strong>Environment Control</strong> section</li>
<li>Use the slider to adjust the reality level (1-5)</li>
<li>Click level indicators for quick selection</li>
<li>View current configuration in the details panel</li>
</ol>
<h4 id="configuration-page"><a class="header" href="#configuration-page">Configuration Page</a></h4>
<p>For advanced control and preset management:</p>
<ol>
<li>Navigate to <strong>Configuration</strong> ‚Üí <strong>Reality Slider</strong></li>
<li>Use the full-featured slider with visual feedback</li>
<li>Manage presets (export/import configurations)</li>
<li>View keyboard shortcuts reference</li>
</ol>
<h3 id="cli-usage"><a class="header" href="#cli-usage">CLI Usage</a></h3>
<h4 id="command-line-flag"><a class="header" href="#command-line-flag">Command Line Flag</a></h4>
<pre><code class="language-bash"># Set reality level at startup
mockforge serve --reality-level 5

# With OpenAPI spec
mockforge serve --spec api.yaml --reality-level 3
</code></pre>
<h4 id="environment-variable"><a class="header" href="#environment-variable">Environment Variable</a></h4>
<pre><code class="language-bash"># Set via environment variable
export MOCKFORGE_REALITY_LEVEL=4
mockforge serve

# Or inline
MOCKFORGE_REALITY_LEVEL=2 mockforge serve --spec api.yaml
</code></pre>
<p><strong>Precedence</strong>: CLI flag &gt; Environment variable &gt; Config file &gt; Default (Level 3)</p>
<h3 id="configuration-file-5"><a class="header" href="#configuration-file-5">Configuration File</a></h3>
<p>Add to your <code>mockforge.yaml</code>:</p>
<pre><code class="language-yaml">reality:
  enabled: true
  level: 3  # 1-5
</code></pre>
<p>Or use per-profile configuration:</p>
<pre><code class="language-yaml">profiles:
  development:
    reality:
      level: 2
  staging:
    reality:
      level: 4
  production:
    reality:
      level: 5
</code></pre>
<h2 id="keyboard-shortcuts-2"><a class="header" href="#keyboard-shortcuts-2">Keyboard Shortcuts</a></h2>
<p>Quick reality level changes from anywhere in the UI:</p>
<div class="table-wrapper"><table><thead><tr><th>Shortcut</th><th>Action</th></tr></thead><tbody>
<tr><td><code>Ctrl+Shift+1</code></td><td>Set to Level 1 (Static Stubs)</td></tr>
<tr><td><code>Ctrl+Shift+2</code></td><td>Set to Level 2 (Light Simulation)</td></tr>
<tr><td><code>Ctrl+Shift+3</code></td><td>Set to Level 3 (Moderate Realism)</td></tr>
<tr><td><code>Ctrl+Shift+4</code></td><td>Set to Level 4 (High Realism)</td></tr>
<tr><td><code>Ctrl+Shift+5</code></td><td>Set to Level 5 (Production Chaos)</td></tr>
<tr><td><code>Ctrl+Shift+R</code></td><td>Reset to default (Level 3)</td></tr>
<tr><td><code>Ctrl+Shift+P</code></td><td>Open preset manager (Config page)</td></tr>
</tbody></table>
</div>
<p><strong>Note</strong>: Shortcuts are disabled when typing in input fields to avoid conflicts.</p>
<h2 id="presets"><a class="header" href="#presets">Presets</a></h2>
<h3 id="exporting-presets"><a class="header" href="#exporting-presets">Exporting Presets</a></h3>
<p>Save your current reality configuration for reuse:</p>
<ol>
<li>Navigate to <strong>Configuration</strong> ‚Üí <strong>Reality Slider</strong></li>
<li>Click <strong>Export Current</strong></li>
<li>Enter a preset name (e.g., ‚Äúproduction-chaos‚Äù, ‚Äústaging-realistic‚Äù)</li>
<li>Optionally add a description</li>
<li>Click <strong>Export Preset</strong></li>
</ol>
<p>Presets are saved as JSON or YAML files in the workspace presets directory.</p>
<h3 id="importing-presets"><a class="header" href="#importing-presets">Importing Presets</a></h3>
<ol>
<li>Navigate to <strong>Configuration</strong> ‚Üí <strong>Reality Slider</strong></li>
<li>Click <strong>Import Preset</strong></li>
<li>Select a preset from the list</li>
<li>Click <strong>Load</strong> to apply</li>
</ol>
<h3 id="preset-file-format"><a class="header" href="#preset-file-format">Preset File Format</a></h3>
<p>Presets are stored as JSON or YAML:</p>
<pre><code class="language-json">{
  "metadata": {
    "name": "production-chaos",
    "description": "Maximum realism for resilience testing",
    "created_at": "2025-01-15T10:30:00Z",
    "version": "1.0"
  },
  "config": {
    "chaos": {
      "enabled": true,
      "error_rate": 0.15,
      "delay_rate": 0.30
    },
    "latency": {
      "base_ms": 200,
      "jitter_ms": 1800
    },
    "mockai": {
      "enabled": true
    }
  }
}
</code></pre>
<h2 id="cicd-integration-9"><a class="header" href="#cicd-integration-9">CI/CD Integration</a></h2>
<h3 id="github-actions-2"><a class="header" href="#github-actions-2">GitHub Actions</a></h3>
<pre><code class="language-yaml">env:
  MOCKFORGE_REALITY_LEVEL: 3  # Moderate Realism for tests

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - name: Run tests with mock
        run: |
          mockforge serve --reality-level ${{ env.MOCKFORGE_REALITY_LEVEL }} &amp;
          # Run your tests
</code></pre>
<h3 id="docker-compose-2"><a class="header" href="#docker-compose-2">Docker Compose</a></h3>
<pre><code class="language-yaml">services:
  mockforge:
    environment:
      - MOCKFORGE_REALITY_LEVEL=${MOCKFORGE_REALITY_LEVEL:-3}
</code></pre>
<h2 id="api-reference"><a class="header" href="#api-reference">API Reference</a></h2>
<h3 id="get-current-reality-level"><a class="header" href="#get-current-reality-level">Get Current Reality Level</a></h3>
<pre><code class="language-http">GET /__mockforge/reality/level
</code></pre>
<p><strong>Response</strong>:</p>
<pre><code class="language-json">{
  "level": 3,
  "level_name": "Moderate Realism",
  "description": "Some chaos, moderate latency, full intelligence",
  "chaos": {
    "enabled": true,
    "error_rate": 0.05,
    "delay_rate": 0.10
  },
  "latency": {
    "base_ms": 50,
    "jitter_ms": 150
  },
  "mockai": {
    "enabled": true
  }
}
</code></pre>
<h3 id="set-reality-level"><a class="header" href="#set-reality-level">Set Reality Level</a></h3>
<pre><code class="language-http">PUT /__mockforge/reality/level
Content-Type: application/json

{
  "level": 5
}
</code></pre>
<h2 id="use-cases-8"><a class="header" href="#use-cases-8">Use Cases</a></h2>
<h3 id="development-workflow-4"><a class="header" href="#development-workflow-4">Development Workflow</a></h3>
<ol>
<li>
<p><strong>Start Development</strong>: Level 2 (Light Simulation)</p>
<ul>
<li>Fast responses for rapid iteration</li>
<li>Basic AI for realistic data</li>
</ul>
</li>
<li>
<p><strong>Integration Testing</strong>: Level 3 (Moderate Realism)</p>
<ul>
<li>Some chaos to catch error handling</li>
<li>Realistic latency for network-aware code</li>
</ul>
</li>
<li>
<p><strong>Pre-Production</strong>: Level 4 (High Realism)</p>
<ul>
<li>Production-like conditions</li>
<li>Full feature set enabled</li>
</ul>
</li>
<li>
<p><strong>Resilience Testing</strong>: Level 5 (Production Chaos)</p>
<ul>
<li>Maximum chaos for stress testing</li>
<li>Simulate worst-case scenarios</li>
</ul>
</li>
</ol>
<h3 id="testing-scenarios-1"><a class="header" href="#testing-scenarios-1">Testing Scenarios</a></h3>
<h4 id="unit-tests-1"><a class="header" href="#unit-tests-1">Unit Tests</a></h4>
<pre><code class="language-bash"># Fast, predictable responses
MOCKFORGE_REALITY_LEVEL=1 npm test
</code></pre>
<h4 id="integration-tests"><a class="header" href="#integration-tests">Integration Tests</a></h4>
<pre><code class="language-bash"># Moderate realism
MOCKFORGE_REALITY_LEVEL=3 npm test
</code></pre>
<h4 id="e2e-tests"><a class="header" href="#e2e-tests">E2E Tests</a></h4>
<pre><code class="language-bash"># High realism for production-like testing
MOCKFORGE_REALITY_LEVEL=4 npm test
</code></pre>
<h4 id="chaos-engineering"><a class="header" href="#chaos-engineering">Chaos Engineering</a></h4>
<pre><code class="language-bash"># Maximum chaos for resilience testing
MOCKFORGE_REALITY_LEVEL=5 npm test
</code></pre>
<h2 id="best-practices-31"><a class="header" href="#best-practices-31">Best Practices</a></h2>
<ol>
<li><strong>Start Low, Increase Gradually</strong>: Begin with Level 1-2 for development, increase as you approach production</li>
<li><strong>Use Presets</strong>: Save common configurations for different environments</li>
<li><strong>CI/CD Integration</strong>: Set appropriate levels for different test stages</li>
<li><strong>Monitor Impact</strong>: Watch metrics as you change levels to understand the impact</li>
<li><strong>Document Your Levels</strong>: Use preset descriptions to document when to use each configuration</li>
</ol>
<h2 id="troubleshooting-42"><a class="header" href="#troubleshooting-42">Troubleshooting</a></h2>
<h3 id="level-changes-not-applying"><a class="header" href="#level-changes-not-applying">Level Changes Not Applying</a></h3>
<ul>
<li>Check that the reality slider is enabled in configuration</li>
<li>Verify API endpoint is accessible: <code>curl http://localhost:9080/__mockforge/reality/level</code></li>
<li>Check server logs for errors</li>
</ul>
<h3 id="shortcuts-not-working"><a class="header" href="#shortcuts-not-working">Shortcuts Not Working</a></h3>
<ul>
<li>Ensure you‚Äôre not typing in an input field</li>
<li>Check browser console for JavaScript errors</li>
<li>Verify shortcuts are enabled (disabled in compact mode)</li>
</ul>
<h3 id="presets-not-loading"><a class="header" href="#presets-not-loading">Presets Not Loading</a></h3>
<ul>
<li>Verify preset file format (JSON or YAML)</li>
<li>Check file permissions</li>
<li>Ensure preset path is correct</li>
<li>Review server logs for import errors</li>
</ul>
<h2 id="related-documentation-15"><a class="header" href="#related-documentation-15">Related Documentation</a></h2>
<ul>
<li><a href="user-guide/chaos-lab.html">Chaos Lab</a> - Detailed chaos engineering features</li>
<li><a href="user-guide/mockai.html">MockAI</a> - Intelligent mocking system</li>
<li><a href="user-guide/../configuration/files.html">Configuration Guide</a> - Complete configuration reference</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="reality-profiles-marketplace-1"><a class="header" href="#reality-profiles-marketplace-1">Reality Profiles Marketplace</a></h1>
<p><strong>Pillars:</strong> [Reality]</p>
<p>The Reality Profiles Marketplace provides pre-tuned ‚Äúrealism packs‚Äù that bundle personas, scenarios, chaos rules, latency curves, error distributions, data mutation behaviors, and protocol behaviors into ready-to-use packages. Think of them as MockForge‚Äôs ‚ÄúKubernetes Operators‚Äù moment‚Äîreusable ops-level behaviors.</p>
<h2 id="overview-22"><a class="header" href="#overview-22">Overview</a></h2>
<p>Reality profile packs are complete configurations that simulate real-world scenarios for specific domains. Instead of manually configuring latency curves, error distributions, and behavioral patterns, you can install a pack that provides all of this out of the box.</p>
<h2 id="available-packs"><a class="header" href="#available-packs">Available Packs</a></h2>
<h3 id="e-commerce-peak-season-pack"><a class="header" href="#e-commerce-peak-season-pack">E-Commerce Peak Season Pack</a></h3>
<p>Simulates high-load e-commerce scenarios with:</p>
<ul>
<li><strong>Increased latency</strong> during peak hours (300ms mean, up to 2000ms)</li>
<li><strong>Cart abandonment patterns</strong> (cart value decreases over time)</li>
<li><strong>Inventory depletion behaviors</strong> (quantity decreases under load)</li>
<li><strong>Seasonal purchase patterns</strong></li>
</ul>
<p><strong>Install:</strong></p>
<pre><code class="language-bash">mockforge reality-profile install ecommerce-peak-season
</code></pre>
<p><strong>Use Case:</strong> Testing your frontend‚Äôs resilience during Black Friday, Cyber Monday, or other high-traffic events.</p>
<h3 id="fintech-fraud-pack"><a class="header" href="#fintech-fraud-pack">Fintech Fraud Pack</a></h3>
<p>Simulates financial services scenarios with:</p>
<ul>
<li><strong>Fraud detection triggers</strong> (suspicious transaction patterns)</li>
<li><strong>Transaction declines</strong> (card declined, insufficient funds)</li>
<li><strong>Risk scoring</strong> (high-risk vs low-risk customer segments)</li>
<li><strong>Compliance behaviors</strong> (KYC checks, AML flags)</li>
</ul>
<p><strong>Install:</strong></p>
<pre><code class="language-bash">mockforge reality-profile install fintech-fraud
</code></pre>
<p><strong>Use Case:</strong> Testing fraud detection systems, payment flows, and compliance workflows.</p>
<h3 id="healthcare-hl7insurance-edge-cases-pack"><a class="header" href="#healthcare-hl7insurance-edge-cases-pack">Healthcare HL7/Insurance Edge Cases Pack</a></h3>
<p>Simulates healthcare scenarios with:</p>
<ul>
<li><strong>HL7 message patterns</strong> (ADT, ORU, MDM message types)</li>
<li><strong>Insurance edge cases</strong> (pre-authorization failures, coverage gaps)</li>
<li><strong>Patient data patterns</strong> (HIPAA-compliant test data)</li>
<li><strong>Medical device integration</strong> (device disconnections, data bursts)</li>
</ul>
<p><strong>Install:</strong></p>
<pre><code class="language-bash">mockforge reality-profile install healthcare-hl7
</code></pre>
<p><strong>Use Case:</strong> Testing HL7 integrations, insurance workflows, and medical device connectivity.</p>
<h3 id="iot-device-fleet-chaos-pack"><a class="header" href="#iot-device-fleet-chaos-pack">IoT Device Fleet Chaos Pack</a></h3>
<p>Simulates IoT scenarios with:</p>
<ul>
<li><strong>Device disconnections</strong> (random disconnects, network failures)</li>
<li><strong>Message bursts</strong> (sudden spikes in telemetry data)</li>
<li><strong>Protocol behaviors</strong> (MQTT, CoAP, WebSocket patterns)</li>
<li><strong>Edge computing patterns</strong> (offline mode, sync conflicts)</li>
</ul>
<p><strong>Install:</strong></p>
<pre><code class="language-bash">mockforge reality-profile install iot-fleet-chaos
</code></pre>
<p><strong>Use Case:</strong> Testing IoT platforms, device management systems, and edge computing scenarios.</p>
<h2 id="installing-packs"><a class="header" href="#installing-packs">Installing Packs</a></h2>
<h3 id="from-pre-built-packs"><a class="header" href="#from-pre-built-packs">From Pre-built Packs</a></h3>
<pre><code class="language-bash"># List available packs
mockforge reality-profile list

# Install a pack
mockforge reality-profile install &lt;pack-name&gt;

# Examples
mockforge reality-profile install ecommerce-peak-season
mockforge reality-profile install fintech-fraud
mockforge reality-profile install healthcare-hl7
mockforge reality-profile install iot-fleet-chaos
</code></pre>
<h3 id="from-custom-paths"><a class="header" href="#from-custom-paths">From Custom Paths</a></h3>
<p>You can also install packs from local files or URLs:</p>
<pre><code class="language-bash"># From local file
mockforge reality-profile install ./my-custom-pack.yaml

# From URL
mockforge reality-profile install https://example.com/packs/custom-pack.yaml
</code></pre>
<h2 id="pack-structure"><a class="header" href="#pack-structure">Pack Structure</a></h2>
<p>Each reality profile pack includes:</p>
<h3 id="1-personas"><a class="header" href="#1-personas">1. Personas</a></h3>
<p>Pre-configured personas with traits matching the domain:</p>
<ul>
<li>E-commerce: <code>premium-customer</code>, <code>bargain-hunter</code>, <code>cart-abandoner</code></li>
<li>Fintech: <code>high-risk-user</code>, <code>vip-customer</code>, <code>fraud-suspect</code></li>
<li>Healthcare: <code>new-patient</code>, <code>chronic-care-patient</code>, <code>emergency-case</code></li>
<li>IoT: <code>smart-home-owner</code>, <code>industrial-operator</code>, <code>fleet-manager</code></li>
</ul>
<h3 id="2-scenarios"><a class="header" href="#2-scenarios">2. Scenarios</a></h3>
<p>Ready-to-use scenarios for common workflows:</p>
<ul>
<li>E-commerce: <code>peak-season-checkout</code>, <code>cart-abandonment-flow</code>, <code>inventory-depletion</code></li>
<li>Fintech: <code>fraud-detection-flow</code>, <code>payment-decline-scenario</code>, <code>kyc-verification</code></li>
<li>Healthcare: <code>patient-admission</code>, <code>insurance-claim-processing</code>, <code>device-alert</code></li>
<li>IoT: <code>device-onboarding</code>, <code>telemetry-burst</code>, <code>firmware-update-failure</code></li>
</ul>
<h3 id="3-chaos-rules"><a class="header" href="#3-chaos-rules">3. Chaos Rules</a></h3>
<p>Pre-configured chaos engineering rules:</p>
<ul>
<li>Latency spikes during peak hours</li>
<li>Error rate increases under load</li>
<li>Network partition simulations</li>
<li>Resource exhaustion patterns</li>
</ul>
<h3 id="4-latency-curves"><a class="header" href="#4-latency-curves">4. Latency Curves</a></h3>
<p>Realistic latency distributions:</p>
<ul>
<li>Normal distributions for typical traffic</li>
<li>Exponential distributions for burst scenarios</li>
<li>Custom curves for specific endpoints</li>
</ul>
<h3 id="5-error-distributions"><a class="header" href="#5-error-distributions">5. Error Distributions</a></h3>
<p>Realistic error patterns:</p>
<ul>
<li>5xx errors under load</li>
<li>4xx errors for invalid requests</li>
<li>Rate limiting (429) during peak</li>
<li>Timeout errors (504) for slow endpoints</li>
</ul>
<h3 id="6-data-mutation-behaviors"><a class="header" href="#6-data-mutation-behaviors">6. Data Mutation Behaviors</a></h3>
<p>Dynamic data changes:</p>
<ul>
<li>Inventory depletion over time</li>
<li>Cart abandonment patterns</li>
<li>Account balance changes</li>
<li>Device state transitions</li>
</ul>
<h3 id="7-protocol-behaviors"><a class="header" href="#7-protocol-behaviors">7. Protocol Behaviors</a></h3>
<p>Protocol-specific behaviors:</p>
<ul>
<li>REST: HTTP method patterns, status code distributions</li>
<li>WebSocket: Connection lifecycle, message patterns</li>
<li>MQTT: Topic subscriptions, QoS levels</li>
<li>gRPC: Streaming patterns, error codes</li>
</ul>
<h2 id="using-packs-in-your-workspace"><a class="header" href="#using-packs-in-your-workspace">Using Packs in Your Workspace</a></h2>
<p>After installing a pack, it‚Äôs available for use in your workspace configuration:</p>
<pre><code class="language-yaml"># mockforge.yaml
reality:
  profiles:
    - name: ecommerce-peak-season
      enabled: true
      # Pack-specific configuration
      peak_hours:
        start: "09:00"
        end: "17:00"
      load_multiplier: 1.5  # 50% more load during peak
</code></pre>
<h2 id="creating-custom-packs"><a class="header" href="#creating-custom-packs">Creating Custom Packs</a></h2>
<p>You can create your own reality profile packs:</p>
<h3 id="1-create-pack-manifest"><a class="header" href="#1-create-pack-manifest">1. Create Pack Manifest</a></h3>
<pre><code class="language-yaml"># my-custom-pack.yaml
name: my-custom-pack
version: 1.0.0
title: My Custom Reality Pack
description: Custom reality profile for my domain
domain: custom
author: My Team

tags:
  - custom
  - internal

# Latency curves
latency_curves:
  - protocol: rest
    distribution: normal
    params:
      mean: 200.0
      std_dev: 50.0
    base_ms: 200
    endpoint_patterns:
      - "/api/custom/*"
    jitter_ms: 25
    min_ms: 100
    max_ms: 1000

# Error distributions
error_distributions:
  - endpoint_pattern: "/api/custom/*"
    error_codes: [500, 503]
    probabilities: [0.05, 0.02]
    pattern:
      type: random
      probability: 0.07

# Data mutation behaviors
data_mutation_behaviors:
  - field_pattern: "body.value"
    mutation_type: increment
    rate: 0.1
    params:
      increment_by: 1
      max_value: 100
</code></pre>
<h3 id="2-install-custom-pack"><a class="header" href="#2-install-custom-pack">2. Install Custom Pack</a></h3>
<pre><code class="language-bash">mockforge reality-profile install ./my-custom-pack.yaml
</code></pre>
<h2 id="pack-configuration"><a class="header" href="#pack-configuration">Pack Configuration</a></h2>
<p>Packs can be configured per-workspace:</p>
<pre><code class="language-yaml">reality:
  profiles:
    - name: ecommerce-peak-season
      enabled: true
      config:
        # Override pack defaults
        peak_hours:
          start: "10:00"
          end: "18:00"
        load_multiplier: 2.0
        error_rate_multiplier: 1.5
</code></pre>
<h2 id="integration-with-other-features"><a class="header" href="#integration-with-other-features">Integration with Other Features</a></h2>
<p>Reality profile packs integrate seamlessly with:</p>
<ul>
<li><strong>Smart Personas</strong>: Packs include personas that work with the pack‚Äôs scenarios</li>
<li><strong>Scenarios</strong>: Pre-built scenarios use the pack‚Äôs behavioral patterns</li>
<li><strong>Chaos Lab</strong>: Pack chaos rules integrate with your chaos experiments</li>
<li><strong>Reality Continuum</strong>: Packs work with blend ratios and reality levels</li>
<li><strong>Time Travel</strong>: Pack behaviors respect virtual time settings</li>
</ul>
<h2 id="best-practices-32"><a class="header" href="#best-practices-32">Best Practices</a></h2>
<ol>
<li><strong>Start with Pre-built Packs</strong>: Use existing packs before creating custom ones</li>
<li><strong>Combine Packs</strong>: You can enable multiple packs and combine their behaviors</li>
<li><strong>Customize Gradually</strong>: Start with defaults, then customize as needed</li>
<li><strong>Version Control</strong>: Keep pack configurations in version control</li>
<li><strong>Team Sharing</strong>: Share custom packs via Git or internal registry</li>
</ol>
<h2 id="examples-9"><a class="header" href="#examples-9">Examples</a></h2>
<h3 id="e-commerce-peak-season-testing"><a class="header" href="#e-commerce-peak-season-testing">E-Commerce Peak Season Testing</a></h3>
<pre><code class="language-bash"># Install pack
mockforge reality-profile install ecommerce-peak-season

# Configure workspace
# mockforge.yaml
reality:
  profiles:
    - name: ecommerce-peak-season
      enabled: true
      config:
        peak_hours:
          start: "00:00"  # Black Friday - all day peak
          end: "23:59"
        load_multiplier: 3.0  # 3x normal load
</code></pre>
<h3 id="fintech-fraud-testing"><a class="header" href="#fintech-fraud-testing">Fintech Fraud Testing</a></h3>
<pre><code class="language-bash"># Install pack
mockforge reality-profile install fintech-fraud

# Use in scenarios
scenarios:
  - name: fraud-detection-test
    persona: high-risk-user
    reality_profile: fintech-fraud
    steps:
      - endpoint: POST /api/transactions
        expected_fraud_score: "&gt; 0.7"
</code></pre>
<h2 id="troubleshooting-43"><a class="header" href="#troubleshooting-43">Troubleshooting</a></h2>
<h3 id="pack-not-found"><a class="header" href="#pack-not-found">Pack Not Found</a></h3>
<p>If a pack isn‚Äôt found, check:</p>
<ul>
<li>Pack name spelling</li>
<li>Pack is installed: <code>mockforge reality-profile list</code></li>
<li>Pack version compatibility</li>
</ul>
<h3 id="conflicts-between-packs"><a class="header" href="#conflicts-between-packs">Conflicts Between Packs</a></h3>
<p>If multiple packs conflict:</p>
<ul>
<li>Check endpoint pattern overlaps</li>
<li>Adjust pack priorities</li>
<li>Disable conflicting packs</li>
<li>Create custom pack combining needed features</li>
</ul>
<h2 id="related-documentation-16"><a class="header" href="#related-documentation-16">Related Documentation</a></h2>
<ul>
<li><a href="user-guide/advanced-features/smart-personas.html">Smart Personas</a> - Persona system used by packs</li>
<li><a href="user-guide/advanced-features/chaos-lab.html">Chaos Lab</a> - Chaos rules in packs</li>
<li><a href="user-guide/advanced-features/reality-continuum.html">Reality Continuum</a> - Reality levels and blending</li>
<li><a href="user-guide/advanced-features/scenario-state-machines.html">Scenarios</a> - Scenario system</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="behavioral-economics-engine-1"><a class="header" href="#behavioral-economics-engine-1">Behavioral Economics Engine</a></h1>
<p><strong>Pillars:</strong> [Reality]</p>
<p>The Behavioral Economics Engine makes mocks react to real-world pressures like latency, load, pricing changes, fraud suspicion, and customer segments. This creates mocks that behave like real customer-driven systems, not just static endpoints.</p>
<h2 id="overview-23"><a class="header" href="#overview-23">Overview</a></h2>
<p>Traditional mocks return fixed responses. The Behavioral Economics Engine adds intelligence that makes mocks adapt their behavior based on system conditions:</p>
<ul>
<li><strong>Cart conversion drops</strong> if latency exceeds 400ms</li>
<li><strong>Bank declines transactions</strong> if prior balance checks failed</li>
<li><strong>User churn increases</strong> after multiple 500 errors</li>
<li><strong>Pricing changes</strong> affect purchase behavior</li>
<li><strong>Fraud suspicion</strong> triggers additional verification</li>
</ul>
<h2 id="key-concepts"><a class="header" href="#key-concepts">Key Concepts</a></h2>
<h3 id="conditions-1"><a class="header" href="#conditions-1">Conditions</a></h3>
<p>Conditions are triggers that evaluate system state:</p>
<ul>
<li><strong>Latency Threshold</strong>: Endpoint latency exceeds a threshold</li>
<li><strong>Load Pressure</strong>: Requests per second exceeds a threshold</li>
<li><strong>Pricing Change</strong>: Product pricing changes by a percentage</li>
<li><strong>Fraud Suspicion</strong>: User‚Äôs risk score exceeds a threshold</li>
<li><strong>Customer Segment</strong>: User belongs to a specific segment</li>
<li><strong>Error Rate</strong>: Error rate for an endpoint exceeds a threshold</li>
</ul>
<h3 id="actions-1"><a class="header" href="#actions-1">Actions</a></h3>
<p>Actions are behaviors executed when conditions are met:</p>
<ul>
<li><strong>Modify Conversion Rate</strong>: Adjust success probability</li>
<li><strong>Change Response Behavior</strong>: Modify response data</li>
<li><strong>Trigger Chaos</strong>: Activate chaos scenarios</li>
<li><strong>Adjust Latency</strong>: Increase/decrease response time</li>
<li><strong>Change Error Rate</strong>: Modify error probability</li>
</ul>
<h3 id="rules"><a class="header" href="#rules">Rules</a></h3>
<p>Rules combine conditions and actions:</p>
<ul>
<li><strong>Declarative Rules</strong>: Simple if-then logic (YAML/JSON)</li>
<li><strong>Scriptable Rules</strong>: Advanced logic (JavaScript/WASM)</li>
</ul>
<h2 id="quick-start-15"><a class="header" href="#quick-start-15">Quick Start</a></h2>
<h3 id="basic-configuration-5"><a class="header" href="#basic-configuration-5">Basic Configuration</a></h3>
<pre><code class="language-yaml"># mockforge.yaml
behavioral_economics:
  enabled: true
  rules:
    - name: latency-conversion-impact
      condition:
        type: latency_threshold
        endpoint: "/api/checkout/*"
        threshold_ms: 400
      action:
        type: modify_conversion_rate
        multiplier: 0.8  # 20% drop in conversion
      priority: 100
</code></pre>
<h3 id="example-cart-abandonment"><a class="header" href="#example-cart-abandonment">Example: Cart Abandonment</a></h3>
<pre><code class="language-yaml">behavioral_economics:
  enabled: true
  rules:
    - name: cart-abandonment-on-latency
      condition:
        type: latency_threshold
        endpoint: "/api/checkout/*"
        threshold_ms: 500
      action:
        type: modify_response
        field: "body.cart_status"
        value: "abandoned"
      priority: 200
</code></pre>
<h2 id="condition-types-1"><a class="header" href="#condition-types-1">Condition Types</a></h2>
<h3 id="latency-threshold"><a class="header" href="#latency-threshold">Latency Threshold</a></h3>
<p>Triggers when endpoint latency exceeds a threshold:</p>
<pre><code class="language-yaml">condition:
  type: latency_threshold
  endpoint: "/api/checkout/*"  # Pattern matching
  threshold_ms: 400
</code></pre>
<p><strong>Use Cases:</strong></p>
<ul>
<li>Cart abandonment on slow checkout</li>
<li>User frustration on slow search</li>
<li>Timeout handling</li>
</ul>
<h3 id="load-pressure"><a class="header" href="#load-pressure">Load Pressure</a></h3>
<p>Triggers when requests per second exceed a threshold:</p>
<pre><code class="language-yaml">condition:
  type: load_pressure
  threshold_rps: 100.0
</code></pre>
<p><strong>Use Cases:</strong></p>
<ul>
<li>Degraded service under load</li>
<li>Rate limiting activation</li>
<li>Circuit breaker patterns</li>
</ul>
<h3 id="pricing-change"><a class="header" href="#pricing-change">Pricing Change</a></h3>
<p>Triggers when product pricing changes:</p>
<pre><code class="language-yaml">condition:
  type: pricing_change
  product_id: "product-123"
  threshold: 0.1  # 10% change
</code></pre>
<p><strong>Use Cases:</strong></p>
<ul>
<li>Purchase behavior changes</li>
<li>Cart abandonment on price increase</li>
<li>Surge pricing effects</li>
</ul>
<h3 id="fraud-suspicion"><a class="header" href="#fraud-suspicion">Fraud Suspicion</a></h3>
<p>Triggers when user‚Äôs fraud risk score exceeds threshold:</p>
<pre><code class="language-yaml">condition:
  type: fraud_suspicion
  user_id: "user-123"
  risk_score: 0.7  # 0.0 to 1.0
</code></pre>
<p><strong>Use Cases:</strong></p>
<ul>
<li>Additional verification required</li>
<li>Transaction declines</li>
<li>Account restrictions</li>
</ul>
<h3 id="customer-segment"><a class="header" href="#customer-segment">Customer Segment</a></h3>
<p>Triggers when user belongs to a segment:</p>
<pre><code class="language-yaml">condition:
  type: customer_segment
  segment: "premium"
</code></pre>
<p><strong>Use Cases:</strong></p>
<ul>
<li>Different service levels</li>
<li>Priority handling</li>
<li>Exclusive features</li>
</ul>
<h3 id="error-rate"><a class="header" href="#error-rate">Error Rate</a></h3>
<p>Triggers when error rate exceeds threshold:</p>
<pre><code class="language-yaml">condition:
  type: error_rate
  endpoint: "/api/payments/*"
  threshold: 0.05  # 5% error rate
</code></pre>
<p><strong>Use Cases:</strong></p>
<ul>
<li>User churn after errors</li>
<li>Retry behavior changes</li>
<li>Fallback activation</li>
</ul>
<h3 id="composite-conditions"><a class="header" href="#composite-conditions">Composite Conditions</a></h3>
<p>Combine multiple conditions with logical operators:</p>
<pre><code class="language-yaml">condition:
  type: composite
  operator: and  # or, not
  conditions:
    - type: latency_threshold
      endpoint: "/api/checkout/*"
      threshold_ms: 400
    - type: load_pressure
      threshold_rps: 100.0
</code></pre>
<h2 id="action-types"><a class="header" href="#action-types">Action Types</a></h2>
<h3 id="modify-conversion-rate"><a class="header" href="#modify-conversion-rate">Modify Conversion Rate</a></h3>
<p>Adjusts the probability of successful operations:</p>
<pre><code class="language-yaml">action:
  type: modify_conversion_rate
  multiplier: 0.8  # 80% of normal conversion
</code></pre>
<p><strong>Use Cases:</strong></p>
<ul>
<li>Cart abandonment on slow checkout</li>
<li>Purchase drop on high latency</li>
<li>Signup reduction on errors</li>
</ul>
<h3 id="modify-response"><a class="header" href="#modify-response">Modify Response</a></h3>
<p>Changes response data:</p>
<pre><code class="language-yaml">action:
  type: modify_response
  field: "body.status"
  value: "pending"
</code></pre>
<p><strong>Use Cases:</strong></p>
<ul>
<li>Status changes based on conditions</li>
<li>Data mutations</li>
<li>State transitions</li>
</ul>
<h3 id="trigger-chaos"><a class="header" href="#trigger-chaos">Trigger Chaos</a></h3>
<p>Activates chaos scenarios:</p>
<pre><code class="language-yaml">action:
  type: trigger_chaos
  scenario: "high-error-rate"
  duration_seconds: 60
</code></pre>
<p><strong>Use Cases:</strong></p>
<ul>
<li>Simulating incidents</li>
<li>Testing resilience</li>
<li>Chaos engineering</li>
</ul>
<h3 id="adjust-latency"><a class="header" href="#adjust-latency">Adjust Latency</a></h3>
<p>Modifies response latency:</p>
<pre><code class="language-yaml">action:
  type: adjust_latency
  multiplier: 1.5  # 50% increase
  max_ms: 2000
</code></pre>
<p><strong>Use Cases:</strong></p>
<ul>
<li>Degraded performance simulation</li>
<li>Network condition emulation</li>
<li>Timeout testing</li>
</ul>
<h3 id="change-error-rate"><a class="header" href="#change-error-rate">Change Error Rate</a></h3>
<p>Modifies error probability:</p>
<pre><code class="language-yaml">action:
  type: change_error_rate
  multiplier: 2.0  # Double error rate
  error_codes: [500, 503]
</code></pre>
<p><strong>Use Cases:</strong></p>
<ul>
<li>Error spike simulation</li>
<li>Failure testing</li>
<li>Resilience validation</li>
</ul>
<h2 id="advanced-scriptable-rules"><a class="header" href="#advanced-scriptable-rules">Advanced: Scriptable Rules</a></h2>
<p>For complex logic, use JavaScript/WASM scripts:</p>
<pre><code class="language-yaml">behavioral_economics:
  enabled: true
  rules:
    - name: complex-fraud-detection
      rule_type: scriptable
      script: |
        function evaluate(context) {
          const latency = context.latency;
          const load = context.load_rps;
          const fraudScore = context.fraud_score;
          
          if (latency &gt; 400 &amp;&amp; load &gt; 100 &amp;&amp; fraudScore &gt; 0.7) {
            return {
              action: "decline_transaction",
              reason: "High risk under load"
            };
          }
          return null;
        }
      priority: 1000
</code></pre>
<h2 id="real-world-examples"><a class="header" href="#real-world-examples">Real-World Examples</a></h2>
<h3 id="e-commerce-cart-conversion"><a class="header" href="#e-commerce-cart-conversion">E-Commerce: Cart Conversion</a></h3>
<pre><code class="language-yaml">behavioral_economics:
  rules:
    - name: cart-conversion-drop
      condition:
        type: latency_threshold
        endpoint: "/api/checkout/*"
        threshold_ms: 400
      action:
        type: modify_conversion_rate
        multiplier: 0.7  # 30% drop
      priority: 100
</code></pre>
<p><strong>Result:</strong> When checkout latency exceeds 400ms, only 70% of carts convert (vs normal 90%).</p>
<h3 id="fintech-transaction-declines"><a class="header" href="#fintech-transaction-declines">Fintech: Transaction Declines</a></h3>
<pre><code class="language-yaml">behavioral_economics:
  rules:
    - name: decline-on-failed-balance-check
      condition:
        type: composite
        operator: and
        conditions:
          - type: error_rate
            endpoint: "/api/balance/*"
            threshold: 0.1
          - type: fraud_suspicion
            risk_score: 0.6
      action:
        type: modify_response
        field: "body.status"
        value: "declined"
        reason: "Balance check failed"
      priority: 200
</code></pre>
<p><strong>Result:</strong> Transactions are declined if balance checks fail and fraud risk is high.</p>
<h3 id="saas-user-churn"><a class="header" href="#saas-user-churn">SaaS: User Churn</a></h3>
<pre><code class="language-yaml">behavioral_economics:
  rules:
    - name: churn-after-multiple-errors
      condition:
        type: error_rate
        endpoint: "/api/*"
        threshold: 0.05  # 5% error rate
      action:
        type: modify_response
        field: "body.churn_risk"
        value: "high"
      priority: 150
</code></pre>
<p><strong>Result:</strong> User churn risk increases after experiencing multiple errors.</p>
<h2 id="integration-with-other-features-1"><a class="header" href="#integration-with-other-features-1">Integration with Other Features</a></h2>
<p>The Behavioral Economics Engine integrates with:</p>
<ul>
<li><strong>Smart Personas</strong>: Persona traits influence condition evaluation</li>
<li><strong>Chaos Lab</strong>: Actions can trigger chaos scenarios</li>
<li><strong>Reality Continuum</strong>: Behaviors respect reality levels</li>
<li><strong>Scenarios</strong>: Rules can be scenario-specific</li>
<li><strong>Time Travel</strong>: Conditions respect virtual time</li>
</ul>
<h2 id="configuration-reference"><a class="header" href="#configuration-reference">Configuration Reference</a></h2>
<h3 id="full-configuration"><a class="header" href="#full-configuration">Full Configuration</a></h3>
<pre><code class="language-yaml">behavioral_economics:
  enabled: true
  update_interval_ms: 1000  # How often to evaluate rules
  rules:
    - name: rule-name
      rule_type: declarative  # or scriptable
      condition:
        # Condition configuration
      action:
        # Action configuration
      priority: 100  # Higher = evaluated first
      enabled: true
</code></pre>
<h3 id="rule-priority"><a class="header" href="#rule-priority">Rule Priority</a></h3>
<p>Rules are evaluated in priority order (highest first). The first matching rule‚Äôs action is executed.</p>
<h2 id="best-practices-33"><a class="header" href="#best-practices-33">Best Practices</a></h2>
<ol>
<li><strong>Start Simple</strong>: Use declarative rules for 80% of use cases</li>
<li><strong>Test Incrementally</strong>: Add one rule at a time and test</li>
<li><strong>Monitor Impact</strong>: Track how rules affect system behavior</li>
<li><strong>Document Rules</strong>: Document why each rule exists</li>
<li><strong>Version Control</strong>: Keep rules in version control</li>
</ol>
<h2 id="troubleshooting-44"><a class="header" href="#troubleshooting-44">Troubleshooting</a></h2>
<h3 id="rules-not-triggering"><a class="header" href="#rules-not-triggering">Rules Not Triggering</a></h3>
<ul>
<li>Check condition thresholds (may be too high/low)</li>
<li>Verify endpoint patterns match actual endpoints</li>
<li>Check rule priority (higher priority rules may override)</li>
<li>Enable debug logging: <code>behavioral_economics.debug: true</code></li>
</ul>
<h3 id="unexpected-behavior"><a class="header" href="#unexpected-behavior">Unexpected Behavior</a></h3>
<ul>
<li>Review rule priority order</li>
<li>Check for conflicting rules</li>
<li>Verify condition evaluation logic</li>
<li>Test rules in isolation</li>
</ul>
<h2 id="related-documentation-17"><a class="header" href="#related-documentation-17">Related Documentation</a></h2>
<ul>
<li><a href="user-guide/advanced-features/smart-personas.html">Smart Personas</a> - Persona system</li>
<li><a href="user-guide/advanced-features/chaos-lab.html">Chaos Lab</a> - Chaos scenarios</li>
<li><a href="user-guide/advanced-features/reality-continuum.html">Reality Continuum</a> - Reality levels</li>
<li><a href="user-guide/advanced-features/scenario-state-machines.html">Scenarios</a> - Scenario system</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="world-state-engine-1"><a class="header" href="#world-state-engine-1">World State Engine</a></h1>
<p><strong>Pillars:</strong> [Reality][DevX]</p>
<p>The World State Engine unifies all MockForge state systems into a single ‚Äúworld state‚Äù visualization. Think of it as a miniature game engine for your backend‚Äîa unified view of personas, lifecycle, reality, time, multi-protocol state, behavior trees, generative schemas, recorded data, and AI modifiers.</p>
<h2 id="overview-24"><a class="header" href="#overview-24">Overview</a></h2>
<p>The World State Engine aggregates and visualizes:</p>
<ul>
<li><strong>Personas</strong>: Persona profiles, relationships, and graphs</li>
<li><strong>Lifecycle</strong>: Lifecycle states, transitions, and time-based changes</li>
<li><strong>Reality</strong>: Reality levels, continuum ratios, and chaos rules</li>
<li><strong>Time</strong>: Virtual clock state, scheduled events, and time scale</li>
<li><strong>Multi-Protocol</strong>: Protocol-specific state, sessions, and entity state</li>
<li><strong>Behavior</strong>: Behavior trees, rules, and AI modifiers</li>
<li><strong>Schemas</strong>: Generative schema definitions and entity relationships</li>
<li><strong>Recorded Data</strong>: Recorded requests/responses, fixtures, and replay state</li>
<li><strong>AI Modifiers</strong>: AI response configurations and modifiers</li>
</ul>
<h2 id="key-features"><a class="header" href="#key-features">Key Features</a></h2>
<ul>
<li><strong>Unified State Aggregation</strong>: Collects state from all MockForge subsystems</li>
<li><strong>Graph Visualization</strong>: Represents state as nodes and edges for visualization</li>
<li><strong>Real-time Updates</strong>: Streams state changes in real-time</li>
<li><strong>Time Travel</strong>: View state at any point in time</li>
<li><strong>Query Interface</strong>: Flexible querying of state with filters</li>
<li><strong>Export Capabilities</strong>: Export state in various formats (JSON, GraphML, DOT)</li>
</ul>
<h2 id="usage-2"><a class="header" href="#usage-2">Usage</a></h2>
<h3 id="create-snapshot-1"><a class="header" href="#create-snapshot-1">Create Snapshot</a></h3>
<pre><code class="language-bash"># Create world state snapshot
mockforge world-state snapshot create

# Or via API
POST /api/v1/world-state/snapshots
{
  "workspace_id": "workspace-123",
  "include_layers": ["personas", "reality", "time"]
}
</code></pre>
<h3 id="query-state"><a class="header" href="#query-state">Query State</a></h3>
<pre><code class="language-bash"># Query world state
mockforge world-state query \
  --layers personas,reality \
  --filter "persona_id=premium-customer"

# Or via API
GET /api/v1/world-state/query?layers=personas,reality&amp;filter=persona_id=premium-customer
</code></pre>
<h3 id="visualize-state"><a class="header" href="#visualize-state">Visualize State</a></h3>
<pre><code class="language-bash"># Export as graph
mockforge world-state export --format graphml --output state.graphml

# View in UI
# Navigate to World State page in Admin UI
</code></pre>
<h2 id="state-layers"><a class="header" href="#state-layers">State Layers</a></h2>
<h3 id="personas-layer"><a class="header" href="#personas-layer">Personas Layer</a></h3>
<p>Persona profiles and relationships:</p>
<pre><code class="language-json">{
  "layer": "personas",
  "nodes": [
    {
      "id": "persona:premium-001",
      "type": "persona",
      "data": {
        "traits": {...},
        "relationships": [...]
      }
    }
  ],
  "edges": [
    {
      "from": "persona:premium-001",
      "to": "order:123",
      "type": "has_orders"
    }
  ]
}
</code></pre>
<h3 id="reality-layer"><a class="header" href="#reality-layer">Reality Layer</a></h3>
<p>Reality levels and continuum ratios:</p>
<pre><code class="language-json">{
  "layer": "reality",
  "state": {
    "reality_level": 3,
    "continuum_ratio": 0.5,
    "chaos_rules": [...]
  }
}
</code></pre>
<h3 id="time-layer"><a class="header" href="#time-layer">Time Layer</a></h3>
<p>Virtual clock and scheduled events:</p>
<pre><code class="language-json">{
  "layer": "time",
  "state": {
    "virtual_time": "2025-01-27T10:00:00Z",
    "time_scale": 1.0,
    "scheduled_events": [...]
  }
}
</code></pre>
<h3 id="protocols-layer"><a class="header" href="#protocols-layer">Protocols Layer</a></h3>
<p>Protocol-specific state:</p>
<pre><code class="language-json">{
  "layer": "protocols",
  "state": {
    "http": {
      "sessions": [...],
      "connections": [...]
    },
    "websocket": {
      "connections": [...],
      "subscriptions": [...]
    }
  }
}
</code></pre>
<h2 id="query-interface"><a class="header" href="#query-interface">Query Interface</a></h2>
<h3 id="filter-by-layer"><a class="header" href="#filter-by-layer">Filter by Layer</a></h3>
<pre><code class="language-bash"># Query specific layers
mockforge world-state query --layers personas,reality
</code></pre>
<h3 id="filter-by-criteria"><a class="header" href="#filter-by-criteria">Filter by Criteria</a></h3>
<pre><code class="language-bash"># Filter by persona
mockforge world-state query --filter "persona_id=premium-customer"

# Filter by reality level
mockforge world-state query --filter "reality_level&gt;=3"

# Filter by time
mockforge world-state query --filter "time&gt;=2025-01-27"
</code></pre>
<h3 id="complex-queries"><a class="header" href="#complex-queries">Complex Queries</a></h3>
<pre><code class="language-bash"># Multiple filters
mockforge world-state query \
  --layers personas,reality \
  --filter "persona_id=premium-customer" \
  --filter "reality_level&gt;=3"
</code></pre>
<h2 id="time-travel"><a class="header" href="#time-travel">Time Travel</a></h2>
<p>View state at any point in time:</p>
<pre><code class="language-bash"># View state at specific time
mockforge world-state query \
  --time "2025-01-27T10:00:00Z" \
  --layers personas,reality
</code></pre>
<h2 id="export-formats"><a class="header" href="#export-formats">Export Formats</a></h2>
<h3 id="json-1"><a class="header" href="#json-1">JSON</a></h3>
<pre><code class="language-bash">mockforge world-state export --format json --output state.json
</code></pre>
<h3 id="graphml"><a class="header" href="#graphml">GraphML</a></h3>
<pre><code class="language-bash">mockforge world-state export --format graphml --output state.graphml
</code></pre>
<h3 id="dot"><a class="header" href="#dot">DOT</a></h3>
<pre><code class="language-bash">mockforge world-state export --format dot --output state.dot
</code></pre>
<h2 id="real-world-example"><a class="header" href="#real-world-example">Real-World Example</a></h2>
<h3 id="e-commerce-world-state"><a class="header" href="#e-commerce-world-state">E-Commerce World State</a></h3>
<pre><code class="language-json">{
  "workspace_id": "ecommerce-123",
  "snapshot_time": "2025-01-27T10:00:00Z",
  "layers": {
    "personas": {
      "nodes": [
        {
          "id": "persona:premium-001",
          "type": "persona",
          "data": {
            "traits": {"tier": "premium"},
            "lifecycle_state": "active"
          }
        },
        {
          "id": "order:456",
          "type": "order",
          "data": {
            "status": "pending",
            "total": 99.99
          }
        }
      ],
      "edges": [
        {
          "from": "persona:premium-001",
          "to": "order:456",
          "type": "has_orders"
        }
      ]
    },
    "reality": {
      "reality_level": 3,
      "continuum_ratio": 0.5,
      "chaos_rules": []
    },
    "time": {
      "virtual_time": "2025-01-27T10:00:00Z",
      "time_scale": 1.0
    }
  }
}
</code></pre>
<h2 id="best-practices-34"><a class="header" href="#best-practices-34">Best Practices</a></h2>
<ol>
<li><strong>Regular Snapshots</strong>: Take snapshots at key points</li>
<li><strong>Query Efficiently</strong>: Use filters to query only needed layers</li>
<li><strong>Visualize</strong>: Use graph visualization to understand relationships</li>
<li><strong>Time Travel</strong>: Use time travel to debug temporal issues</li>
<li><strong>Export for Analysis</strong>: Export state for external analysis</li>
</ol>
<h2 id="related-documentation-18"><a class="header" href="#related-documentation-18">Related Documentation</a></h2>
<ul>
<li><a href="user-guide/advanced-features/smart-personas.html">Smart Personas</a> - Persona system</li>
<li><a href="user-guide/advanced-features/reality-continuum.html">Reality Continuum</a> - Reality levels</li>
<li><a href="user-guide/advanced-features/temporal-simulation.html">Temporal Simulation</a> - Time travel</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="performance-mode-load-simulation"><a class="header" href="#performance-mode-load-simulation">Performance Mode (Load Simulation)</a></h1>
<p><strong>Pillars:</strong> [DevX]</p>
<p>Performance Mode provides lightweight load simulation for running scenarios at N RPS, simulating bottlenecks, recording latencies, and observing how responses change under load. This is NOT true load testing‚Äîit‚Äôs realistic behavior simulation under stress testing conditions.</p>
<h2 id="overview-25"><a class="header" href="#overview-25">Overview</a></h2>
<p>Performance Mode enables:</p>
<ul>
<li><strong>Run scenarios at n RPS</strong>: Control request rate</li>
<li><strong>Simulate bottlenecks</strong>: Add artificial delays</li>
<li><strong>Record latencies</strong>: Track response times</li>
<li><strong>Observe behavior changes</strong>: See how responses change under load</li>
</ul>
<h2 id="quick-start-16"><a class="header" href="#quick-start-16">Quick Start</a></h2>
<h3 id="start-performance-mode"><a class="header" href="#start-performance-mode">Start Performance Mode</a></h3>
<pre><code class="language-bash"># Start performance mode
mockforge performance start --rps 100

# Start with bottlenecks
mockforge performance start \
  --rps 100 \
  --bottleneck checkout:500ms \
  --bottleneck payments:1000ms
</code></pre>
<h3 id="via-api"><a class="header" href="#via-api">Via API</a></h3>
<pre><code class="language-bash"># Start performance mode
POST /api/performance/start
{
  "initial_rps": 100,
  "rps_profile": "constant",
  "bottlenecks": [
    {
      "endpoint": "/api/checkout/*",
      "delay_ms": 500
    }
  ]
}
</code></pre>
<h2 id="rps-profiles"><a class="header" href="#rps-profiles">RPS Profiles</a></h2>
<h3 id="constant-rps"><a class="header" href="#constant-rps">Constant RPS</a></h3>
<p>Maintain constant requests per second:</p>
<pre><code class="language-yaml">rps_profile:
  type: constant
  rps: 100
</code></pre>
<h3 id="ramp-profile"><a class="header" href="#ramp-profile">Ramp Profile</a></h3>
<p>Gradually increase RPS:</p>
<pre><code class="language-yaml">rps_profile:
  type: ramp
  start_rps: 10
  end_rps: 100
  duration_seconds: 60
</code></pre>
<h3 id="spike-profile"><a class="header" href="#spike-profile">Spike Profile</a></h3>
<p>Sudden spike in RPS:</p>
<pre><code class="language-yaml">rps_profile:
  type: spike
  base_rps: 50
  spike_rps: 200
  spike_duration_seconds: 10
  spike_interval_seconds: 60
</code></pre>
<h2 id="bottleneck-simulation"><a class="header" href="#bottleneck-simulation">Bottleneck Simulation</a></h2>
<h3 id="endpoint-bottlenecks"><a class="header" href="#endpoint-bottlenecks">Endpoint Bottlenecks</a></h3>
<p>Add delays to specific endpoints:</p>
<pre><code class="language-yaml">bottlenecks:
  - endpoint: "/api/checkout/*"
    delay_ms: 500
    probability: 1.0  # Always delay
  - endpoint: "/api/payments/*"
    delay_ms: 1000
    probability: 0.5  # 50% chance
</code></pre>
<h3 id="database-bottlenecks"><a class="header" href="#database-bottlenecks">Database Bottlenecks</a></h3>
<p>Simulate database slowdowns:</p>
<pre><code class="language-yaml">bottlenecks:
  - type: database
    delay_ms: 200
    probability: 0.3
</code></pre>
<h3 id="network-bottlenecks"><a class="header" href="#network-bottlenecks">Network Bottlenecks</a></h3>
<p>Simulate network conditions:</p>
<pre><code class="language-yaml">bottlenecks:
  - type: network
    latency_ms: 100
    packet_loss: 0.01
</code></pre>
<h2 id="latency-recording"><a class="header" href="#latency-recording">Latency Recording</a></h2>
<h3 id="automatic-recording"><a class="header" href="#automatic-recording">Automatic Recording</a></h3>
<p>Latencies are automatically recorded:</p>
<pre><code class="language-json">{
  "endpoint": "/api/users/{id}",
  "method": "GET",
  "latency_ms": 150,
  "status_code": 200,
  "timestamp": "2025-01-27T10:00:00Z"
}
</code></pre>
<h3 id="latency-analysis-1"><a class="header" href="#latency-analysis-1">Latency Analysis</a></h3>
<p>Analyze recorded latencies:</p>
<pre><code class="language-bash"># Get latency statistics
GET /api/performance/snapshot

# Response:
{
  "stats": {
    "mean_latency_ms": 150,
    "p50_latency_ms": 140,
    "p95_latency_ms": 250,
    "p99_latency_ms": 400,
    "max_latency_ms": 500
  }
}
</code></pre>
<h2 id="response-changes-under-load"><a class="header" href="#response-changes-under-load">Response Changes Under Load</a></h2>
<h3 id="behavioral-economics-integration"><a class="header" href="#behavioral-economics-integration">Behavioral Economics Integration</a></h3>
<p>Responses may change under load due to behavioral economics:</p>
<pre><code class="language-yaml"># Under normal load
GET /api/checkout ‚Üí 200 OK, conversion: 90%

# Under high load (latency &gt; 400ms)
GET /api/checkout ‚Üí 200 OK, conversion: 70%  # 20% drop
</code></pre>
<h3 id="error-rate-increases"><a class="header" href="#error-rate-increases">Error Rate Increases</a></h3>
<p>Error rates may increase under load:</p>
<pre><code class="language-yaml"># Normal load
Error rate: 1%

# High load
Error rate: 5%  # Increased errors
</code></pre>
<h2 id="usage-examples-1"><a class="header" href="#usage-examples-1">Usage Examples</a></h2>
<h3 id="example-1-constant-load"><a class="header" href="#example-1-constant-load">Example 1: Constant Load</a></h3>
<pre><code class="language-bash"># Run at constant 100 RPS
mockforge performance start --rps 100

# Monitor
GET /api/performance/snapshot
</code></pre>
<h3 id="example-2-ramp-load"><a class="header" href="#example-2-ramp-load">Example 2: Ramp Load</a></h3>
<pre><code class="language-bash"># Ramp from 10 to 100 RPS over 60 seconds
mockforge performance start \
  --rps-profile ramp \
  --start-rps 10 \
  --end-rps 100 \
  --duration 60
</code></pre>
<h3 id="example-3-with-bottlenecks"><a class="header" href="#example-3-with-bottlenecks">Example 3: With Bottlenecks</a></h3>
<pre><code class="language-bash"># Run with checkout bottleneck
mockforge performance start \
  --rps 100 \
  --bottleneck "/api/checkout/*:500ms"
</code></pre>
<h2 id="configuration-16"><a class="header" href="#configuration-16">Configuration</a></h2>
<h3 id="performance-mode-config"><a class="header" href="#performance-mode-config">Performance Mode Config</a></h3>
<pre><code class="language-yaml"># mockforge.yaml
performance:
  enabled: true
  default_rps: 100
  max_latency_samples: 10000
  max_latency_age_seconds: 300
</code></pre>
<h3 id="rps-controller"><a class="header" href="#rps-controller">RPS Controller</a></h3>
<pre><code class="language-yaml">performance:
  rps_controller:
    type: token_bucket
    capacity: 1000
    refill_rate: 100  # per second
</code></pre>
<h2 id="best-practices-35"><a class="header" href="#best-practices-35">Best Practices</a></h2>
<ol>
<li><strong>Start Low</strong>: Begin with low RPS and increase gradually</li>
<li><strong>Monitor Latencies</strong>: Watch latency percentiles</li>
<li><strong>Test Bottlenecks</strong>: Simulate realistic bottlenecks</li>
<li><strong>Observe Behavior</strong>: Watch how responses change</li>
<li><strong>Not True Load Testing</strong>: This is simulation, not production load testing</li>
</ol>
<h2 id="related-documentation-19"><a class="header" href="#related-documentation-19">Related Documentation</a></h2>
<ul>
<li><a href="user-guide/advanced-features/behavioral-economics.html">Behavioral Economics Engine</a> - Behavior under load</li>
<li><a href="user-guide/advanced-features/chaos-lab.html">Chaos Lab</a> - Chaos engineering</li>
<li><a href="user-guide/advanced-features/reality-slider.html">Reality Slider</a> - Reality levels</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="synthetic--recorded-drift-learning"><a class="header" href="#synthetic--recorded-drift-learning">Synthetic ‚Üí Recorded Drift Learning</a></h1>
<p><strong>Pillars:</strong> [Reality]</p>
<p>The Drift Learning System allows mocks to gradually learn from recorded traffic and adapt their behavior. Instead of static synthetic data, mocks can evolve to match real-world patterns observed in traffic.</p>
<h2 id="overview-26"><a class="header" href="#overview-26">Overview</a></h2>
<p>Drift Learning extends the DataDriftEngine with learning capabilities that enable:</p>
<ul>
<li><strong>Traffic Pattern Learning</strong>: Mocks learn from recorded request patterns</li>
<li><strong>Persona Behavior Adaptation</strong>: Personas adapt based on observed request patterns</li>
<li><strong>Configurable Learning Rate</strong>: Control how quickly mocks learn</li>
<li><strong>Opt-in Per Endpoint/Persona</strong>: Enable learning selectively</li>
<li><strong>Pattern Decay</strong>: Old patterns fade if upstream patterns reverse</li>
</ul>
<h2 id="key-concepts-1"><a class="header" href="#key-concepts-1">Key Concepts</a></h2>
<h3 id="learning-modes"><a class="header" href="#learning-modes">Learning Modes</a></h3>
<p>Drift Learning supports three learning modes:</p>
<h4 id="behavioral-learning"><a class="header" href="#behavioral-learning">Behavioral Learning</a></h4>
<p>Adapts to behavior patterns observed in traffic:</p>
<ul>
<li><strong>Request Sequences</strong>: Learns common request sequences</li>
<li><strong>User Flows</strong>: Adapts to typical user workflows</li>
<li><strong>Interaction Patterns</strong>: Learns how users interact with the API</li>
</ul>
<p><strong>Use Case:</strong> When you want mocks to reflect real user behavior patterns.</p>
<h4 id="statistical-learning"><a class="header" href="#statistical-learning">Statistical Learning</a></h4>
<p>Adapts to statistical patterns in traffic:</p>
<ul>
<li><strong>Latency Patterns</strong>: Learns typical latency distributions</li>
<li><strong>Error Rates</strong>: Adapts to observed error rate patterns</li>
<li><strong>Request Frequency</strong>: Learns request frequency patterns</li>
</ul>
<p><strong>Use Case:</strong> When you want mocks to match statistical properties of real traffic.</p>
<h4 id="hybrid-learning"><a class="header" href="#hybrid-learning">Hybrid Learning</a></h4>
<p>Combines behavioral and statistical learning:</p>
<ul>
<li><strong>Best of Both</strong>: Uses both behavioral and statistical patterns</li>
<li><strong>Balanced Adaptation</strong>: Balances behavior and statistics</li>
<li><strong>Comprehensive Learning</strong>: Most comprehensive learning mode</li>
</ul>
<p><strong>Use Case:</strong> When you want the most realistic mocks possible.</p>
<h3 id="learning-configuration"><a class="header" href="#learning-configuration">Learning Configuration</a></h3>
<pre><code class="language-yaml">drift_learning:
  enabled: true
  mode: hybrid  # behavioral, statistical, or hybrid
  sensitivity: 0.2  # How quickly mocks learn (0.0-1.0)
  decay: 0.05  # How quickly old patterns fade (0.0-1.0)
  min_samples: 10  # Minimum samples before learning starts
  update_interval: 60s  # How often to update learned patterns
  persona_adaptation: true  # Enable persona-specific learning
  traffic_mirroring: true  # Enable traffic pattern mirroring
</code></pre>
<h2 id="how-it-works-5"><a class="header" href="#how-it-works-5">How It Works</a></h2>
<h3 id="1-traffic-recording"><a class="header" href="#1-traffic-recording">1. Traffic Recording</a></h3>
<p>The system records traffic patterns:</p>
<ul>
<li><strong>Request Sequences</strong>: Tracks sequences of requests</li>
<li><strong>Response Patterns</strong>: Records response patterns</li>
<li><strong>Timing Information</strong>: Captures latency and timing data</li>
<li><strong>Error Patterns</strong>: Tracks error occurrences</li>
</ul>
<h3 id="2-pattern-analysis"><a class="header" href="#2-pattern-analysis">2. Pattern Analysis</a></h3>
<p>Recorded traffic is analyzed to identify patterns:</p>
<ul>
<li><strong>Behavioral Patterns</strong>: User behavior sequences</li>
<li><strong>Statistical Patterns</strong>: Latency, error rate distributions</li>
<li><strong>Persona Patterns</strong>: Persona-specific behavior patterns</li>
</ul>
<h3 id="3-learning-application"><a class="header" href="#3-learning-application">3. Learning Application</a></h3>
<p>Learned patterns are applied to mocks:</p>
<ul>
<li><strong>Gradual Adaptation</strong>: Mocks gradually adapt to learned patterns</li>
<li><strong>Confidence Scoring</strong>: Patterns are scored by confidence</li>
<li><strong>Decay Handling</strong>: Low-confidence patterns fade over time</li>
</ul>
<h3 id="4-pattern-updates"><a class="header" href="#4-pattern-updates">4. Pattern Updates</a></h3>
<p>Patterns are updated periodically:</p>
<ul>
<li><strong>Update Interval</strong>: Configurable update frequency</li>
<li><strong>Minimum Samples</strong>: Requires minimum samples before learning</li>
<li><strong>Confidence Threshold</strong>: Only high-confidence patterns are applied</li>
</ul>
<h2 id="usage-3"><a class="header" href="#usage-3">Usage</a></h2>
<h3 id="enable-drift-learning"><a class="header" href="#enable-drift-learning">Enable Drift Learning</a></h3>
<pre><code class="language-yaml"># mockforge.yaml
drift_learning:
  enabled: true
  mode: hybrid
  sensitivity: 0.2
  decay: 0.05
  min_samples: 10
  update_interval: 60s
</code></pre>
<h3 id="per-endpoint-learning"><a class="header" href="#per-endpoint-learning">Per-Endpoint Learning</a></h3>
<p>Enable learning for specific endpoints:</p>
<pre><code class="language-yaml">drift_learning:
  enabled: true
  endpoint_learning:
    "/api/users/*": true  # Enable for user endpoints
    "/api/orders/*": true  # Enable for order endpoints
    "/api/payments/*": false  # Disable for payment endpoints
</code></pre>
<h3 id="per-persona-learning"><a class="header" href="#per-persona-learning">Per-Persona Learning</a></h3>
<p>Enable learning for specific personas:</p>
<pre><code class="language-yaml">drift_learning:
  enabled: true
  persona_adaptation: true
  persona_learning:
    "premium-customer": true  # Enable for premium customers
    "regular-customer": true  # Enable for regular customers
    "admin": false  # Disable for admins
</code></pre>
<h3 id="cli-commands-5"><a class="header" href="#cli-commands-5">CLI Commands</a></h3>
<pre><code class="language-bash"># Enable drift learning
mockforge config set drift_learning.enabled true

# Set learning mode
mockforge config set drift_learning.mode hybrid

# View learned patterns
mockforge drift-learning patterns

# Reset learned patterns
mockforge drift-learning reset
</code></pre>
<h2 id="learning-parameters"><a class="header" href="#learning-parameters">Learning Parameters</a></h2>
<h3 id="sensitivity"><a class="header" href="#sensitivity">Sensitivity</a></h3>
<p>Controls how quickly mocks learn from patterns:</p>
<ul>
<li><strong>Low (0.1)</strong>: Slow, conservative learning</li>
<li><strong>Medium (0.2)</strong>: Balanced learning rate (default)</li>
<li><strong>High (0.5)</strong>: Fast, aggressive learning</li>
</ul>
<p><strong>Recommendation:</strong> Start with 0.2 and adjust based on results.</p>
<h3 id="decay"><a class="header" href="#decay">Decay</a></h3>
<p>Controls how quickly old patterns fade:</p>
<ul>
<li><strong>Low (0.01)</strong>: Patterns persist longer</li>
<li><strong>Medium (0.05)</strong>: Balanced decay (default)</li>
<li><strong>High (0.1)</strong>: Patterns fade quickly</li>
</ul>
<p><strong>Recommendation:</strong> Use 0.05 for most cases.</p>
<h3 id="minimum-samples"><a class="header" href="#minimum-samples">Minimum Samples</a></h3>
<p>Minimum number of samples required before learning starts:</p>
<ul>
<li><strong>Low (5)</strong>: Learn from few samples (may be noisy)</li>
<li><strong>Medium (10)</strong>: Balanced threshold (default)</li>
<li><strong>High (50)</strong>: Require many samples (more stable)</li>
</ul>
<p><strong>Recommendation:</strong> Use 10 for most cases, increase if patterns are noisy.</p>
<h2 id="real-world-examples-1"><a class="header" href="#real-world-examples-1">Real-World Examples</a></h2>
<h3 id="example-1-e-commerce-checkout-flow"><a class="header" href="#example-1-e-commerce-checkout-flow">Example 1: E-Commerce Checkout Flow</a></h3>
<p><strong>Scenario:</strong> Learn from real checkout patterns</p>
<pre><code class="language-yaml">drift_learning:
  enabled: true
  mode: behavioral
  endpoint_learning:
    "/api/checkout/*": true
  persona_adaptation: true
</code></pre>
<p><strong>Result:</strong> Mocks learn the typical checkout flow sequence and adapt responses accordingly.</p>
<h3 id="example-2-api-latency-patterns"><a class="header" href="#example-2-api-latency-patterns">Example 2: API Latency Patterns</a></h3>
<p><strong>Scenario:</strong> Learn latency patterns from real traffic</p>
<pre><code class="language-yaml">drift_learning:
  enabled: true
  mode: statistical
  endpoint_learning:
    "/api/*": true
  sensitivity: 0.3
</code></pre>
<p><strong>Result:</strong> Mocks adapt their latency to match observed latency distributions.</p>
<h3 id="example-3-persona-specific-behavior"><a class="header" href="#example-3-persona-specific-behavior">Example 3: Persona-Specific Behavior</a></h3>
<p><strong>Scenario:</strong> Learn persona-specific behavior patterns</p>
<pre><code class="language-yaml">drift_learning:
  enabled: true
  mode: hybrid
  persona_adaptation: true
  persona_learning:
    "premium-customer": true
    "regular-customer": true
</code></pre>
<p><strong>Result:</strong> Mocks learn different behavior patterns for different personas.</p>
<h2 id="traffic-pattern-mirroring"><a class="header" href="#traffic-pattern-mirroring">Traffic Pattern Mirroring</a></h2>
<p>When <code>traffic_mirroring</code> is enabled, mocks mirror observed traffic patterns:</p>
<ul>
<li><strong>Request Frequency</strong>: Mirrors request frequency patterns</li>
<li><strong>Request Sequences</strong>: Mirrors common request sequences</li>
<li><strong>Timing Patterns</strong>: Mirrors timing patterns</li>
<li><strong>Error Patterns</strong>: Mirrors error occurrence patterns</li>
</ul>
<h3 id="configuration-17"><a class="header" href="#configuration-17">Configuration</a></h3>
<pre><code class="language-yaml">drift_learning:
  enabled: true
  traffic_mirroring: true
  mode: hybrid
</code></pre>
<h2 id="persona-behavior-adaptation"><a class="header" href="#persona-behavior-adaptation">Persona Behavior Adaptation</a></h2>
<p>When <code>persona_adaptation</code> is enabled, personas adapt based on observed behavior:</p>
<ul>
<li><strong>Behavior Patterns</strong>: Personas learn behavior patterns</li>
<li><strong>Request Patterns</strong>: Personas learn request patterns</li>
<li><strong>Response Patterns</strong>: Personas learn response patterns</li>
</ul>
<h3 id="configuration-18"><a class="header" href="#configuration-18">Configuration</a></h3>
<pre><code class="language-yaml">drift_learning:
  enabled: true
  persona_adaptation: true
  persona_learning:
    "premium-customer": true
    "regular-customer": true
</code></pre>
<h2 id="best-practices-36"><a class="header" href="#best-practices-36">Best Practices</a></h2>
<ol>
<li><strong>Start Conservative</strong>: Begin with low sensitivity and high min_samples</li>
<li><strong>Monitor Patterns</strong>: Regularly review learned patterns</li>
<li><strong>Selective Learning</strong>: Enable learning only for endpoints/personas that need it</li>
<li><strong>Test Incrementally</strong>: Enable learning for one endpoint at a time</li>
<li><strong>Review Confidence</strong>: Only apply high-confidence patterns</li>
<li><strong>Reset When Needed</strong>: Reset learned patterns if they become inaccurate</li>
</ol>
<h2 id="troubleshooting-45"><a class="header" href="#troubleshooting-45">Troubleshooting</a></h2>
<h3 id="mocks-not-learning"><a class="header" href="#mocks-not-learning">Mocks Not Learning</a></h3>
<ul>
<li><strong>Check Enabled</strong>: Verify <code>enabled: true</code></li>
<li><strong>Check Samples</strong>: Ensure minimum samples are reached</li>
<li><strong>Check Confidence</strong>: Low-confidence patterns may not be applied</li>
<li><strong>Check Endpoint/Persona</strong>: Verify learning is enabled for the endpoint/persona</li>
</ul>
<h3 id="patterns-too-aggressive"><a class="header" href="#patterns-too-aggressive">Patterns Too Aggressive</a></h3>
<ul>
<li><strong>Lower Sensitivity</strong>: Reduce sensitivity value</li>
<li><strong>Increase Min Samples</strong>: Require more samples before learning</li>
<li><strong>Increase Decay</strong>: Make patterns fade faster</li>
</ul>
<h3 id="patterns-not-updating"><a class="header" href="#patterns-not-updating">Patterns Not Updating</a></h3>
<ul>
<li><strong>Check Update Interval</strong>: Verify update interval is reasonable</li>
<li><strong>Check Samples</strong>: Ensure new samples are being recorded</li>
<li><strong>Check Confidence</strong>: Low-confidence patterns may not update</li>
</ul>
<h2 id="related-documentation-20"><a class="header" href="#related-documentation-20">Related Documentation</a></h2>
<ul>
<li><a href="user-guide/advanced-features/smart-personas.html">Smart Personas</a> - Persona system</li>
<li><a href="user-guide/advanced-features/reality-continuum.html">Reality Continuum</a> - Reality levels</li>
<li><a href="user-guide/advanced-features/behavioral-economics.html">Behavioral Economics Engine</a> - Behavioral rules</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="cloud-workspaces-collaboration"><a class="header" href="#cloud-workspaces-collaboration">Cloud Workspaces (Collaboration)</a></h1>
<p>Cloud Workspaces enables multi-user collaborative editing with real-time state synchronization, version control, and role-based permissions. Work together on mock configurations with Git-style versioning and conflict resolution.</p>
<h2 id="overview-27"><a class="header" href="#overview-27">Overview</a></h2>
<p>Cloud Workspaces provides:</p>
<ul>
<li><strong>User Authentication</strong>: JWT-based authentication with secure sessions</li>
<li><strong>Multi-User Editing</strong>: Real-time collaborative editing with presence awareness</li>
<li><strong>State Synchronization</strong>: WebSocket-based real-time sync between clients</li>
<li><strong>Version Control</strong>: Git-style version control for mocks and data</li>
<li><strong>Change Tracking</strong>: Full history with rollback capabilities</li>
<li><strong>Role-Based Permissions</strong>: Owner, Editor, and Viewer roles</li>
</ul>
<h2 id="quick-start-17"><a class="header" href="#quick-start-17">Quick Start</a></h2>
<h3 id="create-a-workspace"><a class="header" href="#create-a-workspace">Create a Workspace</a></h3>
<pre><code class="language-bash"># Create a new workspace
mockforge workspace create --name "My Workspace" --description "Team workspace"

# Or via API
curl -X POST http://localhost:9080/api/workspaces \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer &lt;token&gt;" \
  -d '{
    "name": "My Workspace",
    "description": "Team workspace"
  }'
</code></pre>
<h3 id="join-a-workspace"><a class="header" href="#join-a-workspace">Join a Workspace</a></h3>
<pre><code class="language-bash"># List available workspaces
mockforge workspace list

# Join a workspace (requires invitation)
mockforge workspace join &lt;workspace-id&gt;
</code></pre>
<h3 id="start-collaborative-server"><a class="header" href="#start-collaborative-server">Start Collaborative Server</a></h3>
<pre><code class="language-bash"># Start server with collaboration enabled
mockforge serve --collab-enabled --collab-port 8080
</code></pre>
<h2 id="features-6"><a class="header" href="#features-6">Features</a></h2>
<h3 id="user-authentication"><a class="header" href="#user-authentication">User Authentication</a></h3>
<h4 id="register"><a class="header" href="#register">Register</a></h4>
<pre><code class="language-bash"># Register new user
mockforge auth register \
  --email "user@example.com" \
  --password "secure-password" \
  --name "User Name"
</code></pre>
<h4 id="login"><a class="header" href="#login">Login</a></h4>
<pre><code class="language-bash"># Login and get JWT token
mockforge auth login \
  --email "user@example.com" \
  --password "secure-password"
</code></pre>
<h3 id="workspace-management"><a class="header" href="#workspace-management">Workspace Management</a></h3>
<h4 id="create-workspace"><a class="header" href="#create-workspace">Create Workspace</a></h4>
<pre><code class="language-bash">mockforge workspace create \
  --name "Team Workspace" \
  --description "Shared workspace for team"
</code></pre>
<h4 id="list-workspaces"><a class="header" href="#list-workspaces">List Workspaces</a></h4>
<pre><code class="language-bash"># List your workspaces
mockforge workspace list

# List all workspaces (admin only)
mockforge workspace list --all
</code></pre>
<h4 id="get-workspace-details"><a class="header" href="#get-workspace-details">Get Workspace Details</a></h4>
<pre><code class="language-bash">mockforge workspace get &lt;workspace-id&gt;
</code></pre>
<h3 id="member-management"><a class="header" href="#member-management">Member Management</a></h3>
<h4 id="add-member"><a class="header" href="#add-member">Add Member</a></h4>
<pre><code class="language-bash"># Add member to workspace
mockforge workspace member add \
  --workspace &lt;workspace-id&gt; \
  --user &lt;user-id&gt; \
  --role editor
</code></pre>
<h4 id="list-members"><a class="header" href="#list-members">List Members</a></h4>
<pre><code class="language-bash"># List workspace members
mockforge workspace member list --workspace &lt;workspace-id&gt;
</code></pre>
<h4 id="change-role"><a class="header" href="#change-role">Change Role</a></h4>
<pre><code class="language-bash"># Change member role
mockforge workspace member role \
  --workspace &lt;workspace-id&gt; \
  --user &lt;user-id&gt; \
  --role viewer
</code></pre>
<h4 id="remove-member"><a class="header" href="#remove-member">Remove Member</a></h4>
<pre><code class="language-bash"># Remove member from workspace
mockforge workspace member remove \
  --workspace &lt;workspace-id&gt; \
  --user &lt;user-id&gt;
</code></pre>
<h3 id="real-time-synchronization"><a class="header" href="#real-time-synchronization">Real-Time Synchronization</a></h3>
<p>Workspaces use WebSocket for real-time synchronization:</p>
<h4 id="websocket-connection"><a class="header" href="#websocket-connection">WebSocket Connection</a></h4>
<pre><code class="language-javascript">const ws = new WebSocket('ws://localhost:8080/ws');

// Subscribe to workspace
ws.send(JSON.stringify({
  type: 'subscribe',
  workspace_id: 'workspace-uuid'
}));

// Receive updates
ws.onmessage = (event) =&gt; {
  const data = JSON.parse(event.data);
  if (data.type === 'change') {
    console.log('Change event:', data.event);
  }
};
</code></pre>
<h4 id="change-events"><a class="header" href="#change-events">Change Events</a></h4>
<ul>
<li><code>mock_created</code> - New mock added</li>
<li><code>mock_updated</code> - Mock modified</li>
<li><code>mock_deleted</code> - Mock removed</li>
<li><code>workspace_updated</code> - Workspace settings changed</li>
<li><code>member_added</code> - New team member</li>
<li><code>member_removed</code> - Member left</li>
<li><code>role_changed</code> - Member role updated</li>
<li><code>snapshot_created</code> - New snapshot</li>
<li><code>user_joined</code> - User connected</li>
<li><code>user_left</code> - User disconnected</li>
<li><code>cursor_moved</code> - Cursor position updated</li>
</ul>
<h3 id="version-control-1"><a class="header" href="#version-control-1">Version Control</a></h3>
<h4 id="create-snapshot-2"><a class="header" href="#create-snapshot-2">Create Snapshot</a></h4>
<pre><code class="language-bash"># Create workspace snapshot
mockforge workspace snapshot create \
  --workspace &lt;workspace-id&gt; \
  --message "Initial state"
</code></pre>
<h4 id="list-snapshots-1"><a class="header" href="#list-snapshots-1">List Snapshots</a></h4>
<pre><code class="language-bash"># List workspace snapshots
mockforge workspace snapshot list --workspace &lt;workspace-id&gt;
</code></pre>
<h4 id="restore-snapshot-1"><a class="header" href="#restore-snapshot-1">Restore Snapshot</a></h4>
<pre><code class="language-bash"># Restore workspace to snapshot
mockforge workspace snapshot restore \
  --workspace &lt;workspace-id&gt; \
  --snapshot &lt;snapshot-id&gt;
</code></pre>
<h3 id="conflict-resolution"><a class="header" href="#conflict-resolution">Conflict Resolution</a></h3>
<p>When multiple users edit simultaneously, conflicts are resolved automatically:</p>
<ul>
<li><strong>Last Write Wins</strong>: Default strategy for simple conflicts</li>
<li><strong>Merge Strategy</strong>: Intelligent merging for compatible changes</li>
<li><strong>Manual Resolution</strong>: Manual conflict resolution for complex cases</li>
</ul>
<h2 id="api-endpoints-4"><a class="header" href="#api-endpoints-4">API Endpoints</a></h2>
<h3 id="authentication-2"><a class="header" href="#authentication-2">Authentication</a></h3>
<pre><code class="language-http">POST /auth/register
Content-Type: application/json

{
  "email": "user@example.com",
  "password": "secure-password",
  "name": "User Name"
}
</code></pre>
<pre><code class="language-http">POST /auth/login
Content-Type: application/json

{
  "email": "user@example.com",
  "password": "secure-password"
}
</code></pre>
<h3 id="workspaces"><a class="header" href="#workspaces">Workspaces</a></h3>
<pre><code class="language-http">POST /workspaces
Authorization: Bearer &lt;token&gt;
Content-Type: application/json

{
  "name": "My Workspace",
  "description": "Team workspace"
}
</code></pre>
<pre><code class="language-http">GET /workspaces
Authorization: Bearer &lt;token&gt;
</code></pre>
<pre><code class="language-http">GET /workspaces/:id
Authorization: Bearer &lt;token&gt;
</code></pre>
<pre><code class="language-http">PUT /workspaces/:id
Authorization: Bearer &lt;token&gt;
Content-Type: application/json

{
  "name": "Updated Name",
  "description": "Updated description"
}
</code></pre>
<pre><code class="language-http">DELETE /workspaces/:id
Authorization: Bearer &lt;token&gt;
</code></pre>
<h3 id="members"><a class="header" href="#members">Members</a></h3>
<pre><code class="language-http">POST /workspaces/:id/members
Authorization: Bearer &lt;token&gt;
Content-Type: application/json

{
  "user_id": "user-uuid",
  "role": "editor"
}
</code></pre>
<pre><code class="language-http">GET /workspaces/:id/members
Authorization: Bearer &lt;token&gt;
</code></pre>
<pre><code class="language-http">PUT /workspaces/:id/members/:user_id/role
Authorization: Bearer &lt;token&gt;
Content-Type: application/json

{
  "role": "viewer"
}
</code></pre>
<pre><code class="language-http">DELETE /workspaces/:id/members/:user_id
Authorization: Bearer &lt;token&gt;
</code></pre>
<h2 id="role-based-permissions"><a class="header" href="#role-based-permissions">Role-Based Permissions</a></h2>
<h3 id="owner"><a class="header" href="#owner">Owner</a></h3>
<ul>
<li>Full access to workspace</li>
<li>Can delete workspace</li>
<li>Can manage all members</li>
<li>Can change any member‚Äôs role</li>
</ul>
<h3 id="editor"><a class="header" href="#editor">Editor</a></h3>
<ul>
<li>Can create, update, and delete mocks</li>
<li>Can view all workspace content</li>
<li>Cannot delete workspace</li>
<li>Cannot manage members</li>
</ul>
<h3 id="viewer"><a class="header" href="#viewer">Viewer</a></h3>
<ul>
<li>Can view workspace content</li>
<li>Cannot modify anything</li>
<li>Read-only access</li>
</ul>
<h2 id="configuration-19"><a class="header" href="#configuration-19">Configuration</a></h2>
<h3 id="server-configuration"><a class="header" href="#server-configuration">Server Configuration</a></h3>
<pre><code class="language-yaml">collab:
  enabled: true
  port: 8080
  database:
    type: "sqlite"  # or "postgres"
    path: "./collab.db"  # For SQLite
    connection_string: "postgresql://..."  # For PostgreSQL
  jwt:
    secret: "${JWT_SECRET}"
    expiration_hours: 24
</code></pre>
<h3 id="client-configuration-1"><a class="header" href="#client-configuration-1">Client Configuration</a></h3>
<pre><code class="language-yaml">collab:
  server_url: "http://localhost:8080"
  workspace_id: "workspace-uuid"
  auto_sync: true
  sync_interval_ms: 1000
</code></pre>
<h2 id="use-cases-9"><a class="header" href="#use-cases-9">Use Cases</a></h2>
<h3 id="team-development"><a class="header" href="#team-development">Team Development</a></h3>
<p>Multiple developers working on the same mock configuration:</p>
<ol>
<li>Create shared workspace</li>
<li>Invite team members</li>
<li>Edit mocks collaboratively</li>
<li>View changes in real-time</li>
</ol>
<h3 id="staging-environment"><a class="header" href="#staging-environment">Staging Environment</a></h3>
<p>Shared staging environment with controlled access:</p>
<ol>
<li>Create workspace for staging</li>
<li>Add team members as editors</li>
<li>Add stakeholders as viewers</li>
<li>Track all changes with version control</li>
</ol>
<h3 id="client-demos"><a class="header" href="#client-demos">Client Demos</a></h3>
<p>Share mock environments with clients:</p>
<ol>
<li>Create workspace for client</li>
<li>Add client as viewer</li>
<li>Update mocks as needed</li>
<li>Client sees changes in real-time</li>
</ol>
<h2 id="best-practices-37"><a class="header" href="#best-practices-37">Best Practices</a></h2>
<ol>
<li><strong>Use Appropriate Roles</strong>: Assign roles based on responsibilities</li>
<li><strong>Regular Snapshots</strong>: Create snapshots before major changes</li>
<li><strong>Monitor Conflicts</strong>: Watch for conflict warnings</li>
<li><strong>Version Control</strong>: Use snapshots for important milestones</li>
<li><strong>Secure Secrets</strong>: Never commit JWT secrets to version control</li>
</ol>
<h2 id="troubleshooting-46"><a class="header" href="#troubleshooting-46">Troubleshooting</a></h2>
<h3 id="connection-issues"><a class="header" href="#connection-issues">Connection Issues</a></h3>
<ul>
<li>Verify WebSocket endpoint is accessible</li>
<li>Check firewall settings</li>
<li>Review server logs for errors</li>
</ul>
<h3 id="sync-conflicts"><a class="header" href="#sync-conflicts">Sync Conflicts</a></h3>
<ul>
<li>Review conflict resolution strategy</li>
<li>Use manual resolution for complex cases</li>
<li>Create snapshots before major changes</li>
</ul>
<h3 id="permission-errors-1"><a class="header" href="#permission-errors-1">Permission Errors</a></h3>
<ul>
<li>Verify user role has required permissions</li>
<li>Check workspace membership</li>
<li>Review JWT token expiration</li>
</ul>
<h2 id="related-documentation-21"><a class="header" href="#related-documentation-21">Related Documentation</a></h2>
<ul>
<li><a href="user-guide/vbr-engine.html">VBR Engine</a> - State management</li>
<li><a href="user-guide/scenario-marketplace.html">Scenario Marketplace</a> - Sharing scenarios</li>
<li><a href="user-guide/../configuration/files.html">Configuration Guide</a> - Complete configuration reference</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="data-scenario-marketplace-1"><a class="header" href="#data-scenario-marketplace-1">Data Scenario Marketplace</a></h1>
<p>The Data Scenario Marketplace allows you to discover, install, and use community-built realistic mock scenarios with one-click import functionality. Share your scenarios with the community or use pre-built scenarios for common use cases.</p>
<h2 id="overview-28"><a class="header" href="#overview-28">Overview</a></h2>
<p>Scenarios are complete mock system configurations that include:</p>
<ul>
<li>MockForge configuration files (<code>config.yaml</code>)</li>
<li>OpenAPI specifications</li>
<li>Protocol-specific fixtures</li>
<li>Example data files</li>
<li>Documentation</li>
</ul>
<h2 id="quick-start-18"><a class="header" href="#quick-start-18">Quick Start</a></h2>
<h3 id="install-a-scenario"><a class="header" href="#install-a-scenario">Install a Scenario</a></h3>
<pre><code class="language-bash"># Install from local path
mockforge scenario install ./examples/scenarios/ecommerce-store

# Install from URL
mockforge scenario install https://example.com/scenarios/ecommerce-store.zip

# Install from Git repository
mockforge scenario install https://github.com/user/scenarios#main:ecommerce-store

# Install from registry
mockforge scenario install ecommerce-store
</code></pre>
<h3 id="apply-scenario-to-workspace"><a class="header" href="#apply-scenario-to-workspace">Apply Scenario to Workspace</a></h3>
<pre><code class="language-bash"># Apply installed scenario to current directory
mockforge scenario use ecommerce-store

# This copies:
# - config.yaml
# - openapi.json
# - fixtures/
# - examples/
</code></pre>
<h3 id="start-the-server"><a class="header" href="#start-the-server">Start the Server</a></h3>
<pre><code class="language-bash">mockforge serve --config config.yaml
</code></pre>
<h2 id="available-commands"><a class="header" href="#available-commands">Available Commands</a></h2>
<h3 id="install"><a class="header" href="#install">Install</a></h3>
<p>Install a scenario from various sources:</p>
<pre><code class="language-bash">mockforge scenario install &lt;source&gt; [--force] [--skip-validation] [--checksum &lt;sha256&gt;]
</code></pre>
<p><strong>Sources:</strong></p>
<ul>
<li>Local path: <code>./scenarios/my-scenario</code></li>
<li>URL: <code>https://example.com/scenario.zip</code></li>
<li>Git: <code>https://github.com/user/repo#main:scenarios/my-scenario</code></li>
<li>Registry: <code>ecommerce-store</code> or <code>ecommerce-store@1.0.0</code></li>
</ul>
<p><strong>Options:</strong></p>
<ul>
<li><code>--force</code>: Force reinstall even if scenario exists</li>
<li><code>--skip-validation</code>: Skip package validation</li>
<li><code>--checksum</code>: Expected SHA-256 checksum (for URL sources)</li>
</ul>
<h3 id="list"><a class="header" href="#list">List</a></h3>
<p>List all installed scenarios:</p>
<pre><code class="language-bash">mockforge scenario list [--detailed]
</code></pre>
<h3 id="info"><a class="header" href="#info">Info</a></h3>
<p>Show detailed information about an installed scenario:</p>
<pre><code class="language-bash">mockforge scenario info &lt;name&gt; [--version &lt;version&gt;]
</code></pre>
<h3 id="use"><a class="header" href="#use">Use</a></h3>
<p>Apply a scenario to the current workspace:</p>
<pre><code class="language-bash">mockforge scenario use &lt;name&gt; [--version &lt;version&gt;]
</code></pre>
<p>This copies scenario files to the current directory, allowing you to start using the scenario immediately.</p>
<h3 id="search"><a class="header" href="#search">Search</a></h3>
<p>Search for scenarios in the registry:</p>
<pre><code class="language-bash">mockforge scenario search &lt;query&gt; [--category &lt;category&gt;] [--tags &lt;tags&gt;]
</code></pre>
<h3 id="publish"><a class="header" href="#publish">Publish</a></h3>
<p>Publish your scenario to the marketplace:</p>
<pre><code class="language-bash">mockforge scenario publish \
  --name "my-scenario" \
  --version "1.0.0" \
  --description "My awesome scenario" \
  --category "ecommerce" \
  --tags "api,rest,mock"
</code></pre>
<h2 id="scenario-structure"><a class="header" href="#scenario-structure">Scenario Structure</a></h2>
<p>A scenario package must follow this structure:</p>
<pre><code>my-scenario/
‚îú‚îÄ‚îÄ scenario.yaml          # Scenario metadata
‚îú‚îÄ‚îÄ config.yaml            # MockForge configuration
‚îú‚îÄ‚îÄ openapi.json           # OpenAPI specification
‚îú‚îÄ‚îÄ fixtures/              # Protocol-specific fixtures
‚îÇ   ‚îú‚îÄ‚îÄ http/
‚îÇ   ‚îú‚îÄ‚îÄ grpc/
‚îÇ   ‚îî‚îÄ‚îÄ websocket/
‚îú‚îÄ‚îÄ examples/              # Example data files
‚îú‚îÄ‚îÄ README.md              # Documentation
‚îî‚îÄ‚îÄ CHANGELOG.md           # Version history
</code></pre>
<h3 id="scenarioyaml"><a class="header" href="#scenarioyaml">scenario.yaml</a></h3>
<pre><code class="language-yaml">name: ecommerce-store
version: 1.0.0
description: Complete e-commerce API mock
author: John Doe
category: ecommerce
tags:
  - api
  - rest
  - ecommerce
  - shopping
dependencies: []
</code></pre>
<h2 id="marketplace-features"><a class="header" href="#marketplace-features">Marketplace Features</a></h2>
<h3 id="tags-and-categories"><a class="header" href="#tags-and-categories">Tags and Categories</a></h3>
<p>Scenarios are organized by:</p>
<ul>
<li><strong>Categories</strong>: ecommerce, fintech, healthcare, iot, etc.</li>
<li><strong>Tags</strong>: api, rest, grpc, websocket, etc.</li>
<li><strong>Ratings</strong>: Community ratings and reviews</li>
<li><strong>Versioning</strong>: Semantic versioning support</li>
</ul>
<h3 id="ratings-and-reviews"><a class="header" href="#ratings-and-reviews">Ratings and Reviews</a></h3>
<p>Rate and review scenarios:</p>
<pre><code class="language-bash"># Rate a scenario
mockforge scenario rate &lt;name&gt; --rating 5 --comment "Great scenario!"

# View ratings
mockforge scenario info &lt;name&gt; --show-ratings
</code></pre>
<h3 id="versioning-1"><a class="header" href="#versioning-1">Versioning</a></h3>
<p>Scenarios use semantic versioning:</p>
<pre><code class="language-bash"># Install specific version
mockforge scenario install ecommerce-store@1.0.0

# Install latest version
mockforge scenario install ecommerce-store@latest

# Update to latest
mockforge scenario update ecommerce-store
</code></pre>
<h2 id="domain-specific-packs"><a class="header" href="#domain-specific-packs">Domain-Specific Packs</a></h2>
<h3 id="e-commerce"><a class="header" href="#e-commerce">E-commerce</a></h3>
<p>Complete e-commerce API scenarios:</p>
<pre><code class="language-bash">mockforge scenario install ecommerce-store
</code></pre>
<p>Includes:</p>
<ul>
<li>Product catalog</li>
<li>Shopping cart</li>
<li>Order management</li>
<li>Payment processing</li>
<li>User accounts</li>
</ul>
<h3 id="fintech"><a class="header" href="#fintech">Fintech</a></h3>
<p>Financial services scenarios:</p>
<pre><code class="language-bash">mockforge scenario install fintech-banking
</code></pre>
<p>Includes:</p>
<ul>
<li>Account management</li>
<li>Transactions</li>
<li>Payments</li>
<li>Cards</li>
<li>Loans</li>
</ul>
<h3 id="healthcare"><a class="header" href="#healthcare">Healthcare</a></h3>
<p>Healthcare API scenarios:</p>
<pre><code class="language-bash">mockforge scenario install healthcare-api
</code></pre>
<p>Includes:</p>
<ul>
<li>Patient records</li>
<li>Appointments</li>
<li>Prescriptions</li>
<li>Medical devices</li>
</ul>
<h3 id="iot"><a class="header" href="#iot">IoT</a></h3>
<p>IoT device scenarios:</p>
<pre><code class="language-bash">mockforge scenario install iot-devices
</code></pre>
<p>Includes:</p>
<ul>
<li>Device management</li>
<li>Sensor data</li>
<li>Commands</li>
<li>Telemetry</li>
</ul>
<h2 id="integration-with-vbr-and-mockai"><a class="header" href="#integration-with-vbr-and-mockai">Integration with VBR and MockAI</a></h2>
<p>Scenarios automatically integrate with VBR and MockAI:</p>
<h3 id="vbr-integration-2"><a class="header" href="#vbr-integration-2">VBR Integration</a></h3>
<p>Scenarios can include VBR entity definitions:</p>
<pre><code class="language-yaml"># scenario.yaml
vbr_entities:
  - name: users
    schema: ./schemas/user.json
    seed_data: ./data/users.json
</code></pre>
<h3 id="mockai-integration"><a class="header" href="#mockai-integration">MockAI Integration</a></h3>
<p>Scenarios can include MockAI rules:</p>
<pre><code class="language-yaml"># scenario.yaml
mockai_rules:
  - endpoint: "/users"
    rules: ./rules/users.json
</code></pre>
<h2 id="api-endpoints-5"><a class="header" href="#api-endpoints-5">API Endpoints</a></h2>
<h3 id="marketplace-api"><a class="header" href="#marketplace-api">Marketplace API</a></h3>
<pre><code class="language-http">GET /api/scenarios/marketplace?category=ecommerce&amp;tags=api
</code></pre>
<p>List scenarios from marketplace.</p>
<pre><code class="language-http">GET /api/scenarios/marketplace/{name}
</code></pre>
<p>Get scenario details.</p>
<pre><code class="language-http">POST /api/scenarios/marketplace/{name}/install
</code></pre>
<p>Install scenario from marketplace.</p>
<h3 id="local-scenarios"><a class="header" href="#local-scenarios">Local Scenarios</a></h3>
<pre><code class="language-http">GET /api/scenarios/local
</code></pre>
<p>List installed scenarios.</p>
<pre><code class="language-http">GET /api/scenarios/local/{name}
</code></pre>
<p>Get installed scenario details.</p>
<pre><code class="language-http">POST /api/scenarios/local/{name}/use
</code></pre>
<p>Apply scenario to workspace.</p>
<h2 id="use-cases-10"><a class="header" href="#use-cases-10">Use Cases</a></h2>
<h3 id="quick-prototyping"><a class="header" href="#quick-prototyping">Quick Prototyping</a></h3>
<p>Start with a pre-built scenario:</p>
<pre><code class="language-bash"># Install e-commerce scenario
mockforge scenario install ecommerce-store

# Apply to workspace
mockforge scenario use ecommerce-store

# Start server
mockforge serve --config config.yaml
</code></pre>
<h3 id="team-sharing"><a class="header" href="#team-sharing">Team Sharing</a></h3>
<p>Share scenarios within your team:</p>
<pre><code class="language-bash"># Publish to internal registry
mockforge scenario publish \
  --name "internal-api" \
  --registry "https://internal-registry.example.com"
</code></pre>
<h3 id="community-contribution"><a class="header" href="#community-contribution">Community Contribution</a></h3>
<p>Contribute scenarios to the community:</p>
<pre><code class="language-bash"># Publish to public marketplace
mockforge scenario publish \
  --name "my-awesome-scenario" \
  --public
</code></pre>
<h2 id="best-practices-38"><a class="header" href="#best-practices-38">Best Practices</a></h2>
<ol>
<li><strong>Document Well</strong>: Include comprehensive README and examples</li>
<li><strong>Version Properly</strong>: Use semantic versioning</li>
<li><strong>Test Thoroughly</strong>: Ensure scenarios work out of the box</li>
<li><strong>Tag Appropriately</strong>: Use relevant tags and categories</li>
<li><strong>Keep Updated</strong>: Maintain scenarios with bug fixes and improvements</li>
</ol>
<h2 id="troubleshooting-47"><a class="header" href="#troubleshooting-47">Troubleshooting</a></h2>
<h3 id="installation-fails"><a class="header" href="#installation-fails">Installation Fails</a></h3>
<ul>
<li>Verify scenario structure is correct</li>
<li>Check file permissions</li>
<li>Review scenario.yaml for errors</li>
</ul>
<h3 id="scenario-not-working"><a class="header" href="#scenario-not-working">Scenario Not Working</a></h3>
<ul>
<li>Check MockForge version compatibility</li>
<li>Verify all dependencies are installed</li>
<li>Review scenario documentation</li>
</ul>
<h3 id="marketplace-connection-issues"><a class="header" href="#marketplace-connection-issues">Marketplace Connection Issues</a></h3>
<ul>
<li>Verify network connectivity</li>
<li>Check marketplace URL is correct</li>
<li>Review authentication credentials</li>
</ul>
<h2 id="related-documentation-22"><a class="header" href="#related-documentation-22">Related Documentation</a></h2>
<ul>
<li><a href="user-guide/cloud-workspaces.html">Cloud Workspaces</a> - Sharing scenarios with teams</li>
<li><a href="user-guide/vbr-engine.html">VBR Engine</a> - State management in scenarios</li>
<li><a href="user-guide/../configuration/files.html">Configuration Guide</a> - Complete configuration reference</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="forgeconnect-sdk-1"><a class="header" href="#forgeconnect-sdk-1">ForgeConnect SDK</a></h1>
<p>ForgeConnect SDK provides browser extension and framework SDKs for capturing network traffic, auto-generating mocks, and integrating with popular frontend frameworks. Develop and test frontend applications with seamless mock integration.</p>
<h2 id="overview-29"><a class="header" href="#overview-29">Overview</a></h2>
<p>ForgeConnect includes:</p>
<ul>
<li><strong>Browser Extension</strong>: Capture network traffic and create mocks automatically</li>
<li><strong>Browser SDK</strong>: JavaScript/TypeScript SDK for framework integration</li>
<li><strong>Auto-Mock Generation</strong>: Automatically create mocks for unhandled requests</li>
<li><strong>Framework Adapters</strong>: React, Vue, Angular, Next.js support</li>
<li><strong>Auth Passthrough</strong>: Support for OAuth flows and authentication</li>
</ul>
<h2 id="quick-start-19"><a class="header" href="#quick-start-19">Quick Start</a></h2>
<h3 id="install-browser-extension"><a class="header" href="#install-browser-extension">Install Browser Extension</a></h3>
<ol>
<li>Install from Chrome Web Store or Firefox Add-ons</li>
<li>Open browser DevTools</li>
<li>Navigate to ‚ÄúMockForge‚Äù tab</li>
<li>Connect to MockForge server</li>
</ol>
<h3 id="install-browser-sdk"><a class="header" href="#install-browser-sdk">Install Browser SDK</a></h3>
<pre><code class="language-bash">npm install @mockforge/forgeconnect
</code></pre>
<h3 id="basic-usage-1"><a class="header" href="#basic-usage-1">Basic Usage</a></h3>
<pre><code class="language-typescript">import { ForgeConnect } from '@mockforge/forgeconnect';

// Initialize ForgeConnect
const forgeConnect = new ForgeConnect({
  serverUrl: 'http://localhost:3000',
  autoMock: true
});

// Start intercepting requests
forgeConnect.start();
</code></pre>
<h2 id="browser-extension"><a class="header" href="#browser-extension">Browser Extension</a></h2>
<h3 id="features-7"><a class="header" href="#features-7">Features</a></h3>
<ul>
<li><strong>Request Capture</strong>: Automatically capture all network requests</li>
<li><strong>Mock Creation</strong>: Create mocks from captured requests with one click</li>
<li><strong>DevTools Integration</strong>: Full DevTools panel with React UI</li>
<li><strong>Auto-Discovery</strong>: Automatically discover MockForge server</li>
<li><strong>Request Filtering</strong>: Filter requests by URL, method, status</li>
<li><strong>Live Response Modification</strong>: Modify responses on-the-fly in DevTools</li>
<li><strong>Persona/Scenario Toggling</strong>: Switch personas and scenarios directly from DevTools</li>
<li><strong>Reverse Injection</strong>: Automatically inject mocks back into workspace</li>
<li><strong>Snapshot Diff</strong>: Compare mock behavior between environments</li>
</ul>
<h3 id="devtools-panel"><a class="header" href="#devtools-panel">DevTools Panel</a></h3>
<p>The ForgeConnect extension adds a dedicated ‚ÄúMockForge‚Äù tab to your browser‚Äôs DevTools with the following features:</p>
<h4 id="request-capture-tab"><a class="header" href="#request-capture-tab">Request Capture Tab</a></h4>
<ul>
<li><strong>Live Request Monitoring</strong>: See all fetch/XHR requests in real-time</li>
<li><strong>Request Details</strong>: View request method, URL, headers, body, and response</li>
<li><strong>Filter &amp; Search</strong>: Filter requests by URL pattern, method, or status code</li>
<li><strong>One-Click Mock Creation</strong>: Click ‚ÄúMock this endpoint‚Äù to create a mock from any request</li>
</ul>
<h4 id="mocks-management-tab"><a class="header" href="#mocks-management-tab">Mocks Management Tab</a></h4>
<ul>
<li><strong>View All Mocks</strong>: See all mocks in your MockForge workspace</li>
<li><strong>Edit Mocks</strong>: Modify mock responses directly in DevTools</li>
<li><strong>Delete Mocks</strong>: Remove mocks with one click</li>
<li><strong>Toggle Mocks</strong>: Enable/disable mocks without leaving the browser</li>
</ul>
<h4 id="mock-preview-tab"><a class="header" href="#mock-preview-tab">Mock Preview Tab</a></h4>
<ul>
<li><strong>Create/Edit Mocks</strong>: Visual interface for creating and editing mocks</li>
<li><strong>Response Editor</strong>: JSON editor with syntax highlighting</li>
<li><strong>Status Code Selection</strong>: Choose response status codes</li>
<li><strong>Headers Configuration</strong>: Add/modify response headers</li>
<li><strong>Save to Workspace</strong>: Automatically reverse-inject mocks into your workspace</li>
</ul>
<h4 id="x-ray-tab"><a class="header" href="#x-ray-tab">X-Ray Tab</a></h4>
<ul>
<li><strong>Request Analysis</strong>: Deep dive into request/response details</li>
<li><strong>Timing Information</strong>: View request latency and timing breakdown</li>
<li><strong>Header Inspection</strong>: Inspect all request and response headers</li>
<li><strong>Body Analysis</strong>: View and analyze request/response bodies</li>
</ul>
<h4 id="snapshot-diff-tab"><a class="header" href="#snapshot-diff-tab">Snapshot Diff Tab</a></h4>
<ul>
<li><strong>Environment Comparison</strong>: Compare mock behavior between test and prod</li>
<li><strong>Persona Comparison</strong>: Compare responses for different personas</li>
<li><strong>Reality Level Comparison</strong>: Compare behavior at different reality levels</li>
<li><strong>Side-by-Side Visualization</strong>: See differences highlighted side-by-side</li>
</ul>
<h3 id="usage-4"><a class="header" href="#usage-4">Usage</a></h3>
<ol>
<li><strong>Open DevTools</strong>: Press F12 or right-click ‚Üí Inspect</li>
<li><strong>Navigate to MockForge Tab</strong>: Click ‚ÄúMockForge‚Äù in DevTools</li>
<li><strong>Connect to Server</strong>: Enter MockForge server URL or use auto-discovery</li>
<li><strong>Capture Requests</strong>: Requests are automatically captured</li>
<li><strong>Create Mocks</strong>: Click ‚ÄúMock this endpoint‚Äù on any captured request</li>
</ol>
<h3 id="mock-this-endpoint-feature"><a class="header" href="#mock-this-endpoint-feature">‚ÄúMock this Endpoint‚Äù Feature</a></h3>
<p>The ‚ÄúMock this endpoint‚Äù button appears on every captured request:</p>
<ol>
<li><strong>Click ‚ÄúMock this endpoint‚Äù</strong>: Opens the mock preview panel</li>
<li><strong>Review Request Details</strong>: See the original request method, path, headers, and body</li>
<li><strong>Edit Response</strong>: Modify the response status, headers, and body</li>
<li><strong>Save Mock</strong>: Click ‚ÄúSave‚Äù to create the mock in your workspace</li>
<li><strong>Auto-Injection</strong>: The mock is automatically reverse-injected into your MockForge workspace</li>
</ol>
<p><strong>Example Workflow:</strong></p>
<pre><code>1. Make API call: GET /api/users/123
2. Request appears in DevTools "Captured Requests" tab
3. Click "Mock this endpoint" button
4. Edit response in preview panel
5. Click "Save" ‚Üí Mock created in workspace
6. Future requests to /api/users/123 use the mock
</code></pre>
<h3 id="live-response-modification"><a class="header" href="#live-response-modification">Live Response Modification</a></h3>
<p>Modify responses on-the-fly without leaving the browser:</p>
<ol>
<li><strong>Select a Mock</strong>: Click on a mock in the ‚ÄúMocks‚Äù tab</li>
<li><strong>Edit Response</strong>: Modify the response JSON directly</li>
<li><strong>Save Changes</strong>: Changes are immediately applied</li>
<li><strong>Test</strong>: Refresh the page to see the new response</li>
</ol>
<h3 id="personascenario-toggling"><a class="header" href="#personascenario-toggling">Persona/Scenario Toggling</a></h3>
<p>Switch personas and scenarios directly from DevTools:</p>
<ol>
<li><strong>Open Mocks Tab</strong>: Navigate to the ‚ÄúMocks‚Äù tab</li>
<li><strong>Select Mock</strong>: Click on a mock to view details</li>
<li><strong>Change Persona</strong>: Use the persona dropdown to switch personas</li>
<li><strong>Change Scenario</strong>: Use the scenario dropdown to switch scenarios</li>
<li><strong>Apply</strong>: Changes are immediately applied to the mock</li>
</ol>
<h3 id="reverse-injection-into-workspace"><a class="header" href="#reverse-injection-into-workspace">Reverse Injection into Workspace</a></h3>
<p>When you create or modify a mock in DevTools, it‚Äôs automatically reverse-injected into your MockForge workspace:</p>
<ul>
<li><strong>Automatic Sync</strong>: Changes sync to your workspace immediately</li>
<li><strong>Workspace Integration</strong>: Mocks appear in your workspace configuration</li>
<li><strong>Version Control</strong>: Mocks can be committed to version control</li>
<li><strong>Team Sharing</strong>: Other team members see the mocks in shared workspaces</li>
</ul>
<h3 id="auto-mock-generation"><a class="header" href="#auto-mock-generation">Auto-Mock Generation</a></h3>
<p>When a request fails or returns an error, ForgeConnect can automatically create a mock:</p>
<pre><code class="language-typescript">const forgeConnect = new ForgeConnect({
  serverUrl: 'http://localhost:3000',
  autoMock: true,
  autoMockOnError: true  // Create mock on 4xx/5xx errors
});
</code></pre>
<h2 id="browser-sdk"><a class="header" href="#browser-sdk">Browser SDK</a></h2>
<h3 id="installation-5"><a class="header" href="#installation-5">Installation</a></h3>
<pre><code class="language-bash">npm install @mockforge/forgeconnect
</code></pre>
<h3 id="basic-setup-2"><a class="header" href="#basic-setup-2">Basic Setup</a></h3>
<pre><code class="language-typescript">import { ForgeConnect } from '@mockforge/forgeconnect';

const forgeConnect = new ForgeConnect({
  serverUrl: 'http://localhost:3000',
  autoMock: true,
  interceptFetch: true,
  interceptXHR: true
});

// Start intercepting
forgeConnect.start();
</code></pre>
<h3 id="framework-adapters"><a class="header" href="#framework-adapters">Framework Adapters</a></h3>
<h4 id="react"><a class="header" href="#react">React</a></h4>
<pre><code class="language-typescript">import { useForgeConnect } from '@mockforge/forgeconnect/react';

function App() {
  const { isConnected, mocks } = useForgeConnect({
    serverUrl: 'http://localhost:3000'
  });

  return (
    &lt;div&gt;
      {isConnected ? 'Connected' : 'Disconnected'}
      &lt;ul&gt;
        {mocks.map(mock =&gt; (
          &lt;li key={mock.id}&gt;{mock.path}&lt;/li&gt;
        ))}
      &lt;/ul&gt;
    &lt;/div&gt;
  );
}
</code></pre>
<h4 id="vue"><a class="header" href="#vue">Vue</a></h4>
<pre><code class="language-typescript">import { useForgeConnect } from '@mockforge/forgeconnect/vue';

export default {
  setup() {
    const { isConnected, mocks } = useForgeConnect({
      serverUrl: 'http://localhost:3000'
    });

    return { isConnected, mocks };
  }
};
</code></pre>
<h4 id="nextjs"><a class="header" href="#nextjs">Next.js</a></h4>
<pre><code class="language-typescript">// pages/_app.tsx
import { ForgeConnectProvider } from '@mockforge/forgeconnect/next';

function MyApp({ Component, pageProps }) {
  return (
    &lt;ForgeConnectProvider serverUrl="http://localhost:3000"&gt;
      &lt;Component {...pageProps} /&gt;
    &lt;/ForgeConnectProvider&gt;
  );
}
</code></pre>
<h3 id="request-interception"><a class="header" href="#request-interception">Request Interception</a></h3>
<p>ForgeConnect intercepts both <code>fetch</code> and <code>XMLHttpRequest</code>:</p>
<pre><code class="language-typescript">const forgeConnect = new ForgeConnect({
  serverUrl: 'http://localhost:3000',
  interceptFetch: true,
  interceptXHR: true
});

// All fetch requests are intercepted
fetch('/api/users')
  .then(response =&gt; response.json())
  .then(data =&gt; console.log(data));

// All XHR requests are intercepted
const xhr = new XMLHttpRequest();
xhr.open('GET', '/api/users');
xhr.send();
</code></pre>
<h3 id="mock-management"><a class="header" href="#mock-management">Mock Management</a></h3>
<h4 id="list-mocks"><a class="header" href="#list-mocks">List Mocks</a></h4>
<pre><code class="language-typescript">const mocks = await forgeConnect.listMocks();
console.log('Available mocks:', mocks);
</code></pre>
<h4 id="create-mock"><a class="header" href="#create-mock">Create Mock</a></h4>
<pre><code class="language-typescript">const mock = await forgeConnect.createMock({
  method: 'GET',
  path: '/api/users',
  response: {
    status: 200,
    body: { users: [] }
  }
});
</code></pre>
<h4 id="update-mock"><a class="header" href="#update-mock">Update Mock</a></h4>
<pre><code class="language-typescript">await forgeConnect.updateMock(mockId, {
  response: {
    status: 200,
    body: { users: [{ id: 1, name: 'Alice' }] }
  }
});
</code></pre>
<h4 id="delete-mock"><a class="header" href="#delete-mock">Delete Mock</a></h4>
<pre><code class="language-typescript">await forgeConnect.deleteMock(mockId);
</code></pre>
<h2 id="auth-passthrough"><a class="header" href="#auth-passthrough">Auth Passthrough</a></h2>
<p>ForgeConnect supports OAuth flows and authentication:</p>
<pre><code class="language-typescript">const forgeConnect = new ForgeConnect({
  serverUrl: 'http://localhost:3000',
  authPassthrough: true,
  authPaths: ['/auth', '/oauth', '/login']
});
</code></pre>
<p>Requests to auth paths are passed through to the real server without interception.</p>
<h2 id="configuration-20"><a class="header" href="#configuration-20">Configuration</a></h2>
<h3 id="sdk-configuration"><a class="header" href="#sdk-configuration">SDK Configuration</a></h3>
<pre><code class="language-typescript">interface ForgeConnectConfig {
  serverUrl: string;
  autoMock?: boolean;
  autoMockOnError?: boolean;
  interceptFetch?: boolean;
  interceptXHR?: boolean;
  authPassthrough?: boolean;
  authPaths?: string[];
  mockPaths?: string[];
  excludePaths?: string[];
}
</code></pre>
<h3 id="extension-configuration"><a class="header" href="#extension-configuration">Extension Configuration</a></h3>
<p>Configure via extension options:</p>
<ol>
<li>Right-click extension icon</li>
<li>Select ‚ÄúOptions‚Äù</li>
<li>Configure server URL and settings</li>
</ol>
<h2 id="use-cases-11"><a class="header" href="#use-cases-11">Use Cases</a></h2>
<h3 id="frontend-development-1"><a class="header" href="#frontend-development-1">Frontend Development</a></h3>
<p>Develop frontend without backend:</p>
<pre><code class="language-typescript">// Start ForgeConnect
const forgeConnect = new ForgeConnect({
  serverUrl: 'http://localhost:3000',
  autoMock: true
});

forgeConnect.start();

// Develop frontend - mocks created automatically
</code></pre>
<h3 id="api-testing-1"><a class="header" href="#api-testing-1">API Testing</a></h3>
<p>Test API integration:</p>
<pre><code class="language-typescript">// Capture real API calls
const forgeConnect = new ForgeConnect({
  serverUrl: 'http://localhost:3000',
  autoMock: false  // Don't auto-create, capture only
});

// Review captured requests
const captures = await forgeConnect.getCaptures();

// Create mocks from captures
for (const capture of captures) {
  await forgeConnect.createMockFromCapture(capture);
}
</code></pre>
<h3 id="debugging-1"><a class="header" href="#debugging-1">Debugging</a></h3>
<p>Debug API issues:</p>
<pre><code class="language-typescript">// Enable detailed logging
const forgeConnect = new ForgeConnect({
  serverUrl: 'http://localhost:3000',
  debug: true
});

// View intercepted requests in console
forgeConnect.on('request', (request) =&gt; {
  console.log('Intercepted:', request);
});
</code></pre>
<h2 id="best-practices-39"><a class="header" href="#best-practices-39">Best Practices</a></h2>
<ol>
<li><strong>Use Auto-Mock Sparingly</strong>: Only enable for development</li>
<li><strong>Filter Requests</strong>: Use <code>mockPaths</code> and <code>excludePaths</code> to control interception</li>
<li><strong>Auth Passthrough</strong>: Always enable for authentication flows</li>
<li><strong>Version Control Mocks</strong>: Export and commit mocks to version control</li>
<li><strong>Test with Real APIs</strong>: Periodically test against real APIs</li>
</ol>
<h2 id="troubleshooting-48"><a class="header" href="#troubleshooting-48">Troubleshooting</a></h2>
<h3 id="extension-not-connecting-2"><a class="header" href="#extension-not-connecting-2">Extension Not Connecting</a></h3>
<ul>
<li>Verify MockForge server is running</li>
<li>Check server URL is correct</li>
<li>Review browser console for errors</li>
</ul>
<h3 id="requests-not-intercepted"><a class="header" href="#requests-not-intercepted">Requests Not Intercepted</a></h3>
<ul>
<li>Verify interception is enabled</li>
<li>Check request paths match configuration</li>
<li>Review SDK logs for errors</li>
</ul>
<h3 id="mocks-not-working"><a class="header" href="#mocks-not-working">Mocks Not Working</a></h3>
<ul>
<li>Verify mock is created correctly</li>
<li>Check mock path matches request path</li>
<li>Review MockForge server logs</li>
</ul>
<h2 id="related-documentation-23"><a class="header" href="#related-documentation-23">Related Documentation</a></h2>
<ul>
<li><a href="user-guide/advanced-behavior.html#browser-proxy-with-conditional-forwarding">Browser Proxy Mode</a> - Proxy mode features</li>
<li><a href="user-guide/../configuration/files.html">Configuration Guide</a> - Complete configuration reference</li>
<li><a href="user-guide/../../sdk/README.html">SDK Documentation</a> - Complete SDK reference</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="deceptive-deploys-1"><a class="header" href="#deceptive-deploys-1">Deceptive Deploys</a></h1>
<p>Deceptive Deploy allows you to deploy mock APIs that look identical to production endpoints. Perfect for front-end demos, PoCs, investor prototypes, and client presentations without exposing production systems.</p>
<h2 id="overview-30"><a class="header" href="#overview-30">Overview</a></h2>
<p>Deceptive Deploy configures MockForge to automatically:</p>
<ul>
<li>‚úÖ Add production-like headers to all responses</li>
<li>‚úÖ Configure CORS to match production settings</li>
<li>‚úÖ Apply production-like rate limiting</li>
<li>‚úÖ Support OAuth flows identical to production</li>
<li>‚úÖ Deploy to public URLs via tunneling</li>
</ul>
<p>The result: mock APIs that are indistinguishable from production endpoints to your application and users.</p>
<h2 id="quick-start-20"><a class="header" href="#quick-start-20">Quick Start</a></h2>
<h3 id="basic-deployment"><a class="header" href="#basic-deployment">Basic Deployment</a></h3>
<pre><code class="language-bash"># Deploy with production preset
mockforge deploy deploy --production-preset --spec api.yaml

# Deploy with custom config
mockforge deploy deploy --config config.yaml --spec api.yaml
</code></pre>
<h3 id="configuration-file-6"><a class="header" href="#configuration-file-6">Configuration File</a></h3>
<p>Create a <code>config.yaml</code> file:</p>
<pre><code class="language-yaml">http:
  port: 3000
  openapi_spec: "./api-spec.yaml"

deceptive_deploy:
  enabled: true
  auto_tunnel: true
</code></pre>
<h3 id="start-the-server-1"><a class="header" href="#start-the-server-1">Start the Server</a></h3>
<pre><code class="language-bash">mockforge serve --config config.yaml
</code></pre>
<p>The server will automatically:</p>
<ul>
<li>Apply production-like headers</li>
<li>Configure CORS</li>
<li>Set up rate limiting</li>
<li>Start a tunnel (if <code>auto_tunnel: true</code>)</li>
</ul>
<h2 id="configuration-21"><a class="header" href="#configuration-21">Configuration</a></h2>
<h3 id="basic-configuration-6"><a class="header" href="#basic-configuration-6">Basic Configuration</a></h3>
<pre><code class="language-yaml">deceptive_deploy:
  enabled: true
  auto_tunnel: true
</code></pre>
<h3 id="full-configuration-1"><a class="header" href="#full-configuration-1">Full Configuration</a></h3>
<pre><code class="language-yaml">deceptive_deploy:
  enabled: true

  # Production-like CORS
  cors:
    allowed_origins: ["*"]
    allowed_methods: ["GET", "POST", "PUT", "DELETE", "PATCH", "OPTIONS"]
    allowed_headers: ["*"]
    allow_credentials: true

  # Production-like rate limiting
  rate_limit:
    requests_per_minute: 1000
    burst: 2000
    per_ip: true

  # Production headers (supports templates)
  headers:
    X-API-Version: "1.0"
    X-Request-ID: "{{uuid}}"
    X-Powered-By: "MockForge"

  # OAuth configuration (optional)
  oauth:
    client_id: "your-client-id"
    client_secret: "your-client-secret"
    introspection_url: "https://auth.example.com/introspect"

  # Custom domain (optional)
  custom_domain: "api.example.com"

  # Auto-start tunnel
  auto_tunnel: true
</code></pre>
<h2 id="production-headers"><a class="header" href="#production-headers">Production Headers</a></h2>
<p>Deceptive Deploy automatically adds configured headers to all responses. Headers support template expansion:</p>
<h3 id="supported-templates"><a class="header" href="#supported-templates">Supported Templates</a></h3>
<ul>
<li><code>{{uuid}}</code> - Generates a unique UUID v4 for each request</li>
<li><code>{{now}}</code> - Current timestamp in RFC3339 format</li>
<li><code>{{timestamp}}</code> - Current Unix timestamp (seconds)</li>
</ul>
<h3 id="example-1"><a class="header" href="#example-1">Example</a></h3>
<pre><code class="language-yaml">headers:
  X-Request-ID: "{{uuid}}"           # Unique ID per request
  X-Timestamp: "{{timestamp}}"      # Unix timestamp
  X-Request-Time: "{{now}}"         # RFC3339 timestamp
  X-API-Version: "1.0"               # Static value
</code></pre>
<h3 id="common-production-headers"><a class="header" href="#common-production-headers">Common Production Headers</a></h3>
<pre><code class="language-yaml">headers:
  # Request tracking
  X-Request-ID: "{{uuid}}"
  X-Correlation-ID: "{{uuid}}"

  # API information
  X-API-Version: "1.0"
  X-Environment: "production"

  # Server information
  X-Powered-By: "MockForge"
  Server: "MockForge/1.0"

  # Custom headers
  X-Rate-Limit-Remaining: "999"
  X-Rate-Limit-Reset: "{{timestamp}}"
</code></pre>
<h2 id="cors-configuration"><a class="header" href="#cors-configuration">CORS Configuration</a></h2>
<p>Deceptive Deploy can configure CORS to match production settings:</p>
<pre><code class="language-yaml">cors:
  # Allow all origins (use specific origins in production)
  allowed_origins:
    - "*"
    # Or specific origins:
    # - "https://app.example.com"
    # - "https://staging.example.com"

  # Allowed HTTP methods
  allowed_methods:
    - "GET"
    - "POST"
    - "PUT"
    - "DELETE"
    - "PATCH"
    - "OPTIONS"

  # Allowed headers
  allowed_headers:
    - "*"
    # Or specific headers:
    # - "Content-Type"
    # - "Authorization"
    # - "X-API-Key"

  # Allow credentials (cookies, authorization headers)
  allow_credentials: true
</code></pre>
<h2 id="rate-limiting-1"><a class="header" href="#rate-limiting-1">Rate Limiting</a></h2>
<p>Configure production-like rate limiting:</p>
<pre><code class="language-yaml">rate_limit:
  # Requests per minute
  requests_per_minute: 1000

  # Burst capacity (maximum requests in a short burst)
  burst: 2000

  # Enable per-IP rate limiting
  per_ip: true
</code></pre>
<h3 id="rate-limit-headers"><a class="header" href="#rate-limit-headers">Rate Limit Headers</a></h3>
<p>When rate limiting is enabled, responses include rate limit headers:</p>
<ul>
<li><code>X-Rate-Limit-Limit</code>: Maximum requests per minute</li>
<li><code>X-Rate-Limit-Remaining</code>: Remaining requests in current window</li>
<li><code>X-Rate-Limit-Reset</code>: Unix timestamp when limit resets</li>
</ul>
<h2 id="oauth-configuration"><a class="header" href="#oauth-configuration">OAuth Configuration</a></h2>
<p>Configure OAuth flows to match production:</p>
<pre><code class="language-yaml">oauth:
  client_id: "your-client-id"
  client_secret: "your-client-secret"
  introspection_url: "https://auth.example.com/introspect"
  auth_url: "https://auth.example.com/authorize"
  token_url: "https://auth.example.com/token"
  token_type_hint: "access_token"
</code></pre>
<p>This enables:</p>
<ul>
<li>Token introspection</li>
<li>Authorization code flow</li>
<li>Client credentials flow</li>
<li>Token validation</li>
</ul>
<h2 id="tunneling"><a class="header" href="#tunneling">Tunneling</a></h2>
<p>Deceptive Deploy can automatically start a tunnel to expose your mock API via a public URL:</p>
<pre><code class="language-yaml">deceptive_deploy:
  auto_tunnel: true
  custom_domain: "api.example.com"  # Optional
</code></pre>
<h3 id="tunnel-providers"><a class="header" href="#tunnel-providers">Tunnel Providers</a></h3>
<ul>
<li><strong>Self-hosted</strong>: Use your own tunnel server</li>
<li><strong>Cloud</strong>: Use MockForge Cloud (if available)</li>
<li><strong>Cloudflare</strong>: Use Cloudflare Tunnel (coming soon)</li>
</ul>
<h3 id="manual-tunnel"><a class="header" href="#manual-tunnel">Manual Tunnel</a></h3>
<pre><code class="language-bash"># Start tunnel manually
mockforge tunnel start \
  --local-url http://localhost:3000 \
  --subdomain my-api
</code></pre>
<h2 id="cli-commands-6"><a class="header" href="#cli-commands-6">CLI Commands</a></h2>
<h3 id="deploy"><a class="header" href="#deploy">Deploy</a></h3>
<pre><code class="language-bash"># Deploy with production preset
mockforge deploy deploy --production-preset --spec api.yaml

# Deploy with custom config
mockforge deploy deploy --config config.yaml --spec api.yaml

# Deploy with auto-tunnel
mockforge deploy deploy --config config.yaml --auto-tunnel

# Deploy with custom domain
mockforge deploy deploy --config config.yaml --custom-domain api.example.com
</code></pre>
<h3 id="status"><a class="header" href="#status">Status</a></h3>
<pre><code class="language-bash"># Get deployment status
mockforge deploy status --config config.yaml
</code></pre>
<h3 id="stop"><a class="header" href="#stop">Stop</a></h3>
<pre><code class="language-bash"># Stop deployment
mockforge deploy stop --config config.yaml
</code></pre>
<h2 id="use-cases-12"><a class="header" href="#use-cases-12">Use Cases</a></h2>
<h3 id="front-end-demo"><a class="header" href="#front-end-demo">Front-End Demo</a></h3>
<pre><code class="language-yaml"># config.yaml
http:
  port: 3000
  openapi_spec: "./api.yaml"

deceptive_deploy:
  enabled: true
  auto_tunnel: true
  headers:
    X-API-Version: "1.0"
    X-Request-ID: "{{uuid}}"
</code></pre>
<pre><code class="language-bash"># Deploy
mockforge deploy deploy --config config.yaml

# Start server
mockforge serve --config config.yaml

# Front-end connects to public URL
# https://abc123.tunnel.mockforge.dev
</code></pre>
<h3 id="investor-prototype"><a class="header" href="#investor-prototype">Investor Prototype</a></h3>
<pre><code class="language-yaml">deceptive_deploy:
  enabled: true
  cors:
    allowed_origins: ["*"]
    allow_credentials: true
  rate_limit:
    requests_per_minute: 1000
    burst: 2000
  headers:
    X-API-Version: "1.0"
    X-Environment: "production"
  auto_tunnel: true
  custom_domain: "api.demo.example.com"
</code></pre>
<h3 id="poc-with-oauth"><a class="header" href="#poc-with-oauth">PoC with OAuth</a></h3>
<pre><code class="language-yaml">deceptive_deploy:
  enabled: true
  oauth:
    client_id: "demo-client"
    client_secret: "demo-secret"
    introspection_url: "https://auth.example.com/introspect"
  headers:
    X-Request-ID: "{{uuid}}"
    X-Auth-Provider: "OAuth2"
</code></pre>
<h2 id="best-practices-40"><a class="header" href="#best-practices-40">Best Practices</a></h2>
<h3 id="1-use-specific-origins"><a class="header" href="#1-use-specific-origins">1. Use Specific Origins</a></h3>
<p>Instead of <code>*</code>, use specific origins:</p>
<pre><code class="language-yaml">cors:
  allowed_origins:
    - "https://app.example.com"
    - "https://staging.example.com"
</code></pre>
<h3 id="2-set-realistic-rate-limits"><a class="header" href="#2-set-realistic-rate-limits">2. Set Realistic Rate Limits</a></h3>
<p>Match production rate limits:</p>
<pre><code class="language-yaml">rate_limit:
  requests_per_minute: 1000  # Match production
  burst: 2000
</code></pre>
<h3 id="3-use-meaningful-headers"><a class="header" href="#3-use-meaningful-headers">3. Use Meaningful Headers</a></h3>
<p>Add headers that match production:</p>
<pre><code class="language-yaml">headers:
  X-API-Version: "1.0"
  X-Request-ID: "{{uuid}}"
  X-Environment: "production"
</code></pre>
<h3 id="4-secure-oauth-credentials"><a class="header" href="#4-secure-oauth-credentials">4. Secure OAuth Credentials</a></h3>
<p>Never commit OAuth secrets to version control:</p>
<pre><code class="language-yaml">oauth:
  client_id: "${OAUTH_CLIENT_ID}"
  client_secret: "${OAUTH_CLIENT_SECRET}"
</code></pre>
<h3 id="5-use-custom-domains"><a class="header" href="#5-use-custom-domains">5. Use Custom Domains</a></h3>
<p>For professional presentations:</p>
<pre><code class="language-yaml">deceptive_deploy:
  custom_domain: "api.example.com"
</code></pre>
<h2 id="troubleshooting-49"><a class="header" href="#troubleshooting-49">Troubleshooting</a></h2>
<h3 id="headers-not-appearing"><a class="header" href="#headers-not-appearing">Headers Not Appearing</a></h3>
<p>Check that deceptive deploy is enabled:</p>
<pre><code class="language-yaml">deceptive_deploy:
  enabled: true
  headers:
    X-Request-ID: "{{uuid}}"
</code></pre>
<h3 id="cors-errors-2"><a class="header" href="#cors-errors-2">CORS Errors</a></h3>
<p>Verify CORS configuration:</p>
<pre><code class="language-yaml">cors:
  allowed_origins: ["*"]  # Or specific origins
  allow_credentials: true
</code></pre>
<h3 id="rate-limiting-too-strict"><a class="header" href="#rate-limiting-too-strict">Rate Limiting Too Strict</a></h3>
<p>Adjust rate limits:</p>
<pre><code class="language-yaml">rate_limit:
  requests_per_minute: 1000  # Increase if needed
  burst: 2000
</code></pre>
<h3 id="tunnel-not-starting"><a class="header" href="#tunnel-not-starting">Tunnel Not Starting</a></h3>
<p>Check tunnel configuration:</p>
<pre><code class="language-yaml">deceptive_deploy:
  auto_tunnel: true
</code></pre>
<p>Or start manually:</p>
<pre><code class="language-bash">mockforge tunnel start --local-url http://localhost:3000
</code></pre>
<h2 id="related-documentation-24"><a class="header" href="#related-documentation-24">Related Documentation</a></h2>
<ul>
<li><a href="user-guide/../reference/tunneling.html">Tunneling Guide</a> - Detailed tunnel setup</li>
<li><a href="user-guide/security.html">Authentication Guide</a> - OAuth configuration</li>
<li><a href="user-guide/../configuration/files.html">Configuration Reference</a> - Full config options</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="voice--llm-interface-1"><a class="header" href="#voice--llm-interface-1">Voice + LLM Interface</a></h1>
<p>The Voice + LLM Interface allows you to create mock APIs conversationally using natural language commands, powered by LLM interpretation. Generate OpenAPI specifications and mock APIs from voice or text commands.</p>
<h2 id="overview-31"><a class="header" href="#overview-31">Overview</a></h2>
<p>The Voice + LLM Interface provides:</p>
<ul>
<li><strong>Voice Command Parsing</strong>: Use natural language to describe APIs</li>
<li><strong>OpenAPI Generation</strong>: Automatically generate OpenAPI 3.0 specifications</li>
<li><strong>Conversational Mode</strong>: Multi-turn interactions for complex APIs</li>
<li><strong>Single-Shot Mode</strong>: Complete API generation in one command</li>
<li><strong>CLI and Web UI</strong>: Use from command line or web interface</li>
</ul>
<h2 id="quick-start-21"><a class="header" href="#quick-start-21">Quick Start</a></h2>
<h3 id="cli-usage-1"><a class="header" href="#cli-usage-1">CLI Usage</a></h3>
<h4 id="single-shot-mode"><a class="header" href="#single-shot-mode">Single-Shot Mode</a></h4>
<p>Create a complete API in one command:</p>
<pre><code class="language-bash"># Create API from text command
mockforge voice create \
  --command "Create a user management API with endpoints for listing users, getting a user by ID, creating users, and updating users" \
  --output api.yaml

# Or use interactive input
mockforge voice create
# Enter your command when prompted
</code></pre>
<h4 id="conversational-mode"><a class="header" href="#conversational-mode">Conversational Mode</a></h4>
<p>Build APIs through conversation:</p>
<pre><code class="language-bash"># Start interactive conversation
mockforge voice interactive

# Example conversation:
# &gt; Create a user management API
# &gt; Add an endpoint to get user by email
# &gt; Add authentication to all endpoints
# &gt; Show me the spec
# &gt; done
</code></pre>
<h3 id="web-ui-usage"><a class="header" href="#web-ui-usage">Web UI Usage</a></h3>
<ol>
<li>Navigate to <strong>Voice</strong> page in Admin UI</li>
<li>Click microphone or type your command</li>
<li>View generated OpenAPI spec</li>
<li>Download or use the spec</li>
</ol>
<h2 id="features-8"><a class="header" href="#features-8">Features</a></h2>
<h3 id="natural-language-commands"><a class="header" href="#natural-language-commands">Natural Language Commands</a></h3>
<p>Describe your API in plain English:</p>
<pre><code>Create a REST API for an e-commerce store with:
- Product catalog with categories
- Shopping cart management
- Order processing
- User authentication
</code></pre>
<h3 id="openapi-generation"><a class="header" href="#openapi-generation">OpenAPI Generation</a></h3>
<p>Automatically generates complete OpenAPI 3.0 specifications:</p>
<pre><code class="language-yaml">openapi: 3.0.0
info:
  title: E-commerce Store API
  version: 1.0.0
paths:
  /products:
    get:
      summary: List products
      responses:
        '200':
          description: List of products
  /cart:
    post:
      summary: Add item to cart
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                product_id:
                  type: integer
                quantity:
                  type: integer
</code></pre>
<h3 id="conversational-mode-1"><a class="header" href="#conversational-mode-1">Conversational Mode</a></h3>
<p>Build complex APIs through multiple interactions:</p>
<pre><code>&gt; Create a blog API
‚úì Created blog API with posts endpoint

&gt; Add comments to posts
‚úì Added comments endpoint with post_id relationship

&gt; Add user authentication
‚úì Added authentication to all endpoints

&gt; Show me the spec
[Displays generated OpenAPI spec]

&gt; done
‚úì Saved to blog-api.yaml
</code></pre>
<h3 id="single-shot-mode-1"><a class="header" href="#single-shot-mode-1">Single-Shot Mode</a></h3>
<p>Generate complete APIs in one command:</p>
<pre><code class="language-bash">mockforge voice create \
  --command "Create a task management API with CRUD operations for tasks, projects, and users" \
  --output task-api.yaml
</code></pre>
<h2 id="cli-commands-7"><a class="header" href="#cli-commands-7">CLI Commands</a></h2>
<h3 id="create-single-shot"><a class="header" href="#create-single-shot">Create (Single-Shot)</a></h3>
<pre><code class="language-bash">mockforge voice create \
  --command "&lt;description&gt;" \
  --output &lt;file&gt; \
  --format yaml \
  --ai-provider ollama \
  --ai-model llama3.2
</code></pre>
<p><strong>Options:</strong></p>
<ul>
<li><code>--command</code>: Natural language description of API</li>
<li><code>--output</code>: Output file path (default: <code>generated-api.yaml</code>)</li>
<li><code>--format</code>: Output format (<code>yaml</code> or <code>json</code>)</li>
<li><code>--ai-provider</code>: LLM provider (<code>ollama</code>, <code>openai</code>, <code>anthropic</code>)</li>
<li><code>--ai-model</code>: Model name (e.g., <code>llama3.2</code>, <code>gpt-3.5-turbo</code>)</li>
</ul>
<h3 id="interactive-conversational"><a class="header" href="#interactive-conversational">Interactive (Conversational)</a></h3>
<pre><code class="language-bash">mockforge voice interactive \
  --ai-provider ollama \
  --ai-model llama3.2
</code></pre>
<p><strong>Special Commands:</strong></p>
<ul>
<li><code>help</code> - Show available commands</li>
<li><code>show spec</code> - Display current OpenAPI spec</li>
<li><code>save &lt;file&gt;</code> - Save spec to file</li>
<li><code>done</code> - Exit and save</li>
<li><code>exit</code> - Exit without saving</li>
</ul>
<h2 id="web-ui"><a class="header" href="#web-ui">Web UI</a></h2>
<h3 id="voice-input"><a class="header" href="#voice-input">Voice Input</a></h3>
<p>Use Web Speech API for voice input:</p>
<ol>
<li>Click microphone button</li>
<li>Speak your command</li>
<li>View real-time transcript</li>
<li>See generated spec</li>
</ol>
<h3 id="text-input"><a class="header" href="#text-input">Text Input</a></h3>
<p>Type commands directly:</p>
<ol>
<li>Enter command in text field</li>
<li>Click ‚ÄúGenerate‚Äù or press Enter</li>
<li>View generated spec</li>
<li>Download or use spec</li>
</ol>
<h3 id="command-history"><a class="header" href="#command-history">Command History</a></h3>
<p>View last 10 commands:</p>
<ul>
<li>Click on history item to reuse</li>
<li>Edit before regenerating</li>
<li>Save successful commands</li>
</ul>
<h2 id="configuration-22"><a class="header" href="#configuration-22">Configuration</a></h2>
<h3 id="ai-provider-configuration-1"><a class="header" href="#ai-provider-configuration-1">AI Provider Configuration</a></h3>
<pre><code class="language-yaml">voice:
  enabled: true
  ai_provider: "ollama"  # or "openai", "anthropic"
  ai_model: "llama3.2"
  ai_base_url: "http://localhost:11434"  # For Ollama
  ai_api_key: "${AI_API_KEY}"  # For OpenAI/Anthropic
</code></pre>
<h3 id="cli-configuration"><a class="header" href="#cli-configuration">CLI Configuration</a></h3>
<pre><code class="language-bash"># Set AI provider via environment
export MOCKFORGE_VOICE_AI_PROVIDER=ollama
export MOCKFORGE_VOICE_AI_MODEL=llama3.2
export MOCKFORGE_VOICE_AI_BASE_URL=http://localhost:11434

# Or use OpenAI
export MOCKFORGE_VOICE_AI_PROVIDER=openai
export MOCKFORGE_VOICE_AI_MODEL=gpt-3.5-turbo
export MOCKFORGE_VOICE_AI_API_KEY=sk-...
</code></pre>
<h2 id="api-endpoints-6"><a class="header" href="#api-endpoints-6">API Endpoints</a></h2>
<h3 id="process-voice-command"><a class="header" href="#process-voice-command">Process Voice Command</a></h3>
<pre><code class="language-http">POST /api/v2/voice/process
Content-Type: application/json

{
  "command": "Create a user management API",
  "mode": "single_shot",  # or "conversational"
  "conversation_id": null  # For conversational mode
}
</code></pre>
<p><strong>Response:</strong></p>
<pre><code class="language-json">{
  "success": true,
  "spec": {
    "openapi": "3.0.0",
    "info": {...},
    "paths": {...}
  },
  "conversation_id": "uuid"  # For conversational mode
}
</code></pre>
<h3 id="continue-conversation"><a class="header" href="#continue-conversation">Continue Conversation</a></h3>
<pre><code class="language-http">POST /api/v2/voice/process
Content-Type: application/json

{
  "command": "Add authentication",
  "mode": "conversational",
  "conversation_id": "uuid"
}
</code></pre>
<h2 id="use-cases-13"><a class="header" href="#use-cases-13">Use Cases</a></h2>
<h3 id="rapid-prototyping-2"><a class="header" href="#rapid-prototyping-2">Rapid Prototyping</a></h3>
<p>Quickly create API prototypes:</p>
<pre><code class="language-bash">mockforge voice create \
  --command "Create a simple todo API with CRUD operations" \
  --output todo-api.yaml
</code></pre>
<h3 id="api-design-1"><a class="header" href="#api-design-1">API Design</a></h3>
<p>Design APIs by describing them:</p>
<pre><code class="language-bash">mockforge voice interactive

# &gt; Create a social media API
# &gt; Add posts, comments, and likes
# &gt; Add user profiles
# &gt; Show me the spec
</code></pre>
<h3 id="learning"><a class="header" href="#learning">Learning</a></h3>
<p>Learn OpenAPI by example:</p>
<pre><code class="language-bash"># Generate spec
mockforge voice create --command "..."

# Review generated spec
cat generated-api.yaml
</code></pre>
<h2 id="best-practices-41"><a class="header" href="#best-practices-41">Best Practices</a></h2>
<ol>
<li><strong>Be Specific</strong>: Provide clear, detailed descriptions</li>
<li><strong>Iterate</strong>: Use conversational mode for complex APIs</li>
<li><strong>Review Generated Specs</strong>: Always review and validate generated specs</li>
<li><strong>Use Local LLMs</strong>: Use Ollama for faster, free generation</li>
<li><strong>Save Good Examples</strong>: Save successful commands for reuse</li>
</ol>
<h2 id="troubleshooting-50"><a class="header" href="#troubleshooting-50">Troubleshooting</a></h2>
<h3 id="command-not-understood"><a class="header" href="#command-not-understood">Command Not Understood</a></h3>
<ul>
<li>Be more specific in your description</li>
<li>Break complex APIs into smaller parts</li>
<li>Use conversational mode for clarification</li>
</ul>
<h3 id="spec-generation-fails"><a class="header" href="#spec-generation-fails">Spec Generation Fails</a></h3>
<ul>
<li>Check AI provider is accessible</li>
<li>Verify API key is set (for OpenAI/Anthropic)</li>
<li>Review server logs for errors</li>
</ul>
<h3 id="voice-input-not-working"><a class="header" href="#voice-input-not-working">Voice Input Not Working</a></h3>
<ul>
<li>Check browser permissions for microphone</li>
<li>Verify Web Speech API is supported</li>
<li>Use text input as fallback</li>
</ul>
<h2 id="related-documentation-25"><a class="header" href="#related-documentation-25">Related Documentation</a></h2>
<ul>
<li><a href="user-guide/generative-schema.html">Generative Schema Mode</a> - JSON-based API generation</li>
<li><a href="user-guide/http-mocking/openapi.html">OpenAPI Integration</a> - Working with OpenAPI specs</li>
<li><a href="user-guide/../configuration/files.html">Configuration Guide</a> - Complete configuration reference</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="reality-continuum-1"><a class="header" href="#reality-continuum-1">Reality Continuum</a></h1>
<p>The Reality Continuum feature enables gradual transition from mock to real backend data by intelligently blending responses from both sources. This allows teams to develop and test against a real backend that‚Äôs still under construction, smoothly transitioning from 100% mock to 100% real over time.</p>
<h2 id="overview-32"><a class="header" href="#overview-32">Overview</a></h2>
<p>The Reality Continuum provides:</p>
<ul>
<li><strong>Dynamic Blending</strong>: Intelligently merges mock and real responses based on configurable blend ratios</li>
<li><strong>Time-Based Progression</strong>: Automatically transitions blend ratios over time using virtual clock</li>
<li><strong>Flexible Configuration</strong>: Supports per-route, group-level, and global blend ratio settings</li>
<li><strong>Multiple Merge Strategies</strong>: Field-level merge, weighted selection, or body blending</li>
<li><strong>Fallback Handling</strong>: Gracefully handles failures from either source</li>
</ul>
<h2 id="quick-start-22"><a class="header" href="#quick-start-22">Quick Start</a></h2>
<h3 id="basic-configuration-7"><a class="header" href="#basic-configuration-7">Basic Configuration</a></h3>
<pre><code class="language-yaml">reality_continuum:
  enabled: true
  default_ratio: 0.0  # Start with 100% mock
  transition_mode: "manual"  # or "time_based" or "scheduled"
  merge_strategy: "field_level"
</code></pre>
<h3 id="time-based-progression"><a class="header" href="#time-based-progression">Time-Based Progression</a></h3>
<p>Configure automatic progression from mock to real over a time period:</p>
<pre><code class="language-yaml">reality_continuum:
  enabled: true
  default_ratio: 0.0
  transition_mode: "time_based"
  time_schedule:
    start_time: "2025-01-01T00:00:00Z"
    end_time: "2025-02-01T00:00:00Z"
    start_ratio: 0.0
    end_ratio: 1.0
    curve: "linear"  # or "exponential" or "sigmoid"
</code></pre>
<h3 id="per-route-configuration"><a class="header" href="#per-route-configuration">Per-Route Configuration</a></h3>
<p>Set different blend ratios for specific routes:</p>
<pre><code class="language-yaml">reality_continuum:
  enabled: true
  default_ratio: 0.0
  routes:
    - pattern: "/api/users/*"
      ratio: 0.5  # 50% real for user endpoints
      enabled: true
    - pattern: "/api/orders/*"
      ratio: 0.3  # 30% real for order endpoints
      group: "api-v1"
      enabled: true
</code></pre>
<h2 id="blend-ratio-priority"><a class="header" href="#blend-ratio-priority">Blend Ratio Priority</a></h2>
<p>The blend ratio is determined in the following order (highest to lowest priority):</p>
<ol>
<li><strong>Manual Overrides</strong> - Set via API calls</li>
<li><strong>Route-Specific Rules</strong> - Per-route configuration</li>
<li><strong>Group-Level Overrides</strong> - Migration group settings</li>
<li><strong>Time-Based Schedule</strong> - If time-based mode is enabled</li>
<li><strong>Default Ratio</strong> - Global default setting</li>
</ol>
<h2 id="merge-strategies"><a class="header" href="#merge-strategies">Merge Strategies</a></h2>
<h3 id="field-level-default"><a class="header" href="#field-level-default">Field-Level (Default)</a></h3>
<p>Deep merges JSON objects, combines arrays, and uses weighted selection for primitives:</p>
<pre><code class="language-json">// Mock response
{
  "id": 1,
  "name": "Mock User",
  "email": "mock@example.com"
}

// Real response
{
  "id": 2,
  "name": "Real User",
  "status": "active"
}

// Blended (ratio: 0.5)
{
  "id": 1.5,  // Weighted average
  "name": "Real User",  // Selected based on ratio
  "email": "mock@example.com",  // From mock (ratio &lt; 0.5)
  "status": "active"  // From real (ratio &gt;= 0.5)
}
</code></pre>
<h3 id="weighted-selection"><a class="header" href="#weighted-selection">Weighted Selection</a></h3>
<p>Randomly selects between mock and real based on ratio (for testing/demo).</p>
<h3 id="body-blend"><a class="header" href="#body-blend">Body Blend</a></h3>
<p>Merges arrays, averages numeric fields, and deep merges objects with interleaving.</p>
<h2 id="transition-curves"><a class="header" href="#transition-curves">Transition Curves</a></h2>
<h3 id="linear"><a class="header" href="#linear">Linear</a></h3>
<p>Constant rate of progression:</p>
<pre><code>Ratio
1.0 |                    *
    |               *
    |          *
    |     *
0.0 |*
    +------------------- Time
</code></pre>
<h3 id="exponential"><a class="header" href="#exponential">Exponential</a></h3>
<p>Slow start, fast end:</p>
<pre><code>Ratio
1.0 |                        *
    |                  *
    |            *
    |      *
0.0 |*
    +------------------- Time
</code></pre>
<h3 id="sigmoid"><a class="header" href="#sigmoid">Sigmoid</a></h3>
<p>Slow start and end, fast middle:</p>
<pre><code>Ratio
1.0 |                    *
    |               *
    |          *
    |     *
0.0 |*
    +------------------- Time
</code></pre>
<h2 id="api-endpoints-7"><a class="header" href="#api-endpoints-7">API Endpoints</a></h2>
<h3 id="get-blend-ratio"><a class="header" href="#get-blend-ratio">Get Blend Ratio</a></h3>
<pre><code class="language-http">GET /__mockforge/continuum/ratio?path=/api/users/123
</code></pre>
<p>Response:</p>
<pre><code class="language-json">{
  "success": true,
  "data": {
    "path": "/api/users/123",
    "blend_ratio": 0.5,
    "enabled": true,
    "transition_mode": "Manual",
    "merge_strategy": "FieldLevel",
    "default_ratio": 0.0
  }
}
</code></pre>
<h3 id="set-blend-ratio"><a class="header" href="#set-blend-ratio">Set Blend Ratio</a></h3>
<pre><code class="language-http">PUT /__mockforge/continuum/ratio
Content-Type: application/json

{
  "path": "/api/users/*",
  "ratio": 0.75
}
</code></pre>
<h3 id="get-time-schedule"><a class="header" href="#get-time-schedule">Get Time Schedule</a></h3>
<pre><code class="language-http">GET /__mockforge/continuum/schedule
</code></pre>
<h3 id="update-time-schedule"><a class="header" href="#update-time-schedule">Update Time Schedule</a></h3>
<pre><code class="language-http">PUT /__mockforge/continuum/schedule
Content-Type: application/json

{
  "start_time": "2025-01-01T00:00:00Z",
  "end_time": "2025-02-01T00:00:00Z",
  "start_ratio": 0.0,
  "end_ratio": 1.0,
  "curve": "linear"
}
</code></pre>
<h3 id="manually-advance-ratio"><a class="header" href="#manually-advance-ratio">Manually Advance Ratio</a></h3>
<pre><code class="language-http">POST /__mockforge/continuum/advance
Content-Type: application/json

{
  "increment": 0.1
}
</code></pre>
<h3 id="enabledisable-1"><a class="header" href="#enabledisable-1">Enable/Disable</a></h3>
<pre><code class="language-http">PUT /__mockforge/continuum/enabled
Content-Type: application/json

{
  "enabled": true
}
</code></pre>
<h2 id="integration-with-time-travel"><a class="header" href="#integration-with-time-travel">Integration with Time Travel</a></h2>
<p>The Reality Continuum integrates seamlessly with MockForge‚Äôs time travel system. When virtual time is enabled, blend ratios automatically progress based on the virtual clock:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_core::{RealityContinuumEngine, VirtualClock, TimeSchedule};

let clock = Arc::new(VirtualClock::new());
clock.enable_and_set(start_time);

let schedule = TimeSchedule::new(start_time, end_time, 0.0, 1.0);
let config = ContinuumConfig {
    enabled: true,
    transition_mode: TransitionMode::TimeBased,
    time_schedule: Some(schedule),
    ..Default::default()
};

let engine = RealityContinuumEngine::with_virtual_clock(config, clock);
<span class="boring">}</span></code></pre></pre>
<h2 id="use-cases-14"><a class="header" href="#use-cases-14">Use Cases</a></h2>
<h3 id="gradual-backend-migration"><a class="header" href="#gradual-backend-migration">Gradual Backend Migration</a></h3>
<p>Start with 100% mock responses and gradually increase real backend usage as endpoints are implemented:</p>
<pre><code class="language-yaml">reality_continuum:
  enabled: true
  transition_mode: "time_based"
  time_schedule:
    start_time: "2025-01-01T00:00:00Z"
    end_time: "2025-03-01T00:00:00Z"  # 2 months transition
    start_ratio: 0.0
    end_ratio: 1.0
    curve: "sigmoid"  # Slow start and end
</code></pre>
<h3 id="per-endpoint-rollout"><a class="header" href="#per-endpoint-rollout">Per-Endpoint Rollout</a></h3>
<p>Different endpoints migrate at different rates:</p>
<pre><code class="language-yaml">reality_continuum:
  enabled: true
  routes:
    - pattern: "/api/users/*"
      ratio: 0.9  # Almost fully migrated
    - pattern: "/api/orders/*"
      ratio: 0.3  # Still mostly mock
    - pattern: "/api/payments/*"
      ratio: 0.0  # Not yet migrated
</code></pre>
<h3 id="ab-testing"><a class="header" href="#ab-testing">A/B Testing</a></h3>
<p>Compare mock and real responses by blending them:</p>
<pre><code class="language-yaml">reality_continuum:
  enabled: true
  default_ratio: 0.5  # 50/50 split
  merge_strategy: "field_level"
</code></pre>
<h2 id="fallback-behavior"><a class="header" href="#fallback-behavior">Fallback Behavior</a></h2>
<p>When continuum is enabled:</p>
<ul>
<li><strong>Both sources succeed</strong>: Responses are blended according to the blend ratio</li>
<li><strong>Only proxy succeeds</strong>: Real response is returned (fallback to real)</li>
<li><strong>Only mock succeeds</strong>: Mock response is returned (fallback to mock)</li>
<li><strong>Both fail</strong>: Error is returned (unless migration mode is Real, which fails hard)</li>
</ul>
<h2 id="best-practices-42"><a class="header" href="#best-practices-42">Best Practices</a></h2>
<ol>
<li><strong>Start Conservative</strong>: Begin with <code>default_ratio: 0.0</code> (100% mock)</li>
<li><strong>Use Time-Based Progression</strong>: Automate the transition with time schedules</li>
<li><strong>Monitor Both Sources</strong>: Ensure both mock and real backends are healthy</li>
<li><strong>Test Fallback Behavior</strong>: Verify graceful degradation when one source fails</li>
<li><strong>Use Groups for Batch Control</strong>: Group related routes for coordinated migration</li>
<li><strong>Leverage Virtual Clock</strong>: Use time travel to simulate weeks of development in minutes</li>
</ol>
<h2 id="limitations-2"><a class="header" href="#limitations-2">Limitations</a></h2>
<ul>
<li>Currently supports JSON responses only</li>
<li>Merge strategies may not handle all edge cases perfectly</li>
<li>Time-based progression requires time travel to be enabled for full effect</li>
<li>Blending adds slight latency (both responses must be fetched)</li>
</ul>
<h2 id="related-documentation-26"><a class="header" href="#related-documentation-26">Related Documentation</a></h2>
<ul>
<li><a href="user-guide/temporal-simulation.html">Temporal Simulation</a> - Time travel integration</li>
<li><a href="user-guide/advanced-behavior.html#conditional-proxying">Proxy Mode</a> - Proxy configuration</li>
<li><a href="user-guide/../configuration/files.html">Configuration Guide</a> - Complete configuration reference</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="smart-personas-1"><a class="header" href="#smart-personas-1">Smart Personas</a></h1>
<p>Smart Personas enable generating coherent, consistent mock data using persona profiles with unique backstories and deterministic generation. The same persona always generates the same data, ensuring consistency across endpoints and requests.</p>
<h2 id="overview-33"><a class="header" href="#overview-33">Overview</a></h2>
<p>Smart Personas provide:</p>
<ul>
<li><strong>Persona Profiles</strong>: Unique personas with IDs and domain associations</li>
<li><strong>Coherent Backstories</strong>: Template-based backstory generation</li>
<li><strong>Persona Relationships</strong>: Connections between personas (users, devices, organizations)</li>
<li><strong>Deterministic Generation</strong>: Same persona = same data every time</li>
<li><strong>Domain-Specific Templates</strong>: Finance, E-commerce, Healthcare, IoT personas</li>
</ul>
<h2 id="quick-start-23"><a class="header" href="#quick-start-23">Quick Start</a></h2>
<h3 id="enable-smart-personas"><a class="header" href="#enable-smart-personas">Enable Smart Personas</a></h3>
<pre><code class="language-yaml"># config.yaml
data:
  personas:
    enabled: true
    auto_generate_backstories: true
    domain: "ecommerce"  # or "finance", "healthcare", "iot"
</code></pre>
<h3 id="use-in-templates"><a class="header" href="#use-in-templates">Use in Templates</a></h3>
<pre><code class="language-yaml">responses:
  - path: "/api/users/{id}"
    body: |
      {
        "id": "{{persona.id}}",
        "name": "{{persona.name}}",
        "email": "{{persona.email}}",
        "backstory": "{{persona.backstory}}"
      }
</code></pre>
<h2 id="persona-profiles"><a class="header" href="#persona-profiles">Persona Profiles</a></h2>
<h3 id="automatic-persona-creation"><a class="header" href="#automatic-persona-creation">Automatic Persona Creation</a></h3>
<p>Personas are automatically created when referenced:</p>
<pre><code class="language-bash"># Request to /api/users/123
# Persona with ID "123" is automatically created
# Same persona used for all requests with ID "123"
</code></pre>
<h3 id="manual-persona-creation"><a class="header" href="#manual-persona-creation">Manual Persona Creation</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_data::{PersonaProfile, PersonaRegistry};

let mut registry = PersonaRegistry::new();
let persona = PersonaProfile::new("user-123", "ecommerce");
registry.add_persona(persona);
<span class="boring">}</span></code></pre></pre>
<h2 id="backstories"><a class="header" href="#backstories">Backstories</a></h2>
<h3 id="automatic-backstory-generation"><a class="header" href="#automatic-backstory-generation">Automatic Backstory Generation</a></h3>
<p>Backstories are automatically generated based on domain:</p>
<pre><code class="language-yaml">data:
  personas:
    enabled: true
    auto_generate_backstories: true
    domain: "ecommerce"
</code></pre>
<h3 id="domain-specific-templates"><a class="header" href="#domain-specific-templates">Domain-Specific Templates</a></h3>
<h4 id="e-commerce-1"><a class="header" href="#e-commerce-1">E-commerce</a></h4>
<pre><code>"Alice is a 32-year-old marketing professional living in San Francisco. 
She frequently shops online for electronics and fashion items. 
Her average order value is $150, and she prefers express shipping."
</code></pre>
<h4 id="finance"><a class="header" href="#finance">Finance</a></h4>
<pre><code>"Bob is a 45-year-old investment banker based in New York. 
He manages a portfolio worth $2.5M and prefers conservative investments. 
He has been a customer for 8 years."
</code></pre>
<h4 id="healthcare-1"><a class="header" href="#healthcare-1">Healthcare</a></h4>
<pre><code>"Carol is a 28-year-old nurse practitioner in Boston. 
She manages chronic conditions for 50+ patients. 
She prefers digital health tools and telemedicine."
</code></pre>
<h4 id="iot-1"><a class="header" href="#iot-1">IoT</a></h4>
<pre><code>"Device-001 is a smart thermostat installed in a 3-bedroom home in Seattle. 
It monitors temperature, humidity, and energy usage. 
It's connected to 5 other smart home devices."
</code></pre>
<h3 id="custom-backstories"><a class="header" href="#custom-backstories">Custom Backstories</a></h3>
<p>Set custom backstories:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let mut persona = PersonaProfile::new("user-123", "ecommerce");
persona.set_backstory("Custom backstory text".to_string());
<span class="boring">}</span></code></pre></pre>
<h2 id="persona-relationships"><a class="header" href="#persona-relationships">Persona Relationships</a></h2>
<h3 id="define-relationships"><a class="header" href="#define-relationships">Define Relationships</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_data::PersonaRegistry;

let mut registry = PersonaRegistry::new();

// Add relationship
registry.add_relationship(
    "user-123",
    "device-456",
    "owns"
);

// Get related personas
let devices = registry.get_related_personas("user-123", "owns");
<span class="boring">}</span></code></pre></pre>
<h3 id="relationship-types-1"><a class="header" href="#relationship-types-1">Relationship Types</a></h3>
<p>Common relationship types:</p>
<ul>
<li><code>owns</code> - User owns device/organization</li>
<li><code>belongs_to</code> - Device/organization belongs to user</li>
<li><code>manages</code> - User manages organization</li>
<li><code>connected_to</code> - Device connected to other device</li>
<li><code>parent_of</code> - Organization parent-child relationship</li>
</ul>
<h3 id="cross-entity-consistency"><a class="header" href="#cross-entity-consistency">Cross-Entity Consistency</a></h3>
<p>Same base ID across different entity types:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// User persona
let user = registry.get_or_create_persona_by_type("123", EntityType::User, "ecommerce");

// Device persona (same ID, different type)
let device = registry.get_or_create_persona_by_type("123", EntityType::Device, "iot");

// Automatically establishes relationship
<span class="boring">}</span></code></pre></pre>
<h2 id="deterministic-generation-1"><a class="header" href="#deterministic-generation-1">Deterministic Generation</a></h2>
<h3 id="same-persona-same-data"><a class="header" href="#same-persona-same-data">Same Persona, Same Data</a></h3>
<p>The same persona always generates the same data:</p>
<pre><code class="language-bash"># First request
GET /api/users/123
# Response: {"id": 123, "name": "Alice", "email": "alice@example.com"}

# Second request (same persona ID)
GET /api/users/123
# Response: {"id": 123, "name": "Alice", "email": "alice@example.com"}  # Same!
</code></pre>
<h3 id="seed-based-generation"><a class="header" href="#seed-based-generation">Seed-Based Generation</a></h3>
<p>Personas use deterministic seeds:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let persona = PersonaProfile::new("user-123", "ecommerce");
// Seed is derived from persona ID and domain
// Same ID + same domain = same seed = same data
<span class="boring">}</span></code></pre></pre>
<h2 id="template-functions-1"><a class="header" href="#template-functions-1">Template Functions</a></h2>
<h3 id="persona-functions"><a class="header" href="#persona-functions">Persona Functions</a></h3>
<pre><code class="language-yaml"># In response templates
{
  "id": "{{persona.id}}",
  "name": "{{persona.name}}",
  "email": "{{persona.email}}",
  "phone": "{{persona.phone}}",
  "address": "{{persona.address}}",
  "backstory": "{{persona.backstory}}",
  "traits": "{{persona.traits}}"
}
</code></pre>
<h3 id="relationship-functions"><a class="header" href="#relationship-functions">Relationship Functions</a></h3>
<pre><code class="language-yaml"># Get related personas
{
  "user": {
    "id": "{{persona.id}}",
    "name": "{{persona.name}}"
  },
  "devices": "{{persona.related.owns}}"
}
</code></pre>
<h2 id="configuration-23"><a class="header" href="#configuration-23">Configuration</a></h2>
<h3 id="full-configuration-2"><a class="header" href="#full-configuration-2">Full Configuration</a></h3>
<pre><code class="language-yaml">data:
  personas:
    enabled: true
    auto_generate_backstories: true
    domain: "ecommerce"  # finance, healthcare, iot, generic
    backstory_templates:
      ecommerce:
        - "{{name}} is a {{age}}-year-old {{profession}} living in {{city}}."
        - "They frequently shop for {{interests}} with an average order value of ${{avg_order_value}}."
    relationship_types:
      - owns
      - belongs_to
      - manages
      - connected_to
</code></pre>
<h2 id="use-cases-15"><a class="header" href="#use-cases-15">Use Cases</a></h2>
<h3 id="consistent-user-data"><a class="header" href="#consistent-user-data">Consistent User Data</a></h3>
<p>Generate consistent user data across endpoints:</p>
<pre><code class="language-yaml"># User endpoint
responses:
  - path: "/api/users/{id}"
    body: |
      {
        "id": "{{persona.id}}",
        "name": "{{persona.name}}",
        "email": "{{persona.email}}"
      }

# User's orders endpoint
responses:
  - path: "/api/users/{id}/orders"
    body: |
      {
        "user_id": "{{persona.id}}",
        "user_name": "{{persona.name}}",
        "orders": [...]
      }
</code></pre>
<h3 id="device-relationships"><a class="header" href="#device-relationships">Device Relationships</a></h3>
<p>Model device ownership:</p>
<pre><code class="language-yaml"># Device endpoint
responses:
  - path: "/api/devices/{id}"
    body: |
      {
        "id": "{{persona.id}}",
        "owner_id": "{{persona.relationship.owner}}",
        "type": "{{persona.type}}"
      }
</code></pre>
<h3 id="organization-hierarchies"><a class="header" href="#organization-hierarchies">Organization Hierarchies</a></h3>
<p>Model organizational structures:</p>
<pre><code class="language-yaml"># Organization endpoint
responses:
  - path: "/api/organizations/{id}"
    body: |
      {
        "id": "{{persona.id}}",
        "name": "{{persona.name}}",
        "parent_id": "{{persona.relationship.parent}}",
        "children": "{{persona.related.children}}"
      }
</code></pre>
<h2 id="best-practices-43"><a class="header" href="#best-practices-43">Best Practices</a></h2>
<ol>
<li><strong>Use Consistent IDs</strong>: Use the same persona ID across related endpoints</li>
<li><strong>Choose Appropriate Domain</strong>: Select domain that matches your use case</li>
<li><strong>Leverage Relationships</strong>: Use relationships to model complex data structures</li>
<li><strong>Customize Backstories</strong>: Add domain-specific details to backstories</li>
<li><strong>Test Determinism</strong>: Verify same persona generates same data</li>
</ol>
<h2 id="troubleshooting-51"><a class="header" href="#troubleshooting-51">Troubleshooting</a></h2>
<h3 id="persona-not-found"><a class="header" href="#persona-not-found">Persona Not Found</a></h3>
<ul>
<li>Ensure personas are enabled in configuration</li>
<li>Check persona ID is consistent across requests</li>
<li>Verify domain matches persona domain</li>
</ul>
<h3 id="backstory-not-generated"><a class="header" href="#backstory-not-generated">Backstory Not Generated</a></h3>
<ul>
<li>Check <code>auto_generate_backstories</code> is enabled</li>
<li>Verify domain is supported</li>
<li>Review persona creation logs</li>
</ul>
<h3 id="relationships-not-working"><a class="header" href="#relationships-not-working">Relationships Not Working</a></h3>
<ul>
<li>Verify relationship types are defined</li>
<li>Check relationship is added to registry</li>
<li>Review relationship query syntax</li>
</ul>
<h2 id="related-documentation-27"><a class="header" href="#related-documentation-27">Related Documentation</a></h2>
<ul>
<li><a href="user-guide/vbr-engine.html">VBR Engine</a> - State management with personas</li>
<li><a href="user-guide/../reference/fixtures.html">Data Generation</a> - Data generation features</li>
<li><a href="user-guide/../configuration/files.html">Configuration Guide</a> - Complete configuration reference</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="api-change-forecasting"><a class="header" href="#api-change-forecasting">API Change Forecasting</a></h1>
<p><strong>Pillars:</strong> [Contracts]</p>
<p>API Change Forecasting uses historical sync/diff data to predict likely future contract breaks. This lets teams proactively harden clients before changes occur.</p>
<h2 id="overview-34"><a class="header" href="#overview-34">Overview</a></h2>
<p>Instead of reacting to breaking changes, API Change Forecasting analyzes historical patterns to predict:</p>
<ul>
<li><strong>When</strong> changes are likely to occur</li>
<li><strong>What type</strong> of changes (breaking vs non-breaking)</li>
<li><strong>Which endpoints</strong> are most volatile</li>
<li><strong>Seasonal patterns</strong> in changes</li>
</ul>
<p>This is hugely enterprise-friendly‚Äîit transforms contract management from reactive to proactive.</p>
<h2 id="key-features-1"><a class="header" href="#key-features-1">Key Features</a></h2>
<ul>
<li><strong>Pattern Analysis</strong>: Detects seasonal patterns, volatility, and change frequency</li>
<li><strong>Statistical Modeling</strong>: Predicts change probability and break probability</li>
<li><strong>Multi-Window Forecasting</strong>: 30, 90, and 180-day forecasts</li>
<li><strong>Hierarchical Aggregation</strong>: Workspace, service, and endpoint-level predictions</li>
<li><strong>Confidence Scoring</strong>: Indicates how reliable each forecast is</li>
</ul>
<h2 id="how-it-works-6"><a class="header" href="#how-it-works-6">How It Works</a></h2>
<h3 id="1-historical-analysis"><a class="header" href="#1-historical-analysis">1. Historical Analysis</a></h3>
<p>The system analyzes historical drift incidents to identify patterns:</p>
<ul>
<li><strong>Change Frequency</strong>: How often does this endpoint change?</li>
<li><strong>Change Types</strong>: What types of changes occur (breaking vs non-breaking)?</li>
<li><strong>Seasonal Patterns</strong>: Are changes more common at certain times?</li>
<li><strong>Volatility Score</strong>: How stable is this endpoint?</li>
</ul>
<h3 id="2-statistical-modeling"><a class="header" href="#2-statistical-modeling">2. Statistical Modeling</a></h3>
<p>Using the historical data, the system builds statistical models:</p>
<ul>
<li><strong>Change Probability</strong>: Likelihood of any change in the forecast window</li>
<li><strong>Break Probability</strong>: Likelihood of a breaking change</li>
<li><strong>Next Change Date</strong>: Expected date of next change (if predictable)</li>
<li><strong>Confidence</strong>: How reliable is this forecast?</li>
</ul>
<h3 id="3-forecasting"><a class="header" href="#3-forecasting">3. Forecasting</a></h3>
<p>Forecasts are generated for multiple time windows:</p>
<ul>
<li><strong>30-day forecast</strong>: Short-term predictions</li>
<li><strong>90-day forecast</strong>: Medium-term predictions</li>
<li><strong>180-day forecast</strong>: Long-term predictions</li>
</ul>
<h2 id="usage-5"><a class="header" href="#usage-5">Usage</a></h2>
<h3 id="cli-commands-8"><a class="header" href="#cli-commands-8">CLI Commands</a></h3>
<pre><code class="language-bash"># Generate forecasts for all endpoints
mockforge governance forecast

# Forecast for specific service
mockforge governance forecast --service payments

# Forecast for specific endpoint
mockforge governance forecast --endpoint /api/users/{id}

# Forecast with specific window
mockforge governance forecast --window 90  # 90-day forecast
</code></pre>
<h3 id="api-usage-1"><a class="header" href="#api-usage-1">API Usage</a></h3>
<pre><code class="language-bash"># Get forecasts
GET /api/v1/forecasts?workspace_id=workspace-123&amp;window=90

# Get forecast for specific endpoint
GET /api/v1/forecasts/endpoint?endpoint=/api/users/{id}&amp;method=GET&amp;window=90

# Get service-level forecast
GET /api/v1/forecasts/service?service_id=payments&amp;window=90
</code></pre>
<h2 id="forecast-results"><a class="header" href="#forecast-results">Forecast Results</a></h2>
<h3 id="example-forecast"><a class="header" href="#example-forecast">Example Forecast</a></h3>
<pre><code class="language-json">{
  "endpoint": "/api/users/{id}",
  "method": "GET",
  "forecast_window_days": 90,
  "predicted_change_probability": 0.75,
  "predicted_break_probability": 0.25,
  "next_expected_change_date": "2025-04-15T00:00:00Z",
  "next_expected_break_date": "2025-05-01T00:00:00Z",
  "volatility_score": 0.6,
  "confidence": 0.8,
  "seasonal_patterns": [
    {
      "pattern_type": "monthly",
      "frequency_days": 30.0,
      "last_occurrence": "2025-01-15T00:00:00Z",
      "confidence": 0.7,
      "description": "Changes typically occur monthly"
    }
  ]
}
</code></pre>
<h3 id="understanding-forecasts"><a class="header" href="#understanding-forecasts">Understanding Forecasts</a></h3>
<ul>
<li><strong>predicted_change_probability</strong>: 0.0-1.0, likelihood of any change</li>
<li><strong>predicted_break_probability</strong>: 0.0-1.0, likelihood of breaking change</li>
<li><strong>volatility_score</strong>: 0.0-1.0, how frequently changes occur (higher = more volatile)</li>
<li><strong>confidence</strong>: 0.0-1.0, how reliable the forecast is</li>
<li><strong>seasonal_patterns</strong>: Detected patterns in change timing</li>
</ul>
<h2 id="real-world-examples-2"><a class="header" href="#real-world-examples-2">Real-World Examples</a></h2>
<h3 id="example-1-monthly-field-additions"><a class="header" href="#example-1-monthly-field-additions">Example 1: Monthly Field Additions</a></h3>
<p><strong>Pattern Detected:</strong></p>
<ul>
<li>This team tends to add fields every 2 weeks</li>
<li>Changes are non-breaking (new optional fields)</li>
<li>Pattern confidence: 0.8</li>
</ul>
<p><strong>Forecast:</strong></p>
<ul>
<li>90-day change probability: 0.9</li>
<li>90-day break probability: 0.1</li>
<li>Next expected change: 2 weeks from now</li>
</ul>
<p><strong>Action:</strong> Frontend team can prepare for new optional fields.</p>
<h3 id="example-2-quarterly-breaking-changes"><a class="header" href="#example-2-quarterly-breaking-changes">Example 2: Quarterly Breaking Changes</a></h3>
<p><strong>Pattern Detected:</strong></p>
<ul>
<li>This service usually breaks its PATCH contract every quarter</li>
<li>Changes occur around quarter boundaries</li>
<li>Pattern confidence: 0.7</li>
</ul>
<p><strong>Forecast:</strong></p>
<ul>
<li>90-day break probability: 0.6</li>
<li>Next expected break: End of current quarter</li>
</ul>
<p><strong>Action:</strong> Platform team can schedule client updates before the break.</p>
<h3 id="example-3-frequent-refactors"><a class="header" href="#example-3-frequent-refactors">Example 3: Frequent Refactors</a></h3>
<p><strong>Pattern Detected:</strong></p>
<ul>
<li>This BE team often renames fields during refactors</li>
<li>Renames occur every 1-2 months</li>
<li>Pattern confidence: 0.6</li>
</ul>
<p><strong>Forecast:</strong></p>
<ul>
<li>90-day change probability: 0.8</li>
<li>90-day break probability: 0.5 (renames are breaking)</li>
<li>High volatility score: 0.7</li>
</ul>
<p><strong>Action:</strong> Consumer teams should implement field mapping strategies.</p>
<h2 id="configuration-24"><a class="header" href="#configuration-24">Configuration</a></h2>
<h3 id="enable-forecasting"><a class="header" href="#enable-forecasting">Enable Forecasting</a></h3>
<pre><code class="language-yaml"># mockforge.yaml
contract_drift:
  forecasting:
    enabled: true
    min_incidents_for_forecast: 5  # Need at least 5 incidents
    analysis_windows: [30, 90, 180]  # Days to analyze
    forecast_windows: [30, 90, 180]  # Days to forecast
</code></pre>
<h3 id="forecast-thresholds"><a class="header" href="#forecast-thresholds">Forecast Thresholds</a></h3>
<pre><code class="language-yaml">contract_drift:
  forecasting:
    enabled: true
    thresholds:
      high_volatility: 0.7  # Volatility score threshold
      high_break_probability: 0.5  # Break probability threshold
      low_confidence: 0.5  # Confidence threshold for warnings
</code></pre>
<h2 id="integration-with-drift-budgets"><a class="header" href="#integration-with-drift-budgets">Integration with Drift Budgets</a></h2>
<p>Forecasts integrate with drift budgets:</p>
<pre><code class="language-yaml">contract_drift:
  drift_budget:
    max_breaking_changes: 2
    max_non_breaking_changes: 10
  forecasting:
    enabled: true
    # Forecasts help predict if budget will be exceeded
</code></pre>
<p>When a forecast predicts budget violations, alerts can be sent proactively.</p>
<h2 id="webhooks"><a class="header" href="#webhooks">Webhooks</a></h2>
<p>Forecast updates can trigger webhooks:</p>
<pre><code class="language-yaml">webhooks:
  - url: https://slack.com/hooks/...
    events:
      - forecast.prediction_updated
      - forecast.high_volatility_detected
      - forecast.break_probability_high
</code></pre>
<h2 id="best-practices-44"><a class="header" href="#best-practices-44">Best Practices</a></h2>
<ol>
<li><strong>Collect History</strong>: Ensure sufficient historical data (at least 5 incidents)</li>
<li><strong>Review Regularly</strong>: Check forecasts weekly/monthly</li>
<li><strong>Act on Predictions</strong>: Use forecasts to plan client updates</li>
<li><strong>Track Accuracy</strong>: Monitor forecast accuracy over time</li>
<li><strong>Adjust Thresholds</strong>: Tune thresholds based on your needs</li>
</ol>
<h2 id="troubleshooting-52"><a class="header" href="#troubleshooting-52">Troubleshooting</a></h2>
<h3 id="no-forecasts-available"><a class="header" href="#no-forecasts-available">No Forecasts Available</a></h3>
<ul>
<li><strong>Insufficient History</strong>: Need at least 5 drift incidents</li>
<li><strong>No Patterns</strong>: Endpoint may be too stable or too new</li>
<li><strong>Low Confidence</strong>: Forecasts may be unreliable</li>
</ul>
<h3 id="inaccurate-forecasts"><a class="header" href="#inaccurate-forecasts">Inaccurate Forecasts</a></h3>
<ul>
<li><strong>Pattern Changes</strong>: Historical patterns may have changed</li>
<li><strong>External Factors</strong>: Events outside normal patterns</li>
<li><strong>Low Confidence</strong>: Check confidence scores</li>
</ul>
<h2 id="related-documentation-28"><a class="header" href="#related-documentation-28">Related Documentation</a></h2>
<ul>
<li><a href="user-guide/contracts/../../docs/DRIFT_BUDGETS.html">Drift Budgets</a> - Budget management</li>
<li><a href="user-guide/contracts/semantic-drift.html">Semantic Drift</a> - Semantic change detection</li>
<li><a href="user-guide/contracts/threat-modeling.html">Contract Threat Modeling</a> - Security analysis</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="semantic-drift-notifications"><a class="header" href="#semantic-drift-notifications">Semantic Drift Notifications</a></h1>
<p><strong>Pillars:</strong> [Contracts]</p>
<p>Semantic Drift Notifications detect when the <em>meaning</em> of an API changes, not just its structure. This is where AI Contract Diff goes from ‚Äúnice‚Äù to ‚Äúindispensable.‚Äù</p>
<h2 id="overview-35"><a class="header" href="#overview-35">Overview</a></h2>
<p>Structural diffs catch obvious breaking changes. Semantic drift detection catches subtle changes that break consumers even when the structure appears compatible:</p>
<ul>
<li><strong>Description changes</strong> that alter meaning</li>
<li><strong>Enum narrowing</strong> (values removed)</li>
<li><strong>Soft-breaking changes</strong> hidden behind oneOf/anyOf</li>
<li><strong>Nullable ‚Üí non-nullable</strong> changes</li>
<li><strong>Error codes removed</strong></li>
</ul>
<h2 id="how-it-works-7"><a class="header" href="#how-it-works-7">How It Works</a></h2>
<h3 id="layer-1-structural-diff"><a class="header" href="#layer-1-structural-diff">Layer 1: Structural Diff</a></h3>
<p>Traditional contract diffing compares:</p>
<ul>
<li>Field types</li>
<li>Required vs optional</li>
<li>Schema structure</li>
<li>HTTP methods</li>
</ul>
<h3 id="layer-2-semantic-analysis"><a class="header" href="#layer-2-semantic-analysis">Layer 2: Semantic Analysis</a></h3>
<p>Semantic drift detection adds:</p>
<ul>
<li><strong>LLM-Powered Analysis</strong>: Understands meaning, not just structure</li>
<li><strong>Rule-Based Detection</strong>: Fast detection of common patterns</li>
<li><strong>Soft-Breaking Scoring</strong>: Quantifies likelihood of breaking consumers</li>
<li><strong>Confidence Scoring</strong>: Indicates how certain the detection is</li>
</ul>
<h2 id="detection-types"><a class="header" href="#detection-types">Detection Types</a></h2>
<h3 id="description-changes"><a class="header" href="#description-changes">Description Changes</a></h3>
<p>Detects when field/endpoint descriptions change meaning:</p>
<p><strong>Before:</strong></p>
<pre><code class="language-json">{
  "status": {
    "type": "string",
    "description": "Order status: pending, processing, shipped"
  }
}
</code></pre>
<p><strong>After:</strong></p>
<pre><code class="language-json">{
  "status": {
    "type": "string",
    "description": "Order status: pending, processing, shipped, cancelled"
  }
}
</code></pre>
<p><strong>Detection:</strong> New value added, but description change may indicate behavior change.</p>
<h3 id="enum-narrowing"><a class="header" href="#enum-narrowing">Enum Narrowing</a></h3>
<p>Detects when enum values are removed:</p>
<p><strong>Before:</strong></p>
<pre><code class="language-json">{
  "status": {
    "type": "string",
    "enum": ["pending", "processing", "shipped", "cancelled"]
  }
}
</code></pre>
<p><strong>After:</strong></p>
<pre><code class="language-json">{
  "status": {
    "type": "string",
    "enum": ["pending", "processing", "shipped"]
  }
}
</code></pre>
<p><strong>Detection:</strong> ‚Äúcancelled‚Äù value removed‚Äîbreaking change for consumers using it.</p>
<h3 id="nullable-changes"><a class="header" href="#nullable-changes">Nullable Changes</a></h3>
<p>Detects nullable ‚Üí non-nullable changes hidden behind oneOf:</p>
<p><strong>Before:</strong></p>
<pre><code class="language-json">{
  "email": {
    "oneOf": [
      {"type": "string"},
      {"type": "null"}
    ]
  }
}
</code></pre>
<p><strong>After:</strong></p>
<pre><code class="language-json">{
  "email": {
    "type": "string"
  }
}
</code></pre>
<p><strong>Detection:</strong> Field is no longer nullable‚Äîbreaking for consumers expecting null.</p>
<h3 id="error-code-removals"><a class="header" href="#error-code-removals">Error Code Removals</a></h3>
<p>Detects when error codes are removed:</p>
<p><strong>Before:</strong></p>
<pre><code class="language-json">{
  "responses": {
    "400": {...},
    "404": {...},
    "409": {...}
  }
}
</code></pre>
<p><strong>After:</strong></p>
<pre><code class="language-json">{
  "responses": {
    "400": {...},
    "404": {...}
  }
}
</code></pre>
<p><strong>Detection:</strong> 409 error code removed‚Äîbreaking for consumers handling conflicts.</p>
<h3 id="soft-breaking-changes"><a class="header" href="#soft-breaking-changes">Soft-Breaking Changes</a></h3>
<p>Detects changes that may break consumers but aren‚Äôt structurally breaking:</p>
<ul>
<li><strong>Format changes</strong>: Email format validation tightened</li>
<li><strong>Constraint changes</strong>: Min/max values changed</li>
<li><strong>Pattern changes</strong>: Regex pattern modified</li>
<li><strong>Example changes</strong>: Examples suggest different behavior</li>
</ul>
<h2 id="usage-6"><a class="header" href="#usage-6">Usage</a></h2>
<h3 id="cli-commands-9"><a class="header" href="#cli-commands-9">CLI Commands</a></h3>
<pre><code class="language-bash"># Analyze semantic drift
mockforge governance semantic-drift analyze

# Analyze specific endpoint
mockforge governance semantic-drift analyze --endpoint /api/users/{id}

# Get semantic drift incidents
mockforge governance semantic-drift incidents

# Resolve incident
mockforge governance semantic-drift resolve &lt;incident-id&gt;
</code></pre>
<h3 id="api-usage-2"><a class="header" href="#api-usage-2">API Usage</a></h3>
<pre><code class="language-bash"># Analyze semantic drift
POST /api/v1/semantic-drift/analyze
{
  "before_spec": {...},
  "after_spec": {...}
}

# Get incidents
GET /api/v1/semantic-drift/incidents?workspace_id=workspace-123

# Get incident details
GET /api/v1/semantic-drift/incidents/{id}
</code></pre>
<h2 id="semantic-drift-results"><a class="header" href="#semantic-drift-results">Semantic Drift Results</a></h2>
<h3 id="example-result"><a class="header" href="#example-result">Example Result</a></h3>
<pre><code class="language-json">{
  "semantic_confidence": 0.85,
  "soft_breaking_score": 0.7,
  "change_type": "enum_narrowing",
  "semantic_mismatches": [
    {
      "type": "SemanticEnumNarrowing",
      "severity": "high",
      "location": "/api/orders/{id}",
      "field": "status",
      "description": "Enum value 'cancelled' removed",
      "before": ["pending", "processing", "shipped", "cancelled"],
      "after": ["pending", "processing", "shipped"],
      "confidence": 0.9
    }
  ],
  "llm_analysis": {
    "reasoning": "Removing 'cancelled' status breaks consumers that rely on this value for order cancellation flows.",
    "impact": "High - affects order cancellation workflows",
    "recommendation": "Deprecate 'cancelled' first, then remove in next major version"
  }
}
</code></pre>
<h3 id="understanding-scores"><a class="header" href="#understanding-scores">Understanding Scores</a></h3>
<ul>
<li><strong>semantic_confidence</strong>: 0.0-1.0, how certain the semantic analysis is</li>
<li><strong>soft_breaking_score</strong>: 0.0-1.0, likelihood this breaks consumers</li>
<li><strong>change_type</strong>: Type of semantic change detected</li>
<li><strong>confidence</strong>: Individual mismatch confidence</li>
</ul>
<h2 id="configuration-25"><a class="header" href="#configuration-25">Configuration</a></h2>
<h3 id="enable-semantic-drift-detection"><a class="header" href="#enable-semantic-drift-detection">Enable Semantic Drift Detection</a></h3>
<pre><code class="language-yaml"># mockforge.yaml
contract_drift:
  semantic_drift:
    enabled: true
    confidence_threshold: 0.65  # Minimum confidence to report
    use_llm_analysis: true  # Enable LLM-powered analysis
    rule_based_detection: true  # Enable rule-based detection
</code></pre>
<h3 id="llm-configuration"><a class="header" href="#llm-configuration">LLM Configuration</a></h3>
<pre><code class="language-yaml">contract_drift:
  semantic_drift:
    enabled: true
    llm:
      provider: openai  # or anthropic, local
      model: gpt-4
      temperature: 0.3  # Lower = more deterministic
</code></pre>
<h2 id="integration-with-drift-budgets-1"><a class="header" href="#integration-with-drift-budgets-1">Integration with Drift Budgets</a></h2>
<p>Semantic drift incidents integrate with drift budgets:</p>
<pre><code class="language-yaml">contract_drift:
  drift_budget:
    max_breaking_changes: 2
    semantic_drift:
      enabled: true
      # Semantic drift incidents count toward budget
</code></pre>
<h2 id="webhooks-1"><a class="header" href="#webhooks-1">Webhooks</a></h2>
<p>Semantic drift detection can trigger webhooks:</p>
<pre><code class="language-yaml">webhooks:
  - url: https://slack.com/hooks/...
    events:
      - semantic_drift.detected
      - semantic_drift.high_confidence
      - semantic_drift.soft_breaking
</code></pre>
<h2 id="best-practices-45"><a class="header" href="#best-practices-45">Best Practices</a></h2>
<ol>
<li><strong>Enable LLM Analysis</strong>: More accurate than rule-based alone</li>
<li><strong>Review High Confidence</strong>: Focus on high-confidence detections first</li>
<li><strong>Track Soft-Breaking</strong>: Monitor soft-breaking scores</li>
<li><strong>Document Changes</strong>: Explain why semantic changes were made</li>
<li><strong>Deprecate First</strong>: Use deprecation before removing features</li>
</ol>
<h2 id="real-world-examples-3"><a class="header" href="#real-world-examples-3">Real-World Examples</a></h2>
<h3 id="example-1-description-change"><a class="header" href="#example-1-description-change">Example 1: Description Change</a></h3>
<p><strong>Change:</strong></p>
<ul>
<li>Before: ‚ÄúUser email address‚Äù</li>
<li>After: ‚ÄúUser email address (must be verified)‚Äù</li>
</ul>
<p><strong>Detection:</strong> Semantic change‚Äîimplies new validation requirement.</p>
<p><strong>Impact:</strong> Consumers may need to handle verification errors.</p>
<h3 id="example-2-enum-narrowing"><a class="header" href="#example-2-enum-narrowing">Example 2: Enum Narrowing</a></h3>
<p><strong>Change:</strong></p>
<ul>
<li>Before: <code>["active", "inactive", "suspended"]</code></li>
<li>After: <code>["active", "inactive"]</code></li>
</ul>
<p><strong>Detection:</strong> ‚Äúsuspended‚Äù removed‚Äîbreaking for consumers using it.</p>
<p><strong>Impact:</strong> High‚Äîconsumers relying on ‚Äúsuspended‚Äù will break.</p>
<h3 id="example-3-soft-breaking-format-change"><a class="header" href="#example-3-soft-breaking-format-change">Example 3: Soft-Breaking Format Change</a></h3>
<p><strong>Change:</strong></p>
<ul>
<li>Before: Email format: any string</li>
<li>After: Email format: must match RFC 5322</li>
</ul>
<p><strong>Detection:</strong> Soft-breaking‚Äîmay break consumers with invalid emails.</p>
<p><strong>Impact:</strong> Medium‚Äîonly affects consumers with invalid data.</p>
<h2 id="troubleshooting-53"><a class="header" href="#troubleshooting-53">Troubleshooting</a></h2>
<h3 id="false-positives"><a class="header" href="#false-positives">False Positives</a></h3>
<ul>
<li><strong>Low Confidence</strong>: Check confidence scores</li>
<li><strong>Context Missing</strong>: LLM may need more context</li>
<li><strong>Tuning Needed</strong>: Adjust confidence thresholds</li>
</ul>
<h3 id="missed-detections"><a class="header" href="#missed-detections">Missed Detections</a></h3>
<ul>
<li><strong>Enable LLM</strong>: Rule-based may miss subtle changes</li>
<li><strong>Lower Threshold</strong>: May be filtering valid detections</li>
<li><strong>Review Manually</strong>: Some changes need human review</li>
</ul>
<h2 id="related-documentation-29"><a class="header" href="#related-documentation-29">Related Documentation</a></h2>
<ul>
<li><a href="user-guide/contracts/ai-contract-diff.html">AI Contract Diff</a> - Contract comparison</li>
<li><a href="user-guide/contracts/api-change-forecasting.html">API Change Forecasting</a> - Predicting changes</li>
<li><a href="user-guide/contracts/../../docs/DRIFT_BUDGETS.html">Drift Budgets</a> - Budget management</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="contract-threat-modeling"><a class="header" href="#contract-threat-modeling">Contract Threat Modeling</a></h1>
<p><strong>Pillars:</strong> [Contracts]</p>
<p>Contract Threat Modeling is a new category: <strong>contract security posture</strong>. MockForge becomes not only a contract tool, but an <strong>API safety platform</strong>.</p>
<h2 id="overview-36"><a class="header" href="#overview-36">Overview</a></h2>
<p>Beyond structural validation, Contract Threat Modeling analyzes APIs for security risks:</p>
<ul>
<li><strong>PII Exposure</strong>: APIs returning too much personally identifiable information</li>
<li><strong>DoS Risk</strong>: Unbounded arrays and missing pagination</li>
<li><strong>Error Leakage</strong>: Stack traces and internal details in error responses</li>
<li><strong>Schema Design Issues</strong>: Excessive optional fields, inconsistent patterns</li>
</ul>
<h2 id="threat-categories"><a class="header" href="#threat-categories">Threat Categories</a></h2>
<h3 id="pii-exposure"><a class="header" href="#pii-exposure">PII Exposure</a></h3>
<p>Detects when APIs return sensitive personal information:</p>
<p><strong>Example:</strong></p>
<pre><code class="language-json">{
  "user": {
    "id": "123",
    "email": "user@example.com",
    "ssn": "123-45-6789",  // ‚ö†Ô∏è PII exposure
    "credit_card": "****-****-****-1234"  // ‚ö†Ô∏è PII exposure
  }
}
</code></pre>
<p><strong>Detection:</strong> Fields like <code>ssn</code>, <code>credit_card</code>, <code>passport_number</code> are flagged.</p>
<p><strong>Remediation:</strong> Mask or remove PII from responses.</p>
<h3 id="dos-risk-unbounded-arrays"><a class="header" href="#dos-risk-unbounded-arrays">DoS Risk (Unbounded Arrays)</a></h3>
<p>Detects arrays without size limits:</p>
<p><strong>Example:</strong></p>
<pre><code class="language-json">{
  "users": {
    "type": "array",
    "items": {...}
    // ‚ö†Ô∏è No maxItems constraint
  }
}
</code></pre>
<p><strong>Risk:</strong> Attackers can request unbounded arrays, causing DoS.</p>
<p><strong>Remediation:</strong> Add <code>maxItems</code> constraint:</p>
<pre><code class="language-json">{
  "users": {
    "type": "array",
    "items": {...},
    "maxItems": 100  // ‚úÖ Bounded
  }
}
</code></pre>
<h3 id="error-leakage"><a class="header" href="#error-leakage">Error Leakage</a></h3>
<p>Detects stack traces and internal details in error responses:</p>
<p><strong>Example:</strong></p>
<pre><code class="language-json">{
  "error": {
    "message": "Internal server error",
    "stack_trace": "at com.example.Service.handle()...",  // ‚ö†Ô∏è Leakage
    "internal_id": "uuid-123",  // ‚ö†Ô∏è Internal details
    "database_query": "SELECT * FROM users..."  // ‚ö†Ô∏è SQL leak
  }
}
</code></pre>
<p><strong>Risk:</strong> Exposes internal implementation details.</p>
<p><strong>Remediation:</strong> Sanitize error messages:</p>
<pre><code class="language-json">{
  "error": {
    "message": "An error occurred",
    "code": "ERROR_CODE"  // ‚úÖ Sanitized
  }
}
</code></pre>
<h3 id="schema-design-issues"><a class="header" href="#schema-design-issues">Schema Design Issues</a></h3>
<p>Detects problematic schema patterns:</p>
<p><strong>Excessive Optional Fields:</strong></p>
<pre><code class="language-json">{
  "user": {
    "id": "required",
    "name": "optional",  // ‚ö†Ô∏è Too many optional fields
    "email": "optional",
    "phone": "optional",
    "address": "optional",
    // ... 20 more optional fields
  }
}
</code></pre>
<p><strong>Risk:</strong> Inconsistent responses, unclear contracts.</p>
<p><strong>Remediation:</strong> Split into separate schemas or make more fields required.</p>
<h2 id="usage-7"><a class="header" href="#usage-7">Usage</a></h2>
<h3 id="cli-commands-10"><a class="header" href="#cli-commands-10">CLI Commands</a></h3>
<pre><code class="language-bash"># Analyze contract for threats
mockforge governance threat-model analyze

# Analyze specific service
mockforge governance threat-model analyze --service payments

# Analyze specific endpoint
mockforge governance threat-model analyze --endpoint /api/users/{id}

# Get threat assessments
mockforge governance threat-model assessments

# Get remediation suggestions
mockforge governance threat-model remediations &lt;assessment-id&gt;
</code></pre>
<h3 id="api-usage-3"><a class="header" href="#api-usage-3">API Usage</a></h3>
<pre><code class="language-bash"># Analyze contract
POST /api/v1/threats/analyze
{
  "spec": {...},
  "workspace_id": "workspace-123"
}

# Get assessments
GET /api/v1/threats/assessments?workspace_id=workspace-123

# Get remediation
GET /api/v1/threats/assessments/{id}/remediations
</code></pre>
<h2 id="threat-assessment-results"><a class="header" href="#threat-assessment-results">Threat Assessment Results</a></h2>
<h3 id="example-assessment"><a class="header" href="#example-assessment">Example Assessment</a></h3>
<pre><code class="language-json">{
  "workspace_id": "workspace-123",
  "service_name": "payments",
  "endpoint": "/api/payments",
  "threat_level": "high",
  "threat_score": 0.75,
  "threat_categories": ["pii_exposure", "dos_risk"],
  "findings": [
    {
      "finding_type": "PiiExposure",
      "severity": "high",
      "field_path": "body.card_number",
      "description": "Credit card number exposed in response",
      "confidence": 0.9
    },
    {
      "finding_type": "UnboundedArrays",
      "severity": "high",
      "field_path": "body.transactions",
      "description": "Transactions array has no maxItems constraint",
      "confidence": 1.0
    }
  ],
  "remediation_suggestions": [
    {
      "finding_id": "finding_body.card_number",
      "suggestion": "Mask or remove card_number from response",
      "code_example": {
        "before": "\"card_number\": \"1234-5678-9012-3456\"",
        "after": "\"card_number\": \"****-****-****-3456\""
      },
      "confidence": 0.8,
      "priority": "high"
    }
  ]
}
</code></pre>
<h3 id="threat-levels"><a class="header" href="#threat-levels">Threat Levels</a></h3>
<ul>
<li><strong>Low</strong>: Minor issues, acceptable risks</li>
<li><strong>Medium</strong>: Issues that should be addressed</li>
<li><strong>High</strong>: Significant security risks</li>
<li><strong>Critical</strong>: Immediate security concerns</li>
</ul>
<h3 id="threat-score"><a class="header" href="#threat-score">Threat Score</a></h3>
<p>0.0-1.0 score indicating overall threat level:</p>
<ul>
<li><strong>0.0-0.3</strong>: Low risk</li>
<li><strong>0.3-0.6</strong>: Medium risk</li>
<li><strong>0.6-0.8</strong>: High risk</li>
<li><strong>0.8-1.0</strong>: Critical risk</li>
</ul>
<h2 id="ai-powered-remediation"><a class="header" href="#ai-powered-remediation">AI-Powered Remediation</a></h2>
<p>MockForge provides AI-generated remediation suggestions:</p>
<h3 id="example-remediation"><a class="header" href="#example-remediation">Example Remediation</a></h3>
<p><strong>Finding:</strong> Unbounded array detected</p>
<p><strong>Remediation:</strong></p>
<pre><code class="language-json">{
  "suggestion": "Add maxItems constraint to array schema",
  "code_example": {
    "type": "array",
    "items": {...},
    "maxItems": 100
  },
  "confidence": 0.9,
  "priority": "high"
}
</code></pre>
<h2 id="configuration-26"><a class="header" href="#configuration-26">Configuration</a></h2>
<h3 id="enable-threat-modeling"><a class="header" href="#enable-threat-modeling">Enable Threat Modeling</a></h3>
<pre><code class="language-yaml"># mockforge.yaml
contract_drift:
  threat_modeling:
    enabled: true
    pii_detection: true
    dos_analysis: true
    error_analysis: true
    schema_analysis: true
    ai_remediation: true  # Enable AI-powered suggestions
</code></pre>
<h3 id="thresholds"><a class="header" href="#thresholds">Thresholds</a></h3>
<pre><code class="language-yaml">contract_drift:
  threat_modeling:
    enabled: true
    thresholds:
      high_threat_score: 0.7
      critical_threat_score: 0.9
      max_array_size: 1000  # Default maxItems recommendation
</code></pre>
<h2 id="integration-with-drift-budgets-2"><a class="header" href="#integration-with-drift-budgets-2">Integration with Drift Budgets</a></h2>
<p>Threat assessments can trigger drift budget violations:</p>
<pre><code class="language-yaml">contract_drift:
  drift_budget:
    max_breaking_changes: 2
    threat_modeling:
      enabled: true
      # High-threat findings count toward budget
</code></pre>
<h2 id="webhooks-2"><a class="header" href="#webhooks-2">Webhooks</a></h2>
<p>Threat assessments can trigger webhooks:</p>
<pre><code class="language-yaml">webhooks:
  - url: https://slack.com/hooks/...
    events:
      - threat_assessment.completed
      - threat_remediation.suggested
      - threat_critical_detected
</code></pre>
<h2 id="real-world-examples-4"><a class="header" href="#real-world-examples-4">Real-World Examples</a></h2>
<h3 id="example-1-pii-exposure"><a class="header" href="#example-1-pii-exposure">Example 1: PII Exposure</a></h3>
<p><strong>Finding:</strong></p>
<pre><code class="language-json">{
  "user": {
    "ssn": "123-45-6789"  // ‚ö†Ô∏è PII
  }
}
</code></pre>
<p><strong>Remediation:</strong></p>
<ul>
<li>Remove SSN from response</li>
<li>Or mask: <code>"ssn": "***-**-6789"</code></li>
<li>Or return only last 4: <code>"ssn_last4": "6789"</code></li>
</ul>
<h3 id="example-2-dos-risk"><a class="header" href="#example-2-dos-risk">Example 2: DoS Risk</a></h3>
<p><strong>Finding:</strong></p>
<pre><code class="language-json">{
  "products": {
    "type": "array",
    "items": {...}
    // No maxItems
  }
}
</code></pre>
<p><strong>Remediation:</strong></p>
<pre><code class="language-json">{
  "products": {
    "type": "array",
    "items": {...},
    "maxItems": 100  // ‚úÖ Bounded
  }
}
</code></pre>
<h3 id="example-3-error-leakage"><a class="header" href="#example-3-error-leakage">Example 3: Error Leakage</a></h3>
<p><strong>Finding:</strong></p>
<pre><code class="language-json">{
  "error": {
    "stack_trace": "at com.example..."  // ‚ö†Ô∏è Leakage
  }
}
</code></pre>
<p><strong>Remediation:</strong></p>
<pre><code class="language-json">{
  "error": {
    "message": "An error occurred",
    "code": "INTERNAL_ERROR"  // ‚úÖ Sanitized
  }
}
</code></pre>
<h2 id="best-practices-46"><a class="header" href="#best-practices-46">Best Practices</a></h2>
<ol>
<li><strong>Run Regularly</strong>: Assess contracts in CI/CD pipeline</li>
<li><strong>Fix High Priority</strong>: Address high/critical findings immediately</li>
<li><strong>Review AI Suggestions</strong>: AI suggestions are helpful but review manually</li>
<li><strong>Document Exceptions</strong>: Document why certain risks are acceptable</li>
<li><strong>Track Over Time</strong>: Monitor threat scores over time</li>
</ol>
<h2 id="troubleshooting-54"><a class="header" href="#troubleshooting-54">Troubleshooting</a></h2>
<h3 id="false-positives-1"><a class="header" href="#false-positives-1">False Positives</a></h3>
<ul>
<li><strong>Field Names</strong>: Some field names may trigger false PII detection</li>
<li><strong>Context Missing</strong>: AI may need more context</li>
<li><strong>Tuning Needed</strong>: Adjust detection thresholds</li>
</ul>
<h3 id="missed-threats"><a class="header" href="#missed-threats">Missed Threats</a></h3>
<ul>
<li><strong>Enable All Analyzers</strong>: Ensure all analyzers are enabled</li>
<li><strong>Review Manually</strong>: Some threats need human review</li>
<li><strong>Update Patterns</strong>: Keep PII patterns updated</li>
</ul>
<h2 id="related-documentation-30"><a class="header" href="#related-documentation-30">Related Documentation</a></h2>
<ul>
<li><a href="user-guide/contracts/api-change-forecasting.html">API Change Forecasting</a> - Predicting changes</li>
<li><a href="user-guide/contracts/semantic-drift.html">Semantic Drift</a> - Semantic analysis</li>
<li><a href="user-guide/contracts/../../docs/DRIFT_BUDGETS.html">Drift Budgets</a> - Budget management</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="zero-config-mode-runtime-daemon-1"><a class="header" href="#zero-config-mode-runtime-daemon-1">Zero-Config Mode (Runtime Daemon)</a></h1>
<p><strong>Pillars:</strong> [DevX]</p>
<p>Zero-Config Mode provides the ‚Äúinvisible mock server‚Äù experience. When you hit an endpoint that doesn‚Äôt exist, MockForge automatically creates a mock, generates types, creates client stubs, and sets up scenarios‚Äîall without manual configuration.</p>
<h2 id="overview-37"><a class="header" href="#overview-37">Overview</a></h2>
<p>The Runtime Daemon is a background process that:</p>
<ul>
<li><strong>Detects</strong> when you hit an endpoint that doesn‚Äôt exist (404)</li>
<li><strong>Automatically creates</strong> a mock endpoint</li>
<li><strong>Generates types</strong> (TypeScript, JSON Schema)</li>
<li><strong>Generates client stubs</strong> (React, Vue, etc.)</li>
<li><strong>Updates OpenAPI schema</strong></li>
<li><strong>Creates example responses</strong></li>
<li><strong>Sets up scenarios</strong></li>
</ul>
<p>This is ‚Äúmock server in your shadow‚Äù‚Äîan AI-assisted backend-on-demand.</p>
<h2 id="quick-start-24"><a class="header" href="#quick-start-24">Quick Start</a></h2>
<h3 id="enable-zero-config-mode"><a class="header" href="#enable-zero-config-mode">Enable Zero-Config Mode</a></h3>
<pre><code class="language-bash"># Start MockForge with runtime daemon
mockforge serve --runtime-daemon

# Or via environment variable
MOCKFORGE_RUNTIME_DAEMON_ENABLED=true mockforge serve
</code></pre>
<h3 id="configuration-27"><a class="header" href="#configuration-27">Configuration</a></h3>
<pre><code class="language-yaml"># mockforge.yaml
runtime_daemon:
  enabled: true
  auto_create_on_404: true
  ai_generation: true  # Use AI to generate intelligent responses
  generate_types: true  # Generate TypeScript/JSON Schema
  generate_client_stubs: true  # Generate client code
  update_openapi: true  # Update OpenAPI schema
  create_scenario: true  # Create scenarios automatically
  exclude_patterns:
    - "/health"
    - "/metrics"
    - "/__mockforge/*"
</code></pre>
<h2 id="how-it-works-8"><a class="header" href="#how-it-works-8">How It Works</a></h2>
<h3 id="1-detection"><a class="header" href="#1-detection">1. Detection</a></h3>
<p>When a request hits a non-existent endpoint (404), the daemon detects it:</p>
<pre><code>GET /api/users/123 ‚Üí 404 Not Found
‚Üí Runtime Daemon detects 404
‚Üí Analyzes request (method, path, headers, body)
</code></pre>
<h3 id="2-auto-generation"><a class="header" href="#2-auto-generation">2. Auto-Generation</a></h3>
<p>The daemon automatically:</p>
<ol>
<li>
<p><strong>Creates Mock Endpoint</strong></p>
<ul>
<li>Analyzes request to infer response structure</li>
<li>Uses AI to generate intelligent response</li>
<li>Sets appropriate status code</li>
</ul>
</li>
<li>
<p><strong>Generates Types</strong> (if enabled)</p>
<ul>
<li>TypeScript types</li>
<li>JSON Schema</li>
<li>Saved to <code>generated/types/</code></li>
</ul>
</li>
<li>
<p><strong>Generates Client Stubs</strong> (if enabled)</p>
<ul>
<li>React hooks</li>
<li>Vue composables</li>
<li>Angular services</li>
<li>Saved to <code>generated/clients/</code></li>
</ul>
</li>
<li>
<p><strong>Updates OpenAPI Schema</strong> (if enabled)</p>
<ul>
<li>Adds endpoint to OpenAPI spec</li>
<li>Infers request/response schemas</li>
<li>Updates <code>openapi.json</code></li>
</ul>
</li>
<li>
<p><strong>Creates Scenario</strong> (if enabled)</p>
<ul>
<li>Basic scenario for the endpoint</li>
<li>Includes example request/response</li>
<li>Saved to <code>scenarios/</code></li>
</ul>
</li>
</ol>
<h3 id="3-response"><a class="header" href="#3-response">3. Response</a></h3>
<p>The next request to the same endpoint gets the auto-generated mock:</p>
<pre><code>GET /api/users/123 ‚Üí 200 OK
{
  "id": "123",
  "name": "John Doe",
  "email": "john@example.com"
}
</code></pre>
<h2 id="configuration-options-2"><a class="header" href="#configuration-options-2">Configuration Options</a></h2>
<h3 id="auto-create-on-404"><a class="header" href="#auto-create-on-404">Auto-Create on 404</a></h3>
<pre><code class="language-yaml">runtime_daemon:
  auto_create_on_404: true  # Create mocks automatically
</code></pre>
<h3 id="ai-generation"><a class="header" href="#ai-generation">AI Generation</a></h3>
<pre><code class="language-yaml">runtime_daemon:
  ai_generation: true  # Use AI for intelligent responses
</code></pre>
<p>When enabled, AI generates realistic responses based on:</p>
<ul>
<li>Endpoint path patterns</li>
<li>Request body structure</li>
<li>Domain context</li>
<li>Existing mocks</li>
</ul>
<h3 id="type-generation"><a class="header" href="#type-generation">Type Generation</a></h3>
<pre><code class="language-yaml">runtime_daemon:
  generate_types: true
  types_output_dir: "./generated/types"
</code></pre>
<p>Generates:</p>
<ul>
<li>TypeScript types</li>
<li>JSON Schema</li>
<li>Go types</li>
<li>Rust types</li>
</ul>
<h3 id="client-stub-generation"><a class="header" href="#client-stub-generation">Client Stub Generation</a></h3>
<pre><code class="language-yaml">runtime_daemon:
  generate_client_stubs: true
  clients_output_dir: "./generated/clients"
  client_frameworks:
    - react
    - vue
    - angular
</code></pre>
<h3 id="openapi-updates"><a class="header" href="#openapi-updates">OpenAPI Updates</a></h3>
<pre><code class="language-yaml">runtime_daemon:
  update_openapi: true
  openapi_path: "./openapi.json"
</code></pre>
<p>Automatically updates OpenAPI spec with new endpoints.</p>
<h3 id="scenario-creation"><a class="header" href="#scenario-creation">Scenario Creation</a></h3>
<pre><code class="language-yaml">runtime_daemon:
  create_scenario: true
  scenarios_output_dir: "./scenarios"
</code></pre>
<p>Creates basic scenarios for auto-generated endpoints.</p>
<h2 id="example-workflow"><a class="header" href="#example-workflow">Example Workflow</a></h2>
<h3 id="1-start-development"><a class="header" href="#1-start-development">1. Start Development</a></h3>
<pre><code class="language-bash"># Start MockForge with runtime daemon
mockforge serve --runtime-daemon
</code></pre>
<h3 id="2-make-request"><a class="header" href="#2-make-request">2. Make Request</a></h3>
<pre><code class="language-bash"># Frontend makes request to non-existent endpoint
curl http://localhost:3000/api/products/123
# ‚Üí 404 Not Found
</code></pre>
<h3 id="3-auto-generation"><a class="header" href="#3-auto-generation">3. Auto-Generation</a></h3>
<p>The daemon automatically:</p>
<ul>
<li>Creates mock for <code>/api/products/{id}</code></li>
<li>Generates TypeScript types</li>
<li>Creates React hook</li>
<li>Updates OpenAPI spec</li>
<li>Creates scenario</li>
</ul>
<h3 id="4-use-generated-code"><a class="header" href="#4-use-generated-code">4. Use Generated Code</a></h3>
<pre><code class="language-typescript">// Generated React hook
import { useProduct } from './generated/clients/react';

function ProductPage({ id }) {
  const { data, loading } = useProduct(id);
  // ...
}
</code></pre>
<h2 id="excluding-patterns"><a class="header" href="#excluding-patterns">Excluding Patterns</a></h2>
<p>Exclude certain paths from auto-generation:</p>
<pre><code class="language-yaml">runtime_daemon:
  exclude_patterns:
    - "/health"
    - "/metrics"
    - "/__mockforge/*"
    - "/api/internal/*"
</code></pre>
<h2 id="workspace-integration"><a class="header" href="#workspace-integration">Workspace Integration</a></h2>
<p>The daemon saves generated artifacts to your workspace:</p>
<pre><code>workspace/
‚îú‚îÄ‚îÄ mocks/
‚îÇ   ‚îî‚îÄ‚îÄ auto-generated/
‚îÇ       ‚îî‚îÄ‚îÄ api-products-{id}.yaml
‚îú‚îÄ‚îÄ generated/
‚îÇ   ‚îú‚îÄ‚îÄ types/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Product.ts
‚îÇ   ‚îî‚îÄ‚îÄ clients/
‚îÇ       ‚îî‚îÄ‚îÄ react/
‚îÇ           ‚îî‚îÄ‚îÄ useProduct.ts
‚îú‚îÄ‚îÄ scenarios/
‚îÇ   ‚îî‚îÄ‚îÄ auto-products-{id}.yaml
‚îî‚îÄ‚îÄ openapi.json  # Updated automatically
</code></pre>
<h2 id="ai-powered-generation"><a class="header" href="#ai-powered-generation">AI-Powered Generation</a></h2>
<p>When AI generation is enabled, the daemon uses AI to create intelligent responses:</p>
<h3 id="request-analysis"><a class="header" href="#request-analysis">Request Analysis</a></h3>
<pre><code class="language-bash">POST /api/orders
{
  "product_id": "123",
  "quantity": 2
}
</code></pre>
<h3 id="ai-generated-response"><a class="header" href="#ai-generated-response">AI-Generated Response</a></h3>
<pre><code class="language-json">{
  "id": "order-456",
  "product_id": "123",
  "quantity": 2,
  "status": "pending",
  "total": 99.98,
  "created_at": "2025-01-27T10:00:00Z"
}
</code></pre>
<p>The AI infers:</p>
<ul>
<li>Order structure from request</li>
<li>Realistic IDs and timestamps</li>
<li>Calculated fields (total)</li>
<li>Appropriate status values</li>
</ul>
<h2 id="best-practices-47"><a class="header" href="#best-practices-47">Best Practices</a></h2>
<ol>
<li><strong>Start with AI Generation</strong>: Let AI create intelligent responses</li>
<li><strong>Review Generated Mocks</strong>: Check auto-generated mocks for accuracy</li>
<li><strong>Refine Over Time</strong>: Update mocks as you learn more about the API</li>
<li><strong>Version Control</strong>: Commit generated artifacts to Git</li>
<li><strong>Exclude Internal Endpoints</strong>: Don‚Äôt auto-generate for internal APIs</li>
</ol>
<h2 id="troubleshooting-55"><a class="header" href="#troubleshooting-55">Troubleshooting</a></h2>
<h3 id="mocks-not-created"><a class="header" href="#mocks-not-created">Mocks Not Created</a></h3>
<ul>
<li>Check <code>auto_create_on_404</code> is enabled</li>
<li>Verify endpoint isn‚Äôt in <code>exclude_patterns</code></li>
<li>Check daemon is running: <code>mockforge serve --runtime-daemon</code></li>
</ul>
<h3 id="generated-code-issues"><a class="header" href="#generated-code-issues">Generated Code Issues</a></h3>
<ul>
<li>Review generated types for accuracy</li>
<li>Update OpenAPI spec manually if needed</li>
<li>Regenerate: <code>mockforge generate --from-openapi openapi.json</code></li>
</ul>
<h3 id="ai-generation-quality"><a class="header" href="#ai-generation-quality">AI Generation Quality</a></h3>
<ul>
<li>Provide more context in existing mocks</li>
<li>Use domain-specific reality profiles</li>
<li>Adjust AI model/temperature settings</li>
</ul>
<h2 id="related-documentation-31"><a class="header" href="#related-documentation-31">Related Documentation</a></h2>
<ul>
<li><a href="user-guide/devx/forgeconnect-sdk.html">ForgeConnect SDK</a> - Browser integration</li>
<li><a href="user-guide/devx/devtools-integration.html">DevTools Integration</a> - Browser DevTools</li>
<li><a href="user-guide/devx/scenario-marketplace.html">Scenario Marketplace</a> - Sharing scenarios</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="mock-oriented-development-mod-1"><a class="header" href="#mock-oriented-development-mod-1">Mock-Oriented Development (MOD)</a></h1>
<p><strong>Pillars:</strong> [DevX][Reality][Contracts]</p>
<p>Mock-Oriented Development (MOD) is a software development methodology that places mocks at the center of the development workflow. Just as Test-Driven Development (TDD) revolutionized testing, and Infrastructure as Code (IaC) transformed DevOps, MOD transforms how we build and integrate APIs.</p>
<h2 id="what-is-mod"><a class="header" href="#what-is-mod">What is MOD?</a></h2>
<p>MOD is not just about using mocks‚Äîit‚Äôs about <strong>thinking mock-first</strong>, <strong>designing with mocks</strong>, and <strong>building confidence through realistic simulation</strong>.</p>
<h3 id="the-mod-manifesto"><a class="header" href="#the-mod-manifesto">The MOD Manifesto</a></h3>
<ol>
<li><strong>Mocks are not afterthoughts</strong> ‚Äî They are first-class citizens in your development process</li>
<li><strong>Design with mocks</strong> ‚Äî Use mocks to explore API designs before implementation</li>
<li><strong>Reality matters</strong> ‚Äî Mocks should feel indistinguishable from real backends</li>
<li><strong>Contracts are sacred</strong> ‚Äî Mocks enforce and validate API contracts</li>
<li><strong>Iterate fearlessly</strong> ‚Äî Mocks enable rapid iteration without breaking dependencies</li>
<li><strong>Collaborate through mocks</strong> ‚Äî Teams work in parallel using shared mock definitions</li>
</ol>
<h2 id="why-mod"><a class="header" href="#why-mod">Why MOD?</a></h2>
<h3 id="the-problem-mod-solves"><a class="header" href="#the-problem-mod-solves">The Problem MOD Solves</a></h3>
<p>Traditional development workflows create bottlenecks:</p>
<ul>
<li><strong>Frontend teams</strong> wait for backend APIs to be ready</li>
<li><strong>Backend teams</strong> build APIs in isolation without early feedback</li>
<li><strong>Integration</strong> happens late, revealing design flaws when changes are expensive</li>
<li><strong>Testing</strong> relies on fragile, hard-to-maintain fixtures</li>
<li><strong>Documentation</strong> is outdated or missing</li>
</ul>
<h3 id="the-mod-solution"><a class="header" href="#the-mod-solution">The MOD Solution</a></h3>
<p>MOD flips the script:</p>
<ul>
<li><strong>Frontend teams</strong> start immediately with realistic mocks</li>
<li><strong>Backend teams</strong> validate designs through mock-driven API reviews</li>
<li><strong>Integration</strong> happens continuously through shared mock contracts</li>
<li><strong>Testing</strong> uses living, evolving mock scenarios</li>
<li><strong>Documentation</strong> is generated from mock definitions</li>
</ul>
<h2 id="mod-vs-other-methodologies"><a class="header" href="#mod-vs-other-methodologies">MOD vs. Other Methodologies</a></h2>
<h3 id="mod-vs-tdd-test-driven-development"><a class="header" href="#mod-vs-tdd-test-driven-development">MOD vs. TDD (Test-Driven Development)</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Aspect</th><th>TDD</th><th>MOD</th></tr></thead><tbody>
<tr><td><strong>Focus</strong></td><td>Tests drive implementation</td><td>Mocks drive design and integration</td></tr>
<tr><td><strong>When</strong></td><td>During implementation</td><td>Before and during implementation</td></tr>
<tr><td><strong>Scope</strong></td><td>Unit/component level</td><td>System/integration level</td></tr>
<tr><td><strong>Artifact</strong></td><td>Test code</td><td>Mock definitions + contracts</td></tr>
</tbody></table>
</div>
<p><strong>MOD complements TDD</strong>: Use TDD for implementation, MOD for integration.</p>
<h3 id="mod-vs-bdd-behavior-driven-development"><a class="header" href="#mod-vs-bdd-behavior-driven-development">MOD vs. BDD (Behavior-Driven Development)</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Aspect</th><th>BDD</th><th>MOD</th></tr></thead><tbody>
<tr><td><strong>Focus</strong></td><td>Behavior specifications</td><td>API contracts and interactions</td></tr>
<tr><td><strong>Language</strong></td><td>Natural language (Gherkin)</td><td>API schemas (OpenAPI, gRPC)</td></tr>
<tr><td><strong>Scope</strong></td><td>Feature behavior</td><td>System integration</td></tr>
<tr><td><strong>Artifact</strong></td><td>Feature files</td><td>Mock scenarios</td></tr>
</tbody></table>
</div>
<p><strong>MOD complements BDD</strong>: Use BDD for features, MOD for APIs.</p>
<h3 id="mod-vs-iac-infrastructure-as-code"><a class="header" href="#mod-vs-iac-infrastructure-as-code">MOD vs. IaC (Infrastructure as Code)</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Aspect</th><th>IaC</th><th>MOD</th></tr></thead><tbody>
<tr><td><strong>Focus</strong></td><td>Infrastructure provisioning</td><td>API simulation</td></tr>
<tr><td><strong>Domain</strong></td><td>DevOps/Infrastructure</td><td>Development/Integration</td></tr>
<tr><td><strong>Artifact</strong></td><td>Terraform/CloudFormation</td><td>Mock configurations</td></tr>
<tr><td><strong>Lifecycle</strong></td><td>Deploy/manage infrastructure</td><td>Simulate/validate APIs</td></tr>
</tbody></table>
</div>
<p><strong>MOD is like IaC for APIs</strong>: Version-controlled, reproducible, declarative.</p>
<h2 id="mod-principles"><a class="header" href="#mod-principles">MOD Principles</a></h2>
<h3 id="1-mock-first-design"><a class="header" href="#1-mock-first-design">1. Mock-First Design</a></h3>
<p><strong>Start with mocks, not implementations.</strong></p>
<p>Before writing backend code, create mock APIs that define:</p>
<ul>
<li>Request/response schemas</li>
<li>Error scenarios</li>
<li>Edge cases</li>
<li>Performance characteristics</li>
</ul>
<p><strong>Benefits:</strong></p>
<ul>
<li>Early validation of API design</li>
<li>Frontend can start immediately</li>
<li>Clear contract definition</li>
<li>Stakeholder feedback before implementation</li>
</ul>
<h3 id="2-contract-driven-development"><a class="header" href="#2-contract-driven-development">2. Contract-Driven Development</a></h3>
<p><strong>Contracts are the source of truth.</strong></p>
<p>Define API contracts (OpenAPI, gRPC, GraphQL) first:</p>
<ul>
<li>Generate mocks from contracts</li>
<li>Validate implementations against contracts</li>
<li>Detect contract drift automatically</li>
<li>Version contracts explicitly</li>
</ul>
<p><strong>Benefits:</strong></p>
<ul>
<li>Single source of truth</li>
<li>Automatic validation</li>
<li>Breaking change detection</li>
<li>Clear API evolution</li>
</ul>
<h3 id="3-reality-progression"><a class="header" href="#3-reality-progression">3. Reality Progression</a></h3>
<p><strong>Gradually increase mock realism.</strong></p>
<p>Start with simple mocks, then add:</p>
<ul>
<li>Realistic data generation</li>
<li>Behavioral patterns</li>
<li>Error scenarios</li>
<li>Performance characteristics</li>
</ul>
<p><strong>Benefits:</strong></p>
<ul>
<li>Early development with simple mocks</li>
<li>Gradual complexity as needed</li>
<li>Production-like testing when ready</li>
<li>Smooth transition to real backend</li>
</ul>
<h3 id="4-scenario-driven-testing"><a class="header" href="#4-scenario-driven-testing">4. Scenario-Driven Testing</a></h3>
<p><strong>Test with scenarios, not fixtures.</strong></p>
<p>Use scenarios that define:</p>
<ul>
<li>Multi-step workflows</li>
<li>State transitions</li>
<li>Error paths</li>
<li>Edge cases</li>
</ul>
<p><strong>Benefits:</strong></p>
<ul>
<li>Realistic test flows</li>
<li>Reusable scenarios</li>
<li>Easy scenario updates</li>
<li>Living test documentation</li>
</ul>
<h3 id="5-continuous-integration"><a class="header" href="#5-continuous-integration">5. Continuous Integration</a></h3>
<p><strong>Mocks are part of CI/CD.</strong></p>
<p>Integrate mocks into:</p>
<ul>
<li>Development workflows</li>
<li>CI/CD pipelines</li>
<li>Testing strategies</li>
<li>Documentation generation</li>
</ul>
<p><strong>Benefits:</strong></p>
<ul>
<li>Automated validation</li>
<li>Early error detection</li>
<li>Consistent environments</li>
<li>Up-to-date documentation</li>
</ul>
<h2 id="mod-workflow"><a class="header" href="#mod-workflow">MOD Workflow</a></h2>
<h3 id="1-design-phase"><a class="header" href="#1-design-phase">1. Design Phase</a></h3>
<pre><code>Define Contract ‚Üí Create Mock ‚Üí Review with Team ‚Üí Iterate
</code></pre>
<ol>
<li>Define API contract (OpenAPI, gRPC, etc.)</li>
<li>Generate initial mock from contract</li>
<li>Review mock responses with team</li>
<li>Iterate on design based on feedback</li>
</ol>
<h3 id="2-development-phase"><a class="header" href="#2-development-phase">2. Development Phase</a></h3>
<pre><code>Frontend: Use Mock ‚Üí Backend: Implement Contract ‚Üí Integration: Validate
</code></pre>
<ol>
<li>Frontend team uses mock for development</li>
<li>Backend team implements to match contract</li>
<li>Integration validates implementation against mock</li>
</ol>
<h3 id="3-testing-phase"><a class="header" href="#3-testing-phase">3. Testing Phase</a></h3>
<pre><code>Unit Tests ‚Üí Integration Tests ‚Üí E2E Tests (all with mocks)
</code></pre>
<ol>
<li>Unit tests use mock responses</li>
<li>Integration tests use mock services</li>
<li>E2E tests use mock backends</li>
</ol>
<h3 id="4-review-phase"><a class="header" href="#4-review-phase">4. Review Phase</a></h3>
<pre><code>PR Review ‚Üí Contract Validation ‚Üí Mock Comparison ‚Üí Approval
</code></pre>
<ol>
<li>PR includes contract changes</li>
<li>Validate contract changes</li>
<li>Compare mock vs. implementation</li>
<li>Approve if contract matches</li>
</ol>
<h2 id="getting-started-with-mod"><a class="header" href="#getting-started-with-mod">Getting Started with MOD</a></h2>
<h3 id="1-initialize-mod-project"><a class="header" href="#1-initialize-mod-project">1. Initialize MOD Project</a></h3>
<pre><code class="language-bash"># Initialize a new MOD project
mockforge mod init my-api-project

# This creates:
# - mockforge.yaml (MOD configuration)
# - contracts/ (API contract definitions)
# - mocks/ (Mock definitions)
# - scenarios/ (Test scenarios)
# - personas/ (Persona definitions)
</code></pre>
<h3 id="2-define-your-first-contract"><a class="header" href="#2-define-your-first-contract">2. Define Your First Contract</a></h3>
<pre><code class="language-yaml"># contracts/users-api.yaml
openapi: 3.0.0
info:
  title: Users API
  version: 1.0.0
paths:
  /api/users/{id}:
    get:
      parameters:
        - name: id
          in: path
          required: true
          schema:
            type: string
      responses:
        '200':
          description: User details
          content:
            application/json:
              schema:
                type: object
                properties:
                  id:
                    type: string
                  name:
                    type: string
                  email:
                    type: string
</code></pre>
<h3 id="3-generate-mock-from-contract"><a class="header" href="#3-generate-mock-from-contract">3. Generate Mock from Contract</a></h3>
<pre><code class="language-bash"># Generate mock from OpenAPI contract
mockforge generate --from-openapi contracts/users-api.yaml --output mocks/
</code></pre>
<h3 id="4-use-mock-in-development"><a class="header" href="#4-use-mock-in-development">4. Use Mock in Development</a></h3>
<pre><code class="language-typescript">// Frontend code uses mock
import { useUser } from './generated/clients/react';

function UserProfile({ userId }) {
  const { data, loading } = useUser(userId);
  // ...
}
</code></pre>
<h2 id="mod-folder-structures"><a class="header" href="#mod-folder-structures">MOD Folder Structures</a></h2>
<h3 id="solo-developer"><a class="header" href="#solo-developer">Solo Developer</a></h3>
<pre><code>my-project/
‚îú‚îÄ‚îÄ mockforge.yaml
‚îú‚îÄ‚îÄ contracts/
‚îÇ   ‚îú‚îÄ‚îÄ api.yaml
‚îÇ   ‚îî‚îÄ‚îÄ schemas/
‚îú‚îÄ‚îÄ mocks/
‚îÇ   ‚îî‚îÄ‚îÄ responses/
‚îú‚îÄ‚îÄ scenarios/
‚îÇ   ‚îî‚îÄ‚îÄ user-journeys.yaml
‚îú‚îÄ‚îÄ personas/
‚îÇ   ‚îî‚îÄ‚îÄ default.yaml
‚îî‚îÄ‚îÄ README.md
</code></pre>
<h3 id="small-team-2-5-developers"><a class="header" href="#small-team-2-5-developers">Small Team (2-5 developers)</a></h3>
<pre><code>my-api/
‚îú‚îÄ‚îÄ mockforge.yaml
‚îú‚îÄ‚îÄ contracts/
‚îÇ   ‚îú‚îÄ‚îÄ v1/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ openapi.yaml
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ schemas/
‚îÇ   ‚îî‚îÄ‚îÄ v2/
‚îÇ       ‚îú‚îÄ‚îÄ openapi.yaml
‚îÇ       ‚îî‚îÄ‚îÄ schemas/
‚îú‚îÄ‚îÄ mocks/
‚îÇ   ‚îú‚îÄ‚îÄ endpoints/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ users.yaml
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ orders.yaml
‚îÇ   ‚îî‚îÄ‚îÄ scenarios/
‚îÇ       ‚îî‚îÄ‚îÄ checkout-flow.yaml
‚îú‚îÄ‚îÄ scenarios/
‚îÇ   ‚îú‚îÄ‚îÄ happy-paths/
‚îÇ   ‚îú‚îÄ‚îÄ error-paths/
‚îÇ   ‚îî‚îÄ‚îÄ edge-cases/
‚îî‚îÄ‚îÄ personas/
    ‚îú‚îÄ‚îÄ customers.yaml
    ‚îî‚îÄ‚îÄ admins.yaml
</code></pre>
<h3 id="large-team-6-developers"><a class="header" href="#large-team-6-developers">Large Team (6+ developers)</a></h3>
<pre><code>monorepo/
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ auth-service/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ contracts/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mocks/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scenarios/
‚îÇ   ‚îú‚îÄ‚îÄ payment-service/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ contracts/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mocks/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scenarios/
‚îÇ   ‚îî‚îÄ‚îÄ order-service/
‚îÇ       ‚îú‚îÄ‚îÄ contracts/
‚îÇ       ‚îú‚îÄ‚îÄ mocks/
‚îÇ       ‚îî‚îÄ‚îÄ scenarios/
‚îú‚îÄ‚îÄ shared/
‚îÇ   ‚îú‚îÄ‚îÄ contracts/  # Shared contracts
‚îÇ   ‚îî‚îÄ‚îÄ personas/   # Shared personas
‚îî‚îÄ‚îÄ mockforge.yaml  # Root configuration
</code></pre>
<h2 id="mod-patterns"><a class="header" href="#mod-patterns">MOD Patterns</a></h2>
<h3 id="pattern-1-contract-first-api-design"><a class="header" href="#pattern-1-contract-first-api-design">Pattern 1: Contract-First API Design</a></h3>
<ol>
<li>Design contract (OpenAPI)</li>
<li>Generate mock</li>
<li>Review with team</li>
<li>Implement backend</li>
<li>Validate against contract</li>
</ol>
<h3 id="pattern-2-scenario-driven-development"><a class="header" href="#pattern-2-scenario-driven-development">Pattern 2: Scenario-Driven Development</a></h3>
<ol>
<li>Define scenario (user journey)</li>
<li>Create mocks for scenario</li>
<li>Implement frontend using mocks</li>
<li>Implement backend to match scenario</li>
<li>Test end-to-end with scenario</li>
</ol>
<h3 id="pattern-3-progressive-realism"><a class="header" href="#pattern-3-progressive-realism">Pattern 3: Progressive Realism</a></h3>
<ol>
<li>Start with simple mocks (static responses)</li>
<li>Add realistic data (faker generation)</li>
<li>Add behavioral patterns (personas)</li>
<li>Add error scenarios (chaos)</li>
<li>Blend with real backend (reality continuum)</li>
</ol>
<h2 id="mod-success-metrics"><a class="header" href="#mod-success-metrics">MOD Success Metrics</a></h2>
<p>Track MOD effectiveness:</p>
<ul>
<li><strong>Time to First Integration</strong> ‚Äî How quickly can teams integrate?</li>
<li><strong>Contract Drift</strong> ‚Äî How often do implementations diverge from contracts?</li>
<li><strong>Frontend Blocking</strong> ‚Äî How often is frontend blocked by backend?</li>
<li><strong>API Review Time</strong> ‚Äî How long do API reviews take?</li>
<li><strong>Integration Bugs</strong> ‚Äî How many bugs are found during integration?</li>
</ul>
<h2 id="best-practices-48"><a class="header" href="#best-practices-48">Best Practices</a></h2>
<ol>
<li><strong>Start Early</strong>: Create mocks before implementation</li>
<li><strong>Version Contracts</strong>: Use semantic versioning for contracts</li>
<li><strong>Keep Mocks Updated</strong>: Update mocks as contracts evolve</li>
<li><strong>Use Scenarios</strong>: Test with scenarios, not just fixtures</li>
<li><strong>Document Decisions</strong>: Document why mocks are configured certain ways</li>
</ol>
<h2 id="related-documentation-32"><a class="header" href="#related-documentation-32">Related Documentation</a></h2>
<ul>
<li><a href="user-guide/devx/../../getting-started/getting-started.html">Getting Started</a> - Quick start guide</li>
<li><a href="user-guide/devx/smart-personas.html">Smart Personas</a> - Persona system</li>
<li><a href="user-guide/devx/reality-continuum.html">Reality Continuum</a> - Reality progression</li>
<li><a href="user-guide/devx/scenario-state-machines.html">Scenarios</a> - Scenario system</li>
<li><a href="user-guide/devx/../../docs/PILLARS.html#contracts">Contracts</a> - Contract management</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="snapshot-diff-between-environments"><a class="header" href="#snapshot-diff-between-environments">Snapshot Diff Between Environments</a></h1>
<p><strong>Pillars:</strong> [DevX]</p>
<p>Snapshot Diff provides side-by-side visualization for comparing mock behavior between different environments, personas, scenarios, or ‚Äúrealities‚Äù (Reality 0.1 vs Reality 0.9). This is amazing for demos and debugging.</p>
<h2 id="overview-38"><a class="header" href="#overview-38">Overview</a></h2>
<p>Snapshot Diff enables you to:</p>
<ul>
<li><strong>Compare Test vs Prod</strong> mock behavior</li>
<li><strong>Compare Persona A vs Persona B</strong> responses</li>
<li><strong>Compare Reality 0.1 vs Reality 0.9</strong> behavior</li>
<li><strong>Compare Scenarios</strong> side-by-side</li>
<li><strong>Visualize Differences</strong> with highlighted changes</li>
</ul>
<h2 id="usage-8"><a class="header" href="#usage-8">Usage</a></h2>
<h3 id="browser-extension-1"><a class="header" href="#browser-extension-1">Browser Extension</a></h3>
<ol>
<li>Open DevTools</li>
<li>Navigate to ‚ÄúMockForge‚Äù tab</li>
<li>Select ‚ÄúSnapshot Diff‚Äù panel</li>
<li>Choose comparison type</li>
<li>View side-by-side diff</li>
</ol>
<h3 id="api-usage-4"><a class="header" href="#api-usage-4">API Usage</a></h3>
<pre><code class="language-bash"># Compare snapshots
POST /api/v1/snapshots/compare
{
  "left_environment_id": "test",
  "right_environment_id": "prod",
  "endpoint": "/api/users/{id}",
  "method": "GET"
}
</code></pre>
<h3 id="cli-usage-2"><a class="header" href="#cli-usage-2">CLI Usage</a></h3>
<pre><code class="language-bash"># Compare environments
mockforge snapshot diff \
  --left-env test \
  --right-env prod \
  --endpoint /api/users/{id}

# Compare personas
mockforge snapshot diff \
  --left-persona premium-customer \
  --right-persona regular-customer \
  --endpoint /api/users/{id}

# Compare reality levels
mockforge snapshot diff \
  --left-reality 0.1 \
  --right-reality 0.9 \
  --endpoint /api/users/{id}
</code></pre>
<h2 id="comparison-types"><a class="header" href="#comparison-types">Comparison Types</a></h2>
<h3 id="environment-comparison"><a class="header" href="#environment-comparison">Environment Comparison</a></h3>
<p>Compare mock behavior between environments:</p>
<pre><code>Test Environment              Prod Environment
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ            ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
GET /api/users/123           GET /api/users/123
Status: 200                  Status: 200
Body: {...}                  Body: {...}
  id: "123"                    id: "123"
  name: "Test User"             name: "Prod User"  ‚ö†Ô∏è
  email: "test@..."             email: "prod@..."  ‚ö†Ô∏è
</code></pre>
<h3 id="persona-comparison"><a class="header" href="#persona-comparison">Persona Comparison</a></h3>
<p>Compare responses for different personas:</p>
<pre><code>Premium Customer              Regular Customer
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ            ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
GET /api/users/123           GET /api/users/123
Status: 200                  Status: 200
Body: {...}                  Body: {...}
  tier: "premium"              tier: "regular"  ‚ö†Ô∏è
  features: [...]               features: [...]  ‚ö†Ô∏è
</code></pre>
<h3 id="reality-level-comparison"><a class="header" href="#reality-level-comparison">Reality Level Comparison</a></h3>
<p>Compare behavior at different reality levels:</p>
<pre><code>Reality 0.1 (Low)            Reality 0.9 (High)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ            ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
GET /api/users/123           GET /api/users/123
Status: 200                  Status: 200
Body: {...}                  Body: {...}
  # Synthetic data             # Blended with real
  id: "generated-123"          id: "real-user-123"  ‚ö†Ô∏è
  name: "Generated Name"        name: "Real Name"  ‚ö†Ô∏è
</code></pre>
<h3 id="scenario-comparison"><a class="header" href="#scenario-comparison">Scenario Comparison</a></h3>
<p>Compare different scenarios:</p>
<pre><code>Happy Path                   Error Path
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ            ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
POST /api/orders             POST /api/orders
Status: 201                  Status: 400
Body: {...}                  Body: {...}
  status: "created"            error: "Invalid..."  ‚ö†Ô∏è
</code></pre>
<h2 id="diff-visualization"><a class="header" href="#diff-visualization">Diff Visualization</a></h2>
<h3 id="side-by-side-view"><a class="header" href="#side-by-side-view">Side-by-Side View</a></h3>
<pre><code>Left Snapshot                Right Snapshot
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ            ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Status: 200                  Status: 200
Headers:                     Headers:
  Content-Type: json            Content-Type: json
Body:                         Body:
  {                             {
    "id": "123",                "id": "123",
    "name": "User A",           "name": "User B",  ‚ö†Ô∏è
    "email": "a@..."            "email": "b@..."   ‚ö†Ô∏è
  }                             }
</code></pre>
<h3 id="difference-types"><a class="header" href="#difference-types">Difference Types</a></h3>
<ul>
<li><strong>Missing in Right</strong>: Fields present in left but not right</li>
<li><strong>Missing in Left</strong>: Fields present in right but not left</li>
<li><strong>Status Code Mismatch</strong>: Different status codes</li>
<li><strong>Body Mismatch</strong>: Different response bodies</li>
<li><strong>Headers Mismatch</strong>: Different headers</li>
</ul>
<h2 id="use-cases-16"><a class="header" href="#use-cases-16">Use Cases</a></h2>
<h3 id="demo-preparation"><a class="header" href="#demo-preparation">Demo Preparation</a></h3>
<p>Compare scenarios to prepare demos:</p>
<pre><code class="language-bash"># Compare demo scenarios
mockforge snapshot diff \
  --left-scenario demo-basic \
  --right-scenario demo-premium \
  --endpoint /api/features
</code></pre>
<h3 id="debugging-2"><a class="header" href="#debugging-2">Debugging</a></h3>
<p>Compare behavior to debug issues:</p>
<pre><code class="language-bash"># Compare test vs prod to find differences
mockforge snapshot diff \
  --left-env test \
  --right-env prod \
  --endpoint /api/users/{id}
</code></pre>
<h3 id="reality-progression"><a class="header" href="#reality-progression">Reality Progression</a></h3>
<p>Compare reality levels to understand progression:</p>
<pre><code class="language-bash"># Compare low vs high reality
mockforge snapshot diff \
  --left-reality 0.1 \
  --right-reality 0.9 \
  --endpoint /api/users/{id}
</code></pre>
<h2 id="configuration-28"><a class="header" href="#configuration-28">Configuration</a></h2>
<h3 id="snapshot-storage"><a class="header" href="#snapshot-storage">Snapshot Storage</a></h3>
<pre><code class="language-yaml"># mockforge.yaml
snapshots:
  enabled: true
  storage:
    type: database  # or file
    retention_days: 30
</code></pre>
<h3 id="comparison-options"><a class="header" href="#comparison-options">Comparison Options</a></h3>
<pre><code class="language-yaml">snapshots:
  comparison:
    include_headers: true
    include_timing: true
    diff_format: unified  # or side-by-side
</code></pre>
<h2 id="best-practices-49"><a class="header" href="#best-practices-49">Best Practices</a></h2>
<ol>
<li><strong>Take Snapshots Regularly</strong>: Capture snapshots at key points</li>
<li><strong>Compare Before Deploy</strong>: Compare test vs prod before deployment</li>
<li><strong>Document Differences</strong>: Document expected differences</li>
<li><strong>Use for Demos</strong>: Use comparisons in demos and presentations</li>
<li><strong>Track Over Time</strong>: Compare snapshots over time to track changes</li>
</ol>
<h2 id="related-documentation-33"><a class="header" href="#related-documentation-33">Related Documentation</a></h2>
<ul>
<li><a href="user-guide/devx/zero-config-mode.html">Zero-Config Mode</a> - Auto-mock generation</li>
<li><a href="user-guide/devx/devtools-integration.html">DevTools Integration</a> - Browser integration</li>
<li><a href="user-guide/devx/../forgeconnect-sdk.html">ForgeConnect SDK</a> - Browser SDK</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="mockops-pipelines-1"><a class="header" href="#mockops-pipelines-1">MockOps Pipelines</a></h1>
<p><strong>Pillars:</strong> [Cloud]</p>
<p>MockOps Pipelines provide GitHub Actions-like automation for mock lifecycle management. Think GitHub Actions + mocks‚Äîevent-driven automation that makes MockForge orchestration for mock environments.</p>
<h2 id="overview-39"><a class="header" href="#overview-39">Overview</a></h2>
<p>MockOps Pipelines enable:</p>
<ul>
<li><strong>Schema Change ‚Üí Auto-Regenerate SDK</strong>: When OpenAPI changes, automatically regenerate client SDKs</li>
<li><strong>Scenario Published ‚Üí Auto-Promote to Test ‚Üí Notify Teams</strong>: Automatically promote scenarios and notify teams</li>
<li><strong>Drift Threshold Exceeded ‚Üí Auto-Generate Git PR</strong>: Create PRs with fixes when drift exceeds thresholds</li>
</ul>
<h2 id="pipeline-structure"><a class="header" href="#pipeline-structure">Pipeline Structure</a></h2>
<p>Pipelines are defined in YAML and triggered by events:</p>
<pre><code class="language-yaml">name: schema-change-pipeline
definition:
  enabled: true
  triggers:
    - event: schema.changed
      filters:
        workspace_id: "workspace-123"
        schema_type: ["openapi", "protobuf"]
  steps:
    - name: regenerate-sdks
      step_type: regenerate_sdk
      config:
        languages: ["typescript", "python", "rust"]
        workspace_id: "{{workspace_id}}"
    - name: notify-teams
      step_type: notify
      config:
        type: slack
        channels: ["#api-team", "#frontend-team"]
        message: "SDKs regenerated for {{workspace_id}}"
</code></pre>
<h2 id="available-events"><a class="header" href="#available-events">Available Events</a></h2>
<h3 id="schema-changed"><a class="header" href="#schema-changed">Schema Changed</a></h3>
<p>Triggered when OpenAPI/Protobuf schemas are modified:</p>
<pre><code class="language-yaml">triggers:
  - event: schema.changed
    filters:
      schema_type: ["openapi", "protobuf"]
      workspace_id: "workspace-123"
</code></pre>
<p><strong>Payload:</strong></p>
<ul>
<li><code>spec_path</code>: Path to schema file</li>
<li><code>schema_type</code>: ‚Äúopenapi‚Äù or ‚Äúprotobuf‚Äù</li>
<li><code>changes</code>: List of changes (added/removed/modified endpoints)</li>
</ul>
<h3 id="scenario-published"><a class="header" href="#scenario-published">Scenario Published</a></h3>
<p>Triggered when a new scenario is published:</p>
<pre><code class="language-yaml">triggers:
  - event: scenario.published
    filters:
      workspace_id: "workspace-123"
</code></pre>
<p><strong>Payload:</strong></p>
<ul>
<li><code>scenario_id</code>: ID of published scenario</li>
<li><code>scenario_name</code>: Name of scenario</li>
<li><code>version</code>: Scenario version</li>
<li><code>workspace_id</code>: Workspace ID</li>
</ul>
<h3 id="drift-threshold-exceeded"><a class="header" href="#drift-threshold-exceeded">Drift Threshold Exceeded</a></h3>
<p>Triggered when drift budget threshold is exceeded:</p>
<pre><code class="language-yaml">triggers:
  - event: drift.threshold_exceeded
</code></pre>
<p><strong>Payload:</strong></p>
<ul>
<li><code>endpoint</code>: Affected endpoint</li>
<li><code>drift_count</code>: Number of drift incidents</li>
<li><code>threshold</code>: Threshold that was exceeded</li>
<li><code>drift_data</code>: Detailed drift information</li>
</ul>
<h3 id="promotion-completed"><a class="header" href="#promotion-completed">Promotion Completed</a></h3>
<p>Triggered when entity promotion completes:</p>
<pre><code class="language-yaml">triggers:
  - event: promotion.completed
</code></pre>
<p><strong>Payload:</strong></p>
<ul>
<li><code>promotion_id</code>: Promotion ID</li>
<li><code>entity_type</code>: ‚Äúscenario‚Äù, ‚Äúpersona‚Äù, or ‚Äúconfig‚Äù</li>
<li><code>from_environment</code>: Source environment</li>
<li><code>to_environment</code>: Target environment</li>
</ul>
<h2 id="available-steps"><a class="header" href="#available-steps">Available Steps</a></h2>
<h3 id="regenerate-sdk"><a class="header" href="#regenerate-sdk">Regenerate SDK</a></h3>
<p>Regenerates client SDKs from OpenAPI/Protobuf specs:</p>
<pre><code class="language-yaml">steps:
  - name: regenerate-sdks
    step_type: regenerate_sdk
    config:
      spec_path: "{{event.spec_path}}"
      languages: ["typescript", "python", "rust"]
      output_dir: "./generated-sdks"
</code></pre>
<p><strong>Config Options:</strong></p>
<ul>
<li><code>spec_path</code>: Path to OpenAPI/Protobuf spec</li>
<li><code>languages</code>: Array of languages to generate</li>
<li><code>output_dir</code>: Output directory (default: <code>./generated-sdks</code>)</li>
</ul>
<h3 id="auto-promote"><a class="header" href="#auto-promote">Auto-Promote</a></h3>
<p>Automatically promotes entities between environments:</p>
<pre><code class="language-yaml">steps:
  - name: auto-promote
    step_type: auto_promote
    config:
      entity_type: scenario
      entity_id: "{{event.scenario_id}}"
      from_environment: dev
      to_environment: test
</code></pre>
<p><strong>Config Options:</strong></p>
<ul>
<li><code>entity_type</code>: ‚Äúscenario‚Äù, ‚Äúpersona‚Äù, or ‚Äúconfig‚Äù</li>
<li><code>entity_id</code>: ID of entity to promote</li>
<li><code>from_environment</code>: Source environment</li>
<li><code>to_environment</code>: Target environment</li>
<li><code>comments</code>: Optional promotion comments</li>
</ul>
<h3 id="notify"><a class="header" href="#notify">Notify</a></h3>
<p>Sends notifications via Slack, email, or webhook:</p>
<pre><code class="language-yaml">steps:
  - name: notify-teams
    step_type: notify
    config:
      type: slack
      slack_webhook_url: "https://hooks.slack.com/services/..."
      channels: ["#api-team", "#frontend-team"]
      message: "SDKs regenerated for {{workspace_id}}"
</code></pre>
<p><strong>Config Options:</strong></p>
<ul>
<li><code>type</code>: ‚Äúslack‚Äù, ‚Äúemail‚Äù, or ‚Äúwebhook‚Äù</li>
<li><code>message</code>: Notification message (supports template variables)</li>
<li><code>slack_webhook_url</code>: Slack webhook URL (for Slack type)</li>
<li><code>channels</code>: Array of channel names (for Slack type)</li>
<li><code>email_to</code>: Array of email addresses (for email type)</li>
<li><code>webhook_url</code>: Webhook URL (for webhook type)</li>
</ul>
<h3 id="create-pr"><a class="header" href="#create-pr">Create PR</a></h3>
<p>Creates Git pull requests:</p>
<pre><code class="language-yaml">steps:
  - name: create-pr
    step_type: create_pr
    config:
      repository: "https://github.com/org/repo"
      branch: "main"
      title: "Drift Violation: {{event.endpoint}}"
      body: "Drift count: {{event.drift_count}}, Threshold: {{event.threshold}}"
      files:
        - path: "drift-report.json"
          content: "{{event.drift_data}}"
          operation: create
</code></pre>
<p><strong>Config Options:</strong></p>
<ul>
<li><code>repository</code>: Git repository URL</li>
<li><code>branch</code>: Target branch</li>
<li><code>title</code>: PR title</li>
<li><code>body</code>: PR body (supports template variables)</li>
<li><code>files</code>: Array of files to include in PR</li>
</ul>
<h2 id="common-use-cases-4"><a class="header" href="#common-use-cases-4">Common Use Cases</a></h2>
<h3 id="1-auto-regenerate-sdks-on-schema-changes"><a class="header" href="#1-auto-regenerate-sdks-on-schema-changes">1. Auto-Regenerate SDKs on Schema Changes</a></h3>
<pre><code class="language-yaml">name: auto-sdk-regeneration
definition:
  enabled: true
  triggers:
    - event: schema.changed
      filters:
        schema_type: openapi
  steps:
    - name: regenerate_sdk
      step_type: regenerate_sdk
      config:
        spec_path: "{{event.spec_path}}"
        languages: ["typescript", "rust", "python"]
        output_dir: "./generated-sdks"
</code></pre>
<h3 id="2-auto-promote-scenarios-to-test"><a class="header" href="#2-auto-promote-scenarios-to-test">2. Auto-Promote Scenarios to Test</a></h3>
<pre><code class="language-yaml">name: auto-promote-to-test
definition:
  enabled: true
  triggers:
    - event: scenario.published
      filters:
        workspace_id: "your-workspace-id"
  steps:
    - name: auto_promote
      step_type: auto_promote
      config:
        entity_type: scenario
        entity_id: "{{event.scenario_id}}"
        from_environment: dev
        to_environment: test
    - name: notify_team
      step_type: notify
      config:
        type: slack
        slack_webhook_url: "https://hooks.slack.com/services/..."
        channels: ["#devops"]
        message: "Scenario {{event.scenario_name}} promoted to test"
</code></pre>
<h3 id="3-create-pr-on-drift-violations"><a class="header" href="#3-create-pr-on-drift-violations">3. Create PR on Drift Violations</a></h3>
<pre><code class="language-yaml">name: drift-gitops-pr
definition:
  enabled: true
  triggers:
    - event: drift.threshold_exceeded
  steps:
    - name: create_pr
      step_type: create_pr
      config:
        repository: "https://github.com/org/repo"
        branch: "main"
        title: "Drift Violation: {{event.endpoint}}"
        body: "Drift count: {{event.drift_count}}, Threshold: {{event.threshold}}"
        files:
          - path: "drift-report.json"
            content: "{{event.drift_data}}"
            operation: create
</code></pre>
<h2 id="template-variables-3"><a class="header" href="#template-variables-3">Template Variables</a></h2>
<p>Pipeline steps support template variables:</p>
<ul>
<li><code>{{event.field}}</code>: Access event payload fields</li>
<li><code>{{workspace_id}}</code>: Current workspace ID</li>
<li><code>{{workspace_name}}</code>: Current workspace name</li>
<li><code>{{timestamp}}</code>: Current timestamp</li>
</ul>
<h2 id="pipeline-management"><a class="header" href="#pipeline-management">Pipeline Management</a></h2>
<h3 id="create-pipeline"><a class="header" href="#create-pipeline">Create Pipeline</a></h3>
<pre><code class="language-bash"># Create pipeline from YAML
mockforge pipelines create pipeline.yaml

# Or via API
POST /api/v1/pipelines
{
  "name": "my-pipeline",
  "definition": {...}
}
</code></pre>
<h3 id="list-pipelines"><a class="header" href="#list-pipelines">List Pipelines</a></h3>
<pre><code class="language-bash"># List all pipelines
mockforge pipelines list

# List pipelines for workspace
mockforge pipelines list --workspace workspace-123
</code></pre>
<h3 id="enabledisable-pipeline"><a class="header" href="#enabledisable-pipeline">Enable/Disable Pipeline</a></h3>
<pre><code class="language-bash"># Enable pipeline
mockforge pipelines enable &lt;pipeline-id&gt;

# Disable pipeline
mockforge pipelines disable &lt;pipeline-id&gt;
</code></pre>
<h3 id="view-pipeline-executions"><a class="header" href="#view-pipeline-executions">View Pipeline Executions</a></h3>
<pre><code class="language-bash"># View pipeline executions
mockforge pipelines executions &lt;pipeline-id&gt;

# View execution details
mockforge pipelines execution &lt;execution-id&gt;
</code></pre>
<h2 id="best-practices-50"><a class="header" href="#best-practices-50">Best Practices</a></h2>
<ol>
<li><strong>Start Simple</strong>: Begin with one-step pipelines</li>
<li><strong>Test Incrementally</strong>: Test each step individually</li>
<li><strong>Use Filters</strong>: Filter events to avoid unnecessary executions</li>
<li><strong>Monitor Executions</strong>: Review execution logs regularly</li>
<li><strong>Version Control</strong>: Keep pipeline definitions in Git</li>
</ol>
<h2 id="related-documentation-34"><a class="header" href="#related-documentation-34">Related Documentation</a></h2>
<ul>
<li><a href="user-guide/cloud/federation.html">Federation</a> - Multi-workspace federation</li>
<li><a href="user-guide/cloud/analytics-dashboard.html">Analytics Dashboard</a> - Usage analytics</li>
<li><a href="user-guide/cloud/cloud-workspaces.html">Cloud Workspaces</a> - Workspace management</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="multi-workspace-federation-1"><a class="header" href="#multi-workspace-federation-1">Multi-Workspace Federation</a></h1>
<p><strong>Pillars:</strong> [Cloud]</p>
<p>Multi-Workspace Federation enables composing multiple mock workspaces into one federated ‚Äúvirtual system‚Äù for large organizations with microservices architectures.</p>
<h2 id="overview-40"><a class="header" href="#overview-40">Overview</a></h2>
<p>Federation allows you to:</p>
<ul>
<li><strong>Define Service Boundaries</strong>: Map services to workspaces</li>
<li><strong>Compose Virtual Systems</strong>: Combine multiple workspaces into one system</li>
<li><strong>Run System-Wide Scenarios</strong>: Define scenarios that span multiple services</li>
<li><strong>Control Reality Per Service</strong>: Set reality level independently per service</li>
</ul>
<h2 id="key-concepts-2"><a class="header" href="#key-concepts-2">Key Concepts</a></h2>
<h3 id="service-boundaries"><a class="header" href="#service-boundaries">Service Boundaries</a></h3>
<p>Services represent individual microservices in your architecture:</p>
<pre><code class="language-yaml">services:
  - name: auth
    workspace_id: "workspace-auth-123"
    base_path: "/auth"
    reality_level: "real"  # Use real upstream
</code></pre>
<h3 id="federation"><a class="header" href="#federation">Federation</a></h3>
<p>A federation is a collection of services that work together:</p>
<pre><code class="language-yaml">federation:
  name: "e-commerce-platform"
  services:
    - name: auth
      workspace_id: "workspace-auth-123"
      base_path: "/auth"
      reality_level: "real"
    - name: payments
      workspace_id: "workspace-payments-456"
      base_path: "/payments"
      reality_level: "mock_v3"
</code></pre>
<h3 id="virtual-system"><a class="header" href="#virtual-system">Virtual System</a></h3>
<p>The federated system appears as a single unified API:</p>
<pre><code>/api/auth/*          ‚Üí Auth service (real)
/api/payments/*      ‚Üí Payments service (mock v3)
/api/inventory/*    ‚Üí Inventory service (blended)
/api/shipping/*     ‚Üí Shipping service (chaos-driven)
</code></pre>
<h2 id="service-reality-levels"><a class="header" href="#service-reality-levels">Service Reality Levels</a></h2>
<p>Each service can have its own reality level:</p>
<h3 id="real"><a class="header" href="#real">Real</a></h3>
<p>Use real upstream (no mocking):</p>
<pre><code class="language-yaml">services:
  - name: auth
    reality_level: "real"
</code></pre>
<p><strong>Use Case:</strong> Critical services that must be real (auth, payment processing).</p>
<h3 id="mock-v3"><a class="header" href="#mock-v3">Mock V3</a></h3>
<p>Use mock with reality level 3:</p>
<pre><code class="language-yaml">services:
  - name: payments
    reality_level: "mock_v3"
</code></pre>
<p><strong>Use Case:</strong> Services under development or testing.</p>
<h3 id="blended"><a class="header" href="#blended">Blended</a></h3>
<p>Mix of mock and real data:</p>
<pre><code class="language-yaml">services:
  - name: inventory
    reality_level: "blended"
    blend_ratio: 0.5  # 50% real, 50% mock
</code></pre>
<p><strong>Use Case:</strong> Gradual migration from mock to real.</p>
<h3 id="chaos-driven"><a class="header" href="#chaos-driven">Chaos-Driven</a></h3>
<p>Chaos testing mode:</p>
<pre><code class="language-yaml">services:
  - name: shipping
    reality_level: "chaos_driven"
</code></pre>
<p><strong>Use Case:</strong> Resilience testing, chaos engineering.</p>
<h2 id="configuration-29"><a class="header" href="#configuration-29">Configuration</a></h2>
<h3 id="define-federation"><a class="header" href="#define-federation">Define Federation</a></h3>
<pre><code class="language-yaml"># federation.yaml
federation:
  name: "e-commerce-platform"
  description: "Federated e-commerce system"
  services:
    - name: auth
      workspace_id: "workspace-auth-123"
      base_path: "/auth"
      reality_level: "real"
      config:
        upstream_url: "https://auth.example.com"
    
    - name: payments
      workspace_id: "workspace-payments-456"
      base_path: "/payments"
      reality_level: "mock_v3"
      config:
        reality_level: 3
        chaos_enabled: false
    
    - name: inventory
      workspace_id: "workspace-inventory-789"
      base_path: "/inventory"
      reality_level: "blended"
      config:
        blend_ratio: 0.5
        reality_continuum:
          enabled: true
          default_ratio: 0.5
    
    - name: shipping
      workspace_id: "workspace-shipping-012"
      base_path: "/shipping"
      reality_level: "chaos_driven"
      config:
        chaos:
          enabled: true
          error_rate: 0.1
          latency_spike_probability: 0.2
</code></pre>
<h3 id="service-dependencies"><a class="header" href="#service-dependencies">Service Dependencies</a></h3>
<p>Define dependencies between services:</p>
<pre><code class="language-yaml">services:
  - name: orders
    workspace_id: "workspace-orders-123"
    base_path: "/orders"
    dependencies:
      - payments
      - inventory
      - shipping
</code></pre>
<p>Dependencies are used for:</p>
<ul>
<li>System-wide scenario ordering</li>
<li>Service startup coordination</li>
<li>Dependency graph visualization</li>
</ul>
<h2 id="system-wide-scenarios"><a class="header" href="#system-wide-scenarios">System-Wide Scenarios</a></h2>
<p>Define scenarios that span multiple services:</p>
<pre><code class="language-yaml">system_scenarios:
  - name: end-to-end-checkout
    description: "Complete checkout flow across services"
    steps:
      - service: auth
        endpoint: POST /auth/login
        extract:
          token: "body.token"
      
      - service: inventory
        endpoint: GET /inventory/products/{product_id}
        headers:
          Authorization: "Bearer {{token}}"
        extract:
          product: "body"
      
      - service: payments
        endpoint: POST /payments/charge
        headers:
          Authorization: "Bearer {{token}}"
        body:
          amount: "{{product.price}}"
        extract:
          payment_id: "body.id"
      
      - service: orders
        endpoint: POST /orders
        headers:
          Authorization: "Bearer {{token}}"
        body:
          product_id: "{{product.id}}"
          payment_id: "{{payment_id}}"
</code></pre>
<h2 id="routing"><a class="header" href="#routing">Routing</a></h2>
<p>The federation router routes requests to appropriate services:</p>
<h3 id="path-based-routing"><a class="header" href="#path-based-routing">Path-Based Routing</a></h3>
<p>Requests are routed based on path prefixes:</p>
<pre><code>GET /auth/users/123     ‚Üí Auth service
GET /payments/charge    ‚Üí Payments service
GET /inventory/products ‚Üí Inventory service
</code></pre>
<h3 id="longest-match"><a class="header" href="#longest-match">Longest Match</a></h3>
<p>The router uses longest match for path matching:</p>
<pre><code>/api/v1/payments/charge ‚Üí Payments service (longer match)
/api/v1/payments         ‚Üí Payments service
/api/v1                 ‚Üí Default service
</code></pre>
<h2 id="usage-9"><a class="header" href="#usage-9">Usage</a></h2>
<h3 id="create-federation"><a class="header" href="#create-federation">Create Federation</a></h3>
<pre><code class="language-bash"># Create federation from YAML
mockforge federation create federation.yaml

# Or via API
POST /api/v1/federations
{
  "name": "e-commerce-platform",
  "services": [...]
}
</code></pre>
<h3 id="start-federated-system"><a class="header" href="#start-federated-system">Start Federated System</a></h3>
<pre><code class="language-bash"># Start all services in federation
mockforge federation start e-commerce-platform

# Start specific services
mockforge federation start e-commerce-platform --services auth,payments
</code></pre>
<h3 id="run-system-wide-scenario"><a class="header" href="#run-system-wide-scenario">Run System-Wide Scenario</a></h3>
<pre><code class="language-bash"># Run scenario across all services
mockforge federation scenario run e-commerce-platform end-to-end-checkout
</code></pre>
<h2 id="real-world-example-1"><a class="header" href="#real-world-example-1">Real-World Example</a></h2>
<h3 id="e-commerce-platform"><a class="header" href="#e-commerce-platform">E-Commerce Platform</a></h3>
<pre><code class="language-yaml">federation:
  name: "e-commerce-platform"
  services:
    # Auth - Always real (critical service)
    - name: auth
      workspace_id: "workspace-auth"
      base_path: "/auth"
      reality_level: "real"
    
    # Payments - Mock v3 (under development)
    - name: payments
      workspace_id: "workspace-payments"
      base_path: "/payments"
      reality_level: "mock_v3"
    
    # Inventory - Blended (gradual migration)
    - name: inventory
      workspace_id: "workspace-inventory"
      base_path: "/inventory"
      reality_level: "blended"
      config:
        blend_ratio: 0.3  # 30% real, 70% mock
    
    # Shipping - Chaos-driven (resilience testing)
    - name: shipping
      workspace_id: "workspace-shipping"
      base_path: "/shipping"
      reality_level: "chaos_driven"
</code></pre>
<p><strong>Result:</strong> Single unified API with different reality levels per service.</p>
<h2 id="best-practices-51"><a class="header" href="#best-practices-51">Best Practices</a></h2>
<ol>
<li><strong>Start Small</strong>: Begin with 2-3 services</li>
<li><strong>Define Boundaries</strong>: Clearly define service boundaries</li>
<li><strong>Use Dependencies</strong>: Document service dependencies</li>
<li><strong>Test Scenarios</strong>: Create system-wide test scenarios</li>
<li><strong>Monitor Routing</strong>: Monitor routing performance</li>
</ol>
<h2 id="related-documentation-35"><a class="header" href="#related-documentation-35">Related Documentation</a></h2>
<ul>
<li><a href="user-guide/cloud/mockops-pipelines.html">MockOps Pipelines</a> - Pipeline automation</li>
<li><a href="user-guide/cloud/analytics-dashboard.html">Analytics Dashboard</a> - Usage analytics</li>
<li><a href="user-guide/cloud/cloud-workspaces.html">Cloud Workspaces</a> - Workspace management</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="analytics-dashboard-1"><a class="header" href="#analytics-dashboard-1">Analytics Dashboard</a></h1>
<p><strong>Pillars:</strong> [Cloud]</p>
<p>The Analytics Dashboard provides leadership insight into coverage, risk, and usage. It shows which scenarios are used most, what personas are hit by CI, which endpoints are under-tested, which mocks have stale reality levels, and what percentage of mocks are drifting from real data.</p>
<h2 id="overview-41"><a class="header" href="#overview-41">Overview</a></h2>
<p>The Analytics Dashboard gives you:</p>
<ul>
<li><strong>Scenario Usage Heatmaps</strong>: Which scenarios are used most, usage patterns over time</li>
<li><strong>Persona CI Hit Tracking</strong>: Which personas are hit by CI, persona usage frequency</li>
<li><strong>Endpoint Coverage Analysis</strong>: Which endpoints are under-tested, test coverage per endpoint</li>
<li><strong>Reality Level Staleness</strong>: Which mocks have stale reality levels, recommendations for updates</li>
<li><strong>Drift Percentage Tracking</strong>: What percentage of mocks are drifting from real data, drift trends</li>
</ul>
<h2 id="scenario-usage-heatmaps"><a class="header" href="#scenario-usage-heatmaps">Scenario Usage Heatmaps</a></h2>
<h3 id="overview-42"><a class="header" href="#overview-42">Overview</a></h3>
<p>Visualize which scenarios are used most frequently:</p>
<pre><code>Scenario                    Usage Count    Last Used
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
checkout-success           1,234          2025-01-27
payment-failure            892           2025-01-27
cart-abandonment           567           2025-01-26
user-signup                445           2025-01-25
</code></pre>
<h3 id="usage-patterns"><a class="header" href="#usage-patterns">Usage Patterns</a></h3>
<p>View usage patterns over time:</p>
<ul>
<li>Peak usage times</li>
<li>Usage trends (increasing/decreasing)</li>
<li>Seasonal patterns</li>
</ul>
<h3 id="access"><a class="header" href="#access">Access</a></h3>
<pre><code class="language-bash"># Get scenario usage metrics
GET /api/v2/analytics/scenarios/usage?workspace_id=workspace-123&amp;time_range=30d
</code></pre>
<h2 id="persona-ci-hit-tracking"><a class="header" href="#persona-ci-hit-tracking">Persona CI Hit Tracking</a></h2>
<h3 id="overview-43"><a class="header" href="#overview-43">Overview</a></h3>
<p>Track which personas are used in CI/CD pipelines:</p>
<pre><code>Persona                    CI Hits    Last Hit
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
premium-customer           234        2025-01-27
fraud-suspect              156        2025-01-27
new-user                   89        2025-01-26
churned-user               45        2025-01-25
</code></pre>
<h3 id="insights"><a class="header" href="#insights">Insights</a></h3>
<ul>
<li><strong>Coverage Gaps</strong>: Personas not hit by CI</li>
<li><strong>Usage Frequency</strong>: How often personas are used</li>
<li><strong>CI Integration</strong>: Which CI systems use which personas</li>
</ul>
<h3 id="access-1"><a class="header" href="#access-1">Access</a></h3>
<pre><code class="language-bash"># Get persona CI hits
GET /api/v2/analytics/personas/ci-hits?workspace_id=workspace-123
</code></pre>
<h2 id="endpoint-coverage-analysis"><a class="header" href="#endpoint-coverage-analysis">Endpoint Coverage Analysis</a></h2>
<h3 id="overview-44"><a class="header" href="#overview-44">Overview</a></h3>
<p>Identify which endpoints are under-tested:</p>
<pre><code>Endpoint                    Test Count    Last Tested    Coverage
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
GET /api/users/{id}         45           2025-01-27     100%
POST /api/orders            23           2025-01-26     85%
GET /api/products           12           2025-01-25     60%  ‚ö†Ô∏è
DELETE /api/users/{id}      5            2025-01-20     30%  ‚ö†Ô∏è
</code></pre>
<h3 id="coverage-metrics"><a class="header" href="#coverage-metrics">Coverage Metrics</a></h3>
<ul>
<li><strong>Test Count</strong>: Number of tests covering endpoint</li>
<li><strong>Last Tested</strong>: When endpoint was last tested</li>
<li><strong>Coverage Percentage</strong>: Test coverage score</li>
<li><strong>Missing Scenarios</strong>: Scenarios that should exist but don‚Äôt</li>
</ul>
<h3 id="access-2"><a class="header" href="#access-2">Access</a></h3>
<pre><code class="language-bash"># Get endpoint coverage
GET /api/v2/analytics/endpoints/coverage?workspace_id=workspace-123&amp;min_coverage=80
</code></pre>
<h2 id="reality-level-staleness"><a class="header" href="#reality-level-staleness">Reality Level Staleness</a></h2>
<h3 id="overview-45"><a class="header" href="#overview-45">Overview</a></h3>
<p>Track which mocks have stale reality levels:</p>
<pre><code>Endpoint                    Current Level    Last Updated    Staleness
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
GET /api/users/{id}        3               2025-01-15      12 days  ‚ö†Ô∏è
POST /api/orders           2               2025-01-20      7 days
GET /api/products          4               2025-01-27      0 days
</code></pre>
<h3 id="recommendations"><a class="header" href="#recommendations">Recommendations</a></h3>
<ul>
<li><strong>Update Needed</strong>: Mocks with stale reality levels</li>
<li><strong>Update Priority</strong>: Based on usage and importance</li>
<li><strong>Update Suggestions</strong>: Recommended reality level updates</li>
</ul>
<h3 id="access-3"><a class="header" href="#access-3">Access</a></h3>
<pre><code class="language-bash"># Get reality level staleness
GET /api/v2/analytics/reality-levels/staleness?workspace_id=workspace-123&amp;max_staleness_days=30
</code></pre>
<h2 id="drift-percentage-tracking"><a class="header" href="#drift-percentage-tracking">Drift Percentage Tracking</a></h2>
<h3 id="overview-46"><a class="header" href="#overview-46">Overview</a></h3>
<p>Track what percentage of mocks are drifting from real data:</p>
<pre><code>Metric                      Value    Trend
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Total Mocks                150      ‚îÄ
Drifting Mocks             45       ‚Üë
Drift Percentage           30%      ‚Üë
High-Drift Mocks           12       ‚Üë
</code></pre>
<h3 id="drift-trends"><a class="header" href="#drift-trends">Drift Trends</a></h3>
<p>View drift trends over time:</p>
<ul>
<li>Increasing drift (mocks diverging from real)</li>
<li>Decreasing drift (mocks converging with real)</li>
<li>Stable drift (consistent divergence)</li>
</ul>
<h3 id="access-4"><a class="header" href="#access-4">Access</a></h3>
<pre><code class="language-bash"># Get drift percentage
GET /api/v2/analytics/drift/percentage?workspace_id=workspace-123
</code></pre>
<h2 id="dashboard-views"><a class="header" href="#dashboard-views">Dashboard Views</a></h2>
<h3 id="overview-dashboard"><a class="header" href="#overview-dashboard">Overview Dashboard</a></h3>
<p>High-level metrics:</p>
<ul>
<li>Total scenarios, personas, endpoints</li>
<li>Overall coverage percentage</li>
<li>Average reality level staleness</li>
<li>Overall drift percentage</li>
</ul>
<h3 id="detailed-views"><a class="header" href="#detailed-views">Detailed Views</a></h3>
<p>Drill down into specific areas:</p>
<ul>
<li>Scenario usage details</li>
<li>Persona usage breakdown</li>
<li>Endpoint coverage details</li>
<li>Reality level analysis</li>
<li>Drift analysis</li>
</ul>
<h2 id="configuration-30"><a class="header" href="#configuration-30">Configuration</a></h2>
<h3 id="enable-analytics"><a class="header" href="#enable-analytics">Enable Analytics</a></h3>
<pre><code class="language-yaml"># mockforge.yaml
analytics:
  enabled: true
  collection_interval: 60  # seconds
  retention_days: 90
</code></pre>
<h3 id="coverage-thresholds"><a class="header" href="#coverage-thresholds">Coverage Thresholds</a></h3>
<pre><code class="language-yaml">analytics:
  coverage:
    min_coverage_percentage: 80
    alert_on_low_coverage: true
</code></pre>
<h3 id="staleness-thresholds"><a class="header" href="#staleness-thresholds">Staleness Thresholds</a></h3>
<pre><code class="language-yaml">analytics:
  staleness:
    max_staleness_days: 30
    alert_on_stale: true
</code></pre>
<h2 id="best-practices-52"><a class="header" href="#best-practices-52">Best Practices</a></h2>
<ol>
<li><strong>Review Regularly</strong>: Check dashboard weekly/monthly</li>
<li><strong>Set Thresholds</strong>: Configure coverage and staleness thresholds</li>
<li><strong>Act on Insights</strong>: Use insights to improve testing and mocks</li>
<li><strong>Track Trends</strong>: Monitor trends over time</li>
<li><strong>Share with Team</strong>: Share insights with development teams</li>
</ol>
<h2 id="related-documentation-36"><a class="header" href="#related-documentation-36">Related Documentation</a></h2>
<ul>
<li><a href="user-guide/cloud/mockops-pipelines.html">MockOps Pipelines</a> - Pipeline automation</li>
<li><a href="user-guide/cloud/federation.html">Federation</a> - Multi-workspace federation</li>
<li><a href="user-guide/cloud/cloud-workspaces.html">Cloud Workspaces</a> - Workspace management</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="api-architecture-critique-1"><a class="header" href="#api-architecture-critique-1">API Architecture Critique</a></h1>
<p><strong>Pillars:</strong> [AI]</p>
<p>API Architecture Critique feeds entire API schemas into an LLM and produces comprehensive analysis including anti-pattern detection, redundancy detection, poor naming, emotional tone assessment, and recommended restructuring. This positions MockForge as an <strong>API Architect AI</strong>.</p>
<h2 id="overview-47"><a class="header" href="#overview-47">Overview</a></h2>
<p>Beyond structural validation, API Architecture Critique provides:</p>
<ul>
<li><strong>Anti-Pattern Detection</strong>: REST violations, inconsistent naming, poor resource modeling</li>
<li><strong>Redundancy Detection</strong>: Duplicate endpoints, overlapping functionality</li>
<li><strong>Naming Quality Assessment</strong>: Inconsistent conventions, unclear names, abbreviations</li>
<li><strong>Emotional Tone Analysis</strong>: Error messages that are too vague, technical, or unfriendly</li>
<li><strong>Restructuring Recommendations</strong>: Better resource hierarchy, consolidation opportunities</li>
</ul>
<h2 id="usage-10"><a class="header" href="#usage-10">Usage</a></h2>
<h3 id="cli-commands-11"><a class="header" href="#cli-commands-11">CLI Commands</a></h3>
<pre><code class="language-bash"># Critique API schema
mockforge ai critique --spec openapi.json

# Critique with focus areas
mockforge ai critique --spec openapi.json --focus anti-patterns,naming

# Critique specific endpoint
mockforge ai critique --spec openapi.json --endpoint /api/users/{id}
</code></pre>
<h3 id="api-usage-5"><a class="header" href="#api-usage-5">API Usage</a></h3>
<pre><code class="language-bash"># Critique API
POST /api/v1/ai-studio/critique
{
  "schema": {...},
  "schema_type": "openapi",
  "focus_areas": ["anti-patterns", "naming", "tone"]
}
</code></pre>
<h3 id="ui-usage-1"><a class="header" href="#ui-usage-1">UI Usage</a></h3>
<p>Access via AI Studio page:</p>
<ol>
<li>Navigate to AI Studio</li>
<li>Select ‚ÄúAPI Critique‚Äù</li>
<li>Upload OpenAPI/GraphQL/Protobuf schema</li>
<li>Select focus areas</li>
<li>Review critique results</li>
</ol>
<h2 id="critique-results"><a class="header" href="#critique-results">Critique Results</a></h2>
<h3 id="example-critique"><a class="header" href="#example-critique">Example Critique</a></h3>
<pre><code class="language-json">{
  "anti_patterns": [
    {
      "pattern_type": "rest_violation",
      "severity": "high",
      "location": "/api/users/{id}/delete",
      "description": "DELETE endpoint should use DELETE method, not POST",
      "suggestion": "Change to DELETE /api/users/{id}",
      "example": "POST /api/users/{id}/delete ‚Üí DELETE /api/users/{id}"
    }
  ],
  "redundancies": [
    {
      "redundancy_type": "duplicate_endpoint",
      "severity": "medium",
      "affected_items": [
        "/api/users/list",
        "/api/users"
      ],
      "description": "Both endpoints return user lists",
      "suggestion": "Consolidate to /api/users"
    }
  ],
  "naming_issues": [
    {
      "issue_type": "inconsistent_convention",
      "severity": "low",
      "location": "user_id",
      "current_name": "user_id",
      "description": "Inconsistent: some fields use 'id', others use 'Id'",
      "suggestion": "Standardize to 'id' or 'Id'"
    }
  ],
  "tone_analysis": {
    "overall_tone": "technical",
    "error_message_issues": [
      {
        "issue_type": "too_vague",
        "severity": "medium",
        "location": "400 error",
        "current_text": "Bad request",
        "description": "Error message is too vague",
        "suggestion": "Provide specific error details: 'Invalid user ID format'"
      }
    ],
    "recommendations": [
      "Make error messages more user-friendly",
      "Provide actionable error details"
    ]
  },
  "restructuring": {
    "hierarchy_improvements": [
      {
        "current": "/api/users/{id}/orders/{order_id}",
        "suggested": "/api/orders/{order_id}?user_id={id}",
        "rationale": "Orders are top-level resources, not nested under users",
        "impact": "medium"
      }
    ],
    "consolidation_opportunities": [
      {
        "items": ["/api/users/list", "/api/users"],
        "description": "Duplicate user listing endpoints",
        "suggestion": "Use single /api/users endpoint with query parameters",
        "benefits": ["Simpler API", "Less maintenance"]
      }
    ]
  },
  "overall_score": 72.5,
  "summary": "API has good structure but needs improvements in REST compliance and error messaging."
}
</code></pre>
<h2 id="focus-areas"><a class="header" href="#focus-areas">Focus Areas</a></h2>
<h3 id="anti-patterns"><a class="header" href="#anti-patterns">Anti-Patterns</a></h3>
<p>Detects REST violations and design issues:</p>
<ul>
<li><strong>REST Violations</strong>: Wrong HTTP methods, non-RESTful patterns</li>
<li><strong>Inconsistent Naming</strong>: Mixed naming conventions</li>
<li><strong>Poor Resource Modeling</strong>: Incorrect resource hierarchy</li>
</ul>
<h3 id="redundancy"><a class="header" href="#redundancy">Redundancy</a></h3>
<p>Detects duplicate or overlapping functionality:</p>
<ul>
<li><strong>Duplicate Endpoints</strong>: Multiple endpoints doing the same thing</li>
<li><strong>Overlapping Functionality</strong>: Endpoints with significant overlap</li>
</ul>
<h3 id="naming-quality"><a class="header" href="#naming-quality">Naming Quality</a></h3>
<p>Assesses naming consistency and clarity:</p>
<ul>
<li><strong>Inconsistent Conventions</strong>: Mixed naming styles</li>
<li><strong>Unclear Names</strong>: Ambiguous or confusing names</li>
<li><strong>Abbreviations</strong>: Overuse of abbreviations</li>
</ul>
<h3 id="emotional-tone"><a class="header" href="#emotional-tone">Emotional Tone</a></h3>
<p>Analyzes user-facing text quality:</p>
<ul>
<li><strong>Error Messages</strong>: Too vague, technical, or unfriendly</li>
<li><strong>Descriptions</strong>: Unclear or unhelpful</li>
<li><strong>User-Facing Text</strong>: Tone and clarity issues</li>
</ul>
<h3 id="restructuring"><a class="header" href="#restructuring">Restructuring</a></h3>
<p>Recommends structural improvements:</p>
<ul>
<li><strong>Hierarchy Improvements</strong>: Better resource organization</li>
<li><strong>Consolidation Opportunities</strong>: Endpoints that can be merged</li>
<li><strong>Resource Modeling</strong>: Better resource design</li>
</ul>
<h2 id="real-world-examples-5"><a class="header" href="#real-world-examples-5">Real-World Examples</a></h2>
<h3 id="example-1-rest-violation"><a class="header" href="#example-1-rest-violation">Example 1: REST Violation</a></h3>
<p><strong>Anti-Pattern Detected:</strong></p>
<pre><code>POST /api/users/{id}/delete
</code></pre>
<p><strong>Issue:</strong> DELETE operation should use DELETE method.</p>
<p><strong>Suggestion:</strong></p>
<pre><code>DELETE /api/users/{id}
</code></pre>
<h3 id="example-2-redundancy"><a class="header" href="#example-2-redundancy">Example 2: Redundancy</a></h3>
<p><strong>Redundancy Detected:</strong></p>
<pre><code>GET /api/users/list
GET /api/users
</code></pre>
<p><strong>Issue:</strong> Both endpoints return user lists.</p>
<p><strong>Suggestion:</strong> Consolidate to <code>GET /api/users</code> with query parameters.</p>
<h3 id="example-3-naming-inconsistency"><a class="header" href="#example-3-naming-inconsistency">Example 3: Naming Inconsistency</a></h3>
<p><strong>Issue Detected:</strong></p>
<ul>
<li>Some fields: <code>user_id</code>, <code>order_id</code></li>
<li>Other fields: <code>userId</code>, <code>orderId</code></li>
</ul>
<p><strong>Suggestion:</strong> Standardize to one convention (e.g., <code>user_id</code>).</p>
<h3 id="example-4-error-message-tone"><a class="header" href="#example-4-error-message-tone">Example 4: Error Message Tone</a></h3>
<p><strong>Issue Detected:</strong></p>
<pre><code class="language-json">{
  "error": "Bad request"
}
</code></pre>
<p><strong>Issue:</strong> Too vague, not actionable.</p>
<p><strong>Suggestion:</strong></p>
<pre><code class="language-json">{
  "error": "Invalid user ID format. Expected UUID.",
  "code": "INVALID_USER_ID"
}
</code></pre>
<h2 id="configuration-31"><a class="header" href="#configuration-31">Configuration</a></h2>
<h3 id="enable-api-critique"><a class="header" href="#enable-api-critique">Enable API Critique</a></h3>
<pre><code class="language-yaml"># mockforge.yaml
ai_studio:
  api_critique:
    enabled: true
    default_focus_areas:
      - anti-patterns
      - redundancy
      - naming
      - tone
      - restructuring
</code></pre>
<h3 id="llm-configuration-1"><a class="header" href="#llm-configuration-1">LLM Configuration</a></h3>
<pre><code class="language-yaml">ai_studio:
  api_critique:
    enabled: true
    llm:
      provider: openai
      model: gpt-4
      temperature: 0.3
</code></pre>
<h2 id="best-practices-53"><a class="header" href="#best-practices-53">Best Practices</a></h2>
<ol>
<li><strong>Run Early</strong>: Critique APIs during design phase</li>
<li><strong>Focus Areas</strong>: Select relevant focus areas</li>
<li><strong>Review Recommendations</strong>: AI suggestions are helpful but review manually</li>
<li><strong>Iterate</strong>: Use critique to improve API design</li>
<li><strong>Track Scores</strong>: Monitor overall scores over time</li>
</ol>
<h2 id="related-documentation-37"><a class="header" href="#related-documentation-37">Related Documentation</a></h2>
<ul>
<li><a href="user-guide/ai/../../user-guide/llm-studio.html">AI Studio</a> - AI features overview</li>
<li><a href="user-guide/ai/system-generation.html">System Generation</a> - NL to system generation</li>
<li><a href="user-guide/ai/behavioral-simulation.html">Behavioral Simulation</a> - AI behavioral simulation</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="natural-language-to-system-generation"><a class="header" href="#natural-language-to-system-generation">Natural Language to System Generation</a></h1>
<p><strong>Pillars:</strong> [AI]</p>
<p>Natural Language to System Generation allows you to describe your product in natural language and MockForge generates an entire backend system including endpoints, personas, lifecycle states, WebSocket topics, failure scenarios, and more.</p>
<h2 id="overview-48"><a class="header" href="#overview-48">Overview</a></h2>
<p>Instead of manually creating APIs, describe your product and get:</p>
<ul>
<li><strong>20-30 REST endpoints</strong> (OpenAPI 3.1 spec)</li>
<li><strong>4-5 personas</strong> (based on roles)</li>
<li><strong>6-10 lifecycle states</strong> (state machines)</li>
<li><strong>WebSocket topics</strong> (if real-time features mentioned)</li>
<li><strong>Payment failure scenarios</strong></li>
<li><strong>Surge pricing chaos profiles</strong></li>
<li><strong>Full OpenAPI specification</strong></li>
<li><strong>Mock backend configuration</strong> (mockforge.yaml)</li>
<li><strong>GraphQL schema</strong> (optional)</li>
<li><strong>Typings</strong> (TypeScript/Go/Rust)</li>
<li><strong>CI pipeline templates</strong> (GitHub Actions, GitLab CI)</li>
</ul>
<p>This becomes <strong>a way to bootstrap an entire startup backend</strong>.</p>
<h2 id="quick-start-25"><a class="header" href="#quick-start-25">Quick Start</a></h2>
<h3 id="basic-usage-2"><a class="header" href="#basic-usage-2">Basic Usage</a></h3>
<pre><code class="language-bash"># Generate system from natural language
mockforge ai generate-system \
  "I'm building a ride-sharing app with drivers, riders, trips, payments, live-location updates, pricing, and surge events."
</code></pre>
<h3 id="via-ai-studio"><a class="header" href="#via-ai-studio">Via AI Studio</a></h3>
<ol>
<li>Navigate to AI Studio</li>
<li>Select ‚ÄúSystem Generation‚Äù</li>
<li>Enter your product description</li>
<li>Select output formats</li>
<li>Generate system</li>
</ol>
<h2 id="example-ride-sharing-app"><a class="header" href="#example-ride-sharing-app">Example: Ride-Sharing App</a></h2>
<h3 id="input"><a class="header" href="#input">Input</a></h3>
<pre><code>I'm building a ride-sharing app with drivers, riders, trips, payments, 
live-location updates, pricing, and surge events.
</code></pre>
<h3 id="generated-output"><a class="header" href="#generated-output">Generated Output</a></h3>
<h4 id="openapi-specification"><a class="header" href="#openapi-specification">OpenAPI Specification</a></h4>
<pre><code class="language-yaml">openapi: 3.1.0
info:
  title: Ride-Sharing API
  version: 1.0.0
paths:
  /api/drivers:
    get:
      summary: List drivers
      responses:
        '200':
          description: List of drivers
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: '#/components/schemas/Driver'
  /api/riders:
    get:
      summary: List riders
      # ... more endpoints
  /api/trips:
    post:
      summary: Create trip
      # ... more endpoints
  /api/payments:
    post:
      summary: Process payment
      # ... more endpoints
</code></pre>
<h4 id="personas"><a class="header" href="#personas">Personas</a></h4>
<pre><code class="language-yaml">personas:
  - id: driver:premium-001
    name: Premium Driver
    domain: ridesharing
    traits:
      vehicle_type: premium
      rating: 4.9
      total_trips: 500
  - id: rider:frequent-002
    name: Frequent Rider
    domain: ridesharing
    traits:
      ride_frequency: high
      preferred_payment: credit_card
</code></pre>
<h4 id="lifecycle-states"><a class="header" href="#lifecycle-states">Lifecycle States</a></h4>
<pre><code class="language-yaml">lifecycles:
  - entity: trip
    states:
      - requested
      - matched
      - in_progress
      - completed
      - cancelled
    transitions:
      - from: requested
        to: matched
        condition: driver_accepts
      - from: matched
        to: in_progress
        condition: trip_starts
</code></pre>
<h4 id="websocket-topics"><a class="header" href="#websocket-topics">WebSocket Topics</a></h4>
<pre><code class="language-yaml">websocket_topics:
  - topic: location_updates
    event_types:
      - driver_location
      - rider_location
  - topic: trip_status
    event_types:
      - trip_requested
      - trip_matched
      - trip_completed
  - topic: surge_alerts
    event_types:
      - surge_started
      - surge_ended
</code></pre>
<h4 id="chaos-profiles"><a class="header" href="#chaos-profiles">Chaos Profiles</a></h4>
<pre><code class="language-yaml">chaos_profiles:
  - name: payment_failure
    type: payment_failure
    config:
      failure_scenarios:
        - insufficient_funds
        - card_declined
        - network_error
  - name: surge_pricing
    type: surge_pricing
    config:
      peak_hours:
        - "08:00-10:00"
        - "17:00-19:00"
      surge_multipliers: [1.5, 2.0, 3.0]
</code></pre>
<h2 id="output-formats"><a class="header" href="#output-formats">Output Formats</a></h2>
<h3 id="openapi-specification-1"><a class="header" href="#openapi-specification-1">OpenAPI Specification</a></h3>
<p>Full OpenAPI 3.1 specification with:</p>
<ul>
<li>All endpoints</li>
<li>Request/response schemas</li>
<li>Authentication</li>
<li>Error responses</li>
</ul>
<h3 id="personas-1"><a class="header" href="#personas-1">Personas</a></h3>
<p>4-5 personas based on roles:</p>
<ul>
<li>Driver personas</li>
<li>Rider personas</li>
<li>Admin personas</li>
<li>Support personas</li>
</ul>
<h3 id="lifecycle-states-1"><a class="header" href="#lifecycle-states-1">Lifecycle States</a></h3>
<p>6-10 lifecycle states for main entities:</p>
<ul>
<li>Trip lifecycle</li>
<li>Payment lifecycle</li>
<li>Driver lifecycle</li>
<li>Rider lifecycle</li>
</ul>
<h3 id="websocket-topics-1"><a class="header" href="#websocket-topics-1">WebSocket Topics</a></h3>
<p>If real-time features are mentioned:</p>
<ul>
<li>Topic names</li>
<li>Event types</li>
<li>Event schemas</li>
</ul>
<h3 id="chaos-profiles-1"><a class="header" href="#chaos-profiles-1">Chaos Profiles</a></h3>
<p>Failure and edge case scenarios:</p>
<ul>
<li>Payment failures</li>
<li>Network errors</li>
<li>Surge pricing</li>
<li>Service outages</li>
</ul>
<h3 id="cicd-templates"><a class="header" href="#cicd-templates">CI/CD Templates</a></h3>
<p>GitHub Actions and GitLab CI templates:</p>
<ul>
<li>Test workflows</li>
<li>Deployment workflows</li>
<li>Integration tests</li>
</ul>
<h3 id="graphql-schema"><a class="header" href="#graphql-schema">GraphQL Schema</a></h3>
<p>Optional GraphQL schema:</p>
<ul>
<li>Type definitions</li>
<li>Queries</li>
<li>Mutations</li>
</ul>
<h3 id="typings"><a class="header" href="#typings">Typings</a></h3>
<p>Type definitions:</p>
<ul>
<li>TypeScript</li>
<li>Go</li>
<li>Rust</li>
<li>Python</li>
</ul>
<h2 id="advanced-features-6"><a class="header" href="#advanced-features-6">Advanced Features</a></h2>
<h3 id="versioned-artifacts"><a class="header" href="#versioned-artifacts">Versioned Artifacts</a></h3>
<p>Generated artifacts are versioned (v1, v2, etc.) and never mutate existing:</p>
<pre><code>generated/
‚îú‚îÄ‚îÄ v1/
‚îÇ   ‚îú‚îÄ‚îÄ openapi.json
‚îÇ   ‚îú‚îÄ‚îÄ personas.yaml
‚îÇ   ‚îî‚îÄ‚îÄ scenarios.yaml
‚îî‚îÄ‚îÄ v2/
    ‚îú‚îÄ‚îÄ openapi.json
    ‚îú‚îÄ‚îÄ personas.yaml
    ‚îî‚îÄ‚îÄ scenarios.yaml
</code></pre>
<h3 id="deterministic-mode"><a class="header" href="#deterministic-mode">Deterministic Mode</a></h3>
<p>Honors workspace <code>ai.deterministic_mode</code> setting:</p>
<pre><code class="language-yaml">ai:
  deterministic_mode:
    enabled: true
    auto_freeze: true
    freeze_format: yaml
</code></pre>
<p>When enabled, AI outputs are frozen to deterministic YAML/JSON.</p>
<h3 id="system-coherence-validation"><a class="header" href="#system-coherence-validation">System Coherence Validation</a></h3>
<p>Ensures all generated components are coherent:</p>
<ul>
<li>Personas match endpoints</li>
<li>Lifecycles match entities</li>
<li>Scenarios match personas</li>
<li>WebSocket topics match real-time features</li>
</ul>
<h2 id="configuration-32"><a class="header" href="#configuration-32">Configuration</a></h2>
<h3 id="enable-system-generation"><a class="header" href="#enable-system-generation">Enable System Generation</a></h3>
<pre><code class="language-yaml"># mockforge.yaml
ai_studio:
  system_generation:
    enabled: true
    default_output_formats:
      - openapi
      - personas
      - lifecycles
      - scenarios
</code></pre>
<h3 id="output-format-selection"><a class="header" href="#output-format-selection">Output Format Selection</a></h3>
<pre><code class="language-bash"># Generate with specific formats
mockforge ai generate-system \
  "Description..." \
  --formats openapi,personas,lifecycles,graphql
</code></pre>
<h2 id="best-practices-54"><a class="header" href="#best-practices-54">Best Practices</a></h2>
<ol>
<li><strong>Be Specific</strong>: Detailed descriptions yield better results</li>
<li><strong>Mention Roles</strong>: Include user roles (drivers, riders, admins)</li>
<li><strong>Specify Features</strong>: Mention real-time, payments, etc.</li>
<li><strong>Review Generated</strong>: Always review and refine generated artifacts</li>
<li><strong>Iterate</strong>: Generate multiple versions and compare</li>
</ol>
<h2 id="real-world-examples-6"><a class="header" href="#real-world-examples-6">Real-World Examples</a></h2>
<h3 id="e-commerce-platform-1"><a class="header" href="#e-commerce-platform-1">E-Commerce Platform</a></h3>
<p><strong>Input:</strong></p>
<pre><code>E-commerce platform with products, shopping cart, orders, payments, 
inventory management, shipping, and customer reviews.
</code></pre>
<p><strong>Generated:</strong></p>
<ul>
<li>25 REST endpoints</li>
<li>5 personas (customer, admin, vendor, support, reviewer)</li>
<li>8 lifecycle states (order, payment, shipping)</li>
<li>WebSocket topics (order_updates, inventory_alerts)</li>
<li>Payment failure scenarios</li>
<li>Inventory depletion chaos profiles</li>
</ul>
<h3 id="saas-platform"><a class="header" href="#saas-platform">SaaS Platform</a></h3>
<p><strong>Input:</strong></p>
<pre><code>SaaS platform with users, subscriptions, billing, teams, projects, 
tasks, and real-time collaboration.
</code></pre>
<p><strong>Generated:</strong></p>
<ul>
<li>30 REST endpoints</li>
<li>6 personas (admin, owner, member, viewer, billing_admin, support)</li>
<li>10 lifecycle states (subscription, project, task)</li>
<li>WebSocket topics (collaboration_updates, task_updates)</li>
<li>Billing failure scenarios</li>
<li>Subscription lifecycle chaos profiles</li>
</ul>
<h2 id="related-documentation-38"><a class="header" href="#related-documentation-38">Related Documentation</a></h2>
<ul>
<li><a href="user-guide/ai/llm-studio.html">AI Studio</a> - AI features overview</li>
<li><a href="user-guide/ai/api-architecture-critique.html">API Architecture Critique</a> - API analysis</li>
<li><a href="user-guide/ai/behavioral-simulation.html">Behavioral Simulation</a> - AI behavioral simulation</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="ai-behavioral-simulation-engine"><a class="header" href="#ai-behavioral-simulation-engine">AI Behavioral Simulation Engine</a></h1>
<p><strong>Pillars:</strong> [AI]</p>
<p>The AI Behavioral Simulation Engine models users as narrative agents that react to app state, form intentions, respond to errors, and trigger multi-step interactions automatically. MockForge becomes <strong>an AI user simulator</strong>‚Äînot just an API simulator.</p>
<h2 id="overview-49"><a class="header" href="#overview-49">Overview</a></h2>
<p>Traditional mocks return static responses. The Behavioral Simulation Engine creates <strong>narrative agents</strong> that:</p>
<ul>
<li><strong>React to app state</strong> (e.g., ‚Äúcart is empty‚Äù ‚Üí intention: ‚Äúbrowse products‚Äù)</li>
<li><strong>Form intentions</strong> (shop, browse, buy, abandon, retry, navigate, search, compare, review)</li>
<li><strong>Respond to errors</strong> (rage clicking on 500 errors, retry logic, cart abandonment on payment failure)</li>
<li><strong>Trigger multi-step interactions</strong> automatically</li>
<li><strong>Maintain session context</strong> across interactions</li>
</ul>
<h2 id="key-concepts-3"><a class="header" href="#key-concepts-3">Key Concepts</a></h2>
<h3 id="narrative-agents"><a class="header" href="#narrative-agents">Narrative Agents</a></h3>
<p>Agents are AI-powered personas that simulate user behavior:</p>
<pre><code class="language-yaml">agent:
  agent_id: "agent-123"
  persona_id: "customer:premium-001"
  current_intention: "shop"
  behavioral_traits:
    patience: 0.7
    risk_tolerance: 0.5
    price_sensitivity: 0.3
  state_awareness:
    cart_empty: true
    last_error: null
    session_duration: 120
</code></pre>
<h3 id="intentions"><a class="header" href="#intentions">Intentions</a></h3>
<p>Agents form intentions based on state:</p>
<ul>
<li><strong>Browse</strong>: Explore products/content</li>
<li><strong>Shop</strong>: Actively looking to purchase</li>
<li><strong>Buy</strong>: Ready to complete purchase</li>
<li><strong>Abandon</strong>: Leave due to frustration/error</li>
<li><strong>Retry</strong>: Retry after error</li>
<li><strong>Navigate</strong>: Move to different section</li>
<li><strong>Search</strong>: Search for something</li>
<li><strong>Compare</strong>: Compare options</li>
<li><strong>Review</strong>: Review/read content</li>
</ul>
<h3 id="behavior-policies"><a class="header" href="#behavior-policies">Behavior Policies</a></h3>
<p>Policies define how agents behave:</p>
<ul>
<li><strong>bargain-hunter</strong>: Price-sensitive, compares options</li>
<li><strong>power-user</strong>: Efficient, knows the system</li>
<li><strong>churn-risk</strong>: Frustrated, likely to abandon</li>
<li><strong>new-user</strong>: Exploring, needs guidance</li>
</ul>
<h2 id="usage-11"><a class="header" href="#usage-11">Usage</a></h2>
<h3 id="create-agent"><a class="header" href="#create-agent">Create Agent</a></h3>
<pre><code class="language-bash"># Create agent from persona
mockforge ai behavioral-sim create-agent \
  --persona customer:premium-001 \
  --policy power-user

# Or via API
POST /api/v1/ai-studio/simulate-behavior/create-agent
{
  "persona_id": "customer:premium-001",
  "behavior_policy": "power-user",
  "generate_persona": false
}
</code></pre>
<h3 id="simulate-behavior"><a class="header" href="#simulate-behavior">Simulate Behavior</a></h3>
<pre><code class="language-bash"># Simulate agent behavior
mockforge ai behavioral-sim simulate \
  --agent agent-123 \
  --state '{"cart_empty": true}' \
  --trigger "user_landed_on_homepage"
</code></pre>
<h3 id="via-ui"><a class="header" href="#via-ui">Via UI</a></h3>
<ol>
<li>Navigate to AI Studio</li>
<li>Select ‚ÄúBehavioral Simulation‚Äù</li>
<li>Create or select agent</li>
<li>Set app state</li>
<li>Trigger event</li>
<li>Observe agent behavior</li>
</ol>
<h2 id="example-workflows"><a class="header" href="#example-workflows">Example Workflows</a></h2>
<h3 id="example-1-cart-abandonment"><a class="header" href="#example-1-cart-abandonment">Example 1: Cart Abandonment</a></h3>
<p><strong>State:</strong></p>
<pre><code class="language-json">{
  "cart_empty": true,
  "last_action": "viewed_product",
  "session_duration": 300
}
</code></pre>
<p><strong>Trigger:</strong> <code>user_viewed_product</code></p>
<p><strong>Agent Behavior:</strong></p>
<ul>
<li>Intention: <code>browse</code></li>
<li>Action: <code>GET /api/products?category=electronics</code></li>
<li>Reasoning: ‚ÄúUser is browsing, likely looking for products to add to cart‚Äù</li>
</ul>
<h3 id="example-2-payment-failure-response"><a class="header" href="#example-2-payment-failure-response">Example 2: Payment Failure Response</a></h3>
<p><strong>State:</strong></p>
<pre><code class="language-json">{
  "cart_total": 99.99,
  "payment_attempts": 1,
  "last_error": "payment_failed"
}
</code></pre>
<p><strong>Trigger:</strong> <code>payment_failed</code></p>
<p><strong>Agent Behavior:</strong></p>
<ul>
<li>Intention: <code>retry</code></li>
<li>Action: <code>POST /api/payments/retry</code></li>
<li>Reasoning: ‚ÄúUser will retry payment once, then abandon if it fails again‚Äù</li>
</ul>
<h3 id="example-3-error-rage-clicking"><a class="header" href="#example-3-error-rage-clicking">Example 3: Error Rage Clicking</a></h3>
<p><strong>State:</strong></p>
<pre><code class="language-json">{
  "error_count": 3,
  "last_error": "500",
  "session_duration": 60
}
</code></pre>
<p><strong>Trigger:</strong> <code>error_occurred</code></p>
<p><strong>Agent Behavior:</strong></p>
<ul>
<li>Intention: <code>abandon</code></li>
<li>Action: <code>navigate_away</code></li>
<li>Reasoning: ‚ÄúMultiple errors frustrate user, likely to abandon‚Äù</li>
</ul>
<h2 id="behavior-policies-1"><a class="header" href="#behavior-policies-1">Behavior Policies</a></h2>
<h3 id="bargain-hunter"><a class="header" href="#bargain-hunter">Bargain Hunter</a></h3>
<pre><code class="language-yaml">behavior_policy: bargain-hunter
traits:
  price_sensitivity: 0.9
  comparison_tendency: 0.8
  patience: 0.6
behaviors:
  - always_compares_prices
  - waits_for_discounts
  - abandons_on_high_price
</code></pre>
<h3 id="power-user"><a class="header" href="#power-user">Power User</a></h3>
<pre><code class="language-yaml">behavior_policy: power-user
traits:
  efficiency: 0.9
  system_knowledge: 0.8
  patience: 0.7
behaviors:
  - uses_shortcuts
  - expects_fast_responses
  - retries_on_errors
</code></pre>
<h3 id="churn-risk"><a class="header" href="#churn-risk">Churn Risk</a></h3>
<pre><code class="language-yaml">behavior_policy: churn-risk
traits:
  frustration: 0.8
  patience: 0.3
  loyalty: 0.4
behaviors:
  - abandons_on_errors
  - sensitive_to_latency
  - likely_to_churn
</code></pre>
<h2 id="integration-with-personas"><a class="header" href="#integration-with-personas">Integration with Personas</a></h2>
<p>Agents can be attached to existing Smart Personas:</p>
<pre><code class="language-yaml">persona:
  id: customer:premium-001
  traits:
    subscription_tier: premium
    spending_level: high
  behavioral_simulation:
    enabled: true
    policy: power-user
</code></pre>
<h2 id="configuration-33"><a class="header" href="#configuration-33">Configuration</a></h2>
<h3 id="enable-behavioral-simulation"><a class="header" href="#enable-behavioral-simulation">Enable Behavioral Simulation</a></h3>
<pre><code class="language-yaml"># mockforge.yaml
ai_studio:
  behavioral_simulation:
    enabled: true
    default_policy: power-user
    llm:
      provider: openai
      model: gpt-4
      temperature: 0.7
</code></pre>
<h2 id="best-practices-55"><a class="header" href="#best-practices-55">Best Practices</a></h2>
<ol>
<li><strong>Start with Policies</strong>: Use pre-built policies before creating custom</li>
<li><strong>Test Scenarios</strong>: Test agents with various app states</li>
<li><strong>Monitor Behavior</strong>: Track agent behavior patterns</li>
<li><strong>Refine Policies</strong>: Adjust policies based on observed behavior</li>
<li><strong>Combine with Personas</strong>: Use Smart Personas for realistic agents</li>
</ol>
<h2 id="related-documentation-39"><a class="header" href="#related-documentation-39">Related Documentation</a></h2>
<ul>
<li><a href="user-guide/ai/smart-personas.html">Smart Personas</a> - Persona system</li>
<li><a href="user-guide/ai/llm-studio.html">AI Studio</a> - AI features overview</li>
<li><a href="user-guide/ai/system-generation.html">System Generation</a> - NL to system generation</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="environment-variables-14"><a class="header" href="#environment-variables-14">Environment Variables</a></h1>
<p>MockForge supports extensive configuration through environment variables. This page documents all available environment variables, their purposes, and usage examples.</p>
<h2 id="core-functionality"><a class="header" href="#core-functionality">Core Functionality</a></h2>
<h3 id="server-control-1"><a class="header" href="#server-control-1">Server Control</a></h3>
<ul>
<li>
<p><code>MOCKFORGE_LATENCY_ENABLED=true|false</code> (default: <code>true</code>)</p>
<ul>
<li>Enable/disable response latency simulation</li>
<li>When disabled, responses are immediate</li>
</ul>
</li>
<li>
<p><code>MOCKFORGE_FAILURES_ENABLED=true|false</code> (default: <code>false</code>)</p>
<ul>
<li>Enable/disable failure injection</li>
<li>When enabled, can simulate HTTP errors and timeouts</li>
</ul>
</li>
<li>
<p><code>MOCKFORGE_LOG_LEVEL=debug|info|warn|error</code> (default: <code>info</code>)</p>
<ul>
<li>Set the logging verbosity level</li>
<li>Available: <code>debug</code>, <code>info</code>, <code>warn</code>, <code>error</code></li>
</ul>
</li>
</ul>
<h3 id="recording-and-replay"><a class="header" href="#recording-and-replay">Recording and Replay</a></h3>
<ul>
<li>
<p><code>MOCKFORGE_RECORD_ENABLED=true|false</code> (default: <code>false</code>)</p>
<ul>
<li>Enable recording of HTTP requests as fixtures</li>
<li>Recorded fixtures can be replayed later</li>
</ul>
</li>
<li>
<p><code>MOCKFORGE_REPLAY_ENABLED=true|false</code> (default: <code>false</code>)</p>
<ul>
<li>Enable replay of recorded fixtures</li>
<li>When enabled, serves recorded responses instead of generating new ones</li>
</ul>
</li>
<li>
<p><code>MOCKFORGE_PROXY_ENABLED=true|false</code> (default: <code>false</code>)</p>
<ul>
<li>Enable proxy mode for forwarding requests</li>
<li>Useful for testing against real APIs</li>
</ul>
</li>
</ul>
<h2 id="http-server-configuration"><a class="header" href="#http-server-configuration">HTTP Server Configuration</a></h2>
<h3 id="server-settings-1"><a class="header" href="#server-settings-1">Server Settings</a></h3>
<ul>
<li>
<p><code>MOCKFORGE_HTTP_PORT=3000</code> (default: <code>3000</code>)</p>
<ul>
<li>Port for the HTTP server to listen on</li>
</ul>
</li>
<li>
<p><code>MOCKFORGE_HTTP_HOST=127.0.0.1</code> (default: <code>0.0.0.0</code>)</p>
<ul>
<li>Host address for the HTTP server to bind to</li>
</ul>
</li>
<li>
<p><code>MOCKFORGE_CORS_ENABLED=true|false</code> (default: <code>true</code>)</p>
<ul>
<li>Enable/disable CORS headers in responses</li>
</ul>
</li>
<li>
<p><code>MOCKFORGE_REQUEST_TIMEOUT_SECS=30</code> (default: <code>30</code>)</p>
<ul>
<li>Timeout for HTTP requests in seconds</li>
</ul>
</li>
</ul>
<h3 id="openapi-integration-2"><a class="header" href="#openapi-integration-2">OpenAPI Integration</a></h3>
<ul>
<li><code>MOCKFORGE_HTTP_OPENAPI_SPEC=path/to/spec.json</code>
<ul>
<li>Path to OpenAPI specification file</li>
<li>Enables automatic endpoint generation from OpenAPI spec</li>
</ul>
</li>
</ul>
<h3 id="validation-and-templating"><a class="header" href="#validation-and-templating">Validation and Templating</a></h3>
<ul>
<li>
<p><code>MOCKFORGE_REQUEST_VALIDATION=enforce|warn|off</code> (default: <code>enforce</code>)</p>
<ul>
<li>Level of request validation</li>
<li><code>enforce</code>: Reject invalid requests with error</li>
<li><code>warn</code>: Log warnings but allow requests</li>
<li><code>off</code>: Skip validation entirely</li>
</ul>
</li>
<li>
<p><code>MOCKFORGE_RESPONSE_VALIDATION=true|false</code> (default: <code>false</code>)</p>
<ul>
<li>Enable validation of generated responses</li>
<li>Useful for ensuring response format compliance</li>
</ul>
</li>
<li>
<p><code>MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true|false</code> (default: <code>false</code>)</p>
<ul>
<li>Enable template expansion in responses</li>
<li>Allows use of <code>{{uuid}}</code>, <code>{{now}}</code>, etc. in responses</li>
</ul>
</li>
<li>
<p><code>MOCKFORGE_AGGREGATE_ERRORS=true|false</code> (default: <code>true</code>)</p>
<ul>
<li>Aggregate multiple validation errors into a single response</li>
<li>When enabled, returns all validation errors at once</li>
</ul>
</li>
<li>
<p><code>MOCKFORGE_VALIDATION_STATUS=400|422</code> (default: <code>400</code>)</p>
<ul>
<li>HTTP status code for validation errors</li>
<li><code>400</code>: Bad Request (general)</li>
<li><code>422</code>: Unprocessable Entity (validation-specific)</li>
</ul>
</li>
</ul>
<h2 id="websocket-server-configuration"><a class="header" href="#websocket-server-configuration">WebSocket Server Configuration</a></h2>
<h3 id="server-settings-2"><a class="header" href="#server-settings-2">Server Settings</a></h3>
<ul>
<li>
<p><code>MOCKFORGE_WS_PORT=3001</code> (default: <code>3001</code>)</p>
<ul>
<li>Port for the WebSocket server to listen on</li>
</ul>
</li>
<li>
<p><code>MOCKFORGE_WS_HOST=127.0.0.1</code> (default: <code>0.0.0.0</code>)</p>
<ul>
<li>Host address for the WebSocket server to bind to</li>
</ul>
</li>
<li>
<p><code>MOCKFORGE_WS_CONNECTION_TIMEOUT_SECS=300</code> (default: <code>300</code>)</p>
<ul>
<li>WebSocket connection timeout in seconds</li>
</ul>
</li>
</ul>
<h3 id="replay-configuration"><a class="header" href="#replay-configuration">Replay Configuration</a></h3>
<ul>
<li><code>MOCKFORGE_WS_REPLAY_FILE=path/to/replay.jsonl</code>
<ul>
<li>Path to WebSocket replay file</li>
<li>Enables scripted WebSocket message sequences</li>
</ul>
</li>
</ul>
<h2 id="grpc-server-configuration"><a class="header" href="#grpc-server-configuration">gRPC Server Configuration</a></h2>
<h3 id="server-settings-3"><a class="header" href="#server-settings-3">Server Settings</a></h3>
<ul>
<li>
<p><code>MOCKFORGE_GRPC_PORT=50051</code> (default: <code>50051</code>)</p>
<ul>
<li>Port for the gRPC server to listen on</li>
</ul>
</li>
<li>
<p><code>MOCKFORGE_GRPC_HOST=127.0.0.1</code> (default: <code>0.0.0.0</code>)</p>
<ul>
<li>Host address for the gRPC server to bind to</li>
</ul>
</li>
</ul>
<h2 id="admin-ui-configuration"><a class="header" href="#admin-ui-configuration">Admin UI Configuration</a></h2>
<h3 id="server-settings-4"><a class="header" href="#server-settings-4">Server Settings</a></h3>
<ul>
<li>
<p><code>MOCKFORGE_ADMIN_ENABLED=true|false</code> (default: <code>false</code>)</p>
<ul>
<li>Enable/disable the Admin UI</li>
<li>When enabled, provides web interface for management</li>
</ul>
</li>
<li>
<p><code>MOCKFORGE_ADMIN_PORT=9080</code> (default: <code>9080</code>)</p>
<ul>
<li>Port for the Admin UI server to listen on</li>
</ul>
</li>
<li>
<p><code>MOCKFORGE_ADMIN_HOST=127.0.0.1</code> (default: <code>127.0.0.1</code>)</p>
<ul>
<li>Host address for the Admin UI server to bind to</li>
</ul>
</li>
</ul>
<h3 id="ui-configuration"><a class="header" href="#ui-configuration">UI Configuration</a></h3>
<ul>
<li>
<p><code>MOCKFORGE_ADMIN_MOUNT_PATH=/admin</code> (default: none)</p>
<ul>
<li>Mount path for embedded Admin UI</li>
<li>When set, Admin UI is available under HTTP server</li>
</ul>
</li>
<li>
<p><code>MOCKFORGE_ADMIN_API_ENABLED=true|false</code> (default: <code>true</code>)</p>
<ul>
<li>Enable/disable Admin UI API endpoints</li>
<li>Controls whether <code>/__mockforge/*</code> endpoints are available</li>
</ul>
</li>
</ul>
<h2 id="data-generation-configuration"><a class="header" href="#data-generation-configuration">Data Generation Configuration</a></h2>
<h3 id="faker-control"><a class="header" href="#faker-control">Faker Control</a></h3>
<ul>
<li>
<p><code>MOCKFORGE_RAG_ENABLED=true|false</code> (default: <code>false</code>)</p>
<ul>
<li>Enable Retrieval-Augmented Generation for data</li>
<li>Requires additional setup for LLM integration</li>
</ul>
</li>
<li>
<p><code>MOCKFORGE_FAKE_TOKENS=true|false</code> (default: <code>true</code>)</p>
<ul>
<li>Enable/disable faker token expansion</li>
<li>Controls whether <code>{{faker.email}}</code> etc. work</li>
</ul>
</li>
</ul>
<h2 id="fixtures-and-testing"><a class="header" href="#fixtures-and-testing">Fixtures and Testing</a></h2>
<h3 id="fixtures-configuration"><a class="header" href="#fixtures-configuration">Fixtures Configuration</a></h3>
<ul>
<li>
<p><code>MOCKFORGE_FIXTURES_DIR=path/to/fixtures</code> (default: <code>./fixtures</code>)</p>
<ul>
<li>Directory where fixtures are stored</li>
<li>Used for recording and replaying HTTP requests</li>
</ul>
</li>
<li>
<p><code>MOCKFORGE_RECORD_GET_ONLY=true|false</code> (default: <code>false</code>)</p>
<ul>
<li>When recording, only record GET requests</li>
<li>Reduces fixture file size for read-only APIs</li>
</ul>
</li>
</ul>
<h2 id="configuration-files"><a class="header" href="#configuration-files">Configuration Files</a></h2>
<h3 id="configuration-loading"><a class="header" href="#configuration-loading">Configuration Loading</a></h3>
<ul>
<li><code>MOCKFORGE_CONFIG_FILE=path/to/config.yaml</code>
<ul>
<li>Path to YAML configuration file</li>
<li>Alternative to environment variables</li>
</ul>
</li>
</ul>
<h2 id="usage-examples-2"><a class="header" href="#usage-examples-2">Usage Examples</a></h2>
<h3 id="basic-http-server-with-openapi"><a class="header" href="#basic-http-server-with-openapi">Basic HTTP Server with OpenAPI</a></h3>
<pre><code class="language-bash">export MOCKFORGE_HTTP_OPENAPI_SPEC=examples/openapi-demo.json
export MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true
export MOCKFORGE_ADMIN_ENABLED=true
cargo run -p mockforge-cli -- serve --http-port 3000 --admin-port 9080
</code></pre>
<h3 id="full-websocket-support"><a class="header" href="#full-websocket-support">Full WebSocket Support</a></h3>
<pre><code class="language-bash">export MOCKFORGE_WS_REPLAY_FILE=examples/ws-demo.jsonl
export MOCKFORGE_WS_PORT=3001
export MOCKFORGE_HTTP_OPENAPI_SPEC=examples/openapi-demo.json
export MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true
cargo run -p mockforge-cli -- serve --admin
</code></pre>
<h3 id="development-setup-1"><a class="header" href="#development-setup-1">Development Setup</a></h3>
<pre><code class="language-bash">export MOCKFORGE_LOG_LEVEL=debug
export MOCKFORGE_LATENCY_ENABLED=false
export MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true
export MOCKFORGE_ADMIN_ENABLED=true
export MOCKFORGE_HTTP_OPENAPI_SPEC=examples/openapi-demo.json
cargo run -p mockforge-cli -- serve
</code></pre>
<h3 id="production-setup-1"><a class="header" href="#production-setup-1">Production Setup</a></h3>
<pre><code class="language-bash">export MOCKFORGE_LOG_LEVEL=warn
export MOCKFORGE_LATENCY_ENABLED=true
export MOCKFORGE_FAILURES_ENABLED=false
export MOCKFORGE_REQUEST_VALIDATION=enforce
export MOCKFORGE_ADMIN_ENABLED=false
export MOCKFORGE_HTTP_OPENAPI_SPEC=path/to/production-spec.json
cargo run -p mockforge-cli -- serve --http-port 80
</code></pre>
<h2 id="environment-variable-priority"><a class="header" href="#environment-variable-priority">Environment Variable Priority</a></h2>
<p>Environment variables override configuration file settings. CLI flags take precedence over both. The priority order is:</p>
<ol>
<li>CLI flags (highest priority)</li>
<li>Environment variables</li>
<li>Configuration file settings</li>
<li>Default values (lowest priority)</li>
</ol>
<h2 id="security-considerations-6"><a class="header" href="#security-considerations-6">Security Considerations</a></h2>
<ul>
<li>Be careful with <code>MOCKFORGE_ADMIN_ENABLED=true</code> in production</li>
<li>Consider setting restrictive host bindings (<code>127.0.0.1</code>) for internal use</li>
<li>Use <code>MOCKFORGE_FAKE_TOKENS=false</code> for deterministic testing</li>
<li>Review <code>MOCKFORGE_CORS_ENABLED</code> settings for cross-origin requests</li>
</ul>
<h2 id="troubleshooting-56"><a class="header" href="#troubleshooting-56">Troubleshooting</a></h2>
<h3 id="common-issues-12"><a class="header" href="#common-issues-12">Common Issues</a></h3>
<ol>
<li>
<p><strong>Environment variables not taking effect</strong></p>
<ul>
<li>Check variable names for typos</li>
<li>Ensure variables are exported before running the command</li>
<li>Use <code>env | grep MOCKFORGE</code> to verify variables are set</li>
</ul>
</li>
<li>
<p><strong>Port conflicts</strong></p>
<ul>
<li>Use different ports via <code>MOCKFORGE_HTTP_PORT</code>, <code>MOCKFORGE_WS_PORT</code>, etc.</li>
<li>Check what processes are using ports with <code>netstat -tlnp</code></li>
</ul>
</li>
<li>
<p><strong>OpenAPI spec not loading</strong></p>
<ul>
<li>Verify file path in <code>MOCKFORGE_HTTP_OPENAPI_SPEC</code></li>
<li>Ensure JSON/YAML syntax is valid</li>
<li>Check file permissions</li>
</ul>
</li>
<li>
<p><strong>Template expansion not working</strong></p>
<ul>
<li>Set <code>MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true</code></li>
<li>Verify token syntax (e.g., <code>{{uuid}}</code> not <code>{uuid}</code>)</li>
</ul>
</li>
</ol>
<p>For more detailed configuration options, see the <a href="configuration/files.html">Configuration Files</a> documentation.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="configuration-files-1"><a class="header" href="#configuration-files-1">Configuration Files</a></h1>
<p>MockForge supports comprehensive configuration through YAML files as an alternative to environment variables. This page documents the configuration file format, options, and usage.</p>
<h2 id="quick-start-26"><a class="header" href="#quick-start-26">Quick Start</a></h2>
<h3 id="initialize-a-new-configuration"><a class="header" href="#initialize-a-new-configuration">Initialize a New Configuration</a></h3>
<pre><code class="language-bash"># Create a new project with template configuration
mockforge init my-project

# Or initialize in current directory
mockforge init .
</code></pre>
<p>This creates a <code>mockforge.yaml</code> file with sensible defaults and example configurations.</p>
<h3 id="validate-your-configuration"><a class="header" href="#validate-your-configuration">Validate Your Configuration</a></h3>
<pre><code class="language-bash"># Validate configuration file
mockforge config validate

# Validate specific file
mockforge config validate --config my-config.yaml
</code></pre>
<p>See the <a href="configuration/../reference/config-validation.html">Configuration Validation Guide</a> for detailed validation instructions.</p>
<h2 id="complete-configuration-template"><a class="header" href="#complete-configuration-template">Complete Configuration Template</a></h2>
<p>For a <strong>fully documented configuration template</strong> with all available options, see:
<strong><a href="https://github.com/SaaSy-Solutions/mockforge/blob/main/config.template.yaml">config.template.yaml</a></strong></p>
<p>This template includes:</p>
<ul>
<li>Every configuration option with inline comments</li>
<li>Default values and valid ranges</li>
<li>Example configurations for common scenarios</li>
<li>Links to detailed documentation</li>
</ul>
<h2 id="configuration-file-location"><a class="header" href="#configuration-file-location">Configuration File Location</a></h2>
<p>MockForge looks for configuration files in the following order:</p>
<ol>
<li>Path specified by <code>--config</code> CLI flag</li>
<li>Path specified by <code>MOCKFORGE_CONFIG_FILE</code> environment variable</li>
<li>Default location: <code>./mockforge.yaml</code> or <code>./mockforge.yml</code></li>
<li>No configuration file (uses defaults)</li>
</ol>
<h2 id="basic-configuration-structure"><a class="header" href="#basic-configuration-structure">Basic Configuration Structure</a></h2>
<pre><code class="language-yaml"># MockForge Configuration Example
# This file demonstrates all available configuration options

# HTTP server configuration
http:
  port: 3000
  host: "0.0.0.0"
  openapi_spec: "examples/openapi-demo.json"
  cors_enabled: true
  request_timeout_secs: 30
  request_validation: "enforce"
  aggregate_validation_errors: true
  validate_responses: false
  response_template_expand: true
  skip_admin_validation: true

# WebSocket server configuration
websocket:
  port: 3001
  host: "0.0.0.0"
  replay_file: "examples/ws-demo.jsonl"
  connection_timeout_secs: 300

# gRPC server configuration
grpc:
  port: 50051
  host: "0.0.0.0"

# Admin UI configuration
admin:
  enabled: true
  port: 9080
  host: "127.0.0.1"
  mount_path: null
  api_enabled: true

# Core MockForge configuration
core:
  latency_enabled: true
  failures_enabled: false

# Logging configuration
logging:
  level: "info"
  json_format: false
  file_path: null
  max_file_size_mb: 10
  max_files: 5

# Data generation configuration
data:
  default_rows: 100
  default_format: "json"
  locale: "en"
</code></pre>
<h2 id="http-server-configuration-1"><a class="header" href="#http-server-configuration-1">HTTP Server Configuration</a></h2>
<h3 id="basic-settings"><a class="header" href="#basic-settings">Basic Settings</a></h3>
<pre><code class="language-yaml">http:
  port: 3000                    # Server port
  host: "0.0.0.0"              # Bind address (0.0.0.0 for all interfaces)
  cors_enabled: true           # Enable CORS headers
  request_timeout_secs: 30     # Request timeout in seconds
</code></pre>
<h3 id="openapi-integration-3"><a class="header" href="#openapi-integration-3">OpenAPI Integration</a></h3>
<pre><code class="language-yaml">http:
  openapi_spec: "path/to/spec.json"  # OpenAPI spec file for HTTP server
  # Alternative: use URL
  openapi_spec: "https://example.com/api-spec.yaml"
</code></pre>
<h3 id="validation-and-response-handling"><a class="header" href="#validation-and-response-handling">Validation and Response Handling</a></h3>
<pre><code class="language-yaml">http:
  request_validation: "enforce"      # off|warn|enforce
  aggregate_validation_errors: true  # Combine multiple errors
  validate_responses: false          # Validate generated responses
  response_template_expand: true     # Enable {{uuid}}, {{now}} etc.
  skip_admin_validation: true        # Skip validation for admin endpoints
</code></pre>
<h3 id="validation-overrides-1"><a class="header" href="#validation-overrides-1">Validation Overrides</a></h3>
<pre><code class="language-yaml">http:
  validation_overrides:
    "POST /users/{id}": "warn"      # Override validation level per endpoint
    "GET /internal/health": "off"  # Skip validation for specific endpoints
</code></pre>
<h2 id="websocket-server-configuration-1"><a class="header" href="#websocket-server-configuration-1">WebSocket Server Configuration</a></h2>
<pre><code class="language-yaml">websocket:
  port: 3001                          # Server port
  host: "0.0.0.0"                    # Bind address
  replay_file: "path/to/replay.jsonl" # WebSocket replay file
  connection_timeout_secs: 300       # Connection timeout in seconds
</code></pre>
<h2 id="grpc-server-configuration-1"><a class="header" href="#grpc-server-configuration-1">gRPC Server Configuration</a></h2>
<pre><code class="language-yaml">grpc:
  port: 50051       # Server port
  host: "0.0.0.0"  # Bind address
  proto_dir: null  # Directory containing .proto files
  tls: null        # TLS configuration (optional)
</code></pre>
<h2 id="admin-ui-configuration-1"><a class="header" href="#admin-ui-configuration-1">Admin UI Configuration</a></h2>
<h3 id="standalone-mode-default"><a class="header" href="#standalone-mode-default">Standalone Mode (Default)</a></h3>
<pre><code class="language-yaml">admin:
  enabled: true
  port: 9080
  host: "127.0.0.1"
  api_enabled: true
</code></pre>
<h3 id="embedded-mode"><a class="header" href="#embedded-mode">Embedded Mode</a></h3>
<pre><code class="language-yaml">admin:
  enabled: true
  mount_path: "/admin"  # Mount under HTTP server
  api_enabled: true     # Enable API endpoints
  # Note: port/host ignored when mount_path is set
</code></pre>
<h2 id="core-configuration"><a class="header" href="#core-configuration">Core Configuration</a></h2>
<h3 id="latency-simulation-1"><a class="header" href="#latency-simulation-1">Latency Simulation</a></h3>
<pre><code class="language-yaml">core:
  latency_enabled: true
  default_latency:
    base_ms: 50
    jitter_ms: 20
    distribution: "fixed"  # fixed, normal, or pareto

  # For normal distribution
  # std_dev_ms: 10.0

  # For pareto distribution
  # pareto_shape: 2.0

  min_ms: 10      # Minimum latency
  max_ms: 5000    # Maximum latency (optional)

  # Per-operation overrides
  tag_overrides:
    auth: 100
    payments: 200
</code></pre>
<h3 id="failure-injection-1"><a class="header" href="#failure-injection-1">Failure Injection</a></h3>
<pre><code class="language-yaml">core:
  failures_enabled: true
  failure_config:
    global_error_rate: 0.05  # 5% global error rate

    # Default status codes for failures
    default_status_codes: [500, 502, 503, 504]

    # Per-tag error rates and status codes
    tag_configs:
      auth:
        error_rate: 0.1      # 10% error rate for auth operations
        status_codes: [401, 403]
        error_message: "Authentication failed"
      payments:
        error_rate: 0.02     # 2% error rate for payments
        status_codes: [402, 503]
        error_message: "Payment processing failed"

    # Tag filtering
    include_tags: []         # Empty means all tags included
    exclude_tags: ["health", "metrics"]  # Exclude these tags
</code></pre>
<h3 id="proxy-configuration"><a class="header" href="#proxy-configuration">Proxy Configuration</a></h3>
<pre><code class="language-yaml">core:
  proxy:
    upstream_url: "http://api.example.com"
    timeout_seconds: 30
</code></pre>
<h2 id="logging-configuration"><a class="header" href="#logging-configuration">Logging Configuration</a></h2>
<pre><code class="language-yaml">logging:
  level: "info"           # debug|info|warn|error
  json_format: false      # Use JSON format for logs
  file_path: "logs/mockforge.log"  # Optional log file
  max_file_size_mb: 10    # Rotate when file reaches this size
  max_files: 5           # Keep this many rotated log files
</code></pre>
<h2 id="data-generation-configuration-1"><a class="header" href="#data-generation-configuration-1">Data Generation Configuration</a></h2>
<pre><code class="language-yaml">data:
  default_rows: 100       # Default number of rows to generate
  default_format: "json"  # Default output format
  locale: "en"           # Locale for generated data

  # Custom faker templates
  templates:
    custom_user:
      name: "{{faker.name}}"
      email: "{{faker.email}}"
      department: "{{faker.word}}"

  # RAG (Retrieval-Augmented Generation) configuration
  rag:
    enabled: false
    api_endpoint: null
    api_key: null
    model: null
    context_window: 4000
</code></pre>
<h2 id="advanced-configuration-4"><a class="header" href="#advanced-configuration-4">Advanced Configuration</a></h2>
<h3 id="requestresponse-overrides"><a class="header" href="#requestresponse-overrides">Request/Response Overrides</a></h3>
<pre><code class="language-yaml"># YAML patch overrides for requests/responses
overrides:
  - targets: ["operation:getUser"]     # Target specific operations
    patch:
      - op: add
        path: /metadata/requestId
        value: "{{uuid}}"
      - op: replace
        path: /user/createdAt
        value: "{{now}}"
      - op: add
        path: /user/score
        value: "{{rand.float}}"

  - targets: ["tag:Payments"]          # Target by tags
    patch:
      - op: replace
        path: /payment/status
        value: "FAILED"
</code></pre>
<h3 id="latency-profiles-1"><a class="header" href="#latency-profiles-1">Latency Profiles</a></h3>
<pre><code class="language-yaml"># External latency profiles file
latency_profiles: "config/latency.yaml"

# Example latency configuration:
# operation:getUser:
#   fixed_ms: 120
#   jitter_ms: 80
#   fail_p: 0.0
#
# tag:Payments:
#   fixed_ms: 200
#   jitter_ms: 300
#   fail_p: 0.05
#   fail_status: 503
</code></pre>
<h2 id="configuration-examples-2"><a class="header" href="#configuration-examples-2">Configuration Examples</a></h2>
<h3 id="development-configuration-1"><a class="header" href="#development-configuration-1">Development Configuration</a></h3>
<pre><code class="language-yaml"># Development setup with debugging and fast responses
http:
  port: 3000
  response_template_expand: true
  request_validation: "warn"

admin:
  enabled: true
  port: 9080

core:
  latency_enabled: false  # Disable latency for faster development

logging:
  level: "debug"
  json_format: false
</code></pre>
<h3 id="testing-configuration"><a class="header" href="#testing-configuration">Testing Configuration</a></h3>
<pre><code class="language-yaml"># Testing setup with deterministic responses
http:
  port: 3000
  response_template_expand: false  # Disable random tokens for determinism

core:
  latency_enabled: false

data:
  rag:
    enabled: false  # Disable RAG for consistent test data
</code></pre>
<h3 id="production-configuration"><a class="header" href="#production-configuration">Production Configuration</a></h3>
<pre><code class="language-yaml"># Production setup with monitoring and reliability
http:
  port: 80
  host: "0.0.0.0"
  request_validation: "enforce"
  cors_enabled: false

admin:
  enabled: false  # Disable admin UI in production

core:
  latency_enabled: true
  failures_enabled: false

logging:
  level: "warn"
  json_format: true
  file_path: "/var/log/mockforge.log"
</code></pre>
<h2 id="configuration-file-validation"><a class="header" href="#configuration-file-validation">Configuration File Validation</a></h2>
<p>MockForge validates configuration files at startup. Common issues:</p>
<ol>
<li><strong>Invalid YAML syntax</strong> - Check indentation and quotes</li>
<li><strong>Missing required fields</strong> - Some fields like <code>request_timeout_secs</code> are required</li>
<li><strong>Invalid file paths</strong> - Ensure OpenAPI spec and replay files exist</li>
<li><strong>Port conflicts</strong> - Choose unique ports for each service</li>
</ol>
<h2 id="configuration-precedence"><a class="header" href="#configuration-precedence">Configuration Precedence</a></h2>
<p>Configuration values are resolved in this priority order:</p>
<ol>
<li><strong>CLI flags</strong> (highest priority)</li>
<li><strong>Environment variables</strong></li>
<li><strong>Configuration file</strong></li>
<li><strong>Default values</strong> (lowest priority)</li>
</ol>
<p>This allows you to override specific values without changing your configuration file.</p>
<h2 id="hot-reloading"><a class="header" href="#hot-reloading">Hot Reloading</a></h2>
<p>Configuration changes require a server restart to take effect. For development, you can use:</p>
<pre><code class="language-bash"># Watch for changes and auto-restart
cargo watch -x "run -p mockforge-cli -- serve --config config.yaml"
</code></pre>
<p>For more information on environment variables, see the <a href="configuration/environment.html">Environment Variables</a> documentation.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="advanced-options"><a class="header" href="#advanced-options">Advanced Options</a></h1>
<p>MockForge provides extensive advanced configuration options for enterprise-grade API mocking, testing, and chaos engineering scenarios. This guide covers sophisticated features like traffic shaping, time travel, ML-based anomaly detection, multi-tenancy, and advanced orchestration.</p>
<h2 id="traffic-shaping-and-bandwidth-control"><a class="header" href="#traffic-shaping-and-bandwidth-control">Traffic Shaping and Bandwidth Control</a></h2>
<p>MockForge supports advanced traffic shaping beyond simple latency simulation, including bandwidth throttling and burst control.</p>
<h3 id="bandwidth-throttling"><a class="header" href="#bandwidth-throttling">Bandwidth Throttling</a></h3>
<p>Configure bandwidth limits to simulate network constraints:</p>
<pre><code class="language-yaml"># mockforge.yaml
traffic_shaping:
  bandwidth:
    enabled: true
    max_bytes_per_sec: 1024000  # 1MB/s
    burst_capacity_bytes: 1048576  # 1MB burst allowance

    # Tag-based overrides for specific routes
    tag_overrides:
      premium: 5242880  # 5MB/s for premium routes
      admin: 0  # Unlimited for admin routes
</code></pre>
<h3 id="packet-loss-simulation"><a class="header" href="#packet-loss-simulation">Packet Loss Simulation</a></h3>
<p>Simulate network unreliability with configurable packet loss:</p>
<pre><code class="language-yaml">traffic_shaping:
  packet_loss:
    enabled: true
    loss_rate: 0.05  # 5% packet loss
    burst_loss_probability: 0.1  # 10% chance of burst loss
    burst_length: 5  # 5 consecutive packets lost in burst

    # Route-specific overrides
    route_overrides:
      "/api/health": 0.0  # No loss for health checks
      "/api/slow/*": 0.2  # 20% loss for slow endpoints
</code></pre>
<h3 id="environment-variables-15"><a class="header" href="#environment-variables-15">Environment Variables</a></h3>
<pre><code class="language-bash"># Bandwidth throttling
MOCKFORGE_TRAFFIC_SHAPING_BANDWIDTH_ENABLED=true
MOCKFORGE_TRAFFIC_SHAPING_BANDWIDTH_MAX_BYTES_PER_SEC=1024000
MOCKFORGE_TRAFFIC_SHAPING_BANDWIDTH_BURST_CAPACITY=1048576

# Packet loss
MOCKFORGE_TRAFFIC_SHAPING_PACKET_LOSS_ENABLED=true
MOCKFORGE_TRAFFIC_SHAPING_PACKET_LOSS_RATE=0.05
</code></pre>
<h2 id="time-travel-and-temporal-testing"><a class="header" href="#time-travel-and-temporal-testing">Time Travel and Temporal Testing</a></h2>
<p>MockForge‚Äôs time travel capabilities allow testing time-dependent behavior without waiting for real time to pass.</p>
<h3 id="virtual-clock-configuration"><a class="header" href="#virtual-clock-configuration">Virtual Clock Configuration</a></h3>
<pre><code class="language-yaml"># mockforge.yaml
time_travel:
  enabled: true
  initial_time: "2024-01-01T00:00:00Z"
  scale_factor: 1.0  # 1.0 = real time, 2.0 = 2x speed

  # Scheduled time jumps
  schedule:
    - at: "2024-01-01T01:00:00Z"
      jump_to: "2024-01-01T06:00:00Z"
    - at: "2024-01-01T12:00:00Z"
      advance_by: "1d"
</code></pre>
<h3 id="time-travel-api"><a class="header" href="#time-travel-api">Time Travel API</a></h3>
<p>Control time programmatically through the Admin UI or REST API:</p>
<pre><code class="language-bash"># Set virtual time
curl -X POST http://localhost:9080/api/v2/time/set \
  -H "Content-Type: application/json" \
  -d '{"time": "2024-01-01T12:00:00Z"}'

# Advance time
curl -X POST http://localhost:9080/api/v2/time/advance \
  -H "Content-Type: application/json" \
  -d '{"duration": "1h"}'

# Enable/disable time travel
curl -X POST http://localhost:9080/api/v2/time/enable \
  -H "Content-Type: application/json" \
  -d '{"enabled": true}'
</code></pre>
<h3 id="testing-time-dependent-logic"><a class="header" href="#testing-time-dependent-logic">Testing Time-Dependent Logic</a></h3>
<pre><code class="language-yaml"># Example: Testing token expiry
routes:
  - path: /api/auth/validate
    method: GET
    response:
      status: 200
      condition: "time_travel.now &lt; time_travel.parse('2024-01-01T02:00:00Z')"
      body: |
        {
          "valid": true,
          "expires_at": "2024-01-01T02:00:00Z"
        }

  - path: /api/auth/validate
    method: GET
    response:
      status: 401
      condition: "time_travel.now &gt;= time_travel.parse('2024-01-01T02:00:00Z')"
      body: |
        {
          "error": "Token expired",
          "expired_at": "2024-01-01T02:00:00Z"
        }
</code></pre>
<h2 id="ml-based-anomaly-detection"><a class="header" href="#ml-based-anomaly-detection">ML-Based Anomaly Detection</a></h2>
<p>MockForge integrates machine learning for intelligent anomaly detection in system behavior.</p>
<h3 id="anomaly-detection-configuration"><a class="header" href="#anomaly-detection-configuration">Anomaly Detection Configuration</a></h3>
<pre><code class="language-yaml"># mockforge.yaml
anomaly_detection:
  enabled: true

  # Detection parameters
  config:
    std_dev_threshold: 3.0  # Standard deviations for anomaly
    min_baseline_samples: 30  # Minimum samples for baseline
    moving_average_window: 10  # Smoothing window
    enable_seasonal: true  # Account for seasonal patterns
    seasonal_period: 24  # Hours in daily cycle
    sensitivity: 0.7  # Detection sensitivity (0.0-1.0)

  # Metrics to monitor
  monitored_metrics:
    - name: response_time_ms
      baseline_samples: 100
      alert_on_anomaly: true
      severity_threshold: high

    - name: error_rate
      baseline_samples: 50
      alert_on_anomaly: true
      severity_threshold: medium

    - name: request_throughput
      baseline_samples: 100
      alert_on_anomaly: false
      severity_threshold: high

  # Collective anomaly detection
  collective_detection:
    enabled: true
    metric_groups:
      - name: api_health
        metrics:
          - response_time_ms
          - error_rate
          - request_throughput
        min_affected_metrics: 2
</code></pre>
<h3 id="anomaly-response-actions"><a class="header" href="#anomaly-response-actions">Anomaly Response Actions</a></h3>
<p>Configure automatic responses to detected anomalies:</p>
<pre><code class="language-yaml">anomaly_detection:
  response_actions:
    - trigger: high_severity_anomaly
      action: circuit_breaker
      duration: 5m
      routes: ["/api/*"]

    - trigger: collective_anomaly
      action: failover
      target: backup_service
      routes: ["/api/critical/*"]

    - trigger: performance_degradation
      action: scale_up
      threshold: 2.0  # 2x normal response time
</code></pre>
<h2 id="chaos-mesh-integration"><a class="header" href="#chaos-mesh-integration">Chaos Mesh Integration</a></h2>
<p>Integrate with Chaos Mesh for Kubernetes-native chaos engineering.</p>
<h3 id="chaos-mesh-configuration"><a class="header" href="#chaos-mesh-configuration">Chaos Mesh Configuration</a></h3>
<pre><code class="language-yaml"># mockforge.yaml
chaos_mesh:
  enabled: true
  api_url: https://kubernetes.default.svc
  namespace: chaos-testing

  # Default experiment settings
  defaults:
    mode: one  # one, all, fixed, fixed-percent, random-max-percent
    duration: 5m

  # Pre-configured experiments
  experiments:
    - name: pod-kill-test
      type: PodChaos
      action: pod-kill
      selector:
        namespaces:
          - production
        label_selectors:
          app: api-gateway
          tier: backend
      mode: one
      duration: 30s
      schedule: "*/5 * * * *"  # Every 5 minutes

    - name: network-latency-test
      type: NetworkChaos
      action: delay
      selector:
        namespaces:
          - production
        label_selectors:
          app: database
      delay:
        latency: 100ms
        jitter: 10ms
        correlation: "50"
      duration: 3m

    - name: cpu-stress-test
      type: StressChaos
      selector:
        namespaces:
          - staging
        label_selectors:
          app: worker-service
      stressors:
        cpu_workers: 4
        cpu_load: 80
      duration: 10m
</code></pre>
<h3 id="chaos-experiment-orchestration"><a class="header" href="#chaos-experiment-orchestration">Chaos Experiment Orchestration</a></h3>
<pre><code class="language-yaml"># Orchestrate chaos experiments with MockForge scenarios
orchestration:
  name: chaos-testing-workflow
  description: Comprehensive chaos testing with monitoring

  steps:
    - name: baseline_measurement
      type: metrics_collection
      duration: 5m

    - name: pod_failure_injection
      type: chaos_mesh
      experiment: pod-kill-test
      wait_for_completion: true

    - name: anomaly_detection
      type: ml_detection
      metrics: [response_time_ms, error_rate]
      alert_threshold: high

    - name: network_chaos
      type: chaos_mesh
      experiment: network-latency-test

    - name: recovery_verification
      type: health_check
      endpoints: ["/api/health", "/api/status"]
      timeout: 30s
</code></pre>
<h2 id="multi-tenancy-configuration"><a class="header" href="#multi-tenancy-configuration">Multi-Tenancy Configuration</a></h2>
<p>MockForge supports multi-tenant deployments with configurable plans and quotas.</p>
<h3 id="tenant-plans-configuration"><a class="header" href="#tenant-plans-configuration">Tenant Plans Configuration</a></h3>
<pre><code class="language-yaml"># mockforge.yaml
multi_tenancy:
  enabled: true

  # Define tenant plans
  plans:
    free:
      quotas:
        max_scenarios: 5
        max_concurrent_executions: 1
        max_orchestrations: 3
        max_templates: 5
        max_requests_per_minute: 50
        max_storage_mb: 50
        max_users: 1
        max_experiment_duration_secs: 600

      permissions:
        can_create_scenarios: true
        can_execute_scenarios: true
        can_view_observability: false
        can_manage_resilience: false
        can_use_advanced_features: false
        can_integrate_external: false
        can_use_ml_features: false
        can_manage_users: false

    professional:
      quotas:
        max_scenarios: 100
        max_concurrent_executions: 20
        max_orchestrations: 50
        max_templates: 100
        max_requests_per_minute: 1000
        max_storage_mb: 5000
        max_users: 25
        max_experiment_duration_secs: 14400

      permissions:
        can_create_scenarios: true
        can_execute_scenarios: true
        can_view_observability: true
        can_manage_resilience: true
        can_use_advanced_features: true
        can_integrate_external: true
        can_use_ml_features: true
        can_manage_users: true

  # Default tenants
  tenants:
    - name: acme-corp
      plan: professional
      enabled: true
      metadata:
        organization: Acme Corporation
        contact: admin@acme.com
        environment: production
</code></pre>
<h3 id="tenant-isolation"><a class="header" href="#tenant-isolation">Tenant Isolation</a></h3>
<p>Configure tenant-specific resources and isolation:</p>
<pre><code class="language-yaml">multi_tenancy:
  isolation:
    # Database isolation
    database:
      separate_schemas: true
      schema_prefix: "tenant_"

    # File system isolation
    filesystem:
      tenant_directories: true
      shared_resources: ["global-templates"]

    # Network isolation
    network:
      tenant_subdomains: true
      shared_ports: [80, 443]
</code></pre>
<h2 id="plugin-system-configuration"><a class="header" href="#plugin-system-configuration">Plugin System Configuration</a></h2>
<p>Advanced plugin configuration for extending MockForge functionality.</p>
<h3 id="plugin-registry-configuration"><a class="header" href="#plugin-registry-configuration">Plugin Registry Configuration</a></h3>
<pre><code class="language-yaml"># mockforge.yaml
plugins:
  enabled: true

  # Plugin registry settings
  registry:
    auto_discover: true
    plugin_dirs:
      - /etc/mockforge/plugins
      - ~/.mockforge/plugins
      - ./custom-plugins

  # Built-in plugins
  builtin:
    - id: custom-fault-injector
      enabled: true
      config:
        fault_probability: 0.1
        default_timeout_ms: 5000

    - id: metrics-collector
      enabled: true
      config:
        export_interval_secs: 60
        buffer_size: 1000

  # Custom plugins
  custom:
    - id: database-fault-injector
      enabled: true
      path: /etc/mockforge/plugins/database_fault.so
      config:
        connection_timeout_ms: 5000
        query_timeout_ms: 30000
        fault_types:
          - connection_timeout
          - query_error
          - slow_query
          - deadlock

    - id: prometheus-exporter
      enabled: true
      path: /etc/mockforge/plugins/prometheus.so
      config:
        export_port: 9090
        metrics_path: /metrics
        include_labels:
          - tenant_id
          - scenario_id
          - experiment_type

  # Plugin hooks
  hooks:
    - type: logging
      enabled: true
      config:
        log_level: info
        include_context: true

    - type: metrics
      enabled: true
      config:
        track_execution_time: true
        track_success_rate: true

    - type: rate_limiting
      enabled: true
      config:
        max_executions_per_minute: 100
        burst_size: 20
</code></pre>
<h3 id="plugin-security-3"><a class="header" href="#plugin-security-3">Plugin Security</a></h3>
<p>Configure plugin execution security:</p>
<pre><code class="language-yaml">plugins:
  security:
    # Sandbox configuration
    sandbox:
      enabled: true
      memory_limit_mb: 100
      cpu_limit_percent: 50
      network_access: deny
      filesystem_access: restricted

    # Plugin signing
    signing:
      enabled: true
      trusted_keys:
        - "mockforge-official"
        - "enterprise-customer-key"

    # Resource limits
    limits:
      max_plugins_per_tenant: 10
      max_plugin_memory_mb: 50
      max_plugin_timeout_secs: 30
</code></pre>
<h2 id="advanced-orchestration"><a class="header" href="#advanced-orchestration">Advanced Orchestration</a></h2>
<p>Complex scenario orchestration with conditional logic and dependencies.</p>
<h3 id="orchestration-configuration"><a class="header" href="#orchestration-configuration">Orchestration Configuration</a></h3>
<pre><code class="language-yaml"># mockforge.yaml
orchestration:
  name: advanced-chaos-scenario
  description: Comprehensive chaos test with ML detection and multi-tenancy

  # Tenant context
  tenant_id: production-tenant

  # Enable advanced features
  features:
    anomaly_detection: true
    chaos_mesh_integration: true
    plugin_execution: true
    time_travel: true

  # Complex step orchestration
  steps:
    # Step 1: Baseline measurement
    - name: collect_baseline
      type: custom
      plugin: metrics-collector
      config:
        duration: 5m
        metrics:
          - response_time_ms
          - error_rate
          - request_throughput

    # Step 2: Time travel setup
    - name: setup_time_travel
      type: time_travel
      config:
        enabled: true
        initial_time: "2024-01-01T00:00:00Z"

    # Step 3: Chaos Mesh pod kill
    - name: pod_chaos
      type: chaos_mesh
      experiment: pod-kill-test
      wait_for_completion: true
      depends_on: ["collect_baseline"]

    # Step 4: Monitor for anomalies
    - name: detect_anomalies
      type: ml_detection
      metrics:
        - response_time_ms
        - error_rate
      alert_threshold: high
      depends_on: ["pod_chaos"]

    # Step 5: Custom fault injection
    - name: database_fault
      type: plugin
      plugin: database-fault-injector
      config:
        fault_type: slow_query
        latency_ms: 1000
        duration: 2m
      depends_on: ["detect_anomalies"]

    # Step 6: Network chaos
    - name: network_latency
      type: chaos_mesh
      experiment: network-latency-test
      depends_on: ["database_fault"]

    # Step 7: Final analysis
    - name: analyze_results
      type: custom
      plugin: prometheus-exporter
      config:
        export_metrics: true
        generate_report: true
      depends_on: ["network_latency"]

  # Conditional execution
  conditions:
    - name: high_load_detected
      expression: "metrics.request_throughput &gt; 1000"
      actions:
        - skip_step: "network_latency"
        - enable_step: "load_shedding"

    - name: anomaly_critical
      expression: "anomaly.severity == 'critical'"
      actions:
        - abort_orchestration: true
        - send_alert: "critical_anomaly"

  # Assertions and validations
  assertions:
    - metric: response_time_ms
      operator: less_than
      value: 1000
      severity: high

    - metric: error_rate
      operator: less_than
      value: 0.05
      severity: critical

    - metric: anomaly_count
      operator: equals
      value: 0
      severity: medium

  # Cleanup configuration
  cleanup:
    - delete_chaos_mesh_experiments: true
    - export_metrics: true
    - send_notifications: true
    - reset_time_travel: true
</code></pre>
<h2 id="observability-integration"><a class="header" href="#observability-integration">Observability Integration</a></h2>
<p>Advanced observability with Prometheus, OpenTelemetry, and alerting.</p>
<h3 id="prometheus-integration"><a class="header" href="#prometheus-integration">Prometheus Integration</a></h3>
<pre><code class="language-yaml"># mockforge.yaml
observability:
  prometheus:
    enabled: true
    port: 9090
    path: /metrics

    # Custom metrics
    custom_metrics:
      - name: mockforge_scenario_duration
        type: histogram
        description: "Time spent executing scenarios"
        labels: ["scenario_name", "tenant_id"]

      - name: mockforge_anomaly_detected
        type: counter
        description: "Number of anomalies detected"
        labels: ["severity", "metric_name"]

  opentelemetry:
    enabled: true
    endpoint: http://otel-collector:4317

    # Tracing configuration
    tracing:
      service_name: mockforge
      service_version: "1.0.0"
      sample_rate: 0.1

    # Metrics configuration
    metrics:
      export_interval: 30s
      resource_attributes:
        service.name: mockforge
        service.version: "1.0.0"
</code></pre>
<h3 id="alerting-configuration"><a class="header" href="#alerting-configuration">Alerting Configuration</a></h3>
<pre><code class="language-yaml">observability:
  alerts:
    - name: anomaly_detected
      condition: "anomaly.severity &gt;= 'high'"
      channels:
        - slack
        - email
        - webhook
      cooldown: 5m

    - name: quota_exceeded
      condition: "tenant.usage &gt;= tenant.quota * 0.9"
      channels:
        - email
      cooldown: 1h

    - name: service_degradation
      condition: "metrics.response_time_p95 &gt; 2000"
      channels:
        - slack
        - pager_duty
      cooldown: 10m

  # Alert channels configuration
  channels:
    slack:
      webhook_url: "${SLACK_WEBHOOK_URL}"
      channel: "#alerts"
      username: "MockForge Alert"

    email:
      smtp_server: "smtp.company.com"
      smtp_port: 587
      username: "${SMTP_USERNAME}"
      password: "${SMTP_PASSWORD}"
      from: "alerts@mockforge.company.com"
      to: ["devops@company.com", "engineering@company.com"]

    webhook:
      url: "https://alert-manager.company.com/webhook"
      headers:
        Authorization: "Bearer ${WEBHOOK_TOKEN}"
      method: POST
</code></pre>
<h2 id="security-and-encryption"><a class="header" href="#security-and-encryption">Security and Encryption</a></h2>
<p>Advanced security features for enterprise deployments.</p>
<h3 id="encryption-configuration"><a class="header" href="#encryption-configuration">Encryption Configuration</a></h3>
<pre><code class="language-yaml"># mockforge.yaml
security:
  encryption:
    enabled: true

    # Key management
    keys:
      default:
        algorithm: AES-256-GCM
        key_rotation_days: 30

      sensitive:
        algorithm: AES-256-GCM
        hsm_integration: true

    # Data encryption
    data_encryption:
      fixtures: true
      logs: true
      configuration: false

    # TLS configuration
    tls:
      enabled: true
      certificate_file: /etc/ssl/mockforge.crt
      private_key_file: /etc/ssl/mockforge.key
      client_auth: optional
</code></pre>
<h3 id="authentication-and-authorization-1"><a class="header" href="#authentication-and-authorization-1">Authentication and Authorization</a></h3>
<pre><code class="language-yaml">security:
  auth:
    # JWT configuration
    jwt:
      enabled: true
      secret: "${JWT_SECRET}"
      issuer: "mockforge"
      audience: "mockforge-users"
      algorithms: ["HS256", "RS256"]

    # OAuth2 integration
    oauth2:
      enabled: true
      provider: keycloak
      client_id: "${OAUTH2_CLIENT_ID}"
      client_secret: "${OAUTH2_CLIENT_SECRET}"
      token_url: "https://auth.company.com/token"
      userinfo_url: "https://auth.company.com/userinfo"

    # Role-based access control
    rbac:
      enabled: true
      roles:
        admin:
          permissions:
            - "scenarios:*"
            - "tenants:*"
            - "system:*"

        developer:
          permissions:
            - "scenarios:read"
            - "scenarios:execute"
            - "fixtures:*"

        viewer:
          permissions:
            - "scenarios:read"
            - "fixtures:read"
            - "metrics:read"
</code></pre>
<h2 id="performance-tuning-5"><a class="header" href="#performance-tuning-5">Performance Tuning</a></h2>
<p>Advanced performance configuration for high-throughput scenarios.</p>
<h3 id="resource-limits-2"><a class="header" href="#resource-limits-2">Resource Limits</a></h3>
<pre><code class="language-yaml"># mockforge.yaml
performance:
  # Thread pool configuration
  thread_pool:
    http_workers: 16
    background_workers: 4
    max_blocking_threads: 512

  # Memory management
  memory:
    max_heap_size_mb: 2048
    gc_threshold_mb: 1024
    cache_size_mb: 512

  # Connection pooling
  connections:
    max_http_connections: 1000
    connection_timeout_secs: 30
    keep_alive_secs: 300

  # Request processing
  requests:
    max_concurrent_requests: 10000
    request_timeout_secs: 60
    buffer_size_kb: 64
</code></pre>
<h3 id="caching-configuration"><a class="header" href="#caching-configuration">Caching Configuration</a></h3>
<pre><code class="language-yaml">performance:
  caching:
    # Response caching
    responses:
      enabled: true
      max_size_mb: 100
      ttl_secs: 300
      compression: true

    # Template caching
    templates:
      enabled: true
      max_entries: 1000
      ttl_secs: 3600

    # Plugin caching
    plugins:
      enabled: true
      max_instances: 10
      preload: ["metrics-collector", "template-renderer"]
</code></pre>
<h3 id="monitoring-and-profiling"><a class="header" href="#monitoring-and-profiling">Monitoring and Profiling</a></h3>
<pre><code class="language-yaml">performance:
  monitoring:
    # Performance metrics
    metrics:
      enabled: true
      interval_secs: 30
      export_format: prometheus

    # Profiling
    profiling:
      enabled: true
      sample_rate: 1000  # 1000 Hz
      max_stack_depth: 64

    # Health checks
    health_checks:
      enabled: true
      interval_secs: 60
      failure_threshold: 3
</code></pre>
<h2 id="environment-variables-16"><a class="header" href="#environment-variables-16">Environment Variables</a></h2>
<p>Advanced configuration through environment variables:</p>
<pre><code class="language-bash"># Traffic shaping
MOCKFORGE_TRAFFIC_SHAPING_ENABLED=true
MOCKFORGE_BANDWIDTH_MAX_BYTES_PER_SEC=1024000
MOCKFORGE_PACKET_LOSS_RATE=0.05

# Time travel
MOCKFORGE_TIME_TRAVEL_ENABLED=true
MOCKFORGE_VIRTUAL_TIME_SCALE=1.0

# Anomaly detection
MOCKFORGE_ANOMALY_DETECTION_ENABLED=true
MOCKFORGE_ANOMALY_SENSITIVITY=0.7

# Chaos Mesh
MOCKFORGE_CHAOS_MESH_ENABLED=true
MOCKFORGE_CHAOS_MESH_NAMESPACE=chaos-testing

# Multi-tenancy
MOCKFORGE_MULTI_TENANCY_ENABLED=true
MOCKFORGE_DEFAULT_TENANT_PLAN=professional

# Plugins
MOCKFORGE_PLUGINS_ENABLED=true
MOCKFORGE_PLUGIN_AUTO_DISCOVER=true

# Observability
MOCKFORGE_PROMETHEUS_ENABLED=true
MOCKFORGE_OPENTELEMETRY_ENABLED=true

# Security
MOCKFORGE_ENCRYPTION_ENABLED=true
MOCKFORGE_JWT_ENABLED=true
MOCKFORGE_TLS_ENABLED=true

# Performance
MOCKFORGE_MAX_CONCURRENT_REQUESTS=10000
MOCKFORGE_CACHE_ENABLED=true
MOCKFORGE_PROFILING_ENABLED=true
</code></pre>
<h2 id="best-practices-56"><a class="header" href="#best-practices-56">Best Practices</a></h2>
<h3 id="configuration-management"><a class="header" href="#configuration-management">Configuration Management</a></h3>
<ol>
<li><strong>Version Control</strong>: Keep all configuration files in version control</li>
<li><strong>Environment Separation</strong>: Use different configurations for dev/staging/prod</li>
<li><strong>Secrets Management</strong>: Never commit secrets to version control</li>
<li><strong>Validation</strong>: Always validate configurations before deployment</li>
</ol>
<h3 id="security-3"><a class="header" href="#security-3">Security</a></h3>
<ol>
<li><strong>Principle of Least Privilege</strong>: Grant minimal required permissions</li>
<li><strong>Network Security</strong>: Use firewalls and network policies</li>
<li><strong>Audit Logging</strong>: Enable comprehensive audit logging</li>
<li><strong>Regular Updates</strong>: Keep MockForge and dependencies updated</li>
</ol>
<h3 id="performance-2"><a class="header" href="#performance-2">Performance</a></h3>
<ol>
<li><strong>Resource Monitoring</strong>: Monitor resource usage continuously</li>
<li><strong>Load Testing</strong>: Test configurations under load</li>
<li><strong>Caching Strategy</strong>: Configure appropriate caching for your use case</li>
<li><strong>Scalability Planning</strong>: Plan for growth and scale accordingly</li>
</ol>
<h3 id="troubleshooting-57"><a class="header" href="#troubleshooting-57">Troubleshooting</a></h3>
<ol>
<li><strong>Debug Logging</strong>: Enable debug logging for troubleshooting</li>
<li><strong>Metrics Collection</strong>: Use observability tools for monitoring</li>
<li><strong>Configuration Validation</strong>: Validate configurations regularly</li>
<li><strong>Incremental Changes</strong>: Make configuration changes incrementally</li>
</ol>
<p>This comprehensive guide covers MockForge‚Äôs advanced configuration options for enterprise-grade API mocking and chaos engineering scenarios.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="building-from-source"><a class="header" href="#building-from-source">Building from Source</a></h1>
<p>This guide covers building MockForge from source code, including prerequisites, build processes, and troubleshooting common build issues.</p>
<h2 id="prerequisites-8"><a class="header" href="#prerequisites-8">Prerequisites</a></h2>
<p>Before building MockForge, ensure you have the required development tools installed.</p>
<h3 id="system-requirements"><a class="header" href="#system-requirements">System Requirements</a></h3>
<ul>
<li><strong>Rust</strong>: Version 1.70.0 or later</li>
<li><strong>Cargo</strong>: Included with Rust</li>
<li><strong>Git</strong>: For cloning the repository</li>
<li><strong>C/C++ Compiler</strong>: For native dependencies</li>
</ul>
<h3 id="platform-specific-requirements"><a class="header" href="#platform-specific-requirements">Platform-Specific Requirements</a></h3>
<h4 id="linux-ubuntudebian"><a class="header" href="#linux-ubuntudebian">Linux (Ubuntu/Debian)</a></h4>
<pre><code class="language-bash"># Install build essentials
sudo apt update
sudo apt install build-essential pkg-config libssl-dev

# Install Rust (if not already installed)
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
source $HOME/.cargo/env
</code></pre>
<h4 id="macos"><a class="header" href="#macos">macOS</a></h4>
<pre><code class="language-bash"># Install Xcode command line tools
xcode-select --install

# Install Homebrew (optional, for additional tools)
# /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

# Install Rust
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
source $HOME/.cargo/env
</code></pre>
<h4 id="windows"><a class="header" href="#windows">Windows</a></h4>
<pre><code class="language-powershell"># Install Visual Studio Build Tools
# Download from: https://visualstudio.microsoft.com/visual-cpp-build-tools/

# Install Rust
# Download from: https://rustup.rs/
# Or use winget: winget install --id Rustlang.Rustup
</code></pre>
<h3 id="rust-setup-verification"><a class="header" href="#rust-setup-verification">Rust Setup Verification</a></h3>
<pre><code class="language-bash"># Verify Rust installation
rustc --version
cargo --version

# Update to latest stable
rustup update stable
</code></pre>
<h2 id="cloning-the-repository"><a class="header" href="#cloning-the-repository">Cloning the Repository</a></h2>
<pre><code class="language-bash"># Clone the repository
git clone https://github.com/SaaSy-Solutions/mockforge.git
cd mockforge

# Initialize submodules (if any)
git submodule update --init --recursive
</code></pre>
<h2 id="build-process"><a class="header" href="#build-process">Build Process</a></h2>
<h3 id="basic-build"><a class="header" href="#basic-build">Basic Build</a></h3>
<pre><code class="language-bash"># Build all crates in debug mode (default)
cargo build

# Build in release mode for production
cargo build --release

# Build specific crate
cargo build -p mockforge-cli
</code></pre>
<h3 id="build-outputs"><a class="header" href="#build-outputs">Build Outputs</a></h3>
<p>After building, binaries are available in:</p>
<pre><code class="language-bash"># Debug builds
target/debug/mockforge-cli

# Release builds
target/release/mockforge-cli
</code></pre>
<h3 id="build-features"><a class="header" href="#build-features">Build Features</a></h3>
<p>MockForge supports conditional compilation features:</p>
<pre><code class="language-bash"># Build with all features enabled
cargo build --all-features

# Build with specific features
cargo build --features "grpc,websocket"

# List available features
cargo metadata --format-version 1 | jq '.packages[] | select(.name == "mockforge-cli") | .features'
</code></pre>
<h2 id="development-workflow-5"><a class="header" href="#development-workflow-5">Development Workflow</a></h2>
<h3 id="development-builds"><a class="header" href="#development-builds">Development Builds</a></h3>
<pre><code class="language-bash"># Quick development builds
cargo build

# Run tests during development
cargo test

# Run specific tests
cargo test --package mockforge-core --lib
</code></pre>
<h3 id="watch-mode-development"><a class="header" href="#watch-mode-development">Watch Mode Development</a></h3>
<pre><code class="language-bash"># Install cargo-watch for automatic rebuilds
cargo install cargo-watch

# Watch for changes and rebuild
cargo watch -x build

# Watch and run tests
cargo watch -x test

# Watch and run specific binary
cargo watch -x "run --bin mockforge-cli -- --help"
</code></pre>
<h3 id="ide-setup"><a class="header" href="#ide-setup">IDE Setup</a></h3>
<h4 id="vs-code"><a class="header" href="#vs-code">VS Code</a></h4>
<p>Install recommended extensions:</p>
<ul>
<li><code>rust-lang.rust-analyzer</code></li>
<li><code>ms-vscode.vscode-json</code></li>
<li><code>redhat.vscode-yaml</code></li>
</ul>
<h4 id="intellijclion"><a class="header" href="#intellijclion">IntelliJ/CLion</a></h4>
<p>Install Rust plugin through marketplace.</p>
<h3 id="debugging-3"><a class="header" href="#debugging-3">Debugging</a></h3>
<pre><code class="language-bash"># Build with debug symbols
cargo build

# Run with debugger
rust-gdb target/debug/mockforge-cli

# Or use lldb on macOS
rust-lldb target/debug/mockforge-cli
</code></pre>
<h2 id="advanced-build-options"><a class="header" href="#advanced-build-options">Advanced Build Options</a></h2>
<h3 id="cross-compilation"><a class="header" href="#cross-compilation">Cross-Compilation</a></h3>
<pre><code class="language-bash"># Install cross-compilation targets
rustup target add x86_64-unknown-linux-musl
rustup target add aarch64-unknown-linux-gnu

# Build for different architectures
cargo build --target x86_64-unknown-linux-musl
cargo build --target aarch64-unknown-linux-gnu
</code></pre>
<h3 id="custom-linker"><a class="header" href="#custom-linker">Custom Linker</a></h3>
<pre><code class="language-bash"># Use mold linker for faster linking (Linux)
sudo apt install mold
export RUSTFLAGS="-C link-arg=-fuse-ld=mold"
cargo build
</code></pre>
<h3 id="build-caching"><a class="header" href="#build-caching">Build Caching</a></h3>
<pre><code class="language-bash"># Use sccache for faster rebuilds
cargo install sccache
export RUSTC_WRAPPER=sccache
cargo build
</code></pre>
<h2 id="testing-4"><a class="header" href="#testing-4">Testing</a></h2>
<h3 id="running-tests"><a class="header" href="#running-tests">Running Tests</a></h3>
<pre><code class="language-bash"># Run all tests
cargo test

# Run tests with output
cargo test -- --nocapture

# Run specific test
cargo test test_name

# Run tests for specific package
cargo test -p mockforge-core

# Run integration tests
cargo test --test integration

# Run with release optimizations
cargo test --release
</code></pre>
<h3 id="test-coverage"><a class="header" href="#test-coverage">Test Coverage</a></h3>
<pre><code class="language-bash"># Install cargo-tarpaulin
cargo install cargo-tarpaulin

# Generate coverage report
cargo tarpaulin --out Html

# Open coverage report
open tarpaulin-report.html
</code></pre>
<h3 id="benchmarking"><a class="header" href="#benchmarking">Benchmarking</a></h3>
<pre><code class="language-bash"># Run benchmarks
cargo bench

# Run specific benchmark
cargo bench benchmark_name
</code></pre>
<h2 id="code-quality"><a class="header" href="#code-quality">Code Quality</a></h2>
<h3 id="linting"><a class="header" href="#linting">Linting</a></h3>
<pre><code class="language-bash"># Run clippy lints
cargo clippy

# Run with pedantic mode
cargo clippy -- -W clippy::pedantic

# Auto-fix some issues
cargo clippy --fix
</code></pre>
<h3 id="formatting"><a class="header" href="#formatting">Formatting</a></h3>
<pre><code class="language-bash"># Check code formatting
cargo fmt --check

# Auto-format code
cargo fmt
</code></pre>
<h3 id="security-auditing"><a class="header" href="#security-auditing">Security Auditing</a></h3>
<pre><code class="language-bash"># Install cargo-audit
cargo install cargo-audit

# Audit dependencies for security vulnerabilities
cargo audit
</code></pre>
<h2 id="documentation-1"><a class="header" href="#documentation-1">Documentation</a></h2>
<h3 id="building-documentation"><a class="header" href="#building-documentation">Building Documentation</a></h3>
<pre><code class="language-bash"># Build API documentation
cargo doc

# Open documentation in browser
cargo doc --open

# Build documentation with private items
cargo doc --document-private-items

# Build for specific package
cargo doc -p mockforge-core
</code></pre>
<h3 id="building-mdbook"><a class="header" href="#building-mdbook">Building mdBook</a></h3>
<pre><code class="language-bash"># Install mdbook
cargo install mdbook

# Build the documentation
mdbook build

# Serve documentation locally
mdbook serve
</code></pre>
<h2 id="packaging-and-distribution"><a class="header" href="#packaging-and-distribution">Packaging and Distribution</a></h2>
<h3 id="creating-releases"><a class="header" href="#creating-releases">Creating Releases</a></h3>
<pre><code class="language-bash"># Create a release build
cargo build --release

# Strip debug symbols (Linux/macOS)
strip target/release/mockforge-cli

# Create distribution archive
tar -czf mockforge-v0.1.0-x86_64-linux.tar.gz \
  -C target/release mockforge-cli

# Create Debian package
cargo install cargo-deb
cargo deb
</code></pre>
<h3 id="docker-builds"><a class="header" href="#docker-builds">Docker Builds</a></h3>
<pre><code class="language-bash"># Build Docker image
docker build -t mockforge .

# Build with buildkit for faster builds
DOCKER_BUILDKIT=1 docker build -t mockforge .

# Multi-stage build for smaller images
docker build -f Dockerfile.multi-stage -t mockforge .
</code></pre>
<h2 id="troubleshooting-build-issues"><a class="header" href="#troubleshooting-build-issues">Troubleshooting Build Issues</a></h2>
<h3 id="common-problems"><a class="header" href="#common-problems">Common Problems</a></h3>
<h4 id="compilation-errors"><a class="header" href="#compilation-errors">Compilation Errors</a></h4>
<p><strong>Problem</strong>: <code>error[E0432]: unresolved import</code></p>
<p><strong>Solution</strong>: Check that dependencies are properly specified in <code>Cargo.toml</code></p>
<pre><code class="language-bash"># Update dependencies
cargo update

# Clean and rebuild
cargo clean
cargo build
</code></pre>
<h4 id="linker-errors"><a class="header" href="#linker-errors">Linker Errors</a></h4>
<p><strong>Problem</strong>: <code>undefined reference to...</code></p>
<p><strong>Solution</strong>: Install system dependencies</p>
<pre><code class="language-bash"># Ubuntu/Debian
sudo apt install libssl-dev pkg-config

# macOS
brew install openssl pkg-config
</code></pre>
<h4 id="out-of-memory-1"><a class="header" href="#out-of-memory-1">Out of Memory</a></h4>
<p><strong>Problem</strong>: <code>fatal error: Killed signal terminated program cc1</code></p>
<p><strong>Solution</strong>: Increase available memory or reduce parallelism</p>
<pre><code class="language-bash"># Reduce parallel jobs
cargo build --jobs 1

# Or set memory limits
export CARGO_BUILD_JOBS=2
</code></pre>
<h4 id="slow-builds"><a class="header" href="#slow-builds">Slow Builds</a></h4>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Use incremental compilation
export CARGO_INCREMENTAL=1

# Use faster linker
export RUSTFLAGS="-C link-arg=-fuse-ld=mold"

# Use build cache
cargo install sccache
export RUSTC_WRAPPER=sccache
</code></pre>
<h3 id="platform-specific-issues"><a class="header" href="#platform-specific-issues">Platform-Specific Issues</a></h3>
<h4 id="windows-1"><a class="header" href="#windows-1">Windows</a></h4>
<pre><code class="language-powershell"># Install Windows SDK if missing
# Download from: https://developer.microsoft.com/en-us/windows/downloads/windows-sdk/

# Use different target for static linking
cargo build --target x86_64-pc-windows-msvc
</code></pre>
<h4 id="macos-1"><a class="header" href="#macos-1">macOS</a></h4>
<pre><code class="language-bash"># Install missing headers
open /Library/Developer/CommandLineTools/Packages/macOS_SDK_headers_for_macOS_10.14.pkg

# Or reinstall command line tools
sudo rm -rf /Library/Developer/CommandLineTools
xcode-select --install
</code></pre>
<h4 id="linux"><a class="header" href="#linux">Linux</a></h4>
<pre><code class="language-bash"># Install additional development libraries
sudo apt install libclang-dev llvm-dev

# For cross-compilation
sudo apt install gcc-aarch64-linux-gnu
</code></pre>
<h3 id="network-issues"><a class="header" href="#network-issues">Network Issues</a></h3>
<pre><code class="language-bash"># Clear cargo cache
cargo clean
rm -rf ~/.cargo/registry/cache
rm -rf ~/.cargo/git/checkouts

# Use different registry
export CARGO_REGISTRIES_CRATES_IO_PROTOCOL=sparse
</code></pre>
<h3 id="dependency-conflicts"><a class="header" href="#dependency-conflicts">Dependency Conflicts</a></h3>
<pre><code class="language-bash"># Update Cargo.lock
cargo update

# Resolve conflicts
cargo update -p package-name

# Use cargo-tree to visualize dependencies
cargo install cargo-tree
cargo tree
</code></pre>
<h2 id="performance-optimization-5"><a class="header" href="#performance-optimization-5">Performance Optimization</a></h2>
<h3 id="release-builds"><a class="header" href="#release-builds">Release Builds</a></h3>
<pre><code class="language-bash"># Optimized release build
cargo build --release

# With Link-Time Optimization (LTO)
export RUSTFLAGS="-C opt-level=3 -C lto=fat -C codegen-units=1"
cargo build --release
</code></pre>
<h3 id="profile-guided-optimization-pgo"><a class="header" href="#profile-guided-optimization-pgo">Profile-Guided Optimization (PGO)</a></h3>
<pre><code class="language-bash"># Build with instrumentation
export RUSTFLAGS="-Cprofile-generate=/tmp/pgo-data"
cargo build --release

# Run instrumented binary with representative workload
./target/release/mockforge-cli serve --spec examples/openapi-demo.json &amp;
sleep 10
curl -s http://localhost:3000/users &gt; /dev/null
pkill mockforge-cli

# Build optimized version
export RUSTFLAGS="-Cprofile-use=/tmp/pgo-data"
cargo build --release
</code></pre>
<h2 id="contributing-to-the-build-system"><a class="header" href="#contributing-to-the-build-system">Contributing to the Build System</a></h2>
<h3 id="adding-new-dependencies"><a class="header" href="#adding-new-dependencies">Adding New Dependencies</a></h3>
<pre><code class="language-toml"># Add to workspace Cargo.toml
[workspace.dependencies]
new-dependency = "1.0"

# Use in crate Cargo.toml
[dependencies]
new-dependency = { workspace = true }
</code></pre>
<h3 id="adding-build-scripts"><a class="header" href="#adding-build-scripts">Adding Build Scripts</a></h3>
<pre><pre class="playground"><code class="language-rust">// build.rs
fn main() {
    // Generate code or check dependencies
    println!("cargo:rerun-if-changed=proto/");
    tonic_build::compile_protos("proto/service.proto").unwrap();
}</code></pre></pre>
<h3 id="custom-build-profiles"><a class="header" href="#custom-build-profiles">Custom Build Profiles</a></h3>
<pre><code class="language-toml"># In Cargo.toml
[profile.release]
opt-level = 3
lto = true
codegen-units = 1
panic = "abort"

[profile.dev]
opt-level = 0
debug = true
overflow-checks = true
</code></pre>
<p>This comprehensive build guide ensures developers can successfully compile, test, and contribute to MockForge across different platforms and development environments.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="testing-guide"><a class="header" href="#testing-guide">Testing Guide</a></h1>
<p>This guide covers MockForge‚Äôs comprehensive testing strategy, including unit tests, integration tests, end-to-end tests, and testing best practices.</p>
<h2 id="testing-overview"><a class="header" href="#testing-overview">Testing Overview</a></h2>
<p>MockForge employs a multi-layered testing approach to ensure code quality and prevent regressions:</p>
<ul>
<li><strong>Unit Tests</strong>: Individual functions and modules</li>
<li><strong>Integration Tests</strong>: Component interactions</li>
<li><strong>End-to-End Tests</strong>: Full system workflows</li>
<li><strong>Performance Tests</strong>: Load and performance validation</li>
<li><strong>Security Tests</strong>: Vulnerability and access control testing</li>
</ul>
<h2 id="unit-testing"><a class="header" href="#unit-testing">Unit Testing</a></h2>
<h3 id="running-unit-tests"><a class="header" href="#running-unit-tests">Running Unit Tests</a></h3>
<pre><code class="language-bash"># Run all unit tests
cargo test --lib

# Run tests for specific crate
cargo test -p mockforge-core

# Run specific test function
cargo test test_template_rendering

# Run tests matching pattern
cargo test template

# Run tests with output
cargo test -- --nocapture
</code></pre>
<h3 id="writing-unit-tests"><a class="header" href="#writing-unit-tests">Writing Unit Tests</a></h3>
<h4 id="basic-test-structure"><a class="header" href="#basic-test-structure">Basic Test Structure</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_basic_functionality() {
        // Arrange
        let input = "test input";
        let expected = "expected output";

        // Act
        let result = process_input(input);

        // Assert
        assert_eq!(result, expected);
    }

    #[test]
    fn test_error_conditions() {
        // Test error cases
        let result = process_input("");
        assert!(result.is_err());
    }
}
<span class="boring">}</span></code></pre></pre>
<h4 id="async-tests"><a class="header" href="#async-tests">Async Tests</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod async_tests {
    use tokio::test;

    #[tokio::test]
    async fn test_async_operation() {
        let result = async_operation().await;
        assert!(result.is_ok());
    }

    #[tokio::test]
    async fn test_concurrent_operations() {
        let (result1, result2) = tokio::join(
            async_operation(),
            another_async_operation()
        );

        assert!(result1.is_ok());
        assert!(result2.is_ok());
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="integration-testing-3"><a class="header" href="#integration-testing-3">Integration Testing</a></h2>
<h3 id="component-integration-tests"><a class="header" href="#component-integration-tests">Component Integration Tests</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod integration_tests {
    use mockforge_core::config::MockForgeConfig;
    use mockforge_http::HttpServer;

    #[tokio::test]
    async fn test_http_server_integration() {
        // Start test server
        let config = test_config();
        let server = HttpServer::new(config);
        let addr = server.local_addr();

        tokio::spawn(async move {
            server.serve().await.unwrap();
        });

        // Wait for server to start
        tokio::time::sleep(tokio::time::Duration::from_millis(100)).await;

        // Test HTTP request
        let client = reqwest::Client::new();
        let response = client
            .get(&amp;format!("http://{}/health", addr))
            .send()
            .await
            .unwrap();

        assert_eq!(response.status(), 200);
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="end-to-end-testing"><a class="header" href="#end-to-end-testing">End-to-End Testing</a></h2>
<h3 id="full-system-tests"><a class="header" href="#full-system-tests">Full System Tests</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod e2e_tests {
    use std::process::Command;
    use std::thread;
    use std::time::Duration;

    #[test]
    fn test_full_openapi_workflow() {
        // Start MockForge server
        let mut server = Command::new("cargo")
            .args(&amp;["run", "--bin", "mockforge-cli", "serve",
                   "--spec", "examples/openapi-demo.json",
                   "--http-port", "3000"])
            .spawn()
            .unwrap();

        // Wait for server to start
        thread::sleep(Duration::from_secs(2));

        // Test API endpoints
        test_user_endpoints();
        test_product_endpoints();

        // Stop server
        server.kill().unwrap();
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="performance-testing-1"><a class="header" href="#performance-testing-1">Performance Testing</a></h2>
<h3 id="load-testing-4"><a class="header" href="#load-testing-4">Load Testing</a></h3>
<pre><code class="language-bash"># Using hey for HTTP load testing
hey -n 1000 -c 10 http://localhost:3000/users

# Using wrk for more detailed benchmarking
wrk -t 4 -c 100 -d 30s http://localhost:3000/users
</code></pre>
<h3 id="benchmarking-1"><a class="header" href="#benchmarking-1">Benchmarking</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// In benches/benchmark.rs
use criterion::{black_box, criterion_group, criterion_main, Criterion};

fn benchmark_template_rendering(c: &amp;mut Criterion) {
    let engine = TemplateEngine::new();

    c.bench_function("template_render_simple", |b| {
        b.iter(|| {
            engine.render("Hello {{name}}", &amp;Context::from_value("name", "World"))
        })
    });
}

criterion_group!(benches, benchmark_template_rendering);
criterion_main!(benches);
<span class="boring">}</span></code></pre></pre>
<p>Run benchmarks:</p>
<pre><code class="language-bash">cargo bench
</code></pre>
<h2 id="security-testing"><a class="header" href="#security-testing">Security Testing</a></h2>
<h3 id="input-validation-tests"><a class="header" href="#input-validation-tests">Input Validation Tests</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod security_tests {
    #[test]
    fn test_sql_injection_prevention() {
        let input = "'; DROP TABLE users; --";
        let result = sanitize_input(input);

        // Ensure dangerous characters are escaped
        assert!(!result.contains("DROP"));
    }

    #[test]
    fn test_template_injection() {
        let engine = TemplateEngine::new();
        let malicious = "{{#exec}}rm -rf /{{/exec}}";

        // Should not execute dangerous commands
        let result = engine.render(malicious, &amp;Context::new());
        assert!(!result.contains("exec"));
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="continuous-integration"><a class="header" href="#continuous-integration">Continuous Integration</a></h2>
<h3 id="github-actions-testing"><a class="header" href="#github-actions-testing">GitHub Actions Testing</a></h3>
<pre><code class="language-yaml"># .github/workflows/test.yml
name: Test

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - uses: actions-rs/toolchain@v1
      with:
        toolchain: stable
        override: true

    - name: Cache dependencies
      uses: actions/cache@v2
      with:
        path: |
          ~/.cargo/registry
          ~/.cargo/git
          target
        key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}

    - name: Run tests
      run: cargo test --verbose

    - name: Run clippy
      run: cargo clippy -- -D warnings

    - name: Check formatting
      run: cargo fmt --check

    - name: Run security audit
      run: cargo audit
</code></pre>
<p>This comprehensive testing guide ensures MockForge maintains high code quality and prevents regressions across all components and integration points.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="architecture-overview"><a class="header" href="#architecture-overview">Architecture Overview</a></h1>
<p>MockForge is a modular, Rust-based platform for mocking APIs across HTTP, WebSocket, and gRPC protocols. This document provides a comprehensive overview of the system architecture, design principles, and component interactions.</p>
<h2 id="system-overview"><a class="header" href="#system-overview">System Overview</a></h2>
<p>MockForge enables frontend and integration development without live backends by providing realistic API mocking with configurable latency, failure injection, and dynamic response generation. The system is built as a modular workspace of Rust crates that share a core engine for request routing, validation, and data generation.</p>
<h3 id="key-design-principles"><a class="header" href="#key-design-principles">Key Design Principles</a></h3>
<ul>
<li><strong>Modularity</strong>: Separated concerns across focused crates</li>
<li><strong>Extensibility</strong>: Plugin architecture for custom functionality</li>
<li><strong>Performance</strong>: Async-first design with efficient resource usage</li>
<li><strong>Developer Experience</strong>: Comprehensive tooling and clear APIs</li>
<li><strong>Protocol Agnostic</strong>: Unified approach across different protocols</li>
</ul>
<h2 id="high-level-architecture"><a class="header" href="#high-level-architecture">High-Level Architecture</a></h2>
<pre><code class="language-mermaid">graph TB
    subgraph "User Interfaces"
        CLI[CLI mockforge-cli]
        UI[Admin UI v2]
    end

    subgraph "Core Engine"
        Router[Route Registry]
        Templates[Template Engine]
        Validator[Schema Validator]
        Latency[Latency Injector]
        Failure[Failure Injector]
        Logger[Request Logger]
        Plugins[Plugin System]
    end

    subgraph "Protocol Handlers"
        HTTP[HTTP Server&lt;br/&gt;axum]
        WS[WebSocket Server&lt;br/&gt;tokio-ws]
        GRPC[gRPC Server&lt;br/&gt;tonic]
    end

    subgraph "Data Layer"
        DataGen[Data Generator&lt;br/&gt;faker + RAG]
        Workspace[Workspace Manager]
        Encryption[Encryption Engine]
    end

    CLI --&gt; Router
    UI --&gt; Router

    Router --&gt; HTTP
    Router --&gt; WS
    Router --&gt; GRPC

    HTTP --&gt; Templates
    WS --&gt; Templates
    GRPC --&gt; Templates

    Templates --&gt; Validator
    Validator --&gt; Latency
    Latency --&gt; Failure
    Failure --&gt; Logger

    Templates --&gt; DataGen
    Templates --&gt; Plugins

    Router --&gt; Workspace
    Workspace --&gt; Encryption

    style CLI fill:#e1f5ff
    style UI fill:#e1f5ff
    style Router fill:#ffe1e1
    style Templates fill:#ffe1e1
    style DataGen fill:#e1ffe1
</code></pre>
<h2 id="crate-structure"><a class="header" href="#crate-structure">Crate Structure</a></h2>
<p>MockForge is organized as a Cargo workspace with the following crates:</p>
<pre><code>mockforge/
  crates/
    mockforge-cli/     # Command-line interface
    mockforge-core/    # Shared functionality
    mockforge-http/    # HTTP REST API mocking
    mockforge-ws/      # WebSocket connection mocking
    mockforge-grpc/    # gRPC service mocking
    mockforge-data/   # Synthetic data generation
    mockforge-ui/      # Web-based admin interface
</code></pre>
<h3 id="crate-responsibilities"><a class="header" href="#crate-responsibilities">Crate Responsibilities</a></h3>
<h4 id="mockforge-core---shared-core-engine"><a class="header" href="#mockforge-core---shared-core-engine"><code>mockforge-core</code> - Shared Core Engine</a></h4>
<p>The foundation crate providing common functionality used across all protocols:</p>
<ul>
<li><strong>Request Routing</strong>: Unified route registry and matching logic</li>
<li><strong>Validation Engine</strong>: OpenAPI and schema validation</li>
<li><strong>Template System</strong>: Handlebars-based dynamic content generation</li>
<li><strong>Latency Injection</strong>: Configurable response delays</li>
<li><strong>Failure Injection</strong>: Simulated error conditions</li>
<li><strong>Record/Replay</strong>: Request/response capture and replay</li>
<li><strong>Logging</strong>: Structured request/response logging</li>
<li><strong>Configuration</strong>: Unified configuration management</li>
</ul>
<h4 id="mockforge-http---http-rest-api-mocking"><a class="header" href="#mockforge-http---http-rest-api-mocking"><code>mockforge-http</code> - HTTP REST API Mocking</a></h4>
<p>HTTP-specific implementation built on axum:</p>
<ul>
<li><strong>OpenAPI Integration</strong>: Automatic route generation from specifications</li>
<li><strong>Request Matching</strong>: Method, path, query, header, and body matching</li>
<li><strong>Response Generation</strong>: Schema-driven and template-based responses</li>
<li><strong>Middleware Support</strong>: Custom request/response processing</li>
</ul>
<h4 id="mockforge-ws---websocket-connection-mocking"><a class="header" href="#mockforge-ws---websocket-connection-mocking"><code>mockforge-ws</code> - WebSocket Connection Mocking</a></h4>
<p>Real-time communication mocking:</p>
<ul>
<li><strong>Replay Mode</strong>: Scripted message sequences with timing control</li>
<li><strong>Interactive Mode</strong>: Dynamic responses based on client messages</li>
<li><strong>State Management</strong>: Connection-specific state tracking</li>
<li><strong>Template Support</strong>: Dynamic message content generation</li>
</ul>
<h4 id="mockforge-grpc---grpc-service-mocking"><a class="header" href="#mockforge-grpc---grpc-service-mocking"><code>mockforge-grpc</code> - gRPC Service Mocking</a></h4>
<p>Protocol buffer-based service mocking:</p>
<ul>
<li><strong>Dynamic Proto Discovery</strong>: Automatic compilation of <code>.proto</code> files</li>
<li><strong>Service Reflection</strong>: Runtime service discovery and inspection</li>
<li><strong>Streaming Support</strong>: Unary, server, client, and bidirectional streaming</li>
<li><strong>Schema Validation</strong>: Message validation against proto definitions</li>
</ul>
<h4 id="mockforge-data---synthetic-data-generation"><a class="header" href="#mockforge-data---synthetic-data-generation"><code>mockforge-data</code> - Synthetic Data Generation</a></h4>
<p>Advanced data generation capabilities:</p>
<ul>
<li><strong>Faker Integration</strong>: Realistic fake data generation</li>
<li><strong>RAG Enhancement</strong>: Retrieval-augmented generation for contextual data</li>
<li><strong>Schema-Driven Generation</strong>: Data conforming to JSON Schema/OpenAPI specs</li>
<li><strong>Template Helpers</strong>: Integration with core templating system</li>
</ul>
<h4 id="mockforge-cli---command-line-interface"><a class="header" href="#mockforge-cli---command-line-interface"><code>mockforge-cli</code> - Command-Line Interface</a></h4>
<p>User-facing command-line tool:</p>
<ul>
<li><strong>Server Management</strong>: Start/stop mock servers</li>
<li><strong>Configuration</strong>: Load and validate configuration files</li>
<li><strong>Data Generation</strong>: Command-line data generation utilities</li>
<li><strong>Development Tools</strong>: Testing and debugging utilities</li>
</ul>
<h4 id="mockforge-ui---admin-web-interface"><a class="header" href="#mockforge-ui---admin-web-interface"><code>mockforge-ui</code> - Admin Web Interface</a></h4>
<p>Browser-based management interface:</p>
<ul>
<li><strong>Real-time Monitoring</strong>: Live request/response viewing</li>
<li><strong>Configuration Management</strong>: Runtime configuration changes</li>
<li><strong>Fixture Management</strong>: Recorded interaction management</li>
<li><strong>Performance Metrics</strong>: Response times and error rates</li>
</ul>
<h2 id="core-engine-architecture"><a class="header" href="#core-engine-architecture">Core Engine Architecture</a></h2>
<h3 id="request-processing-pipeline"><a class="header" href="#request-processing-pipeline">Request Processing Pipeline</a></h3>
<p>All requests follow a unified processing pipeline regardless of protocol:</p>
<ol>
<li><strong>Request Reception</strong>: Protocol-specific server receives request</li>
<li><strong>Route Matching</strong>: Core routing engine matches request to handler</li>
<li><strong>Validation</strong>: Schema validation if enabled</li>
<li><strong>Template Processing</strong>: Dynamic content generation</li>
<li><strong>Latency Injection</strong>: Artificial delays if configured</li>
<li><strong>Failure Injection</strong>: Error simulation if enabled</li>
<li><strong>Response Generation</strong>: Handler generates response</li>
<li><strong>Logging</strong>: Request/response logging</li>
<li><strong>Response Delivery</strong>: Protocol-specific response sending</li>
</ol>
<pre><code class="language-mermaid">sequenceDiagram
    participant Client
    participant Server as Protocol Server&lt;br/&gt;(HTTP/WS/gRPC)
    participant Router as Route Registry
    participant Validator
    participant Templates
    participant Latency
    participant Failure
    participant Handler
    participant Logger

    Client-&gt;&gt;Server: Incoming Request
    Server-&gt;&gt;Router: Match Route
    Router-&gt;&gt;Router: Find Handler

    alt Route Found
        Router-&gt;&gt;Validator: Validate Request

        alt Validation Enabled
            Validator-&gt;&gt;Validator: Check Schema
            alt Valid
                Validator-&gt;&gt;Templates: Process Request
            else Invalid
                Validator--&gt;&gt;Server: Validation Error
                Server--&gt;&gt;Client: 400 Bad Request
            end
        else Validation Disabled
            Validator-&gt;&gt;Templates: Process Request
        end

        Templates-&gt;&gt;Templates: Render Template
        Templates-&gt;&gt;Handler: Generate Response
        Handler-&gt;&gt;Latency: Apply Delays
        Latency-&gt;&gt;Failure: Check Failure Rules

        alt Should Fail
            Failure--&gt;&gt;Server: Simulated Error
            Server--&gt;&gt;Client: Error Response
        else Success
            Failure-&gt;&gt;Logger: Log Request/Response
            Logger--&gt;&gt;Server: Response Data
            Server--&gt;&gt;Client: Success Response
        end
    else Route Not Found
        Router--&gt;&gt;Server: No Match
        Server--&gt;&gt;Client: 404 Not Found
    end
</code></pre>
<h3 id="route-registry-system"><a class="header" href="#route-registry-system">Route Registry System</a></h3>
<p>The core routing system provides unified route management:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct RouteRegistry {
    routes: HashMap&lt;RouteKey, Vec&lt;RouteHandler&gt;&gt;,
    overrides: Overrides,
    validation_mode: ValidationMode,
}

impl RouteRegistry {
    pub fn register(&amp;mut self, key: RouteKey, handler: RouteHandler);
    pub fn match_route(&amp;self, request: &amp;Request) -&gt; Option&lt;&amp;RouteHandler&gt;;
    pub fn apply_overrides(&amp;mut self, overrides: &amp;Overrides);
}
<span class="boring">}</span></code></pre></pre>
<h3 id="template-engine"><a class="header" href="#template-engine">Template Engine</a></h3>
<p>Handlebars-based templating with custom helpers:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct TemplateEngine {
    registry: handlebars::Handlebars&lt;'static&gt;,
}

impl TemplateEngine {
    pub fn render(&amp;self, template: &amp;str, context: &amp;Context) -&gt; Result&lt;String&gt;;
    pub fn register_helper(&amp;mut self, name: &amp;str, helper: Box&lt;dyn HelperDef&gt;);
}
<span class="boring">}</span></code></pre></pre>
<p>Built-in helpers include:</p>
<ul>
<li><code>uuid</code>: Generate unique identifiers</li>
<li><code>now</code>: Current timestamp</li>
<li><code>randInt</code>: Random integers</li>
<li><code>request</code>: Access request data</li>
<li><code>faker</code>: Synthetic data generation</li>
</ul>
<h3 id="plugin-system-architecture"><a class="header" href="#plugin-system-architecture">Plugin System Architecture</a></h3>
<p>MockForge uses a WebAssembly-based plugin system for extensibility:</p>
<pre><code class="language-mermaid">graph TB
    subgraph "Plugin Lifecycle"
        Load[Load Plugin WASM]
        Init[Initialize Plugin]
        Register[Register Hooks]
        Execute[Execute Plugin]
        Cleanup[Cleanup Resources]
    end

    subgraph "Plugin Types"
        Auth[Authentication&lt;br/&gt;JWT, OAuth2, etc.]
        Response[Response Generators&lt;br/&gt;GraphQL, Custom Data]
        DataSource[Data Sources&lt;br/&gt;CSV, Database, API]
        Template[Template Extensions&lt;br/&gt;Custom Functions]
    end

    subgraph "Security Sandbox"
        Isolate[WASM Isolation]
        Limits[Resource Limits&lt;br/&gt;Memory, CPU, Time]
        Perms[Permission System]
    end

    subgraph "Core Integration"
        Loader[Plugin Loader]
        Registry[Plugin Registry]
        API[Plugin API]
    end

    Load --&gt; Init
    Init --&gt; Register
    Register --&gt; Execute
    Execute --&gt; Cleanup

    Auth --&gt; Loader
    Response --&gt; Loader
    DataSource --&gt; Loader
    Template --&gt; Loader

    Loader --&gt; Registry
    Registry --&gt; API

    API --&gt; Isolate
    Isolate --&gt; Limits
    Limits --&gt; Perms

    style Auth fill:#e1f5ff
    style Response fill:#e1f5ff
    style DataSource fill:#e1f5ff
    style Template fill:#e1f5ff
    style Isolate fill:#ffe1e1
    style Limits fill:#ffe1e1
    style Perms fill:#ffe1e1
</code></pre>
<p><strong>Plugin Hook Points:</strong></p>
<ol>
<li><strong>Request Interceptors</strong>: Modify incoming requests</li>
<li><strong>Response Generators</strong>: Create custom response data</li>
<li><strong>Template Helpers</strong>: Add custom template functions</li>
<li><strong>Authentication Providers</strong>: Implement auth schemes</li>
<li><strong>Data Source Connectors</strong>: Connect to external data sources</li>
</ol>
<p><strong>Security Model:</strong></p>
<ul>
<li>WASM sandboxing isolates plugin execution</li>
<li>Resource limits prevent DoS attacks</li>
<li>Permission system controls plugin capabilities</li>
<li>Plugin signature verification (planned)</li>
</ul>
<p>This architecture provides a solid foundation for API mocking while maintaining extensibility, performance, and developer experience. The modular design allows for independent evolution of each protocol implementation while sharing common infrastructure.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="cli-crate"><a class="header" href="#cli-crate">CLI Crate</a></h1>
<p>The <code>mockforge-cli</code> crate provides the primary command-line interface for MockForge, serving as the main entry point for users to interact with the MockForge ecosystem. It orchestrates all MockForge services and provides comprehensive configuration and management capabilities.</p>
<h2 id="architecture-overview-1"><a class="header" href="#architecture-overview-1">Architecture Overview</a></h2>
<pre><code class="language-mermaid">graph TD
    A[CLI Entry Point] --&gt; B[Command Parser]
    B --&gt; C{Command Type}
    C --&gt; D[Serve Command]
    C --&gt; E[Plugin Commands]
    C --&gt; F[Workspace Commands]
    C --&gt; G[Data Commands]
    C --&gt; H[Other Commands]

    D --&gt; I[Server Orchestration]
    I --&gt; J[HTTP Server]
    I --&gt; K[WebSocket Server]
    I --&gt; L[gRPC Server]
    I --&gt; M[SMTP Server]
    I --&gt; N[Admin UI]
    I --&gt; O[Metrics Server]
</code></pre>
<h2 id="core-components"><a class="header" href="#core-components">Core Components</a></h2>
<h3 id="command-structure"><a class="header" href="#command-structure">Command Structure</a></h3>
<p>The CLI uses <a href="https://github.com/clap-rs/clap">clap</a> for argument parsing and command structure. The main <code>Cli</code> struct defines the top-level interface with global options and subcommands.</p>
<h4 id="main-commands"><a class="header" href="#main-commands">Main Commands</a></h4>
<ul>
<li><strong><code>serve</code></strong>: Start MockForge servers (HTTP, WebSocket, gRPC, SMTP)</li>
<li><strong><code>admin</code></strong>: Start standalone admin UI server</li>
<li><strong><code>sync</code></strong>: Bidirectional workspace synchronization daemon</li>
<li><strong><code>plugin</code></strong>: Plugin management (install, uninstall, update, list)</li>
<li><strong><code>workspace</code></strong>: Multi-tenant workspace management</li>
<li><strong><code>data</code></strong>: Synthetic data generation</li>
<li><strong><code>generate-tests</code></strong>: Test generation from recorded API interactions</li>
<li><strong><code>suggest</code></strong>: AI-powered API specification suggestions</li>
<li><strong><code>bench</code></strong>: Load testing against real services</li>
<li><strong><code>orchestrate</code></strong>: Chaos experiment orchestration</li>
</ul>
<h3 id="server-orchestration"><a class="header" href="#server-orchestration">Server Orchestration</a></h3>
<p>The <code>serve</code> command is the most complex, supporting extensive configuration options:</p>
<h4 id="server-types"><a class="header" href="#server-types">Server Types</a></h4>
<ul>
<li><strong>HTTP Server</strong>: REST API mocking with OpenAPI support</li>
<li><strong>WebSocket Server</strong>: Real-time messaging simulation</li>
<li><strong>gRPC Server</strong>: Protocol buffer-based service mocking</li>
<li><strong>SMTP Server</strong>: Email service simulation</li>
<li><strong>Admin UI</strong>: Web-based management interface</li>
<li><strong>Metrics Server</strong>: Prometheus metrics endpoint</li>
</ul>
<h4 id="configuration-layers"><a class="header" href="#configuration-layers">Configuration Layers</a></h4>
<p>The CLI implements a three-tier configuration precedence system:</p>
<ol>
<li><strong>CLI Arguments</strong>: Highest precedence, command-line flags</li>
<li><strong>Configuration File</strong>: YAML/JSON config file (optional)</li>
<li><strong>Environment Variables</strong>: Lowest precedence, environment overrides</li>
</ol>
<h4 id="advanced-features-7"><a class="header" href="#advanced-features-7">Advanced Features</a></h4>
<ul>
<li><strong>Chaos Engineering</strong>: Fault injection, latency simulation, network degradation</li>
<li><strong>Traffic Shaping</strong>: Bandwidth limiting, packet loss simulation</li>
<li><strong>Observability</strong>: OpenTelemetry tracing, Prometheus metrics, API flight recording</li>
<li><strong>AI Integration</strong>: RAG-powered intelligent mocking</li>
<li><strong>Multi-tenancy</strong>: Workspace isolation and management</li>
</ul>
<h2 id="key-modules"><a class="header" href="#key-modules">Key Modules</a></h2>
<h3 id="mainrs"><a class="header" href="#mainrs"><code>main.rs</code></a></h3>
<p>The main entry point that:</p>
<ul>
<li>Parses CLI arguments using clap</li>
<li>Initializes logging and observability</li>
<li>Routes commands to appropriate handlers</li>
<li>Manages server lifecycle and graceful shutdown</li>
</ul>
<h3 id="plugin_commandsrs"><a class="header" href="#plugin_commandsrs"><code>plugin_commands.rs</code></a></h3>
<p>Handles plugin ecosystem management:</p>
<ul>
<li>Plugin installation from various sources (URLs, Git repos, local paths)</li>
<li>Plugin validation and security verification</li>
<li>Cache management for downloaded plugins</li>
<li>Registry integration (future feature)</li>
</ul>
<h3 id="workspace_commandsrs"><a class="header" href="#workspace_commandsrs"><code>workspace_commands.rs</code></a></h3>
<p>Multi-tenant workspace management:</p>
<ul>
<li>CRUD operations for workspaces</li>
<li>Workspace statistics and monitoring</li>
<li>Enable/disable workspace functionality</li>
<li>REST API integration with admin UI</li>
</ul>
<h3 id="import-modules"><a class="header" href="#import-modules">Import Modules</a></h3>
<ul>
<li><code>curl_import.rs</code>: Convert curl commands to MockForge configurations</li>
<li><code>postman_import.rs</code>: Import Postman collections</li>
<li><code>insomnia_import.rs</code>: Import Insomnia workspaces</li>
<li><code>import_utils.rs</code>: Shared utilities for import operations</li>
</ul>
<h2 id="configuration-management-1"><a class="header" href="#configuration-management-1">Configuration Management</a></h2>
<h3 id="server-configuration-building"><a class="header" href="#server-configuration-building">Server Configuration Building</a></h3>
<p>The <code>build_server_config_from_cli()</code> function merges configuration from multiple sources:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Step 1: Load config from file if provided
let mut config = load_config_with_fallback(path)?;

// Step 2: Apply environment variable overrides
config = apply_env_overrides(config);

// Step 3: Apply CLI argument overrides (highest precedence)
config.http.port = serve_args.http_port;
// ... more overrides
<span class="boring">}</span></code></pre></pre>
<h3 id="validation-2"><a class="header" href="#validation-2">Validation</a></h3>
<p>Before starting servers, the CLI performs comprehensive validation:</p>
<ul>
<li>Configuration file existence and readability</li>
<li>OpenAPI spec file validation</li>
<li>Port availability checking</li>
<li>Dry-run mode for configuration testing</li>
</ul>
<h2 id="server-lifecycle-management"><a class="header" href="#server-lifecycle-management">Server Lifecycle Management</a></h2>
<h3 id="concurrent-server-startup"><a class="header" href="#concurrent-server-startup">Concurrent Server Startup</a></h3>
<p>All servers are started concurrently using Tokio tasks:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Start HTTP server
let http_handle = tokio::spawn(async move {
    mockforge_http::serve_router(http_port, http_app)
});

// Start WebSocket server
let ws_handle = tokio::spawn(async move {
    mockforge_ws::start_with_latency(ws_port, None)
});

// Start gRPC server
let grpc_handle = tokio::spawn(async move {
    mockforge_grpc::start(grpc_port)
});
<span class="boring">}</span></code></pre></pre>
<h3 id="graceful-shutdown"><a class="header" href="#graceful-shutdown">Graceful Shutdown</a></h3>
<p>The CLI implements graceful shutdown using Tokio‚Äôs <code>CancellationToken</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let shutdown_token = CancellationToken::new();

// All servers listen for cancellation
tokio::select! {
    result = server_task =&gt; { /* handle result */ }
    _ = shutdown_token.cancelled() =&gt; { /* cleanup */ }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="integration-points"><a class="header" href="#integration-points">Integration Points</a></h2>
<h3 id="core-crate-dependencies"><a class="header" href="#core-crate-dependencies">Core Crate Dependencies</a></h3>
<p>The CLI depends on all MockForge service crates:</p>
<ul>
<li><code>mockforge-core</code>: Configuration and shared utilities</li>
<li><code>mockforge-http</code>: HTTP server implementation</li>
<li><code>mockforge-ws</code>: WebSocket server</li>
<li><code>mockforge-grpc</code>: gRPC server</li>
<li><code>mockforge-smtp</code>: SMTP server</li>
<li><code>mockforge-ui</code>: Admin interface</li>
<li><code>mockforge-observability</code>: Metrics and tracing</li>
<li><code>mockforge-data</code>: Data generation and RAG</li>
<li><code>mockforge-plugin-*</code>: Plugin ecosystem</li>
</ul>
<h3 id="external-integrations"><a class="header" href="#external-integrations">External Integrations</a></h3>
<ul>
<li><strong>OpenTelemetry</strong>: Distributed tracing</li>
<li><strong>Prometheus</strong>: Metrics collection</li>
<li><strong>Jaeger</strong>: Trace visualization</li>
<li><strong>Plugin Registry</strong>: Remote plugin distribution</li>
<li><strong>AI Providers</strong>: OpenAI, Anthropic, Ollama for intelligent features</li>
</ul>
<h2 id="error-handling-4"><a class="header" href="#error-handling-4">Error Handling</a></h2>
<p>The CLI implements comprehensive error handling:</p>
<ul>
<li>User-friendly error messages with suggestions</li>
<li>Validation errors with specific guidance</li>
<li>Network error recovery and retry logic</li>
<li>Graceful degradation when services fail</li>
</ul>
<h2 id="testing-5"><a class="header" href="#testing-5">Testing</a></h2>
<p>The CLI includes integration tests in <code>tests/cli_integration_tests.rs</code> and configuration validation tests in <code>tests/config_validation_tests.rs</code>, ensuring reliability of the command-line interface and configuration parsing.</p>
<h2 id="future-enhancements"><a class="header" href="#future-enhancements">Future Enhancements</a></h2>
<ul>
<li><strong>Plugin Marketplace</strong>: Integrated plugin discovery and installation</li>
<li><strong>Interactive Mode</strong>: Shell-like interface for complex workflows</li>
<li><strong>Configuration Wizards</strong>: Guided setup for new users</li>
<li><strong>Remote Management</strong>: Cloud-based MockForge instance management</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="http-crate"><a class="header" href="#http-crate">HTTP Crate</a></h1>
<p>The <code>mockforge-http</code> crate provides comprehensive HTTP/REST API mocking capabilities for MockForge, built on top of the <a href="https://github.com/tokio-rs/axum">Axum</a> web framework. It integrates OpenAPI specification support, AI-powered response generation, comprehensive management APIs, and advanced middleware for observability and traffic control.</p>
<h2 id="architecture-overview-2"><a class="header" href="#architecture-overview-2">Architecture Overview</a></h2>
<pre><code class="language-mermaid">graph TD
    A[HTTP Server] --&gt; B[Router Builder]
    B --&gt; C{Configuration Type}
    C --&gt; D[OpenAPI Router]
    C --&gt; E[Basic Router]
    C --&gt; F[Auth Router]
    C --&gt; G[Chain Router]

    D --&gt; H[OpenAPI Spec Loader]
    H --&gt; I[Route Registry]
    I --&gt; J[Validation Middleware]

    A --&gt; K[Middleware Stack]
    K --&gt; L[Rate Limiting]
    K --&gt; M[Request Logging]
    K --&gt; N[Metrics Collection]
    K --&gt; O[Tracing]

    A --&gt; P[Management API]
    P --&gt; Q[REST Endpoints]
    P --&gt; R[WebSocket Events]
    P --&gt; S[SSE Streams]

    A --&gt; T[AI Integration]
    T --&gt; U[Intelligent Generation]
    T --&gt; V[Data Drift]
</code></pre>
<h2 id="core-components-1"><a class="header" href="#core-components-1">Core Components</a></h2>
<h3 id="router-building-system"><a class="header" href="#router-building-system">Router Building System</a></h3>
<p>The HTTP crate provides multiple router builders for different use cases:</p>
<h4 id="build_router"><a class="header" href="#build_router"><code>build_router()</code></a></h4>
<p>Basic router with optional OpenAPI integration:</p>
<ul>
<li>Loads and validates OpenAPI specifications</li>
<li>Creates route handlers from spec operations</li>
<li>Applies validation middleware</li>
<li>Includes health check endpoints</li>
</ul>
<h4 id="build_router_with_auth"><a class="header" href="#build_router_with_auth"><code>build_router_with_auth()</code></a></h4>
<p>Router with authentication support:</p>
<ul>
<li>Integrates OAuth2 and JWT authentication</li>
<li>Supports custom auth middleware</li>
<li>Validates tokens and permissions</li>
</ul>
<h4 id="build_router_with_chains"><a class="header" href="#build_router_with_chains"><code>build_router_with_chains()</code></a></h4>
<p>Router with request chaining support:</p>
<ul>
<li>Enables multi-step request workflows</li>
<li>Manages chain execution state</li>
<li>Provides chain management endpoints</li>
</ul>
<h4 id="build_router_with_traffic_shaping"><a class="header" href="#build_router_with_traffic_shaping"><code>build_router_with_traffic_shaping()</code></a></h4>
<p>Router with traffic control:</p>
<ul>
<li>Bandwidth limiting and packet loss simulation</li>
<li>Network condition emulation</li>
<li>Traffic shaping middleware</li>
</ul>
<h3 id="openapi-integration-4"><a class="header" href="#openapi-integration-4">OpenAPI Integration</a></h3>
<h4 id="specification-loading"><a class="header" href="#specification-loading">Specification Loading</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Load OpenAPI spec from file
let openapi = OpenApiSpec::from_file("api.yaml").await?;

// Create route registry with validation options
let registry = OpenApiRouteRegistry::new_with_options(
    openapi,
    ValidationOptions::enforce()
);
<span class="boring">}</span></code></pre></pre>
<h4 id="route-generation"><a class="header" href="#route-generation">Route Generation</a></h4>
<ul>
<li>Automatic endpoint creation from OpenAPI operations</li>
<li>Parameter extraction and validation</li>
<li>Response schema validation</li>
<li>Error response generation</li>
</ul>
<h4 id="validation-modes-2"><a class="header" href="#validation-modes-2">Validation Modes</a></h4>
<ul>
<li><strong>Strict</strong>: Full request/response validation</li>
<li><strong>Lenient</strong>: Warnings for validation failures</li>
<li><strong>Disabled</strong>: No validation (performance mode)</li>
</ul>
<h3 id="middleware-architecture"><a class="header" href="#middleware-architecture">Middleware Architecture</a></h3>
<h4 id="request-processing-pipeline-1"><a class="header" href="#request-processing-pipeline-1">Request Processing Pipeline</a></h4>
<pre><code>Request ‚Üí Rate Limiting ‚Üí Authentication ‚Üí Logging ‚Üí Metrics ‚Üí Handler ‚Üí Response
</code></pre>
<h4 id="key-middleware-components"><a class="header" href="#key-middleware-components">Key Middleware Components</a></h4>
<ul>
<li><strong>Rate Limiting</strong>: Uses <code>governor</code> crate for distributed rate limiting</li>
<li><strong>Request Logging</strong>: Comprehensive HTTP request/response logging</li>
<li><strong>Metrics Collection</strong>: Prometheus-compatible metrics</li>
<li><strong>Tracing</strong>: OpenTelemetry integration for distributed tracing</li>
<li><strong>Traffic Shaping</strong>: Bandwidth and latency control</li>
</ul>
<h3 id="management-api"><a class="header" href="#management-api">Management API</a></h3>
<h4 id="rest-endpoints-1"><a class="header" href="#rest-endpoints-1">REST Endpoints</a></h4>
<ul>
<li><code>GET /__mockforge/health</code> - Health check</li>
<li><code>GET /__mockforge/stats</code> - Server statistics</li>
<li><code>GET /__mockforge/routes</code> - Route information</li>
<li><code>GET /__mockforge/coverage</code> - API coverage metrics</li>
<li><code>GET/POST/PUT/DELETE /__mockforge/mocks</code> - Mock management</li>
</ul>
<h4 id="websocket-integration"><a class="header" href="#websocket-integration">WebSocket Integration</a></h4>
<ul>
<li>Real-time server events</li>
<li>Live request monitoring</li>
<li>Interactive mock configuration</li>
</ul>
<h4 id="server-sent-events-sse"><a class="header" href="#server-sent-events-sse">Server-Sent Events (SSE)</a></h4>
<ul>
<li>Log streaming to clients</li>
<li>Real-time metrics updates</li>
<li>Coverage report streaming</li>
</ul>
<h3 id="ai-powered-features"><a class="header" href="#ai-powered-features">AI-Powered Features</a></h3>
<h4 id="intelligent-mock-generation"><a class="header" href="#intelligent-mock-generation">Intelligent Mock Generation</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let ai_config = AiResponseConfig {
    enabled: true,
    rag_config: RagConfig {
        provider: "openai".to_string(),
        model: "gpt-4".to_string(),
        api_key: Some(api_key),
    },
    prompt: "Generate realistic user data".to_string(),
};

let response = process_response_with_ai(&amp;ai_config, request_data).await?;
<span class="boring">}</span></code></pre></pre>
<h4 id="data-drift-simulation"><a class="header" href="#data-drift-simulation">Data Drift Simulation</a></h4>
<ul>
<li>Progressive response changes over time</li>
<li>Realistic data evolution patterns</li>
<li>Configurable drift parameters</li>
</ul>
<h3 id="authentication-system"><a class="header" href="#authentication-system">Authentication System</a></h3>
<h4 id="supported-methods"><a class="header" href="#supported-methods">Supported Methods</a></h4>
<ul>
<li><strong>OAuth2</strong>: Authorization code, client credentials flows</li>
<li><strong>JWT</strong>: Token validation and claims extraction</li>
<li><strong>API Keys</strong>: Header and query parameter validation</li>
<li><strong>Basic Auth</strong>: Username/password authentication</li>
</ul>
<h4 id="auth-middleware"><a class="header" href="#auth-middleware">Auth Middleware</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let auth_middleware = auth_middleware(auth_state);
app = app.layer(auth_middleware);
<span class="boring">}</span></code></pre></pre>
<h3 id="request-chaining"><a class="header" href="#request-chaining">Request Chaining</a></h3>
<h4 id="chain-execution-engine"><a class="header" href="#chain-execution-engine">Chain Execution Engine</a></h4>
<ul>
<li>Multi-step request workflows</li>
<li>Conditional execution based on responses</li>
<li>Chain state management and persistence</li>
<li>Execution history and debugging</li>
</ul>
<h4 id="chain-management-api"><a class="header" href="#chain-management-api">Chain Management API</a></h4>
<ul>
<li><code>POST /__mockforge/chains</code> - Create chains</li>
<li><code>GET /__mockforge/chains/{id}/execute</code> - Execute chains</li>
<li><code>GET /__mockforge/chains/{id}/history</code> - View execution history</li>
</ul>
<h3 id="multi-tenant-support"><a class="header" href="#multi-tenant-support">Multi-Tenant Support</a></h3>
<h4 id="workspace-isolation"><a class="header" href="#workspace-isolation">Workspace Isolation</a></h4>
<ul>
<li>Path-based routing (<code>/workspace1/api/*</code>, <code>/workspace2/api/*</code>)</li>
<li>Port-based isolation (different ports per tenant)</li>
<li>Configuration isolation per workspace</li>
</ul>
<h4 id="auto-discovery"><a class="header" href="#auto-discovery">Auto-Discovery</a></h4>
<ul>
<li>Automatic workspace loading from config directories</li>
<li>YAML-based workspace definitions</li>
<li>Dynamic workspace registration</li>
</ul>
<h3 id="observability-integration-1"><a class="header" href="#observability-integration-1">Observability Integration</a></h3>
<h4 id="metrics-collection"><a class="header" href="#metrics-collection">Metrics Collection</a></h4>
<ul>
<li>Request/response counts and timings</li>
<li>Error rates and status code distribution</li>
<li>Route coverage and usage statistics</li>
<li>Performance histograms</li>
</ul>
<h4 id="tracing-integration"><a class="header" href="#tracing-integration">Tracing Integration</a></h4>
<ul>
<li>Distributed tracing with OpenTelemetry</li>
<li>Request correlation IDs</li>
<li>Span tagging for operations</li>
<li>Jaeger and Zipkin export support</li>
</ul>
<h4 id="logging"><a class="header" href="#logging">Logging</a></h4>
<ul>
<li>Structured JSON logging</li>
<li>Request/response body logging (configurable)</li>
<li>Error tracking and correlation</li>
<li>Log level configuration</li>
</ul>
<h3 id="traffic-shaping-and-chaos-engineering"><a class="header" href="#traffic-shaping-and-chaos-engineering">Traffic Shaping and Chaos Engineering</a></h3>
<h4 id="network-simulation"><a class="header" href="#network-simulation">Network Simulation</a></h4>
<ul>
<li>Bandwidth limiting (bytes per second)</li>
<li>Packet loss simulation (percentage)</li>
<li>Latency injection (fixed or random)</li>
<li>Connection failure simulation</li>
</ul>
<h4 id="chaos-scenarios"><a class="header" href="#chaos-scenarios">Chaos Scenarios</a></h4>
<ul>
<li>Predefined network profiles (3G, 4G, 5G, satellite)</li>
<li>Custom traffic shaping rules</li>
<li>Circuit breaker patterns</li>
<li>Bulkhead isolation</li>
</ul>
<h3 id="testing-and-validation"><a class="header" href="#testing-and-validation">Testing and Validation</a></h3>
<h4 id="integration-tests-1"><a class="header" href="#integration-tests-1">Integration Tests</a></h4>
<ul>
<li>End-to-end request/response validation</li>
<li>OpenAPI compliance testing</li>
<li>Authentication flow testing</li>
<li>Performance benchmarking</li>
</ul>
<h4 id="coverage-analysis"><a class="header" href="#coverage-analysis">Coverage Analysis</a></h4>
<ul>
<li>API endpoint coverage tracking</li>
<li>Request pattern analysis</li>
<li>Missing endpoint detection</li>
<li>Coverage reporting and visualization</li>
</ul>
<h2 id="key-data-structures"><a class="header" href="#key-data-structures">Key Data Structures</a></h2>
<h3 id="httpserverstate"><a class="header" href="#httpserverstate"><code>HttpServerState</code></a></h3>
<p>Shared state for route information and rate limiting:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct HttpServerState {
    pub routes: Vec&lt;RouteInfo&gt;,
    pub rate_limiter: Option&lt;Arc&lt;GlobalRateLimiter&gt;&gt;,
}
<span class="boring">}</span></code></pre></pre>
<h3 id="managementstate"><a class="header" href="#managementstate"><code>ManagementState</code></a></h3>
<p>Management API state with server statistics:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct ManagementState {
    pub mocks: Arc&lt;RwLock&lt;Vec&lt;MockConfig&gt;&gt;&gt;,
    pub spec: Option&lt;Arc&lt;OpenApiSpec&gt;&gt;,
    pub request_counter: Arc&lt;RwLock&lt;u64&gt;&gt;,
}
<span class="boring">}</span></code></pre></pre>
<h3 id="airesponsehandler"><a class="header" href="#airesponsehandler"><code>AiResponseHandler</code></a></h3>
<p>AI-powered response generation:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct AiResponseHandler {
    intelligent_generator: Option&lt;IntelligentMockGenerator&gt;,
    drift_engine: Option&lt;Arc&lt;RwLock&lt;DataDriftEngine&gt;&gt;&gt;,
}
<span class="boring">}</span></code></pre></pre>
<h2 id="integration-points-1"><a class="header" href="#integration-points-1">Integration Points</a></h2>
<h3 id="core-dependencies"><a class="header" href="#core-dependencies">Core Dependencies</a></h3>
<ul>
<li><code>mockforge-core</code>: OpenAPI handling, validation, routing</li>
<li><code>mockforge-data</code>: AI generation, data templating</li>
<li><code>mockforge-observability</code>: Metrics, logging, tracing</li>
</ul>
<h3 id="external-integrations-1"><a class="header" href="#external-integrations-1">External Integrations</a></h3>
<ul>
<li><strong>Axum</strong>: Web framework for HTTP handling</li>
<li><strong>OpenTelemetry</strong>: Distributed tracing</li>
<li><strong>Prometheus</strong>: Metrics collection</li>
<li><strong>OAuth2</strong>: Authentication flows</li>
<li><strong>Governor</strong>: Rate limiting</li>
<li><strong>Reqwest</strong>: HTTP client for chaining</li>
</ul>
<h2 id="performance-considerations-4"><a class="header" href="#performance-considerations-4">Performance Considerations</a></h2>
<h3 id="startup-optimization"><a class="header" href="#startup-optimization">Startup Optimization</a></h3>
<ul>
<li>Lazy OpenAPI spec loading</li>
<li>Parallel route registry creation</li>
<li>Cached validation schemas</li>
<li>Startup time profiling and logging</li>
</ul>
<h3 id="runtime-performance"><a class="header" href="#runtime-performance">Runtime Performance</a></h3>
<ul>
<li>Efficient middleware pipeline</li>
<li>Minimal allocations in hot paths</li>
<li>Async request processing</li>
<li>Connection pooling for external calls</li>
</ul>
<h3 id="memory-management-1"><a class="header" href="#memory-management-1">Memory Management</a></h3>
<ul>
<li>Shared state with Arc/RwLock</li>
<li>Response streaming for large payloads</li>
<li>Configurable request body limits</li>
<li>Automatic cleanup of expired sessions</li>
</ul>
<h2 id="error-handling-5"><a class="header" href="#error-handling-5">Error Handling</a></h2>
<h3 id="validation-errors-2"><a class="header" href="#validation-errors-2">Validation Errors</a></h3>
<ul>
<li>Structured error responses</li>
<li>OpenAPI-compliant error schemas</li>
<li>Configurable error verbosity</li>
<li>Error correlation IDs</li>
</ul>
<h3 id="recovery-mechanisms"><a class="header" href="#recovery-mechanisms">Recovery Mechanisms</a></h3>
<ul>
<li>Graceful degradation on failures</li>
<li>Fallback responses for AI generation</li>
<li>Circuit breaker patterns</li>
<li>Automatic retry logic</li>
</ul>
<h2 id="future-enhancements-1"><a class="header" href="#future-enhancements-1">Future Enhancements</a></h2>
<ul>
<li><strong>GraphQL Integration</strong>: Schema-based GraphQL mocking</li>
<li><strong>WebSocket Mocking</strong>: Interactive WebSocket scenarios</li>
<li><strong>Advanced Caching</strong>: Response caching and invalidation</li>
<li><strong>Load Balancing</strong>: Multi-instance coordination</li>
<li><strong>Plugin Architecture</strong>: Extensible middleware system</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="grpc-crate"><a class="header" href="#grpc-crate">gRPC Crate</a></h1>
<p>The <code>mockforge-grpc</code> crate provides comprehensive gRPC protocol support for MockForge, featuring dynamic service discovery, runtime protobuf parsing, and HTTP bridge capabilities. It enables automatic mocking of gRPC services without code generation, supporting all streaming patterns and providing rich introspection features.</p>
<h2 id="architecture-overview-3"><a class="header" href="#architecture-overview-3">Architecture Overview</a></h2>
<pre><code class="language-mermaid">graph TD
    A[gRPC Server] --&gt; B[Dynamic Service Discovery]
    B --&gt; C[Proto Parser]
    C --&gt; D[Service Registry]
    D --&gt; E[Dynamic Service Generator]

    A --&gt; F[gRPC Reflection]
    F --&gt; G[Reflection Proxy]
    G --&gt; H[Descriptor Pool]

    A --&gt; I[HTTP Bridge]
    I --&gt; J[REST API Generator]
    J --&gt; K[OpenAPI Spec]

    A --&gt; L[Streaming Support]
    L --&gt; M[Unary RPC]
    L --&gt; N[Server Streaming]
    L --&gt; O[Client Streaming]
    L --&gt; P[Bidirectional Streaming]
</code></pre>
<h2 id="core-components-2"><a class="header" href="#core-components-2">Core Components</a></h2>
<h3 id="dynamic-service-discovery"><a class="header" href="#dynamic-service-discovery">Dynamic Service Discovery</a></h3>
<p>The gRPC crate‚Äôs core innovation is runtime service discovery and mocking without code generation:</p>
<h4 id="proto-parser"><a class="header" href="#proto-parser">Proto Parser</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Parse protobuf files at runtime
let mut parser = ProtoParser::new();
parser.parse_directory("./proto").await?;

// Extract services and methods
let services = parser.services();
let descriptor_pool = parser.into_pool();
<span class="boring">}</span></code></pre></pre>
<h4 id="service-registry"><a class="header" href="#service-registry">Service Registry</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Create registry with parsed services
let mut registry = ServiceRegistry::with_descriptor_pool(descriptor_pool);

// Register dynamic service implementations
for (name, proto_service) in services {
    let dynamic_service = DynamicGrpcService::new(proto_service, config);
    registry.register(name, dynamic_service);
}
<span class="boring">}</span></code></pre></pre>
<h3 id="grpc-reflection"><a class="header" href="#grpc-reflection">gRPC Reflection</a></h3>
<h4 id="reflection-proxy"><a class="header" href="#reflection-proxy">Reflection Proxy</a></h4>
<p>Enables runtime service discovery and method invocation:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let proxy_config = ProxyConfig::default();
let mock_proxy = MockReflectionProxy::new(proxy_config, registry).await?;

// Server supports reflection queries
// grpcurl -plaintext localhost:50051 list
// grpcurl -plaintext localhost:50051 describe MyService
<span class="boring">}</span></code></pre></pre>
<h4 id="descriptor-management"><a class="header" href="#descriptor-management">Descriptor Management</a></h4>
<ul>
<li><strong>Descriptor Pool</strong>: In-memory protobuf descriptor storage</li>
<li><strong>Dynamic Resolution</strong>: Runtime method and message resolution</li>
<li><strong>Schema Introspection</strong>: Full protobuf schema access</li>
</ul>
<h3 id="http-bridge"><a class="header" href="#http-bridge">HTTP Bridge</a></h3>
<h4 id="rest-api-generation"><a class="header" href="#rest-api-generation">REST API Generation</a></h4>
<p>Automatically converts gRPC services to REST endpoints:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let config = DynamicGrpcConfig {
    enable_http_bridge: true,
    http_bridge_port: 8080,
    generate_openapi: true,
    ..Default::default()
};

// gRPC: MyService/GetUser ‚Üí HTTP: POST /api/myservice/getuser
<span class="boring">}</span></code></pre></pre>
<h4 id="openapi-generation-1"><a class="header" href="#openapi-generation-1">OpenAPI Generation</a></h4>
<ul>
<li>Automatic OpenAPI 3.0 spec generation from protobuf definitions</li>
<li>REST endpoint documentation</li>
<li>Request/response schema documentation</li>
</ul>
<h3 id="streaming-support-1"><a class="header" href="#streaming-support-1">Streaming Support</a></h3>
<h4 id="all-streaming-patterns"><a class="header" href="#all-streaming-patterns">All Streaming Patterns</a></h4>
<p>The crate supports all four gRPC streaming patterns:</p>
<ul>
<li><strong>Unary RPC</strong>: Simple request-response</li>
<li><strong>Server Streaming</strong>: Single request, streaming response</li>
<li><strong>Client Streaming</strong>: Streaming request, single response</li>
<li><strong>Bidirectional Streaming</strong>: Streaming in both directions</li>
</ul>
<h4 id="streaming-implementation"><a class="header" href="#streaming-implementation">Streaming Implementation</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Server streaming
async fn list_users(
    &amp;self,
    request: Request&lt;ListUsersRequest&gt;,
) -&gt; Result&lt;Response&lt;Self::ListUsersStream&gt;, Status&gt; {
    // Return stream of User messages
}

// Bidirectional streaming
async fn chat(
    &amp;self,
    request: Request&lt;Streaming&lt;ChatMessage&gt;&gt;,
) -&gt; Result&lt;Response&lt;Self::ChatStream&gt;, Status&gt; {
    // Handle bidirectional message stream
}
<span class="boring">}</span></code></pre></pre>
<h2 id="key-modules-1"><a class="header" href="#key-modules-1">Key Modules</a></h2>
<h3 id="dynamic"><a class="header" href="#dynamic"><code>dynamic/</code></a></h3>
<p>Core dynamic service functionality:</p>
<h4 id="proto_parserrs"><a class="header" href="#proto_parserrs"><code>proto_parser.rs</code></a></h4>
<ul>
<li>Runtime protobuf file parsing</li>
<li>Service and method extraction</li>
<li>Message descriptor generation</li>
</ul>
<h4 id="service_generatorrs"><a class="header" href="#service_generatorrs"><code>service_generator.rs</code></a></h4>
<ul>
<li>Dynamic service implementation generation</li>
<li>Mock response synthesis</li>
<li>Streaming method handling</li>
</ul>
<h4 id="http_bridge"><a class="header" href="#http_bridge"><code>http_bridge/</code></a></h4>
<ul>
<li>REST API conversion logic</li>
<li>OpenAPI specification generation</li>
<li>HTTP request/response mapping</li>
</ul>
<h3 id="reflection"><a class="header" href="#reflection"><code>reflection/</code></a></h3>
<p>gRPC reflection protocol implementation:</p>
<h4 id="mock_proxyrs"><a class="header" href="#mock_proxyrs"><code>mock_proxy.rs</code></a></h4>
<ul>
<li>Reflection service implementation</li>
<li>Dynamic method invocation</li>
<li>Response generation</li>
</ul>
<h4 id="clientrs"><a class="header" href="#clientrs"><code>client.rs</code></a></h4>
<ul>
<li>Reflection client for service discovery</li>
<li>Dynamic RPC calls</li>
<li>Connection pooling</li>
</ul>
<h4 id="smart_mock_generatorrs"><a class="header" href="#smart_mock_generatorrs"><code>smart_mock_generator.rs</code></a></h4>
<ul>
<li>AI-powered response generation</li>
<li>Schema-aware data synthesis</li>
<li>Contextual mock data</li>
</ul>
<h3 id="registryrs"><a class="header" href="#registryrs"><code>registry.rs</code></a></h3>
<p>Service registration and management:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct GrpcProtoRegistry {
    services: HashMap&lt;String, ProtoService&gt;,
    descriptor_pool: DescriptorPool,
}
<span class="boring">}</span></code></pre></pre>
<h2 id="configuration-34"><a class="header" href="#configuration-34">Configuration</a></h2>
<h3 id="dynamicgrpcconfig"><a class="header" href="#dynamicgrpcconfig">DynamicGrpcConfig</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[derive(Debug, Clone)]
pub struct DynamicGrpcConfig {
    pub proto_dir: String,                    // Proto file directory
    pub enable_reflection: bool,              // Enable gRPC reflection
    pub excluded_services: Vec&lt;String&gt;,       // Services to skip
    pub http_bridge: Option&lt;HttpBridgeConfig&gt;, // HTTP bridge settings
    pub max_message_size: usize,              // Max message size
}
<span class="boring">}</span></code></pre></pre>
<h3 id="http-bridge-config"><a class="header" href="#http-bridge-config">HTTP Bridge Config</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct HttpBridgeConfig {
    pub enabled: bool,                        // Enable HTTP bridge
    pub port: u16,                           // HTTP server port
    pub generate_openapi: bool,              // Generate OpenAPI specs
    pub cors_enabled: bool,                  // Enable CORS
}
<span class="boring">}</span></code></pre></pre>
<h2 id="advanced-data-synthesis-1"><a class="header" href="#advanced-data-synthesis-1">Advanced Data Synthesis</a></h2>
<h3 id="intelligent-field-inference"><a class="header" href="#intelligent-field-inference">Intelligent Field Inference</a></h3>
<p>The crate uses field names and types to generate realistic mock data:</p>
<pre><code class="language-protobuf">message User {
  string id = 1;           // Generates UUIDs
  string email = 2;        // Generates email addresses
  string phone = 3;        // Generates phone numbers
  repeated string tags = 4; // Generates string arrays
}
</code></pre>
<h3 id="referential-integrity-1"><a class="header" href="#referential-integrity-1">Referential Integrity</a></h3>
<p>Maintains relationships between messages:</p>
<ul>
<li>Foreign key relationships</li>
<li>Consistent ID generation</li>
<li>Cross-message data consistency</li>
</ul>
<h3 id="deterministic-seeding"><a class="header" href="#deterministic-seeding">Deterministic Seeding</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Reproducible test data
let config = MockConfig {
    seed: Some(42),
    ..Default::default()
};
<span class="boring">}</span></code></pre></pre>
<h2 id="performance-features"><a class="header" href="#performance-features">Performance Features</a></h2>
<h3 id="connection-pooling-1"><a class="header" href="#connection-pooling-1">Connection Pooling</a></h3>
<ul>
<li>Efficient gRPC connection management</li>
<li>Connection reuse and lifecycle management</li>
<li>Load balancing across connections</li>
</ul>
<h3 id="caching-1"><a class="header" href="#caching-1">Caching</a></h3>
<ul>
<li>Descriptor caching for performance</li>
<li>Response caching for repeated requests</li>
<li>Schema compilation caching</li>
</ul>
<h3 id="async-processing"><a class="header" href="#async-processing">Async Processing</a></h3>
<ul>
<li>Tokio-based async runtime</li>
<li>Streaming data processing</li>
<li>Concurrent request handling</li>
</ul>
<h2 id="integration-points-2"><a class="header" href="#integration-points-2">Integration Points</a></h2>
<h3 id="core-dependencies-1"><a class="header" href="#core-dependencies-1">Core Dependencies</a></h3>
<ul>
<li><code>mockforge-core</code>: Base mocking functionality</li>
<li><code>mockforge-data</code>: Advanced data generation</li>
<li><code>mockforge-observability</code>: Metrics and tracing</li>
</ul>
<h3 id="external-libraries"><a class="header" href="#external-libraries">External Libraries</a></h3>
<ul>
<li><strong>Tonic</strong>: gRPC framework for Rust</li>
<li><strong>Prost</strong>: Protocol buffer implementation</li>
<li><strong>Prost-reflect</strong>: Runtime protobuf reflection</li>
<li><strong>Tokio</strong>: Async runtime</li>
</ul>
<h2 id="observability"><a class="header" href="#observability">Observability</a></h2>
<h3 id="metrics-collection-1"><a class="header" href="#metrics-collection-1">Metrics Collection</a></h3>
<ul>
<li>Request/response counts</li>
<li>Method execution times</li>
<li>Error rates by service/method</li>
<li>Streaming metrics</li>
</ul>
<h3 id="tracing-integration-1"><a class="header" href="#tracing-integration-1">Tracing Integration</a></h3>
<ul>
<li>OpenTelemetry tracing support</li>
<li>Distributed tracing across services</li>
<li>Request correlation IDs</li>
</ul>
<h3 id="logging-1"><a class="header" href="#logging-1">Logging</a></h3>
<ul>
<li>Structured logging for all operations</li>
<li>Debug logging for request/response payloads</li>
<li>Performance logging</li>
</ul>
<h2 id="testing-support"><a class="header" href="#testing-support">Testing Support</a></h2>
<h3 id="integration-tests-2"><a class="header" href="#integration-tests-2">Integration Tests</a></h3>
<ul>
<li>End-to-end gRPC testing</li>
<li>HTTP bridge validation</li>
<li>Reflection service testing</li>
<li>Streaming functionality tests</li>
</ul>
<h3 id="mock-data-generation"><a class="header" href="#mock-data-generation">Mock Data Generation</a></h3>
<ul>
<li>Deterministic test data</li>
<li>Schema-compliant mock generation</li>
<li>Custom data providers</li>
</ul>
<h2 id="error-handling-6"><a class="header" href="#error-handling-6">Error Handling</a></h2>
<h3 id="grpc-status-codes-1"><a class="header" href="#grpc-status-codes-1">gRPC Status Codes</a></h3>
<ul>
<li>Proper gRPC status code mapping</li>
<li>Detailed error messages</li>
<li>Error correlation IDs</li>
</ul>
<h3 id="recovery-mechanisms-1"><a class="header" href="#recovery-mechanisms-1">Recovery Mechanisms</a></h3>
<ul>
<li>Connection retry logic</li>
<li>Graceful degradation</li>
<li>Fallback responses</li>
</ul>
<h2 id="build-system"><a class="header" href="#build-system">Build System</a></h2>
<h3 id="proto-compilation"><a class="header" href="#proto-compilation">Proto Compilation</a></h3>
<p>The crate uses <code>tonic-prost-build</code> for compile-time proto generation:</p>
<pre><pre class="playground"><code class="language-rust">// build.rs
fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    tonic_build::compile_protos("proto/greeter.proto")?;
    Ok(())
}</code></pre></pre>
<h3 id="feature-flags"><a class="header" href="#feature-flags">Feature Flags</a></h3>
<ul>
<li><code>data-faker</code>: Enable advanced data synthesis</li>
<li>Default features include data faker for rich mock data</li>
</ul>
<h2 id="usage-examples-3"><a class="header" href="#usage-examples-3">Usage Examples</a></h2>
<h3 id="basic-grpc-server-1"><a class="header" href="#basic-grpc-server-1">Basic gRPC Server</a></h3>
<pre><pre class="playground"><code class="language-rust">use mockforge_grpc::start;

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error + Send + Sync&gt;&gt; {
    // Auto-discovers services from ./proto directory
    start(50051).await?;
    Ok(())
}</code></pre></pre>
<h3 id="with-http-bridge"><a class="header" href="#with-http-bridge">With HTTP Bridge</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_grpc::{start_with_config, DynamicGrpcConfig};

let config = DynamicGrpcConfig {
    proto_dir: "./proto".to_string(),
    enable_reflection: true,
    http_bridge: Some(HttpBridgeConfig {
        enabled: true,
        port: 8080,
        generate_openapi: true,
    }),
    ..Default::default()
};

start_with_config(50051, None, config).await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="client-usage"><a class="header" href="#client-usage">Client Usage</a></h3>
<pre><code class="language-bash"># List services
grpcurl -plaintext localhost:50051 list

# Describe service
grpcurl -plaintext localhost:50051 describe MyService

# Call method
grpcurl -plaintext -d '{"id": "123"}' localhost:50051 MyService/GetUser

# HTTP bridge
curl -X POST http://localhost:8080/api/myservice/getuser \
  -H "Content-Type: application/json" \
  -d '{"id": "123"}'
</code></pre>
<h2 id="future-enhancements-2"><a class="header" href="#future-enhancements-2">Future Enhancements</a></h2>
<ul>
<li><strong>Advanced Streaming</strong>: Enhanced bidirectional streaming support</li>
<li><strong>Service Mesh Integration</strong>: Istio and Linkerd integration</li>
<li><strong>Schema Evolution</strong>: Automatic handling of protobuf schema changes</li>
<li><strong>Load Testing</strong>: Built-in gRPC load testing capabilities</li>
<li><strong>Code Generation</strong>: Optional compile-time service generation</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="websocket-crate"><a class="header" href="#websocket-crate">WebSocket Crate</a></h1>
<p>The <code>mockforge-ws</code> crate provides comprehensive WebSocket protocol support for MockForge, featuring replay capabilities, proxy functionality, and AI-powered event generation. It enables realistic WebSocket interaction simulation for testing and development.</p>
<h2 id="architecture-overview-4"><a class="header" href="#architecture-overview-4">Architecture Overview</a></h2>
<pre><code class="language-mermaid">graph TD
    A[WebSocket Server] --&gt; B[Connection Handler]
    B --&gt; C{Operation Mode}
    C --&gt; D[Replay Mode]
    C --&gt; E[Proxy Mode]
    C --&gt; F[Interactive Mode]
    C --&gt; G[AI Event Mode]

    D --&gt; H[Replay File Parser]
    H --&gt; I[JSONL Processor]
    I --&gt; J[Template Expansion]

    E --&gt; K[Proxy Handler]
    K --&gt; L[Upstream Connection]
    L --&gt; M[Message Forwarding]

    F --&gt; N[Message Router]
    N --&gt; O[Pattern Matching]
    O --&gt; P[Response Generation]

    G --&gt; Q[AI Event Generator]
    Q --&gt; R[LLM Integration]
    R --&gt; S[Event Stream]
</code></pre>
<h2 id="core-components-3"><a class="header" href="#core-components-3">Core Components</a></h2>
<h3 id="connection-management-2"><a class="header" href="#connection-management-2">Connection Management</a></h3>
<h4 id="websocket-router"><a class="header" href="#websocket-router">WebSocket Router</a></h4>
<p>The crate provides multiple router configurations for different use cases:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Basic WebSocket router
let app = router();

// With latency simulation
let latency_injector = LatencyInjector::new(profile, Default::default());
let app = router_with_latency(latency_injector);

// With proxy support
let proxy_handler = WsProxyHandler::new(proxy_config);
let app = router_with_proxy(proxy_handler);
<span class="boring">}</span></code></pre></pre>
<h4 id="connection-lifecycle"><a class="header" href="#connection-lifecycle">Connection Lifecycle</a></h4>
<ul>
<li><strong>Establishment</strong>: Connection tracking and metrics collection</li>
<li><strong>Message Handling</strong>: Bidirectional message processing</li>
<li><strong>Error Handling</strong>: Graceful error recovery and logging</li>
<li><strong>Termination</strong>: Connection cleanup and statistics recording</li>
</ul>
<h3 id="operational-modes"><a class="header" href="#operational-modes">Operational Modes</a></h3>
<h4 id="1-replay-mode"><a class="header" href="#1-replay-mode">1. Replay Mode</a></h4>
<p>Scripted message playback from JSONL files:</p>
<pre><code class="language-json">{"ts":0,"dir":"out","text":"HELLO {{uuid}}","waitFor":"^CLIENT_READY$"}
{"ts":10,"dir":"out","text":"{\"type\":\"welcome\",\"sessionId\":\"{{uuid}}\"}"}
{"ts":20,"dir":"out","text":"{\"data\":{{randInt 1 100}}}","waitFor":"^ACK$"}
</code></pre>
<p><strong>Features:</strong></p>
<ul>
<li>Timestamp-based message sequencing</li>
<li>Template expansion (<code>{{uuid}}</code>, <code>{{now}}</code>, <code>{{randInt min max}}</code>)</li>
<li>Conditional waiting with regex/JSONPath patterns</li>
<li>Deterministic replay for testing</li>
</ul>
<h4 id="2-proxy-mode"><a class="header" href="#2-proxy-mode">2. Proxy Mode</a></h4>
<p>Forward messages to upstream WebSocket servers:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let proxy_config = WsProxyConfig {
    upstream_url: "wss://api.example.com/ws".to_string(),
    should_proxy: true,
    message_transform: Some(transform_fn),
};
<span class="boring">}</span></code></pre></pre>
<p><strong>Features:</strong></p>
<ul>
<li>Transparent message forwarding</li>
<li>Optional message transformation</li>
<li>Connection pooling and reuse</li>
<li>Error handling and fallback</li>
</ul>
<h4 id="3-interactive-mode"><a class="header" href="#3-interactive-mode">3. Interactive Mode</a></h4>
<p>Dynamic responses based on client messages:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Echo mode (default)
while let Some(msg) = socket.recv().await {
    if let Ok(Message::Text(text)) = msg {
        let response = format!("echo: {}", text);
        socket.send(Message::Text(response.into())).await?;
    }
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Features:</strong></p>
<ul>
<li>Pattern-based response matching</li>
<li>JSONPath query support</li>
<li>State-aware conversations</li>
<li>Custom response logic</li>
</ul>
<h4 id="4-ai-event-mode"><a class="header" href="#4-ai-event-mode">4. AI Event Mode</a></h4>
<p>LLM-powered event stream generation:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let ai_config = WebSocketAiConfig {
    enabled: true,
    narrative: "Simulate 5 minutes of live stock market trading".to_string(),
    event_count: 20,
    replay: Some(ReplayAugmentationConfig {
        provider: "openai".to_string(),
        model: "gpt-3.5-turbo".to_string(),
        ..Default::default()
    }),
};

let generator = AiEventGenerator::new(ai_config);
generator.stream_events(socket, Some(20)).await;
<span class="boring">}</span></code></pre></pre>
<h3 id="message-processing"><a class="header" href="#message-processing">Message Processing</a></h3>
<h4 id="template-expansion"><a class="header" href="#template-expansion">Template Expansion</a></h4>
<p>Rich templating system for dynamic content:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// UUID generation
"session_{{uuid}}" ‚Üí "session_550e8400-e29b-41d4-a716-446655440000"

// Timestamp manipulation
"{{now}}" ‚Üí "2024-01-15T10:30:00Z"
"{{now+1h}}" ‚Üí "2024-01-15T11:30:00Z"

// Random values
"{{randInt 1 100}}" ‚Üí "42"
<span class="boring">}</span></code></pre></pre>
<h4 id="jsonpath-matching"><a class="header" href="#jsonpath-matching">JSONPath Matching</a></h4>
<p>Sophisticated message pattern matching:</p>
<pre><code class="language-json">// Wait for specific message types
{"waitFor": "$.type", "text": "Type received: {{$.type}}"}

// Match nested object properties
{"waitFor": "$.user.id", "text": "User {{$.user.name}} authenticated"}

// Array element matching
{"waitFor": "$.items[0].status", "text": "First item status: {{$.items[0].status}}"}
</code></pre>
<h3 id="ai-integration"><a class="header" href="#ai-integration">AI Integration</a></h3>
<h4 id="event-generation"><a class="header" href="#event-generation">Event Generation</a></h4>
<p>Narrative-driven event stream creation:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct AiEventGenerator {
    engine: Arc&lt;RwLock&lt;ReplayAugmentationEngine&gt;&gt;,
}

impl AiEventGenerator {
    pub async fn stream_events(&amp;self, socket: WebSocket, max_events: Option&lt;usize&gt;) {
        // Generate contextual events based on narrative
        let events = self.engine.write().await.generate_stream().await?;
        // Stream events to client with configurable rate
    }
}
<span class="boring">}</span></code></pre></pre>
<h4 id="replay-augmentation"><a class="header" href="#replay-augmentation">Replay Augmentation</a></h4>
<p>Enhance existing replay files with AI-generated content:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let augmentation_config = ReplayAugmentationConfig {
    narrative: "Add realistic user interactions to chat replay".to_string(),
    augmentation_points: vec!["user_message".to_string()],
    provider: "openai".to_string(),
    model: "gpt-4".to_string(),
};
<span class="boring">}</span></code></pre></pre>
<h3 id="observability-1"><a class="header" href="#observability-1">Observability</a></h3>
<h4 id="metrics-collection-2"><a class="header" href="#metrics-collection-2">Metrics Collection</a></h4>
<p>Comprehensive WebSocket metrics:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let registry = get_global_registry();
registry.record_ws_connection_established();
registry.record_ws_message_received();
registry.record_ws_message_sent();
registry.record_ws_connection_closed(duration, status);
<span class="boring">}</span></code></pre></pre>
<h4 id="tracing-integration-2"><a class="header" href="#tracing-integration-2">Tracing Integration</a></h4>
<p>Distributed tracing for WebSocket connections:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let span = create_ws_connection_span(&amp;request);
let _guard = span.enter();
// Connection handling with tracing context
record_ws_message_success(&amp;span, message_size);
<span class="boring">}</span></code></pre></pre>
<h4 id="logging-2"><a class="header" href="#logging-2">Logging</a></h4>
<p>Structured logging for connection lifecycle and message flow:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>info!("WebSocket connection established from {}", peer_addr);
debug!("Received message: {} bytes", message.len());
error!("WebSocket error: {}", error);
<span class="boring">}</span></code></pre></pre>
<h3 id="performance-features-1"><a class="header" href="#performance-features-1">Performance Features</a></h3>
<h4 id="connection-pooling-2"><a class="header" href="#connection-pooling-2">Connection Pooling</a></h4>
<p>Efficient management of upstream connections in proxy mode:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Connection reuse for proxy operations
let connection = pool.get_connection(upstream_url).await?;
connection.forward_message(message).await?;
<span class="boring">}</span></code></pre></pre>
<h4 id="message-buffering"><a class="header" href="#message-buffering">Message Buffering</a></h4>
<p>Optimized message processing with buffering:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Stream processing for large message volumes
while let Some(batch) = message_buffer.next_batch().await {
    for message in batch {
        process_message(message).await?;
    }
}
<span class="boring">}</span></code></pre></pre>
<h4 id="rate-limiting-2"><a class="header" href="#rate-limiting-2">Rate Limiting</a></h4>
<p>Configurable message rate limits:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let rate_limiter = RateLimiter::new(1000, Duration::from_secs(60)); // 1000 msg/min
if rate_limiter.check_limit().await {
    process_message(message).await?;
}
<span class="boring">}</span></code></pre></pre>
<h2 id="configuration-35"><a class="header" href="#configuration-35">Configuration</a></h2>
<h3 id="websocket-server-config"><a class="header" href="#websocket-server-config">WebSocket Server Config</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct WsConfig {
    pub port: u16,
    pub max_connections: usize,
    pub max_message_size: usize,
    pub heartbeat_interval: Duration,
    pub replay_file: Option&lt;PathBuf&gt;,
    pub proxy_config: Option&lt;WsProxyConfig&gt;,
    pub ai_config: Option&lt;WebSocketAiConfig&gt;,
}
<span class="boring">}</span></code></pre></pre>
<h3 id="proxy-configuration-1"><a class="header" href="#proxy-configuration-1">Proxy Configuration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct WsProxyConfig {
    pub upstream_url: String,
    pub should_proxy: bool,
    pub message_transform: Option&lt;TransformFn&gt;,
    pub connection_pool_size: usize,
    pub retry_attempts: u32,
}
<span class="boring">}</span></code></pre></pre>
<h3 id="ai-configuration"><a class="header" href="#ai-configuration">AI Configuration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct WebSocketAiConfig {
    pub enabled: bool,
    pub narrative: String,
    pub event_count: usize,
    pub events_per_second: f64,
    pub replay: Option&lt;ReplayAugmentationConfig&gt;,
}
<span class="boring">}</span></code></pre></pre>
<h2 id="testing-support-1"><a class="header" href="#testing-support-1">Testing Support</a></h2>
<h3 id="integration-tests-3"><a class="header" href="#integration-tests-3">Integration Tests</a></h3>
<p>End-to-end WebSocket testing:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[tokio::test]
async fn test_websocket_replay() {
    // Start WebSocket server with replay file
    let server = TestServer::new(router()).await;

    // Connect test client
    let (ws_stream, _) = connect_async(server.url()).await?;

    // Verify replay sequence
    let msg = ws_stream.next().await.unwrap()?;
    assert_eq!(msg, Message::Text("HELLO test-session".into()));
}
<span class="boring">}</span></code></pre></pre>
<h3 id="replay-file-validation-1"><a class="header" href="#replay-file-validation-1">Replay File Validation</a></h3>
<p>Automated validation of replay configurations:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[test]
fn test_replay_file_parsing() {
    let replay_data = r#"{"ts":0,"text":"hello","waitFor":"ready"}"#;
    let entry: ReplayEntry = serde_json::from_str(replay_data)?;
    assert_eq!(entry.ts, 0);
    assert_eq!(entry.text, "hello");
}
<span class="boring">}</span></code></pre></pre>
<h2 id="error-handling-7"><a class="header" href="#error-handling-7">Error Handling</a></h2>
<h3 id="connection-errors"><a class="header" href="#connection-errors">Connection Errors</a></h3>
<p>Graceful handling of connection failures:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>match socket.recv().await {
    Ok(Some(Message::Close(frame))) =&gt; {
        info!("Client closed connection: {:?}", frame);
        break;
    }
    Err(e) =&gt; {
        error!("WebSocket error: {}", e);
        record_ws_error();
        break;
    }
    _ =&gt; continue,
}
<span class="boring">}</span></code></pre></pre>
<h3 id="message-processing-errors"><a class="header" href="#message-processing-errors">Message Processing Errors</a></h3>
<p>Robust message parsing and transformation:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>match serde_json::from_str::&lt;Value&gt;(&amp;text) {
    Ok(json) =&gt; process_json_message(json).await,
    Err(e) =&gt; {
        warn!("Invalid JSON message: {}", e);
        send_error_response("Invalid JSON format").await?;
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="usage-examples-4"><a class="header" href="#usage-examples-4">Usage Examples</a></h2>
<h3 id="basic-websocket-server"><a class="header" href="#basic-websocket-server">Basic WebSocket Server</a></h3>
<pre><pre class="playground"><code class="language-rust">use mockforge_ws::start_with_latency;

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    // Start with default latency profile
    start_with_latency(3001, Some(LatencyProfile::normal())).await?;
    Ok(())
}</code></pre></pre>
<h3 id="replay-mode-2"><a class="header" href="#replay-mode-2">Replay Mode</a></h3>
<pre><code class="language-bash"># Set environment variable for replay file
export MOCKFORGE_WS_REPLAY_FILE=./replay.jsonl

# Start server
mockforge serve --ws-port 3001
</code></pre>
<h3 id="proxy-mode"><a class="header" href="#proxy-mode">Proxy Mode</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_ws::router_with_proxy;
use mockforge_core::{WsProxyConfig, WsProxyHandler};

let proxy_config = WsProxyConfig {
    upstream_url: "wss://api.example.com/ws".to_string(),
    should_proxy: true,
};

let proxy = WsProxyHandler::new(proxy_config);
let app = router_with_proxy(proxy);
<span class="boring">}</span></code></pre></pre>
<h3 id="ai-event-generation"><a class="header" href="#ai-event-generation">AI Event Generation</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_ws::{AiEventGenerator, WebSocketAiConfig};

let config = WebSocketAiConfig {
    enabled: true,
    narrative: "Simulate real-time chat conversation".to_string(),
    event_count: 50,
    events_per_second: 2.0,
};

let generator = AiEventGenerator::new(config)?;
generator.stream_events_with_rate(socket, None, 2.0).await;
<span class="boring">}</span></code></pre></pre>
<h2 id="future-enhancements-3"><a class="header" href="#future-enhancements-3">Future Enhancements</a></h2>
<ul>
<li><strong>Advanced Pattern Matching</strong>: Complex event correlation and state machines</li>
<li><strong>Load Testing</strong>: Built-in WebSocket load testing capabilities</li>
<li><strong>Recording Mode</strong>: Capture live WebSocket interactions for replay</li>
<li><strong>Clustering</strong>: Distributed WebSocket session management</li>
<li><strong>Protocol Extensions</strong>: Support for custom WebSocket subprotocols</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="cli-reference"><a class="header" href="#cli-reference">CLI Reference</a></h1>
<p>MockForge provides a comprehensive command-line interface for managing mock servers and generating test data. This reference covers all available commands, options, and usage patterns.</p>
<h2 id="global-options"><a class="header" href="#global-options">Global Options</a></h2>
<p>All MockForge commands support the following global options:</p>
<pre><code class="language-bash">mockforge-cli [OPTIONS] &lt;COMMAND&gt;
</code></pre>
<h3 id="global-options-1"><a class="header" href="#global-options-1">Global Options</a></h3>
<ul>
<li><code>-h, --help</code>: Display help information</li>
</ul>
<h2 id="commands-1"><a class="header" href="#commands-1">Commands</a></h2>
<h3 id="serve---start-mock-servers"><a class="header" href="#serve---start-mock-servers"><code>serve</code> - Start Mock Servers</a></h3>
<p>The primary command for starting MockForge‚Äôs mock servers with support for HTTP, WebSocket, and gRPC protocols.</p>
<pre><code class="language-bash">mockforge-cli serve [OPTIONS]
</code></pre>
<h4 id="server-options-1"><a class="header" href="#server-options-1">Server Options</a></h4>
<p><strong>Port Configuration:</strong></p>
<ul>
<li><code>--http-port &lt;PORT&gt;</code>: HTTP server port (default: 3000)</li>
<li><code>--ws-port &lt;PORT&gt;</code>: WebSocket server port (default: 3001)</li>
<li><code>--grpc-port &lt;PORT&gt;</code>: gRPC server port (default: 50051)</li>
</ul>
<p><strong>API Specification:</strong></p>
<ul>
<li><code>--spec &lt;PATH&gt;</code>: OpenAPI spec file for HTTP server (JSON or YAML format)</li>
</ul>
<p><strong>Configuration:</strong></p>
<ul>
<li><code>-c, --config &lt;PATH&gt;</code>: Path to configuration file</li>
</ul>
<h4 id="admin-ui-options"><a class="header" href="#admin-ui-options">Admin UI Options</a></h4>
<p><strong>Admin UI Control:</strong></p>
<ul>
<li><code>--admin</code>: Enable admin UI</li>
<li><code>--admin-port &lt;PORT&gt;</code>: Admin UI port (default: 9080)</li>
<li><code>--admin-embed</code>: Force embedding Admin UI under HTTP server</li>
<li><code>--admin-mount-path &lt;PATH&gt;</code>: Explicit mount path for embedded Admin UI (implies <code>--admin-embed</code>)</li>
<li><code>--admin-standalone</code>: Force standalone Admin UI on separate port (overrides embed)</li>
<li><code>--disable-admin-api</code>: Disable Admin API endpoints (UI loads but API routes are absent)</li>
</ul>
<h4 id="validation-options-1"><a class="header" href="#validation-options-1">Validation Options</a></h4>
<p><strong>Request Validation:</strong></p>
<ul>
<li><code>--validation &lt;MODE&gt;</code>: Request validation mode (default: enforce)
<ul>
<li><code>off</code>: Disable validation</li>
<li><code>warn</code>: Log warnings but allow requests</li>
<li><code>enforce</code>: Reject invalid requests</li>
</ul>
</li>
<li><code>--aggregate-errors</code>: Aggregate request validation errors into JSON array</li>
<li><code>--validate-responses</code>: Validate responses (warn-only)</li>
<li><code>--validation-status &lt;CODE&gt;</code>: Validation error HTTP status code (default: 400)</li>
</ul>
<h4 id="response-processing"><a class="header" href="#response-processing">Response Processing</a></h4>
<p><strong>Template Expansion:</strong></p>
<ul>
<li><code>--response-template-expand</code>: Expand templating tokens in responses/examples</li>
</ul>
<h4 id="chaos-engineering-1"><a class="header" href="#chaos-engineering-1">Chaos Engineering</a></h4>
<p><strong>Latency Simulation:</strong></p>
<ul>
<li><code>--latency-enabled</code>: Enable latency simulation</li>
</ul>
<p><strong>Failure Injection:</strong></p>
<ul>
<li><code>--failures-enabled</code>: Enable failure injection</li>
</ul>
<h4 id="examples-10"><a class="header" href="#examples-10">Examples</a></h4>
<p><strong>Basic HTTP Server:</strong></p>
<pre><code class="language-bash">mockforge-cli serve --spec examples/openapi-demo.json --http-port 3000
</code></pre>
<p><strong>Full Multi-Protocol Setup:</strong></p>
<pre><code class="language-bash">mockforge-cli serve \
  --spec examples/openapi-demo.json \
  --http-port 3000 \
  --ws-port 3001 \
  --grpc-port 50051 \
  --admin \
  --admin-port 9080 \
  --response-template-expand
</code></pre>
<p><strong>Development Configuration:</strong></p>
<pre><code class="language-bash">mockforge-cli serve \
  --config demo-config.yaml \
  --validation warn \
  --response-template-expand \
  --latency-enabled
</code></pre>
<p><strong>Production Configuration:</strong></p>
<pre><code class="language-bash">mockforge-cli serve \
  --config production-config.yaml \
  --validation enforce \
  --admin-standalone
</code></pre>
<h3 id="init---initialize-new-project"><a class="header" href="#init---initialize-new-project"><code>init</code> - Initialize New Project</a></h3>
<p>Create a new MockForge project with a template configuration file.</p>
<pre><code class="language-bash">mockforge-cli init [OPTIONS] &lt;NAME&gt;
</code></pre>
<h4 id="arguments"><a class="header" href="#arguments">Arguments</a></h4>
<ul>
<li><code>&lt;NAME&gt;</code>: Project name or directory path
<ul>
<li>Use <code>.</code> to initialize in the current directory</li>
<li>Use a project name to create a new directory</li>
</ul>
</li>
</ul>
<h4 id="options"><a class="header" href="#options">Options</a></h4>
<ul>
<li><code>--no-examples</code>: Skip creating example files (only create <code>mockforge.yaml</code>)</li>
</ul>
<h4 id="examples-11"><a class="header" href="#examples-11">Examples</a></h4>
<pre><code class="language-bash"># Create a new project in a new directory
mockforge-cli init my-mock-api

# Initialize in the current directory
mockforge-cli init .

# Initialize without examples
mockforge-cli init my-project --no-examples
</code></pre>
<h4 id="what-gets-created-1"><a class="header" href="#what-gets-created-1">What Gets Created</a></h4>
<ol>
<li>
<p><strong>mockforge.yaml</strong>: Main configuration file with:</p>
<ul>
<li>HTTP, WebSocket, gRPC server configurations</li>
<li>Admin UI settings</li>
<li>Core features (latency, failures, overrides)</li>
<li>Observability configuration</li>
<li>Data generation settings</li>
<li>Logging configuration</li>
</ul>
</li>
<li>
<p><strong>examples/</strong> directory (unless <code>--no-examples</code>):</p>
<ul>
<li><code>openapi.json</code>: Sample OpenAPI specification</li>
<li>Example data files</li>
</ul>
</li>
</ol>
<h4 id="see-also"><a class="header" href="#see-also">See Also</a></h4>
<ul>
<li><a href="api/../configuration/files.html">Configuration Files Guide</a></li>
<li><a href="https://github.com/SaaSy-Solutions/mockforge/blob/main/config.template.yaml">Complete Config Template</a></li>
</ul>
<hr />
<h3 id="config---configuration-management"><a class="header" href="#config---configuration-management"><code>config</code> - Configuration Management</a></h3>
<p>Validate and manage MockForge configuration files.</p>
<pre><code class="language-bash">mockforge-cli config &lt;SUBCOMMAND&gt;
</code></pre>
<h4 id="subcommands"><a class="header" href="#subcommands">Subcommands</a></h4>
<h5 id="validate---validate-configuration-file"><a class="header" href="#validate---validate-configuration-file"><code>validate</code> - Validate Configuration File</a></h5>
<p>Validate a MockForge configuration file for syntax and structure errors.</p>
<pre><code class="language-bash">mockforge-cli config validate [OPTIONS]
</code></pre>
<p><strong>Options:</strong></p>
<ul>
<li><code>--config &lt;PATH&gt;</code>: Path to config file to validate
<ul>
<li>If omitted, auto-discovers <code>mockforge.yaml</code> or <code>mockforge.yml</code> in current and parent directories</li>
</ul>
</li>
</ul>
<p><strong>What Gets Validated:</strong></p>
<ul>
<li>YAML syntax and structure</li>
<li>File existence</li>
<li>HTTP endpoints count</li>
<li>Request chains count</li>
<li>Missing sections (warnings)</li>
</ul>
<p><strong>Examples:</strong></p>
<pre><code class="language-bash"># Validate config in current directory
mockforge-cli config validate

# Validate specific config file
mockforge-cli config validate --config my-config.yaml

# Validate before starting server
mockforge-cli config validate &amp;&amp; mockforge-cli serve
</code></pre>
<p><strong>Output Example:</strong></p>
<pre><code>üîç Validating MockForge configuration...
üìÑ Checking configuration file: mockforge.yaml
‚úÖ Configuration is valid

üìä Summary:
   Found 5 HTTP endpoints
   Found 2 chains

‚ö†Ô∏è  Warnings:
   - No WebSocket configuration found
</code></pre>
<p><strong>Common Issues:</strong></p>
<ul>
<li><strong>Invalid YAML syntax</strong>: Fix indentation, quotes, or structure</li>
<li><strong>File not found</strong>: Check path or run <code>mockforge init</code></li>
<li><strong>Missing sections</strong>: Add HTTP, admin, or other required sections</li>
</ul>
<p><strong>Note</strong>: Current validation is basic (syntax, structure, counts). For comprehensive field validation, see the <a href="api/../reference/config-validation.html">Configuration Validation Guide</a>.</p>
<h4 id="see-also-1"><a class="header" href="#see-also-1">See Also</a></h4>
<ul>
<li><a href="api/../reference/config-validation.html">Configuration Validation Guide</a></li>
<li><a href="api/../reference/config-schema.html">Configuration Schema Reference</a></li>
<li><a href="api/../reference/troubleshooting.html">Troubleshooting Guide</a></li>
</ul>
<hr />
<h3 id="data---generate-synthetic-data"><a class="header" href="#data---generate-synthetic-data"><code>data</code> - Generate Synthetic Data</a></h3>
<p>Generate synthetic test data using various templates and schemas.</p>
<pre><code class="language-bash">mockforge-cli data &lt;SUBCOMMAND&gt;
</code></pre>
<h4 id="subcommands-1"><a class="header" href="#subcommands-1">Subcommands</a></h4>
<h5 id="template---generate-from-built-in-templates"><a class="header" href="#template---generate-from-built-in-templates"><code>template</code> - Generate from Built-in Templates</a></h5>
<p>Generate data using MockForge‚Äôs built-in data generation templates.</p>
<pre><code class="language-bash">mockforge-cli data template [OPTIONS]
</code></pre>
<p><strong>Options:</strong></p>
<ul>
<li><code>--count &lt;N&gt;</code>: Number of items to generate (default: 1)</li>
<li><code>--format &lt;FORMAT&gt;</code>: Output format (json, yaml, csv)</li>
<li><code>--template &lt;NAME&gt;</code>: Template name (user, product, order, etc.)</li>
<li><code>--output &lt;PATH&gt;</code>: Output file path</li>
</ul>
<p><strong>Examples:</strong></p>
<pre><code class="language-bash"># Generate 10 user records as JSON
mockforge-cli data template --template user --count 10 --format json

# Generate product data to file
mockforge-cli data template --template product --count 50 --output products.json
</code></pre>
<h5 id="schema---generate-from-json-schema"><a class="header" href="#schema---generate-from-json-schema"><code>schema</code> - Generate from JSON Schema</a></h5>
<p>Generate data conforming to a JSON Schema specification.</p>
<pre><code class="language-bash">mockforge-cli data schema [OPTIONS] &lt;SCHEMA&gt;
</code></pre>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>&lt;SCHEMA&gt;</code>: Path to JSON Schema file</li>
</ul>
<p><strong>Options:</strong></p>
<ul>
<li><code>--count &lt;N&gt;</code>: Number of items to generate (default: 1)</li>
<li><code>--format &lt;FORMAT&gt;</code>: Output format (json, yaml)</li>
<li><code>--output &lt;PATH&gt;</code>: Output file path</li>
</ul>
<p><strong>Examples:</strong></p>
<pre><code class="language-bash"># Generate data from user schema
mockforge-cli data schema --count 5 user-schema.json

# Generate and save to file
mockforge-cli data schema --count 100 --output generated-data.json api-schema.json
</code></pre>
<h5 id="open-api---generate-from-openapi-spec"><a class="header" href="#open-api---generate-from-openapi-spec"><code>open-api</code> - Generate from OpenAPI Spec</a></h5>
<p>Generate mock data based on OpenAPI specification schemas.</p>
<pre><code class="language-bash">mockforge-cli data open-api [OPTIONS] &lt;SPEC&gt;
</code></pre>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>&lt;SPEC&gt;</code>: Path to OpenAPI specification file</li>
</ul>
<p><strong>Options:</strong></p>
<ul>
<li><code>--endpoint &lt;PATH&gt;</code>: Specific endpoint to generate data for</li>
<li><code>--method &lt;METHOD&gt;</code>: HTTP method (get, post, put, delete)</li>
<li><code>--count &lt;N&gt;</code>: Number of items to generate (default: 1)</li>
<li><code>--format &lt;FORMAT&gt;</code>: Output format (json, yaml)</li>
<li><code>--output &lt;PATH&gt;</code>: Output file path</li>
</ul>
<p><strong>Examples:</strong></p>
<pre><code class="language-bash"># Generate data for all endpoints in OpenAPI spec
mockforge-cli data open-api api-spec.yaml

# Generate data for specific endpoint
mockforge-cli data open-api --endpoint /users --method get --count 20 api-spec.yaml

# Generate POST request body data
mockforge-cli data open-api --endpoint /users --method post api-spec.yaml
</code></pre>
<h3 id="admin---admin-ui-server"><a class="header" href="#admin---admin-ui-server"><code>admin</code> - Admin UI Server</a></h3>
<p>Start the Admin UI as a standalone server without the main mock servers.</p>
<pre><code class="language-bash">mockforge-cli admin [OPTIONS]
</code></pre>
<h4 id="options-1"><a class="header" href="#options-1">Options</a></h4>
<ul>
<li><code>--port &lt;PORT&gt;</code>: Server port (default: 9080)</li>
</ul>
<h4 id="examples-12"><a class="header" href="#examples-12">Examples</a></h4>
<pre><code class="language-bash"># Start admin UI on default port
mockforge-cli admin

# Start admin UI on custom port
mockforge-cli admin --port 9090
</code></pre>
<h3 id="sync---workspace-synchronization-daemon"><a class="header" href="#sync---workspace-synchronization-daemon"><code>sync</code> - Workspace Synchronization Daemon</a></h3>
<p>Start a background daemon that monitors a workspace directory for file changes and automatically syncs them to MockForge workspaces.</p>
<pre><code class="language-bash">mockforge-cli sync [OPTIONS]
</code></pre>
<h4 id="options-2"><a class="header" href="#options-2">Options</a></h4>
<p><strong>Required:</strong></p>
<ul>
<li><code>--workspace-dir &lt;PATH&gt;</code> or <code>-w &lt;PATH&gt;</code>: Workspace directory to monitor for changes</li>
</ul>
<p><strong>Optional:</strong></p>
<ul>
<li><code>--config &lt;PATH&gt;</code> or <code>-c &lt;PATH&gt;</code>: Configuration file path for sync settings</li>
</ul>
<h4 id="how-it-works-9"><a class="header" href="#how-it-works-9">How It Works</a></h4>
<p>The sync daemon provides bidirectional synchronization between workspace files and MockForge‚Äôs internal workspace storage:</p>
<ol>
<li><strong>File Monitoring</strong>: Watches for <code>.yaml</code> and <code>.yml</code> files in the workspace directory</li>
<li><strong>Automatic Import</strong>: When files are created or modified, they‚Äôre automatically imported into the workspace</li>
<li><strong>Real-time Updates</strong>: Changes are detected and processed immediately</li>
<li><strong>Visual Feedback</strong>: Clear console output shows what‚Äôs happening in real-time</li>
</ol>
<p><strong>File Requirements:</strong></p>
<ul>
<li>Only <code>.yaml</code> and <code>.yml</code> files are monitored</li>
<li>Hidden files (starting with <code>.</code>) are ignored</li>
<li>Files must be valid MockRequest YAML format</li>
</ul>
<p><strong>What You‚Äôll See:</strong></p>
<ul>
<li>File creation notifications with import status</li>
<li>File modification notifications with update status</li>
<li>File deletion notifications (files are not auto-deleted from workspace)</li>
<li>Error messages if imports fail</li>
<li>Real-time feedback for all sync operations</li>
</ul>
<h4 id="examples-13"><a class="header" href="#examples-13">Examples</a></h4>
<p><strong>Basic Usage:</strong></p>
<pre><code class="language-bash"># Start sync daemon for a workspace directory
mockforge-cli sync --workspace-dir ./my-workspace

# Use short form
mockforge-cli sync -w ./my-workspace

# With custom config
mockforge-cli sync --workspace-dir /path/to/workspace --config sync-config.yaml
</code></pre>
<p><strong>Git Integration:</strong></p>
<pre><code class="language-bash"># Monitor a Git repository directory
mockforge-cli sync --workspace-dir /path/to/git/repo/workspaces

# Changes you make in Git will automatically sync to MockForge
# Perfect for team collaboration via Git
</code></pre>
<p><strong>Development Workflow:</strong></p>
<pre><code class="language-bash"># 1. Start the sync daemon in one terminal
mockforge-cli sync --workspace-dir ./workspaces

# 2. In another terminal, edit workspace files
vim ./workspaces/my-request.yaml

# 3. Save the file - it will automatically import to MockForge
# You'll see output like:
#   üîÑ Detected 1 file change in workspace 'default'
#     üìù Modified: my-request.yaml
#        ‚úÖ Successfully updated
</code></pre>
<h4 id="example-output-1"><a class="header" href="#example-output-1">Example Output</a></h4>
<p>When you start the sync daemon, you‚Äôll see:</p>
<pre><code>üîÑ Starting MockForge Sync Daemon...
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
üìÅ Workspace directory: ./my-workspace

‚ÑπÔ∏è  What the sync daemon does:
   ‚Ä¢ Monitors the workspace directory for .yaml/.yml file changes
   ‚Ä¢ Automatically imports new or modified request files
   ‚Ä¢ Syncs changes bidirectionally between files and workspace
   ‚Ä¢ Skips hidden files (starting with .)

üîç Monitoring for file changes...
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

‚úÖ Sync daemon started successfully!
üí° Press Ctrl+C to stop

üìÇ Monitoring workspace 'default' in directory: ./my-workspace
</code></pre>
<p>When files change, you‚Äôll see:</p>
<pre><code>üîÑ Detected 1 file change in workspace 'default'
  ‚ûï Created: new-endpoint.yaml
     ‚úÖ Successfully imported

üîÑ Detected 2 file changes in workspace 'default'
  üìù Modified: user-api.yaml
     ‚úÖ Successfully updated
  üóëÔ∏è  Deleted: old-endpoint.yaml
     ‚ÑπÔ∏è  Auto-deletion from workspace is disabled
</code></pre>
<p>If errors occur:</p>
<pre><code>üîÑ Detected 1 file change in workspace 'default'
  üìù Modified: invalid-file.yaml
     ‚ö†Ô∏è  Failed to import: File is not a recognized format (expected MockRequest YAML)
</code></pre>
<h4 id="stopping-the-daemon"><a class="header" href="#stopping-the-daemon">Stopping the Daemon</a></h4>
<p>Press <code>Ctrl+C</code> to gracefully stop the sync daemon:</p>
<pre><code>^C
üõë Received shutdown signal
‚èπÔ∏è  Stopped monitoring workspace 'default' in directory: ./my-workspace
üëã Sync daemon stopped
</code></pre>
<h4 id="best-practices-57"><a class="header" href="#best-practices-57">Best Practices</a></h4>
<p><strong>Version Control:</strong></p>
<pre><code class="language-bash"># Use sync with Git for team collaboration
cd /path/to/git/repo
mockforge-cli sync --workspace-dir ./workspaces

# Team members can push/pull changes
# The sync daemon will automatically import updates
</code></pre>
<p><strong>Development Workflow:</strong></p>
<pre><code class="language-bash"># Keep sync daemon running during development
# Edit files in your favorite editor
# Changes automatically sync to MockForge
# Perfect for file-based workflows
</code></pre>
<p><strong>Directory Organization:</strong></p>
<pre><code class="language-bash"># Organize workspace files in subdirectories
workspaces/
‚îú‚îÄ‚îÄ api-v1/
‚îÇ   ‚îú‚îÄ‚îÄ users.yaml
‚îÇ   ‚îî‚îÄ‚îÄ products.yaml
‚îú‚îÄ‚îÄ api-v2/
‚îÇ   ‚îî‚îÄ‚îÄ users.yaml
‚îî‚îÄ‚îÄ internal/
    ‚îî‚îÄ‚îÄ admin.yaml

# All .yaml files will be monitored
mockforge-cli sync --workspace-dir ./workspaces
</code></pre>
<h4 id="troubleshooting-58"><a class="header" href="#troubleshooting-58">Troubleshooting</a></h4>
<p><strong>Files not importing:</strong></p>
<ul>
<li>Ensure files have <code>.yaml</code> or <code>.yml</code> extension</li>
<li>Check that files are valid MockRequest YAML format</li>
<li>Look for error messages in the console output</li>
<li>Verify files are not hidden (don‚Äôt start with <code>.</code>)</li>
</ul>
<p><strong>Permission errors:</strong></p>
<ul>
<li>Ensure MockForge has read access to the workspace directory</li>
<li>Check file permissions: <code>ls -la workspace-dir/</code></li>
</ul>
<p><strong>Changes not detected:</strong></p>
<ul>
<li>The sync daemon uses filesystem notifications</li>
<li>Some network filesystems may not support change notifications</li>
<li>Try editing the file locally rather than over a network mount</li>
</ul>
<p><strong>Enable debug logging:</strong></p>
<pre><code class="language-bash">RUST_LOG=mockforge_core::sync_watcher=debug mockforge-cli sync --workspace-dir ./workspace
</code></pre>
<h2 id="configuration-file-format"><a class="header" href="#configuration-file-format">Configuration File Format</a></h2>
<p>MockForge supports YAML configuration files that can be used instead of command-line options.</p>
<h3 id="basic-configuration-structure-1"><a class="header" href="#basic-configuration-structure-1">Basic Configuration Structure</a></h3>
<pre><code class="language-yaml"># Server configuration
server:
  http_port: 3000
  ws_port: 3001
  grpc_port: 50051

# API specification
spec: examples/openapi-demo.json

# Admin UI configuration
admin:
  enabled: true
  port: 9080
  embedded: false
  mount_path: "/admin"
  standalone: true
  disable_api: false

# Validation settings
validation:
  mode: enforce
  aggregate_errors: false
  validate_responses: false
  status_code: 400

# Response processing
response:
  template_expand: true

# Chaos engineering
chaos:
  latency_enabled: false
  failures_enabled: false

# Protocol-specific settings
grpc:
  proto_dir: "proto/"
  enable_reflection: true

websocket:
  replay_file: "examples/ws-demo.jsonl"
</code></pre>
<h3 id="configuration-precedence-1"><a class="header" href="#configuration-precedence-1">Configuration Precedence</a></h3>
<p>Configuration values are applied in the following order (later sources override earlier ones):</p>
<ol>
<li><strong>Default values</strong> (compiled into the binary)</li>
<li><strong>Configuration file</strong> (<code>-c/--config</code> option)</li>
<li><strong>Environment variables</strong></li>
<li><strong>Command-line arguments</strong> (highest priority)</li>
</ol>
<h3 id="environment-variables-17"><a class="header" href="#environment-variables-17">Environment Variables</a></h3>
<p>All configuration options can be set via environment variables using the <code>MOCKFORGE_</code> prefix:</p>
<pre><code class="language-bash"># Server ports
export MOCKFORGE_HTTP_PORT=3000
export MOCKFORGE_WS_PORT=3001
export MOCKFORGE_GRPC_PORT=50051

# Admin UI
export MOCKFORGE_ADMIN_ENABLED=true
export MOCKFORGE_ADMIN_PORT=9080
export MOCKFORGE_ADMIN_JWT_SECRET=your-secret-key
export MOCKFORGE_ADMIN_SESSION_TIMEOUT=86400
export MOCKFORGE_ADMIN_AUTH_ENABLED=true

# Validation
export MOCKFORGE_VALIDATION_MODE=enforce
export MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true

# gRPC settings
export MOCKFORGE_PROTO_DIR=proto/
export MOCKFORGE_GRPC_REFLECTION_ENABLED=true

# WebSocket settings
export MOCKFORGE_WS_REPLAY_FILE=examples/ws-demo.jsonl

# Plugin system
export MOCKFORGE_PLUGINS_ENABLED=true
export MOCKFORGE_PLUGINS_DIRECTORY=~/.mockforge/plugins
export MOCKFORGE_PLUGIN_MEMORY_LIMIT=64
export MOCKFORGE_PLUGIN_CPU_LIMIT=10
export MOCKFORGE_PLUGIN_TIMEOUT=5000

# Encryption
export MOCKFORGE_ENCRYPTION_ENABLED=true
export MOCKFORGE_ENCRYPTION_ALGORITHM=aes-256-gcm
export MOCKFORGE_KEY_STORE_PATH=~/.mockforge/keys

# Synchronization
export MOCKFORGE_SYNC_ENABLED=true
export MOCKFORGE_SYNC_DIRECTORY=./workspace-sync
export MOCKFORGE_SYNC_MODE=bidirectional
export MOCKFORGE_SYNC_WATCH=true

# Data generation
export MOCKFORGE_DATA_RAG_ENABLED=true
export MOCKFORGE_DATA_RAG_PROVIDER=openai
export MOCKFORGE_DATA_RAG_API_KEY=your-api-key
</code></pre>
<h2 id="exit-codes"><a class="header" href="#exit-codes">Exit Codes</a></h2>
<p>MockForge uses standard exit codes:</p>
<ul>
<li><strong>0</strong>: Success</li>
<li><strong>1</strong>: General error</li>
<li><strong>2</strong>: Configuration error</li>
<li><strong>3</strong>: Validation error</li>
<li><strong>4</strong>: File I/O error</li>
<li><strong>5</strong>: Network error</li>
</ul>
<h2 id="logging-3"><a class="header" href="#logging-3">Logging</a></h2>
<p>MockForge provides configurable logging output to help with debugging and monitoring.</p>
<h3 id="log-levels"><a class="header" href="#log-levels">Log Levels</a></h3>
<ul>
<li><code>error</code>: Only error messages</li>
<li><code>warn</code>: Warnings and errors</li>
<li><code>info</code>: General information (default)</li>
<li><code>debug</code>: Detailed debugging information</li>
<li><code>trace</code>: Very verbose tracing information</li>
</ul>
<h3 id="log-configuration"><a class="header" href="#log-configuration">Log Configuration</a></h3>
<pre><code class="language-bash"># Set log level via environment variable
export RUST_LOG=mockforge=debug

# Or via configuration file
logging:
  level: debug
  format: json
</code></pre>
<h3 id="log-output"><a class="header" href="#log-output">Log Output</a></h3>
<p>Logs include structured information about:</p>
<ul>
<li>HTTP requests/responses</li>
<li>WebSocket connections and messages</li>
<li>gRPC calls and streaming</li>
<li>Configuration loading</li>
<li>Template expansion</li>
<li>Validation errors</li>
</ul>
<h2 id="examples-14"><a class="header" href="#examples-14">Examples</a></h2>
<h3 id="complete-development-setup"><a class="header" href="#complete-development-setup">Complete Development Setup</a></h3>
<pre><code class="language-bash"># Start all servers with admin UI
mockforge-cli serve \
  --spec examples/openapi-demo.json \
  --http-port 3000 \
  --ws-port 3001 \
  --grpc-port 50051 \
  --admin \
  --admin-port 9080 \
  --response-template-expand \
  --validation warn
</code></pre>
<h3 id="cicd-testing-pipeline"><a class="header" href="#cicd-testing-pipeline">CI/CD Testing Pipeline</a></h3>
<pre><code class="language-bash">#!/bin/bash
# test-mockforge.sh

# Start MockForge in background
mockforge-cli serve --spec api-spec.yaml --http-port 3000 &amp;
MOCKFORGE_PID=$!

# Wait for server to start
sleep 5

# Run API tests
npm test

# Generate test data
mockforge-cli data open-api --endpoint /users --count 100 api-spec.yaml &gt; test-users.json

# Stop MockForge
kill $MOCKFORGE_PID
</code></pre>
<h3 id="load-testing-setup"><a class="header" href="#load-testing-setup">Load Testing Setup</a></h3>
<pre><code class="language-bash">#!/bin/bash
# load-test-setup.sh

# Start MockForge with minimal validation for performance
MOCKFORGE_VALIDATION_MODE=off \
MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=false \
mockforge-cli serve \
  --spec load-test-spec.yaml \
  --http-port 3000 \
  --validation off

# Now run your load testing tool against localhost:3000
# Example: hey -n 10000 -c 100 http://localhost:3000/api/test
</code></pre>
<h3 id="docker-integration-1"><a class="header" href="#docker-integration-1">Docker Integration</a></h3>
<pre><code class="language-bash"># Run MockForge in Docker with CLI commands
docker run --rm -v $(pwd)/examples:/examples \
  mockforge \
  serve --spec /examples/openapi-demo.json --http-port 3000
</code></pre>
<h2 id="troubleshooting-59"><a class="header" href="#troubleshooting-59">Troubleshooting</a></h2>
<h3 id="common-issues-13"><a class="header" href="#common-issues-13">Common Issues</a></h3>
<p><strong>Server won‚Äôt start:</strong></p>
<pre><code class="language-bash"># Check if ports are available
lsof -i :3000
lsof -i :3001

# Try different ports
mockforge-cli serve --http-port 3001 --ws-port 3002
</code></pre>
<p><strong>Configuration not loading:</strong></p>
<pre><code class="language-bash"># Validate YAML syntax
yamllint config.yaml

# Check file permissions
ls -la config.yaml
</code></pre>
<p><strong>OpenAPI spec not found:</strong></p>
<pre><code class="language-bash"># Verify file exists and path is correct
ls -la examples/openapi-demo.json

# Use absolute path
mockforge-cli serve --spec /full/path/to/examples/openapi-demo.json
</code></pre>
<p><strong>Template expansion not working:</strong></p>
<pre><code class="language-bash"># Ensure template expansion is enabled
mockforge-cli serve --response-template-expand --spec api-spec.yaml
</code></pre>
<h3 id="debug-mode-3"><a class="header" href="#debug-mode-3">Debug Mode</a></h3>
<p>Run with debug logging for detailed information:</p>
<pre><code class="language-bash">RUST_LOG=mockforge=debug mockforge-cli serve --spec api-spec.yaml
</code></pre>
<h3 id="health-checks"><a class="header" href="#health-checks">Health Checks</a></h3>
<p>Test basic functionality:</p>
<pre><code class="language-bash"># HTTP health check
curl http://localhost:3000/health

# WebSocket connection test
websocat ws://localhost:3001/ws

# gRPC service discovery
grpcurl -plaintext localhost:50051 list
</code></pre>
<p>This CLI reference provides comprehensive coverage of MockForge‚Äôs command-line interface. For programmatic usage, see the <a href="api/rust.html">Rust API Reference</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="admin-ui-rest-api"><a class="header" href="#admin-ui-rest-api">Admin UI REST API</a></h1>
<p>This document provides comprehensive documentation for the MockForge Admin UI REST API endpoints.</p>
<h2 id="overview-50"><a class="header" href="#overview-50">Overview</a></h2>
<p>The MockForge Admin UI provides a web-based interface for managing and monitoring MockForge servers. The API is organized around the following main areas:</p>
<ul>
<li><strong>Dashboard</strong>: System overview and real-time metrics</li>
<li><strong>Server Management</strong>: Control and monitor server instances</li>
<li><strong>Configuration</strong>: Update latency, faults, proxy, and validation settings</li>
<li><strong>Logging</strong>: View and filter request logs</li>
<li><strong>Metrics</strong>: Performance monitoring and analytics</li>
<li><strong>Fixtures</strong>: Manage mock data and fixtures</li>
<li><strong>Environment</strong>: Environment variable management</li>
</ul>
<h2 id="base-url"><a class="header" href="#base-url">Base URL</a></h2>
<p>All API endpoints are prefixed with <code>/__mockforge/api</code> to avoid conflicts with user-defined routes.</p>
<h3 id="standalone-mode-vs-embedded-mode"><a class="header" href="#standalone-mode-vs-embedded-mode">Standalone Mode vs Embedded Mode</a></h3>
<p>The REST API works identically in both standalone and embedded modes:</p>
<p><strong>Standalone Mode (Default):</strong></p>
<ul>
<li>Admin UI runs on a separate port (default: 9080)</li>
<li>REST API endpoints available at: <code>http://localhost:9080/__mockforge/api/*</code></li>
<li>Main HTTP server runs on port 3000 (or configured port)</li>
<li>Example: <code>curl http://localhost:9080/__mockforge/api/mocks</code></li>
</ul>
<p><strong>Embedded Mode:</strong></p>
<ul>
<li>Admin UI mounted under HTTP server (e.g., <code>/admin</code>)</li>
<li>REST API endpoints available at: <code>http://localhost:3000/__mockforge/api/*</code></li>
<li>Same endpoints, different base URL</li>
<li>Example: <code>curl http://localhost:3000/__mockforge/api/mocks</code></li>
</ul>
<p><strong>Configuration via REST API (JSON over HTTP):</strong></p>
<p>The REST API supports full configuration management via JSON over HTTP, making it suitable for:</p>
<ul>
<li>CI/CD pipelines</li>
<li>Automated testing</li>
<li>Remote configuration</li>
<li>Integration with external tools</li>
</ul>
<p>All endpoints accept and return JSON, following standard REST conventions.</p>
<h3 id="standalone-mode-examples"><a class="header" href="#standalone-mode-examples">Standalone Mode Examples</a></h3>
<p><strong>Starting MockForge in Standalone Mode:</strong></p>
<pre><code class="language-bash"># Start MockForge with standalone admin UI
mockforge serve --admin --admin-standalone --admin-port 9080

# Or via config file
# admin:
#   enabled: true
#   port: 9080
#   api_enabled: true
</code></pre>
<p><strong>Creating a Mock via REST API (Standalone Mode):</strong></p>
<pre><code class="language-bash"># Create a mock using JSON over HTTP
curl -X POST http://localhost:9080/__mockforge/api/mocks \
  -H "Content-Type: application/json" \
  -d '{
    "id": "user-get",
    "name": "Get User",
    "method": "GET",
    "path": "/api/users/{id}",
    "response": {
      "body": {
        "id": "{{request.path.id}}",
        "name": "Alice",
        "email": "alice@example.com"
      },
      "headers": {
        "Content-Type": "application/json"
      }
    },
    "enabled": true,
    "status_code": 200
  }'
</code></pre>
<p><strong>Updating Configuration via REST API:</strong></p>
<pre><code class="language-bash"># Update latency configuration
curl -X POST http://localhost:9080/__mockforge/api/config/latency \
  -H "Content-Type: application/json" \
  -d '{
    "base_ms": 100,
    "jitter_ms": 50
  }'
</code></pre>
<p><strong>Listing All Mocks:</strong></p>
<pre><code class="language-bash"># Get all configured mocks
curl http://localhost:9080/__mockforge/api/mocks
</code></pre>
<p><strong>Using the SDK with Standalone Mode:</strong></p>
<pre><pre class="playground"><code class="language-rust">use mockforge_sdk::AdminClient;
use mockforge_sdk::MockConfigBuilder;
use serde_json::json;

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    // Connect to standalone admin API
    let client = AdminClient::new("http://localhost:9080");
    
    // Create a mock using the fluent builder API
    let mock = MockConfigBuilder::new("POST", "/api/users")
        .name("Create User")
        .with_header("Authorization", "Bearer.*")
        .with_query_param("role", "admin")
        .status(201)
        .body(json!({
            "id": "{{uuid}}",
            "name": "{{faker.name}}",
            "created": true
        }))
        .priority(10)
        .build();
    
    // Create the mock via REST API
    client.create_mock(mock).await?;
    
    Ok(())
}</code></pre></pre>
<h2 id="authentication-3"><a class="header" href="#authentication-3">Authentication</a></h2>
<p>Currently, the API does not implement authentication. In production deployments, consider adding authentication middleware.</p>
<h2 id="response-format"><a class="header" href="#response-format">Response Format</a></h2>
<p>All API responses follow a consistent format:</p>
<pre><code class="language-json">{
  "success": boolean,
  "data": object | array | null,
  "error": string | null,
  "timestamp": string
}
</code></pre>
<h3 id="success-response"><a class="header" href="#success-response">Success Response</a></h3>
<pre><code class="language-json">{
  "success": true,
  "data": { ... },
  "error": null,
  "timestamp": "2025-09-17T10:30:00Z"
}
</code></pre>
<h3 id="error-response"><a class="header" href="#error-response">Error Response</a></h3>
<pre><code class="language-json">{
  "success": false,
  "data": null,
  "error": "Error message",
  "timestamp": "2025-09-17T10:30:00Z"
}
</code></pre>
<h2 id="api-endpoints-8"><a class="header" href="#api-endpoints-8">API Endpoints</a></h2>
<h3 id="dashboard-3"><a class="header" href="#dashboard-3">Dashboard</a></h3>
<h4 id="get-__mockforgedashboard"><a class="header" href="#get-__mockforgedashboard">GET <code>/__mockforge/dashboard</code></a></h4>
<p>Get comprehensive dashboard data including system information, server status, routes, and recent logs.</p>
<p><strong>Response:</strong></p>
<pre><code class="language-json">{
  "success": true,
  "data": {
    "system": {
      "version": "0.1.0",
      "uptime_seconds": 3600,
      "memory_usage_mb": 128,
      "cpu_usage_percent": 15.5,
      "active_threads": 8,
      "total_routes": 25,
      "total_fixtures": 150
    },
    "servers": [
      {
        "server_type": "HTTP",
        "address": "127.0.0.1:3000",
        "running": true,
        "start_time": "2025-09-17T09:30:00Z",
        "uptime_seconds": 3600,
        "active_connections": 5,
        "total_requests": 1250
      }
    ],
    "routes": [
      {
        "method": "GET",
        "path": "/api/users",
        "priority": 0,
        "has_fixtures": true,
        "latency_ms": 45,
        "request_count": 125,
        "last_request": "2025-09-17T10:25:00Z",
        "error_count": 2
      }
    ],
    "recent_logs": [
      {
        "id": "log_1",
        "timestamp": "2025-09-17T10:29:00Z",
        "method": "GET",
        "path": "/api/users",
        "status_code": 200,
        "response_time_ms": 45,
        "client_ip": "127.0.0.1",
        "user_agent": "test-agent",
        "headers": {},
        "response_size_bytes": 1024,
        "error_message": null
      }
    ],
    "latency_profile": {
      "name": "default",
      "base_ms": 50,
      "jitter_ms": 20,
      "tag_overrides": {}
    },
    "fault_config": {
      "enabled": false,
      "failure_rate": 0.0,
      "status_codes": [500],
      "active_failures": 0
    },
    "proxy_config": {
      "enabled": false,
      "upstream_url": null,
      "timeout_seconds": 30,
      "requests_proxied": 0
    }
  }
}
</code></pre>
<h3 id="health-check"><a class="header" href="#health-check">Health Check</a></h3>
<h4 id="get-__mockforgehealth"><a class="header" href="#get-__mockforgehealth">GET <code>/__mockforge/health</code></a></h4>
<p>Get system health status.</p>
<p><strong>Response:</strong></p>
<pre><code class="language-json">{
  "status": "healthy",
  "services": {
    "http": "healthy",
    "websocket": "healthy",
    "grpc": "healthy"
  },
  "last_check": "2025-09-17T10:30:00Z",
  "issues": []
}
</code></pre>
<h3 id="server-management"><a class="header" href="#server-management">Server Management</a></h3>
<h4 id="get-__mockforgeserver-info"><a class="header" href="#get-__mockforgeserver-info">GET <code>/__mockforge/server-info</code></a></h4>
<p>Get information about server addresses and configuration.</p>
<p><strong>Response:</strong></p>
<pre><code class="language-json">{
  "success": true,
  "data": {
    "http_server": "127.0.0.1:3000",
    "ws_server": "127.0.0.1:3001",
    "grpc_server": "127.0.0.1:50051"
  }
}
</code></pre>
<h4 id="post-__mockforgeserversrestart"><a class="header" href="#post-__mockforgeserversrestart">POST <code>/__mockforge/servers/restart</code></a></h4>
<p>Initiate server restart.</p>
<p><strong>Request Body:</strong></p>
<pre><code class="language-json">{
  "reason": "Manual restart requested"
}
</code></pre>
<p><strong>Response:</strong></p>
<pre><code class="language-json">{
  "success": true,
  "data": {
    "message": "Server restart initiated. Please wait for completion."
  }
}
</code></pre>
<h4 id="get-__mockforgeserversrestartstatus"><a class="header" href="#get-__mockforgeserversrestartstatus">GET <code>/__mockforge/servers/restart/status</code></a></h4>
<p>Get restart status.</p>
<p><strong>Response:</strong></p>
<pre><code class="language-json">{
  "success": true,
  "data": {
    "in_progress": false,
    "initiated_at": null,
    "reason": null,
    "success": null
  }
}
</code></pre>
<h3 id="routes"><a class="header" href="#routes">Routes</a></h3>
<h4 id="get-__mockforgeroutes"><a class="header" href="#get-__mockforgeroutes">GET <code>/__mockforge/routes</code></a></h4>
<p>Get information about configured routes (proxied to HTTP server).</p>
<h3 id="logs"><a class="header" href="#logs">Logs</a></h3>
<h4 id="get-__mockforgelogs"><a class="header" href="#get-__mockforgelogs">GET <code>/__mockforge/logs</code></a></h4>
<p>Get request logs with optional filtering.</p>
<p><strong>Query Parameters:</strong></p>
<ul>
<li><code>method</code> (string): Filter by HTTP method</li>
<li><code>path</code> (string): Filter by path pattern</li>
<li><code>status</code> (number): Filter by status code</li>
<li><code>limit</code> (number): Maximum number of results</li>
</ul>
<p><strong>Examples:</strong></p>
<pre><code>GET /__mockforge/logs?method=GET&amp;limit=50
GET /__mockforge/logs?path=/api/users&amp;status=200
</code></pre>
<p><strong>Response:</strong></p>
<pre><code class="language-json">{
  "success": true,
  "data": [
    {
      "id": "log_1",
      "timestamp": "2025-09-17T10:29:00Z",
      "method": "GET",
      "path": "/api/users",
      "status_code": 200,
      "response_time_ms": 45,
      "client_ip": "127.0.0.1",
      "user_agent": "test-agent",
      "headers": {},
      "response_size_bytes": 1024,
      "error_message": null
    }
  ]
}
</code></pre>
<h4 id="post-__mockforgelogsclear"><a class="header" href="#post-__mockforgelogsclear">POST <code>/__mockforge/logs/clear</code></a></h4>
<p>Clear all request logs.</p>
<p><strong>Response:</strong></p>
<pre><code class="language-json">{
  "success": true,
  "data": {
    "message": "Logs cleared"
  }
}
</code></pre>
<h3 id="metrics"><a class="header" href="#metrics">Metrics</a></h3>
<h4 id="get-__mockforgemetrics"><a class="header" href="#get-__mockforgemetrics">GET <code>/__mockforge/metrics</code></a></h4>
<p>Get performance metrics and analytics.</p>
<p><strong>Response:</strong></p>
<pre><code class="language-json">{
  "success": true,
  "data": {
    "requests_by_endpoint": {
      "GET /api/users": 125,
      "POST /api/users": 45
    },
    "response_time_percentiles": {
      "p50": 45,
      "p95": 120,
      "p99": 250
    },
    "error_rate_by_endpoint": {
      "GET /api/users": 0.02,
      "POST /api/users": 0.0
    },
    "memory_usage_over_time": [
      ["2025-09-17T10:25:00Z", 120],
      ["2025-09-17T10:26:00Z", 125]
    ],
    "cpu_usage_over_time": [
      ["2025-09-17T10:25:00Z", 12.5],
      ["2025-09-17T10:26:00Z", 15.2]
    ]
  }
}
</code></pre>
<h3 id="configuration-36"><a class="header" href="#configuration-36">Configuration</a></h3>
<h4 id="get-__mockforgeconfig"><a class="header" href="#get-__mockforgeconfig">GET <code>/__mockforge/config</code></a></h4>
<p>Get current configuration settings.</p>
<p><strong>Response:</strong></p>
<pre><code class="language-json">{
  "success": true,
  "data": {
    "latency": {
      "enabled": true,
      "base_ms": 50,
      "jitter_ms": 20,
      "tag_overrides": {}
    },
    "faults": {
      "enabled": false,
      "failure_rate": 0.0,
      "status_codes": [500, 502, 503]
    },
    "proxy": {
      "enabled": false,
      "upstream_url": null,
      "timeout_seconds": 30
    },
    "validation": {
      "mode": "enforce",
      "aggregate_errors": true,
      "validate_responses": false,
      "overrides": {}
    }
  }
}
</code></pre>
<h4 id="post-__mockforgeconfiglatency"><a class="header" href="#post-__mockforgeconfiglatency">POST <code>/__mockforge/config/latency</code></a></h4>
<p>Update latency configuration.</p>
<p><strong>Request Body:</strong></p>
<pre><code class="language-json">{
  "config_type": "latency",
  "data": {
    "base_ms": 100,
    "jitter_ms": 50,
    "tag_overrides": {
      "auth": 200
    }
  }
}
</code></pre>
<h4 id="post-__mockforgeconfigfaults"><a class="header" href="#post-__mockforgeconfigfaults">POST <code>/__mockforge/config/faults</code></a></h4>
<p>Update fault injection configuration.</p>
<p><strong>Request Body:</strong></p>
<pre><code class="language-json">{
  "config_type": "faults",
  "data": {
    "enabled": true,
    "failure_rate": 0.1,
    "status_codes": [500, 502, 503]
  }
}
</code></pre>
<h4 id="post-__mockforgeconfigproxy"><a class="header" href="#post-__mockforgeconfigproxy">POST <code>/__mockforge/config/proxy</code></a></h4>
<p>Update proxy configuration.</p>
<p><strong>Request Body:</strong></p>
<pre><code class="language-json">{
  "config_type": "proxy",
  "data": {
    "enabled": true,
    "upstream_url": "http://api.example.com",
    "timeout_seconds": 60
  }
}
</code></pre>
<h4 id="post-__mockforgevalidation"><a class="header" href="#post-__mockforgevalidation">POST <code>/__mockforge/validation</code></a></h4>
<p>Update validation settings.</p>
<p><strong>Request Body:</strong></p>
<pre><code class="language-json">{
  "mode": "warn",
  "aggregate_errors": false,
  "validate_responses": true,
  "overrides": {
    "GET /health": "off"
  }
}
</code></pre>
<h3 id="environment-variables-18"><a class="header" href="#environment-variables-18">Environment Variables</a></h3>
<h4 id="get-__mockforgeenv"><a class="header" href="#get-__mockforgeenv">GET <code>/__mockforge/env</code></a></h4>
<p>Get relevant environment variables.</p>
<p><strong>Response:</strong></p>
<pre><code class="language-json">{
  "success": true,
  "data": {
    "MOCKFORGE_LATENCY_ENABLED": "true",
    "MOCKFORGE_HTTP_PORT": "3000",
    "RUST_LOG": "info"
  }
}
</code></pre>
<h4 id="post-__mockforgeenv"><a class="header" href="#post-__mockforgeenv">POST <code>/__mockforge/env</code></a></h4>
<p>Update an environment variable (runtime only).</p>
<p><strong>Request Body:</strong></p>
<pre><code class="language-json">{
  "key": "MOCKFORGE_LOG_LEVEL",
  "value": "debug"
}
</code></pre>
<p><strong>Response:</strong></p>
<pre><code class="language-json">{
  "success": true,
  "data": {
    "message": "Environment variable MOCKFORGE_LOG_LEVEL updated to 'debug'. Note: This change is not persisted and will be lost on restart."
  }
}
</code></pre>
<h3 id="files"><a class="header" href="#files">Files</a></h3>
<h4 id="post-__mockforgefilescontent"><a class="header" href="#post-__mockforgefilescontent">POST <code>/__mockforge/files/content</code></a></h4>
<p>Get file content.</p>
<p><strong>Request Body:</strong></p>
<pre><code class="language-json">{
  "file_path": "config.yaml",
  "file_type": "yaml"
}
</code></pre>
<p><strong>Response:</strong></p>
<pre><code class="language-json">{
  "success": true,
  "data": "http:\n  request_validation: \"enforce\"\n  aggregate_validation_errors: true\n"
}
</code></pre>
<h4 id="post-__mockforgefilessave"><a class="header" href="#post-__mockforgefilessave">POST <code>/__mockforge/files/save</code></a></h4>
<p>Save file content.</p>
<p><strong>Request Body:</strong></p>
<pre><code class="language-json">{
  "file_path": "config.yaml",
  "content": "http:\n  port: 9080\n"
}
</code></pre>
<p><strong>Response:</strong></p>
<pre><code class="language-json">{
  "success": true,
  "data": {
    "message": "File saved successfully"
  }
}
</code></pre>
<h3 id="fixtures"><a class="header" href="#fixtures">Fixtures</a></h3>
<h4 id="get-__mockforgefixtures"><a class="header" href="#get-__mockforgefixtures">GET <code>/__mockforge/fixtures</code></a></h4>
<p>Get all fixtures with metadata.</p>
<p><strong>Response:</strong></p>
<pre><code class="language-json">{
  "success": true,
  "data": [
    {
      "id": "fixture_123",
      "protocol": "http",
      "method": "GET",
      "path": "/api/users",
      "saved_at": "2025-09-17T09:00:00Z",
      "file_size": 2048,
      "file_path": "http/get/api_users_123.json",
      "fingerprint": "abc123",
      "metadata": { ... }
    }
  ]
}
</code></pre>
<h4 id="post-__mockforgefixturesdelete"><a class="header" href="#post-__mockforgefixturesdelete">POST <code>/__mockforge/fixtures/delete</code></a></h4>
<p>Delete a fixture.</p>
<p><strong>Request Body:</strong></p>
<pre><code class="language-json">{
  "fixture_id": "fixture_123"
}
</code></pre>
<h4 id="post-__mockforgefixturesdelete-bulk"><a class="header" href="#post-__mockforgefixturesdelete-bulk">POST <code>/__mockforge/fixtures/delete-bulk</code></a></h4>
<p>Delete multiple fixtures.</p>
<p><strong>Request Body:</strong></p>
<pre><code class="language-json">{
  "fixture_ids": ["fixture_123", "fixture_456"]
}
</code></pre>
<p><strong>Response:</strong></p>
<pre><code class="language-json">{
  "success": true,
  "data": {
    "deleted_count": 2,
    "total_requested": 2,
    "errors": []
  }
}
</code></pre>
<h4 id="get-__mockforgefixturesdownloadidfixture_123"><a class="header" href="#get-__mockforgefixturesdownloadidfixture_123">GET <code>/__mockforge/fixtures/download?id=fixture_123</code></a></h4>
<p>Download a fixture file.</p>
<p><strong>Response:</strong> Binary file download</p>
<h3 id="smoke-tests"><a class="header" href="#smoke-tests">Smoke Tests</a></h3>
<h4 id="get-__mockforgesmoke"><a class="header" href="#get-__mockforgesmoke">GET <code>/__mockforge/smoke</code></a></h4>
<p>Get smoke test results.</p>
<h4 id="get-__mockforgesmokerun"><a class="header" href="#get-__mockforgesmokerun">GET <code>/__mockforge/smoke/run</code></a></h4>
<p>Run smoke tests against fixtures.</p>
<p><strong>Response:</strong></p>
<pre><code class="language-json">{
  "success": true,
  "data": {
    "message": "Smoke tests started. Check results in the smoke tests section."
  }
}
</code></pre>
<h2 id="error-codes"><a class="header" href="#error-codes">Error Codes</a></h2>
<h3 id="http-status-codes"><a class="header" href="#http-status-codes">HTTP Status Codes</a></h3>
<ul>
<li><code>200 OK</code>: Success</li>
<li><code>400 Bad Request</code>: Invalid request parameters</li>
<li><code>404 Not Found</code>: Endpoint or resource not found</li>
<li><code>500 Internal Server Error</code>: Server error</li>
</ul>
<h3 id="common-error-messages"><a class="header" href="#common-error-messages">Common Error Messages</a></h3>
<ul>
<li><code>"Invalid config type"</code>: Configuration update with invalid type</li>
<li><code>"Failed to load fixtures"</code>: Error reading fixture files</li>
<li><code>"Path traversal detected"</code>: Security violation in file paths</li>
<li><code>"Server restart already in progress"</code>: Attempted restart while one is running</li>
</ul>
<h2 id="rate-limiting-3"><a class="header" href="#rate-limiting-3">Rate Limiting</a></h2>
<p>Currently, no rate limiting is implemented. Consider adding rate limiting for production deployments.</p>
<h2 id="cors"><a class="header" href="#cors">CORS</a></h2>
<p>The API includes CORS middleware allowing cross-origin requests from web applications.</p>
<h2 id="websocket-support"><a class="header" href="#websocket-support">WebSocket Support</a></h2>
<p>The admin UI supports real-time updates through WebSocket connections for live monitoring of metrics and logs.</p>
<h2 id="examples-15"><a class="header" href="#examples-15">Examples</a></h2>
<h3 id="complete-dashboard-fetch"><a class="header" href="#complete-dashboard-fetch">Complete Dashboard Fetch</a></h3>
<pre><code class="language-javascript">const response = await fetch('/__mockforge/dashboard');
const data = await response.json();

if (data.success) {
  console.log('System uptime:', data.data.system.uptime_seconds);
  console.log('Active servers:', data.data.servers.length);
}
</code></pre>
<h3 id="update-latency-configuration"><a class="header" href="#update-latency-configuration">Update Latency Configuration</a></h3>
<pre><code class="language-javascript">const response = await fetch('/__mockforge/config/latency', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    config_type: 'latency',
    data: {
      base_ms: 100,
      jitter_ms: 25
    }
  })
});

const result = await response.json();
console.log(result.data.message);
</code></pre>
<h3 id="filter-logs"><a class="header" href="#filter-logs">Filter Logs</a></h3>
<pre><code class="language-javascript">const response = await fetch('/__mockforge/logs?method=GET&amp;status=200&amp;limit=100');
const data = await response.json();

data.data.forEach(log =&gt; {
  console.log(`${log.method} ${log.path} - ${log.status_code} (${log.response_time_ms}ms)`);
});
</code></pre>
<h2 id="development"><a class="header" href="#development">Development</a></h2>
<h3 id="running-tests-1"><a class="header" href="#running-tests-1">Running Tests</a></h3>
<pre><code class="language-bash"># Run all tests
cargo test --package mockforge-ui

# Run integration tests
cargo test --package mockforge-ui --test integration

# Run smoke tests
cargo test --package mockforge-ui --test smoke
</code></pre>
<h3 id="building-documentation-1"><a class="header" href="#building-documentation-1">Building Documentation</a></h3>
<pre><code class="language-bash"># Generate API documentation
cargo doc --package mockforge-ui --open
</code></pre>
<h2 id="security-considerations-7"><a class="header" href="#security-considerations-7">Security Considerations</a></h2>
<ol>
<li><strong>Input Validation</strong>: All inputs should be validated</li>
<li><strong>Path Traversal</strong>: File operations prevent directory traversal</li>
<li><strong>Rate Limiting</strong>: Consider implementing rate limiting</li>
<li><strong>Authentication</strong>: Add authentication for production use</li>
<li><strong>HTTPS</strong>: Use HTTPS in production</li>
<li><strong>CORS</strong>: Properly configure CORS policies</li>
</ol>
<h2 id="contributing"><a class="header" href="#contributing">Contributing</a></h2>
<p>When adding new API endpoints:</p>
<ol>
<li>Follow the established response format</li>
<li>Add comprehensive error handling</li>
<li>Include integration tests</li>
<li>Update this documentation</li>
<li>Ensure proper CORS and security measures</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rust-api-reference"><a class="header" href="#rust-api-reference">Rust API Reference</a></h1>
<p>MockForge provides comprehensive Rust libraries for programmatic usage and extension. This reference covers the main crates and their APIs.</p>
<h2 id="crate-overview"><a class="header" href="#crate-overview">Crate Overview</a></h2>
<p>MockForge consists of several interconnected crates:</p>
<ul>
<li><strong><code>mockforge-cli</code></strong>: Command-line interface and main executable</li>
<li><strong><code>mockforge-core</code></strong>: Core functionality shared across protocols</li>
<li><strong><code>mockforge-http</code></strong>: HTTP REST API mocking</li>
<li><strong><code>mockforge-grpc</code></strong>: gRPC service mocking</li>
<li><strong><code>mockforge-ui</code></strong>: Web-based admin interface</li>
</ul>
<h2 id="getting-started-4"><a class="header" href="#getting-started-4">Getting Started</a></h2>
<p>Add MockForge to your <code>Cargo.toml</code>:</p>
<pre><code class="language-toml">[dependencies]
mockforge-core = "0.1"
mockforge-http = "0.1"
mockforge-grpc = "0.1"
</code></pre>
<p>For development or testing, you might want to use path dependencies:</p>
<pre><code class="language-toml">[dependencies]
mockforge-core = { path = "../mockforge/crates/mockforge-core" }
mockforge-http = { path = "../mockforge/crates/mockforge-http" }
mockforge-grpc = { path = "../mockforge/crates/mockforge-grpc" }
</code></pre>
<h2 id="core-concepts-2"><a class="header" href="#core-concepts-2">Core Concepts</a></h2>
<h3 id="configuration-system"><a class="header" href="#configuration-system">Configuration System</a></h3>
<p>MockForge uses a hierarchical configuration system that can be built programmatically:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_core::config::MockForgeConfig;

let config = MockForgeConfig {
    server: ServerConfig {
        http_port: Some(3000),
        ws_port: Some(3001),
        grpc_port: Some(50051),
    },
    validation: ValidationConfig {
        mode: ValidationMode::Enforce,
        aggregate_errors: false,
    },
    response: ResponseConfig {
        template_expand: true,
    },
    ..Default::default()
};
<span class="boring">}</span></code></pre></pre>
<h3 id="template-system-1"><a class="header" href="#template-system-1">Template System</a></h3>
<p>MockForge includes a powerful template engine for dynamic content generation:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_core::template::{TemplateEngine, Context};

let engine = TemplateEngine::new();
let context = Context::new()
    .with_value("user_id", "12345")
    .with_value("timestamp", "2025-09-12T10:00:00Z");

let result = engine.render("User {{user_id}} logged in at {{timestamp}}", &amp;context)?;
assert_eq!(result, "User 12345 logged in at 2025-09-12T10:00:00Z");
<span class="boring">}</span></code></pre></pre>
<h3 id="error-handling-8"><a class="header" href="#error-handling-8">Error Handling</a></h3>
<p>MockForge uses the <code>anyhow</code> crate for error handling:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use anyhow::{Result, Context};

fn start_server(config: &amp;Config) -&gt; Result&lt;()&gt; {
    let server = HttpServer::new(config)
        .context("Failed to create HTTP server")?;

    server.start()
        .context("Failed to start server")?;

    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<h2 id="http-api"><a class="header" href="#http-api">HTTP API</a></h2>
<h3 id="basic-http-server"><a class="header" href="#basic-http-server">Basic HTTP Server</a></h3>
<pre><pre class="playground"><code class="language-rust">use mockforge_http::{HttpServer, HttpConfig};
use mockforge_core::config::ServerConfig;

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    // Create HTTP configuration
    let http_config = HttpConfig {
        spec_path: Some("api-spec.yaml".to_string()),
        validation_mode: ValidationMode::Warn,
        template_expand: true,
    };

    // Start HTTP server
    let mut server = HttpServer::new(http_config);
    server.start(([127, 0, 0, 1], 3000)).await?;

    println!("HTTP server running on http://localhost:3000");
    Ok(())
}</code></pre></pre>
<h3 id="custom-route-handlers"><a class="header" href="#custom-route-handlers">Custom Route Handlers</a></h3>
<pre><pre class="playground"><code class="language-rust">use mockforge_http::{HttpServer, RouteHandler};
use warp::{Filter, Reply};

struct CustomHandler;

impl RouteHandler for CustomHandler {
    fn handle(&amp;self, path: &amp;str, method: &amp;str) -&gt; Option&lt;Box&lt;dyn Reply&gt;&gt; {
        if path == "/custom" &amp;&amp; method == "GET" {
            Some(Box::new(warp::reply::json(&amp;serde_json::json!({
                "message": "Custom response",
                "timestamp": chrono::Utc::now()
            }))))
        } else {
            None
        }
    }
}

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    let handler = CustomHandler;
    let server = HttpServer::with_handler(handler);
    server.start(([127, 0, 0, 1], 3000)).await?;
    Ok(())
}</code></pre></pre>
<h2 id="grpc-api"><a class="header" href="#grpc-api">gRPC API</a></h2>
<h3 id="basic-grpc-server-2"><a class="header" href="#basic-grpc-server-2">Basic gRPC Server</a></h3>
<pre><pre class="playground"><code class="language-rust">use mockforge_grpc::{GrpcServer, GrpcConfig};
use std::path::Path;

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    // Configure proto discovery
    let config = GrpcConfig {
        proto_dir: Path::new("proto/"),
        enable_reflection: true,
        ..Default::default()
    };

    // Start gRPC server
    let server = GrpcServer::new(config);
    server.start("127.0.0.1:50051").await?;

    println!("gRPC server running on 127.0.0.1:50051");
    Ok(())
}</code></pre></pre>
<h3 id="custom-service-implementation"><a class="header" href="#custom-service-implementation">Custom Service Implementation</a></h3>
<pre><pre class="playground"><code class="language-rust">use mockforge_grpc::{ServiceRegistry, ServiceImplementation};
use prost::Message;
use tonic::{Request, Response, Status};

// Generated from proto file
mod greeter {
    include!("generated/greeter.rs");
}

pub struct GreeterService;

#[tonic::async_trait]
impl greeter::greeter_server::Greeter for GreeterService {
    async fn say_hello(
        &amp;self,
        request: Request&lt;greeter::HelloRequest&gt;,
    ) -&gt; Result&lt;Response&lt;greeter::HelloReply&gt;, Status&gt; {
        let name = request.into_inner().name;

        let reply = greeter::HelloReply {
            message: format!("Hello, {}!", name),
            timestamp: Some(prost_types::Timestamp::from(std::time::SystemTime::now())),
        };

        Ok(Response::new(reply))
    }
}

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    let service = GreeterService {};
    let server = GrpcServer::with_service(service);
    server.start("127.0.0.1:50051").await?;
    Ok(())
}</code></pre></pre>
<h2 id="websocket-api"><a class="header" href="#websocket-api">WebSocket API</a></h2>
<h3 id="basic-websocket-server-1"><a class="header" href="#basic-websocket-server-1">Basic WebSocket Server</a></h3>
<pre><pre class="playground"><code class="language-rust">use mockforge_ws::{WebSocketServer, WebSocketConfig};

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    let config = WebSocketConfig {
        port: 3001,
        replay_file: Some("ws-replay.jsonl".to_string()),
        ..Default::default()
    };

    let server = WebSocketServer::new(config);
    server.start().await?;

    println!("WebSocket server running on ws://localhost:3001");
    Ok(())
}</code></pre></pre>
<h3 id="custom-message-handler"><a class="header" href="#custom-message-handler">Custom Message Handler</a></h3>
<pre><pre class="playground"><code class="language-rust">use mockforge_ws::{WebSocketServer, MessageHandler};
use futures_util::{SinkExt, StreamExt};

struct EchoHandler;

impl MessageHandler for EchoHandler {
    async fn handle_message(&amp;self, message: String) -&gt; String {
        format!("Echo: {}", message)
    }
}

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    let handler = EchoHandler {};
    let server = WebSocketServer::with_handler(handler);
    server.start().await?;
    Ok(())
}</code></pre></pre>
<p>This Rust API reference provides the foundation for programmatic usage of MockForge. For protocol-specific details, see the <a href="api/rust/http.html">HTTP</a>, <a href="api/rust/grpc.html">gRPC</a>, and <a href="api/rust/ws.html">WebSocket</a> API documentation.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="http-module"><a class="header" href="#http-module">HTTP Module</a></h1>
<p>The <code>mockforge_http</code> crate provides comprehensive HTTP/REST API mocking capabilities with OpenAPI integration, AI-powered responses, and advanced management features.</p>
<h2 id="modules"><a class="header" href="#modules">Modules</a></h2>
<h3 id="core-functions"><a class="header" href="#core-functions">Core Functions</a></h3>
<h4 id="build_router-1"><a class="header" href="#build_router-1"><code>build_router</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub async fn build_router(
    spec_path: Option&lt;String&gt;,
    options: Option&lt;ValidationOptions&gt;,
    failure_config: Option&lt;FailureConfig&gt;,
) -&gt; Router
<span class="boring">}</span></code></pre></pre>
<p>Creates a basic HTTP router with optional OpenAPI specification support.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>spec_path</code>: Optional path to OpenAPI specification file</li>
<li><code>options</code>: Optional validation options for request/response validation</li>
<li><code>failure_config</code>: Optional failure injection configuration</li>
</ul>
<p><strong>Returns:</strong> Axum <code>Router</code> configured for HTTP mocking</p>
<p><strong>Example:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_http::build_router;
use mockforge_core::ValidationOptions;

let router = build_router(
    Some("./api.yaml".to_string()),
    Some(ValidationOptions::enforce()),
    None,
).await;
<span class="boring">}</span></code></pre></pre>
<h4 id="build_router_with_auth-1"><a class="header" href="#build_router_with_auth-1"><code>build_router_with_auth</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub async fn build_router_with_auth(
    spec_path: Option&lt;String&gt;,
    options: Option&lt;ValidationOptions&gt;,
    auth_config: Option&lt;AuthConfig&gt;,
) -&gt; Router
<span class="boring">}</span></code></pre></pre>
<p>Creates an HTTP router with authentication support.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>spec_path</code>: Optional path to OpenAPI specification file</li>
<li><code>options</code>: Optional validation options</li>
<li><code>auth_config</code>: Authentication configuration (OAuth2, JWT, API keys)</li>
</ul>
<p><strong>Returns:</strong> Axum <code>Router</code> with authentication middleware</p>
<p><strong>Example:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_http::build_router_with_auth;
use mockforge_core::config::AuthConfig;

let auth_config = AuthConfig {
    oauth2: Some(OAuth2Config {
        client_id: "client123".to_string(),
        client_secret: "secret".to_string(),
        ..Default::default()
    }),
    ..Default::default()
};

let router = build_router_with_auth(
    Some("./api.yaml".to_string()),
    None,
    Some(auth_config),
).await;
<span class="boring">}</span></code></pre></pre>
<h4 id="build_router_with_chains-1"><a class="header" href="#build_router_with_chains-1"><code>build_router_with_chains</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub async fn build_router_with_chains(
    spec_path: Option&lt;String&gt;,
    options: Option&lt;ValidationOptions&gt;,
    chain_config: Option&lt;RequestChainingConfig&gt;,
) -&gt; Router
<span class="boring">}</span></code></pre></pre>
<p>Creates an HTTP router with request chaining support for multi-step workflows.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>spec_path</code>: Optional path to OpenAPI specification file</li>
<li><code>options</code>: Optional validation options</li>
<li><code>chain_config</code>: Request chaining configuration</li>
</ul>
<p><strong>Returns:</strong> Axum <code>Router</code> with chaining capabilities</p>
<h4 id="build_router_with_multi_tenant"><a class="header" href="#build_router_with_multi_tenant"><code>build_router_with_multi_tenant</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub async fn build_router_with_multi_tenant(
    spec_path: Option&lt;String&gt;,
    options: Option&lt;ValidationOptions&gt;,
    failure_config: Option&lt;FailureConfig&gt;,
    multi_tenant_config: Option&lt;MultiTenantConfig&gt;,
    route_configs: Option&lt;Vec&lt;RouteConfig&gt;&gt;,
    cors_config: Option&lt;HttpCorsConfig&gt;,
) -&gt; Router
<span class="boring">}</span></code></pre></pre>
<p>Creates an HTTP router with multi-tenant workspace support.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>spec_path</code>: Optional path to OpenAPI specification file</li>
<li><code>options</code>: Optional validation options</li>
<li><code>failure_config</code>: Optional failure injection configuration</li>
<li><code>multi_tenant_config</code>: Multi-tenant workspace configuration</li>
<li><code>route_configs</code>: Custom route configurations</li>
<li><code>cors_config</code>: CORS configuration</li>
</ul>
<p><strong>Returns:</strong> Axum <code>Router</code> with multi-tenant support</p>
<h4 id="build_router_with_traffic_shaping-1"><a class="header" href="#build_router_with_traffic_shaping-1"><code>build_router_with_traffic_shaping</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub async fn build_router_with_traffic_shaping(
    spec_path: Option&lt;String&gt;,
    options: Option&lt;ValidationOptions&gt;,
    traffic_shaper: Option&lt;TrafficShaper&gt;,
    traffic_shaping_enabled: bool,
) -&gt; Router
<span class="boring">}</span></code></pre></pre>
<p>Creates an HTTP router with traffic shaping capabilities.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>spec_path</code>: Optional path to OpenAPI specification file</li>
<li><code>options</code>: Optional validation options</li>
<li><code>traffic_shaper</code>: Traffic shaping configuration</li>
<li><code>traffic_shaping_enabled</code>: Whether traffic shaping is active</li>
</ul>
<p><strong>Returns:</strong> Axum <code>Router</code> with traffic shaping middleware</p>
<h3 id="server-functions"><a class="header" href="#server-functions">Server Functions</a></h3>
<h4 id="serve_router"><a class="header" href="#serve_router"><code>serve_router</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub async fn serve_router(
    port: u16,
    app: Router,
) -&gt; Result&lt;(), Box&lt;dyn std::error::Error + Send + Sync&gt;&gt;
<span class="boring">}</span></code></pre></pre>
<p>Starts the HTTP server on the specified port.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>port</code>: Port number to bind to</li>
<li><code>app</code>: Axum router to serve</li>
</ul>
<p><strong>Returns:</strong> <code>Result&lt;(), Error&gt;</code> indicating server startup success</p>
<p><strong>Errors:</strong></p>
<ul>
<li>Port binding failures</li>
<li>Server startup errors</li>
</ul>
<h4 id="start"><a class="header" href="#start"><code>start</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub async fn start(
    port: u16,
    spec_path: Option&lt;String&gt;,
    options: Option&lt;ValidationOptions&gt;,
) -&gt; Result&lt;(), Box&lt;dyn std::error::Error + Send + Sync&gt;&gt;
<span class="boring">}</span></code></pre></pre>
<p>Convenience function to build and start an HTTP server.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>port</code>: Port number to bind to</li>
<li><code>spec_path</code>: Optional path to OpenAPI specification file</li>
<li><code>options</code>: Optional validation options</li>
</ul>
<h4 id="start_with_auth_and_latency"><a class="header" href="#start_with_auth_and_latency"><code>start_with_auth_and_latency</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub async fn start_with_auth_and_latency(
    port: u16,
    spec_path: Option&lt;String&gt;,
    options: Option&lt;ValidationOptions&gt;,
    auth_config: Option&lt;AuthConfig&gt;,
    latency_profile: Option&lt;LatencyProfile&gt;,
) -&gt; Result&lt;(), Box&lt;dyn std::error::Error + Send + Sync&gt;&gt;
<span class="boring">}</span></code></pre></pre>
<p>Starts HTTP server with authentication and latency simulation.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>port</code>: Port number to bind to</li>
<li><code>spec_path</code>: Optional path to OpenAPI specification file</li>
<li><code>options</code>: Optional validation options</li>
<li><code>auth_config</code>: Authentication configuration</li>
<li><code>latency_profile</code>: Latency injection profile</li>
</ul>
<h3 id="management-api-1"><a class="header" href="#management-api-1">Management API</a></h3>
<h4 id="management_router"><a class="header" href="#management_router"><code>management_router</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn management_router(state: ManagementState) -&gt; Router
<span class="boring">}</span></code></pre></pre>
<p>Creates a management API router for server control and monitoring.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>state</code>: Management state containing server statistics and configuration</li>
</ul>
<p><strong>Returns:</strong> Axum <code>Router</code> with management endpoints</p>
<p><strong>Endpoints:</strong></p>
<ul>
<li><code>GET /health</code> - Health check</li>
<li><code>GET /stats</code> - Server statistics</li>
<li><code>GET /routes</code> - Route information</li>
<li><code>GET /coverage</code> - API coverage metrics</li>
<li><code>GET/POST/PUT/DELETE /mocks</code> - Mock management</li>
</ul>
<h4 id="management_ws_router"><a class="header" href="#management_ws_router"><code>management_ws_router</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn ws_management_router(state: WsManagementState) -&gt; Router
<span class="boring">}</span></code></pre></pre>
<p>Creates a WebSocket management router for real-time monitoring.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>state</code>: WebSocket management state</li>
</ul>
<p><strong>Returns:</strong> Axum <code>Router</code> with WebSocket management endpoints</p>
<h3 id="ai-integration-1"><a class="header" href="#ai-integration-1">AI Integration</a></h3>
<h4 id="process_response_with_ai"><a class="header" href="#process_response_with_ai"><code>process_response_with_ai</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub async fn process_response_with_ai(
    response_body: Option&lt;Value&gt;,
    intelligent_config: Option&lt;Value&gt;,
    drift_config: Option&lt;Value&gt;,
) -&gt; Result&lt;Value&gt;
<span class="boring">}</span></code></pre></pre>
<p>Processes a response body using AI features if configured.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>response_body</code>: Base response body as JSON Value</li>
<li><code>intelligent_config</code>: Intelligent mock generation configuration</li>
<li><code>drift_config</code>: Data drift simulation configuration</li>
</ul>
<p><strong>Returns:</strong> <code>Result&lt;Value, Error&gt;</code> with processed response</p>
<p><strong>Example:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_http::process_response_with_ai;
use serde_json::json;

let config = json!({
    "enabled": true,
    "prompt": "Generate realistic user data"
});

let response = process_response_with_ai(
    Some(json!({"name": "John"})),
    Some(config),
    None,
).await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="data-structures"><a class="header" href="#data-structures">Data Structures</a></h3>
<h4 id="httpserverstate-1"><a class="header" href="#httpserverstate-1"><code>HttpServerState</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct HttpServerState {
    pub routes: Vec&lt;RouteInfo&gt;,
    pub rate_limiter: Option&lt;Arc&lt;GlobalRateLimiter&gt;&gt;,
}
<span class="boring">}</span></code></pre></pre>
<p>Shared state for HTTP server route information and rate limiting.</p>
<p><strong>Fields:</strong></p>
<ul>
<li><code>routes</code>: Vector of route information</li>
<li><code>rate_limiter</code>: Optional global rate limiter</li>
</ul>
<p><strong>Methods:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl HttpServerState {
    pub fn new() -&gt; Self
    pub fn with_routes(routes: Vec&lt;RouteInfo&gt;) -&gt; Self
    pub fn with_rate_limiter(rate_limiter: Arc&lt;GlobalRateLimiter&gt;) -&gt; Self
}
<span class="boring">}</span></code></pre></pre>
<h4 id="routeinfo"><a class="header" href="#routeinfo"><code>RouteInfo</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct RouteInfo {
    pub method: String,
    pub path: String,
    pub operation_id: Option&lt;String&gt;,
    pub summary: Option&lt;String&gt;,
    pub description: Option&lt;String&gt;,
    pub parameters: Vec&lt;String&gt;,
}
<span class="boring">}</span></code></pre></pre>
<p>Information about an HTTP route.</p>
<p><strong>Fields:</strong></p>
<ul>
<li><code>method</code>: HTTP method (GET, POST, etc.)</li>
<li><code>path</code>: Route path pattern</li>
<li><code>operation_id</code>: Optional OpenAPI operation ID</li>
<li><code>summary</code>: Optional route summary</li>
<li><code>description</code>: Optional route description</li>
<li><code>parameters</code>: List of parameter names</li>
</ul>
<h4 id="managementstate-1"><a class="header" href="#managementstate-1"><code>ManagementState</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct ManagementState {
    pub mocks: Arc&lt;RwLock&lt;Vec&lt;MockConfig&gt;&gt;&gt;,
    pub spec: Option&lt;Arc&lt;OpenApiSpec&gt;&gt;,
    pub spec_path: Option&lt;String&gt;,
    pub port: u16,
    pub start_time: Instant,
    pub request_counter: Arc&lt;RwLock&lt;u64&gt;&gt;,
}
<span class="boring">}</span></code></pre></pre>
<p>State for the management API.</p>
<p><strong>Fields:</strong></p>
<ul>
<li><code>mocks</code>: Thread-safe vector of mock configurations</li>
<li><code>spec</code>: Optional OpenAPI specification</li>
<li><code>spec_path</code>: Optional path to spec file</li>
<li><code>port</code>: Server port</li>
<li><code>start_time</code>: Server startup timestamp</li>
<li><code>request_counter</code>: Request counter for statistics</li>
</ul>
<p><strong>Methods:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl ManagementState {
    pub fn new(
        spec: Option&lt;Arc&lt;OpenApiSpec&gt;&gt;,
        spec_path: Option&lt;String&gt;,
        port: u16,
    ) -&gt; Self
}
<span class="boring">}</span></code></pre></pre>
<h4 id="mockconfig"><a class="header" href="#mockconfig"><code>MockConfig</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct MockConfig {
    pub id: String,
    pub name: String,
    pub method: String,
    pub path: String,
    pub response: MockResponse,
    pub enabled: bool,
    pub latency_ms: Option&lt;u64&gt;,
    pub status_code: Option&lt;u16&gt;,
}
<span class="boring">}</span></code></pre></pre>
<p>Configuration for a mock endpoint.</p>
<p><strong>Fields:</strong></p>
<ul>
<li><code>id</code>: Unique mock identifier</li>
<li><code>name</code>: Human-readable name</li>
<li><code>method</code>: HTTP method</li>
<li><code>path</code>: Route path</li>
<li><code>response</code>: Mock response configuration</li>
<li><code>enabled</code>: Whether mock is active</li>
<li><code>latency_ms</code>: Optional latency injection</li>
<li><code>status_code</code>: Optional status code override</li>
</ul>
<h4 id="mockresponse"><a class="header" href="#mockresponse"><code>MockResponse</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct MockResponse {
    pub body: Value,
    pub headers: Option&lt;HashMap&lt;String, String&gt;&gt;,
}
<span class="boring">}</span></code></pre></pre>
<p>Mock response configuration.</p>
<p><strong>Fields:</strong></p>
<ul>
<li><code>body</code>: JSON response body</li>
<li><code>headers</code>: Optional HTTP headers</li>
</ul>
<h4 id="serverstats"><a class="header" href="#serverstats"><code>ServerStats</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct ServerStats {
    pub uptime_seconds: u64,
    pub total_requests: u64,
    pub active_mocks: usize,
    pub enabled_mocks: usize,
    pub registered_routes: usize,
}
<span class="boring">}</span></code></pre></pre>
<p>Server statistics.</p>
<p><strong>Fields:</strong></p>
<ul>
<li><code>uptime_seconds</code>: Server uptime in seconds</li>
<li><code>total_requests</code>: Total requests processed</li>
<li><code>active_mocks</code>: Number of configured mocks</li>
<li><code>enabled_mocks</code>: Number of enabled mocks</li>
<li><code>registered_routes</code>: Number of registered routes</li>
</ul>
<h4 id="serverconfig"><a class="header" href="#serverconfig"><code>ServerConfig</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct ServerConfig {
    pub version: String,
    pub port: u16,
    pub has_openapi_spec: bool,
    pub spec_path: Option&lt;String&gt;,
}
<span class="boring">}</span></code></pre></pre>
<p>Server configuration information.</p>
<p><strong>Fields:</strong></p>
<ul>
<li><code>version</code>: MockForge version</li>
<li><code>port</code>: Server port</li>
<li><code>has_openapi_spec</code>: Whether OpenAPI spec is loaded</li>
<li><code>spec_path</code>: Optional path to spec file</li>
</ul>
<h3 id="ai-types"><a class="header" href="#ai-types">AI Types</a></h3>
<h4 id="airesponseconfig"><a class="header" href="#airesponseconfig"><code>AiResponseConfig</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct AiResponseConfig {
    pub enabled: bool,
    pub rag_config: RagConfig,
    pub prompt: String,
    pub schema: Option&lt;Value&gt;,
}
<span class="boring">}</span></code></pre></pre>
<p>Configuration for AI-powered response generation.</p>
<p><strong>Fields:</strong></p>
<ul>
<li><code>enabled</code>: Whether AI responses are enabled</li>
<li><code>rag_config</code>: RAG (Retrieval-Augmented Generation) configuration</li>
<li><code>prompt</code>: AI generation prompt</li>
<li><code>schema</code>: Optional response schema</li>
</ul>
<h4 id="airesponsehandler-1"><a class="header" href="#airesponsehandler-1"><code>AiResponseHandler</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct AiResponseHandler { /* fields omitted */ }
<span class="boring">}</span></code></pre></pre>
<p>Handler for AI-powered response generation.</p>
<p><strong>Methods:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl AiResponseHandler {
    pub fn new(
        intelligent_config: Option&lt;IntelligentMockConfig&gt;,
        drift_config: Option&lt;DataDriftConfig&gt;,
    ) -&gt; Result&lt;Self&gt;

    pub fn is_enabled(&amp;self) -&gt; bool

    pub async fn generate_response(&amp;mut self, base_response: Option&lt;Value&gt;) -&gt; Result&lt;Value&gt;

    pub async fn reset_drift(&amp;self)
}
<span class="boring">}</span></code></pre></pre>
<h3 id="coverage-types"><a class="header" href="#coverage-types">Coverage Types</a></h3>
<h4 id="coveragereport"><a class="header" href="#coveragereport"><code>CoverageReport</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct CoverageReport {
    pub routes: HashMap&lt;String, RouteCoverage&gt;,
    pub total_routes: usize,
    pub covered_routes: usize,
    pub coverage_percentage: f64,
}
<span class="boring">}</span></code></pre></pre>
<p>API coverage report.</p>
<p><strong>Fields:</strong></p>
<ul>
<li><code>routes</code>: Coverage data per route</li>
<li><code>total_routes</code>: Total number of routes</li>
<li><code>covered_routes</code>: Number of covered routes</li>
<li><code>coverage_percentage</code>: Coverage percentage (0.0-100.0)</li>
</ul>
<h4 id="routecoverage"><a class="header" href="#routecoverage"><code>RouteCoverage</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct RouteCoverage {
    pub method: String,
    pub path: String,
    pub methods: HashMap&lt;String, MethodCoverage&gt;,
    pub total_requests: u64,
    pub covered_methods: usize,
}
<span class="boring">}</span></code></pre></pre>
<p>Coverage information for a specific route.</p>
<p><strong>Fields:</strong></p>
<ul>
<li><code>method</code>: HTTP method</li>
<li><code>path</code>: Route path</li>
<li><code>methods</code>: Coverage per HTTP method</li>
<li><code>total_requests</code>: Total requests to this route</li>
<li><code>covered_methods</code>: Number of methods with coverage</li>
</ul>
<h4 id="methodcoverage"><a class="header" href="#methodcoverage"><code>MethodCoverage</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct MethodCoverage {
    pub request_count: u64,
    pub response_codes: HashMap&lt;u16, u64&gt;,
    pub last_request: Option&lt;DateTime&lt;Utc&gt;&gt;,
}
<span class="boring">}</span></code></pre></pre>
<p>Coverage information for a specific HTTP method.</p>
<p><strong>Fields:</strong></p>
<ul>
<li><code>request_count</code>: Number of requests</li>
<li><code>response_codes</code>: Response code distribution</li>
<li><code>last_request</code>: Timestamp of last request</li>
</ul>
<h3 id="coverage-functions"><a class="header" href="#coverage-functions">Coverage Functions</a></h3>
<h4 id="calculate_coverage"><a class="header" href="#calculate_coverage"><code>calculate_coverage</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn calculate_coverage(
    routes: &amp;[RouteInfo],
    request_logs: &amp;[RequestLogEntry],
) -&gt; CoverageReport
<span class="boring">}</span></code></pre></pre>
<p>Calculates API coverage from route information and request logs.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>routes</code>: Available routes</li>
<li><code>request_logs</code>: Historical request logs</li>
</ul>
<p><strong>Returns:</strong> <code>CoverageReport</code> with coverage statistics</p>
<h4 id="get_coverage_handler"><a class="header" href="#get_coverage_handler"><code>get_coverage_handler</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub async fn get_coverage_handler(State(state): State&lt;HttpServerState&gt;) -&gt; Json&lt;Value&gt;
<span class="boring">}</span></code></pre></pre>
<p>Axum handler for coverage endpoint.</p>
<p><strong>Returns:</strong> JSON response with coverage data</p>
<h3 id="middleware-functions"><a class="header" href="#middleware-functions">Middleware Functions</a></h3>
<h4 id="collect_http_metrics"><a class="header" href="#collect_http_metrics"><code>collect_http_metrics</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn collect_http_metrics(request: &amp;Request, response: &amp;Response, duration: Duration)
<span class="boring">}</span></code></pre></pre>
<p>Collects HTTP metrics for observability.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>request</code>: HTTP request</li>
<li><code>response</code>: HTTP response</li>
<li><code>duration</code>: Request processing duration</li>
</ul>
<h4 id="http_tracing_middleware"><a class="header" href="#http_tracing_middleware"><code>http_tracing_middleware</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn http_tracing_middleware(
    request: Request,
    next: Next,
) -&gt; impl Future&lt;Output = Response&gt;
<span class="boring">}</span></code></pre></pre>
<p>Middleware for HTTP request tracing.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>request</code>: Incoming HTTP request</li>
<li><code>next</code>: Next middleware in chain</li>
</ul>
<p><strong>Returns:</strong> Future resolving to HTTP response</p>
<h3 id="error-types"><a class="header" href="#error-types">Error Types</a></h3>
<p>All functions return <code>Result&lt;T, Box&lt;dyn std::error::Error + Send + Sync&gt;&gt;</code> for error handling. Common errors include:</p>
<ul>
<li>File I/O errors (spec file reading)</li>
<li>JSON parsing errors</li>
<li>Server binding errors</li>
<li>Validation errors</li>
<li>AI service errors</li>
</ul>
<h3 id="constants"><a class="header" href="#constants">Constants</a></h3>
<ul>
<li><code>DEFAULT_RATE_LIMIT_RPM</code>: Default requests per minute (1000)</li>
<li><code>DEFAULT_RATE_LIMIT_BURST</code>: Default burst size (2000)</li>
</ul>
<h3 id="feature-flags-1"><a class="header" href="#feature-flags-1">Feature Flags</a></h3>
<ul>
<li><code>data-faker</code>: Enables rich data generation features</li>
</ul>
<h2 id="examples-16"><a class="header" href="#examples-16">Examples</a></h2>
<h3 id="basic-http-server-1"><a class="header" href="#basic-http-server-1">Basic HTTP Server</a></h3>
<pre><pre class="playground"><code class="language-rust">use mockforge_http::build_router;

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    let router = build_router(
        Some("./api.yaml".to_string()),
        None,
        None,
    ).await;

    let listener = tokio::net::TcpListener::bind("0.0.0.0:3000").await?;
    axum::serve(listener, router).await?;
    Ok(())
}</code></pre></pre>
<h3 id="server-with-management-api"><a class="header" href="#server-with-management-api">Server with Management API</a></h3>
<pre><pre class="playground"><code class="language-rust">use mockforge_http::{build_router, management_router, ManagementState};

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    // Build main router
    let app = build_router(None, None, None).await;

    // Add management API
    let mgmt_state = ManagementState::new(None, None, 3000);
    let mgmt_router = management_router(mgmt_state);

    let app = app.nest("/__mockforge", mgmt_router);

    let listener = tokio::net::TcpListener::bind("0.0.0.0:3000").await?;
    axum::serve(listener, app).await?;
    Ok(())
}</code></pre></pre>
<h3 id="ai-powered-responses"><a class="header" href="#ai-powered-responses">AI-Powered Responses</a></h3>
<pre><pre class="playground"><code class="language-rust">use mockforge_http::{AiResponseConfig, process_response_with_ai};
use mockforge_data::RagConfig;

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    let ai_config = AiResponseConfig {
        enabled: true,
        rag_config: RagConfig {
            provider: "openai".to_string(),
            model: "gpt-3.5-turbo".to_string(),
            api_key: Some("sk-...".to_string()),
            ..Default::default()
        },
        prompt: "Generate realistic user data".to_string(),
        schema: None,
    };

    let response = process_response_with_ai(
        Some(serde_json::json!({"id": 1})),
        Some(serde_json::to_value(ai_config)?),
        None,
    ).await?;

    println!("AI response: {}", response);
    Ok(())
}</code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="grpc-module"><a class="header" href="#grpc-module">gRPC Module</a></h1>
<p>The <code>mockforge_grpc</code> crate provides dynamic gRPC service discovery and mocking with HTTP bridge capabilities.</p>
<h2 id="modules-1"><a class="header" href="#modules-1">Modules</a></h2>
<h3 id="core-functions-1"><a class="header" href="#core-functions-1">Core Functions</a></h3>
<h4 id="start-1"><a class="header" href="#start-1"><code>start</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub async fn start(port: u16) -&gt; Result&lt;(), Box&lt;dyn std::error::Error + Send + Sync&gt;&gt;
<span class="boring">}</span></code></pre></pre>
<p>Starts a gRPC server with default configuration on the specified port.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>port</code>: Port number to bind the gRPC server to</li>
</ul>
<p><strong>Returns:</strong> <code>Result&lt;(), Error&gt;</code> indicating server startup success</p>
<p><strong>Example:</strong></p>
<pre><pre class="playground"><code class="language-rust">use mockforge_grpc::start;

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error + Send + Sync&gt;&gt; {
    start(50051).await?;
    Ok(())
}</code></pre></pre>
<h4 id="start_with_config"><a class="header" href="#start_with_config"><code>start_with_config</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub async fn start_with_config(
    port: u16,
    latency_profile: Option&lt;LatencyProfile&gt;,
    config: DynamicGrpcConfig,
) -&gt; Result&lt;(), Box&lt;dyn std::error::Error + Send + Sync&gt;&gt;
<span class="boring">}</span></code></pre></pre>
<p>Starts a gRPC server with custom configuration and optional latency simulation.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>port</code>: Port number to bind the gRPC server to</li>
<li><code>latency_profile</code>: Optional latency injection profile</li>
<li><code>config</code>: Dynamic gRPC configuration</li>
</ul>
<p><strong>Returns:</strong> <code>Result&lt;(), Error&gt;</code> indicating server startup success</p>
<p><strong>Example:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_grpc::{start_with_config, DynamicGrpcConfig};
use mockforge_core::LatencyProfile;

let config = DynamicGrpcConfig {
    proto_dir: "./proto".to_string(),
    enable_reflection: true,
    ..Default::default()
};

start_with_config(50051, Some(LatencyProfile::normal()), config).await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="configuration-types"><a class="header" href="#configuration-types">Configuration Types</a></h3>
<h4 id="dynamicgrpcconfig-1"><a class="header" href="#dynamicgrpcconfig-1"><code>DynamicGrpcConfig</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct DynamicGrpcConfig {
    pub proto_dir: String,
    pub enable_reflection: bool,
    pub excluded_services: Vec&lt;String&gt;,
    pub http_bridge: Option&lt;HttpBridgeConfig&gt;,
}
<span class="boring">}</span></code></pre></pre>
<p>Configuration for dynamic gRPC service discovery.</p>
<p><strong>Fields:</strong></p>
<ul>
<li><code>proto_dir</code>: Directory containing <code>.proto</code> files (default: ‚Äúproto‚Äù)</li>
<li><code>enable_reflection</code>: Whether to enable gRPC reflection (default: false)</li>
<li><code>excluded_services</code>: List of services to exclude from discovery</li>
<li><code>http_bridge</code>: Optional HTTP bridge configuration</li>
</ul>
<p><strong>Methods:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl DynamicGrpcConfig {
    pub fn default() -&gt; Self
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Example:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let config = DynamicGrpcConfig {
    proto_dir: "./my-protos".to_string(),
    enable_reflection: true,
    excluded_services: vec!["HealthService".to_string()],
    http_bridge: Some(HttpBridgeConfig {
        enabled: true,
        port: 8080,
        generate_openapi: true,
    }),
};
<span class="boring">}</span></code></pre></pre>
<h4 id="httpbridgeconfig"><a class="header" href="#httpbridgeconfig"><code>HttpBridgeConfig</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct HttpBridgeConfig {
    pub enabled: bool,
    pub port: u16,
    pub generate_openapi: bool,
    pub cors_enabled: bool,
}
<span class="boring">}</span></code></pre></pre>
<p>Configuration for HTTP bridge functionality.</p>
<p><strong>Fields:</strong></p>
<ul>
<li><code>enabled</code>: Whether HTTP bridge is enabled (default: true)</li>
<li><code>port</code>: HTTP server port (default: 8080)</li>
<li><code>generate_openapi</code>: Whether to generate OpenAPI specs (default: true)</li>
<li><code>cors_enabled</code>: Whether CORS is enabled (default: false)</li>
</ul>
<p><strong>Methods:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl HttpBridgeConfig {
    pub fn default() -&gt; Self
}
<span class="boring">}</span></code></pre></pre>
<h3 id="service-registry-1"><a class="header" href="#service-registry-1">Service Registry</a></h3>
<h4 id="serviceregistry"><a class="header" href="#serviceregistry"><code>ServiceRegistry</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct ServiceRegistry { /* fields omitted */ }
<span class="boring">}</span></code></pre></pre>
<p>Registry containing discovered gRPC services.</p>
<p><strong>Methods:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl ServiceRegistry {
    pub fn new() -&gt; Self
    pub fn with_descriptor_pool(descriptor_pool: DescriptorPool) -&gt; Self
    pub fn descriptor_pool(&amp;self) -&gt; &amp;DescriptorPool
    pub fn register(&amp;mut self, name: String, service: DynamicGrpcService)
    pub fn get(&amp;self, name: &amp;str) -&gt; Option&lt;&amp;Arc&lt;DynamicGrpcService&gt;&gt;
    pub fn service_names(&amp;self) -&gt; Vec&lt;String&gt;
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Example:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_grpc::ServiceRegistry;

let mut registry = ServiceRegistry::new();
registry.register("MyService".to_string(), dynamic_service);
println!("Registered services: {:?}", registry.service_names());
<span class="boring">}</span></code></pre></pre>
<h3 id="dynamic-service-types"><a class="header" href="#dynamic-service-types">Dynamic Service Types</a></h3>
<h4 id="dynamicgrpcservice"><a class="header" href="#dynamicgrpcservice"><code>DynamicGrpcService</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct DynamicGrpcService { /* fields omitted */ }
<span class="boring">}</span></code></pre></pre>
<p>Dynamically generated gRPC service implementation.</p>
<p><strong>Methods:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl DynamicGrpcService {
    pub fn new(
        proto_service: ProtoService,
        config: Option&lt;ServiceConfig&gt;,
    ) -&gt; Self
}
<span class="boring">}</span></code></pre></pre>
<h4 id="protoservice"><a class="header" href="#protoservice"><code>ProtoService</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct ProtoService {
    pub name: String,
    pub methods: HashMap&lt;String, ProtoMethod&gt;,
    pub package: String,
}
<span class="boring">}</span></code></pre></pre>
<p>Parsed protobuf service definition.</p>
<p><strong>Fields:</strong></p>
<ul>
<li><code>name</code>: Service name</li>
<li><code>methods</code>: Map of method names to method definitions</li>
<li><code>package</code>: Protobuf package name</li>
</ul>
<h4 id="protomethod"><a class="header" href="#protomethod"><code>ProtoMethod</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct ProtoMethod {
    pub name: String,
    pub input_type: String,
    pub output_type: String,
    pub is_client_streaming: bool,
    pub is_server_streaming: bool,
}
<span class="boring">}</span></code></pre></pre>
<p>Parsed protobuf method definition.</p>
<p><strong>Fields:</strong></p>
<ul>
<li><code>name</code>: Method name</li>
<li><code>input_type</code>: Input message type name</li>
<li><code>output_type</code>: Output message type name</li>
<li><code>is_client_streaming</code>: Whether method accepts client streaming</li>
<li><code>is_server_streaming</code>: Whether method returns server streaming</li>
</ul>
<h3 id="mock-response-types"><a class="header" href="#mock-response-types">Mock Response Types</a></h3>
<h4 id="mockresponse-1"><a class="header" href="#mockresponse-1"><code>MockResponse</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub enum MockResponse {
    Unary(Value),
    ServerStream(Vec&lt;Value&gt;),
    ClientStream(Value),
    BidiStream(Vec&lt;Value&gt;),
}
<span class="boring">}</span></code></pre></pre>
<p>Mock response types for different gRPC method patterns.</p>
<p><strong>Variants:</strong></p>
<ul>
<li><code>Unary(Value)</code>: Single request-response</li>
<li><code>ServerStream(Vec&lt;Value&gt;)</code>: Server streaming response</li>
<li><code>ClientStream(Value)</code>: Client streaming response</li>
<li><code>BidiStream(Vec&lt;Value&gt;)</code>: Bidirectional streaming</li>
</ul>
<h3 id="reflection-types"><a class="header" href="#reflection-types">Reflection Types</a></h3>
<h4 id="mockreflectionproxy"><a class="header" href="#mockreflectionproxy"><code>MockReflectionProxy</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct MockReflectionProxy { /* fields omitted */ }
<span class="boring">}</span></code></pre></pre>
<p>Proxy for gRPC reflection protocol.</p>
<p><strong>Methods:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl MockReflectionProxy {
    pub async fn new(
        config: ProxyConfig,
        registry: Arc&lt;ServiceRegistry&gt;,
    ) -&gt; Result&lt;Self&gt;
}
<span class="boring">}</span></code></pre></pre>
<h4 id="reflectionproxy"><a class="header" href="#reflectionproxy"><code>ReflectionProxy</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub trait ReflectionProxy {
    fn list_services(&amp;self) -&gt; Vec&lt;String&gt;;
    fn get_service_descriptor(&amp;self, service_name: &amp;str) -&gt; Option&lt;&amp;prost_reflect::ServiceDescriptor&gt;;
    fn get_method_descriptor(&amp;self, service_name: &amp;str, method_name: &amp;str) -&gt; Option&lt;&amp;prost_reflect::MethodDescriptor&gt;;
}
<span class="boring">}</span></code></pre></pre>
<p>Trait for gRPC reflection functionality.</p>
<h4 id="proxyconfig"><a class="header" href="#proxyconfig"><code>ProxyConfig</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct ProxyConfig {
    pub max_message_size: usize,
    pub connection_timeout: Duration,
    pub request_timeout: Duration,
}
<span class="boring">}</span></code></pre></pre>
<p>Configuration for reflection proxy.</p>
<p><strong>Fields:</strong></p>
<ul>
<li><code>max_message_size</code>: Maximum message size in bytes (default: 4MB)</li>
<li><code>connection_timeout</code>: Connection timeout duration</li>
<li><code>request_timeout</code>: Request timeout duration</li>
</ul>
<h3 id="proto-parser-1"><a class="header" href="#proto-parser-1">Proto Parser</a></h3>
<h4 id="protoparser"><a class="header" href="#protoparser"><code>ProtoParser</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct ProtoParser { /* fields omitted */ }
<span class="boring">}</span></code></pre></pre>
<p>Parser for protobuf files.</p>
<p><strong>Methods:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl ProtoParser {
    pub fn new() -&gt; Self
    pub async fn parse_directory(&amp;mut self, dir: &amp;str) -&gt; Result&lt;()&gt;
    pub fn services(&amp;self) -&gt; &amp;HashMap&lt;String, ProtoService&gt;
    pub fn into_pool(self) -&gt; DescriptorPool
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Example:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_grpc::dynamic::proto_parser::ProtoParser;

let mut parser = ProtoParser::new();
parser.parse_directory("./proto").await?;
let services = parser.services();
println!("Found {} services", services.len());
<span class="boring">}</span></code></pre></pre>
<h3 id="discovery-functions"><a class="header" href="#discovery-functions">Discovery Functions</a></h3>
<h4 id="discover_services"><a class="header" href="#discover_services"><code>discover_services</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub async fn discover_services(
    config: &amp;DynamicGrpcConfig,
) -&gt; Result&lt;ServiceRegistry, Box&lt;dyn std::error::Error + Send + Sync&gt;&gt;
<span class="boring">}</span></code></pre></pre>
<p>Discovers and registers gRPC services from proto files.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>config</code>: Discovery configuration</li>
</ul>
<p><strong>Returns:</strong> <code>Result&lt;ServiceRegistry, Error&gt;</code> with discovered services</p>
<p><strong>Example:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_grpc::{discover_services, DynamicGrpcConfig};

let config = DynamicGrpcConfig {
    proto_dir: "./proto".to_string(),
    ..Default::default()
};

let registry = discover_services(&amp;config).await?;
println!("Discovered services: {:?}", registry.service_names());
<span class="boring">}</span></code></pre></pre>
<h3 id="generated-types"><a class="header" href="#generated-types">Generated Types</a></h3>
<h4 id="greeter-service"><a class="header" href="#greeter-service"><code>Greeter</code> Service</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub mod generated {
    pub mod greeter_server {
        pub trait Greeter: Send + Sync + 'static {
            type SayHelloStreamStream: Stream&lt;Item = Result&lt;HelloReply, Status&gt;&gt; + Send + 'static;

            async fn say_hello(
                &amp;self,
                request: Request&lt;HelloRequest&gt;,
            ) -&gt; Result&lt;Response&lt;HelloReply&gt;, Status&gt;;

            async fn say_hello_stream(
                &amp;self,
                request: Request&lt;HelloRequest&gt;,
            ) -&gt; Result&lt;Response&lt;Self::SayHelloStreamStream&gt;, Status&gt;;

            async fn say_hello_client_stream(
                &amp;self,
                request: Request&lt;Streaming&lt;HelloRequest&gt;&gt;,
            ) -&gt; Result&lt;Response&lt;HelloReply&gt;, Status&gt;;

            async fn chat(
                &amp;self,
                request: Request&lt;Streaming&lt;HelloRequest&gt;&gt;,
            ) -&gt; Result&lt;Response&lt;Self::ChatStream&gt;, Status&gt;;
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<p>Generated gRPC service trait with all streaming patterns.</p>
<h3 id="message-types"><a class="header" href="#message-types">Message Types</a></h3>
<h4 id="hellorequest"><a class="header" href="#hellorequest"><code>HelloRequest</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct HelloRequest {
    pub name: String,
}
<span class="boring">}</span></code></pre></pre>
<p>Request message for greeting service.</p>
<p><strong>Fields:</strong></p>
<ul>
<li><code>name</code>: Name to greet</li>
</ul>
<h4 id="helloreply"><a class="header" href="#helloreply"><code>HelloReply</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct HelloReply {
    pub message: String,
    pub metadata: Option&lt;HashMap&lt;String, String&gt;&gt;,
    pub items: Vec&lt;String&gt;,
}
<span class="boring">}</span></code></pre></pre>
<p>Response message for greeting service.</p>
<p><strong>Fields:</strong></p>
<ul>
<li><code>message</code>: Greeting message</li>
<li><code>metadata</code>: Optional metadata map</li>
<li><code>items</code>: Optional list of items</li>
</ul>
<h3 id="error-handling-9"><a class="header" href="#error-handling-9">Error Handling</a></h3>
<p>All functions return <code>Result&lt;T, Box&lt;dyn std::error::Error + Send + Sync&gt;&gt;</code>. Common errors include:</p>
<ul>
<li>File I/O errors (proto file reading)</li>
<li>Protobuf parsing errors</li>
<li>Server binding errors</li>
<li>Reflection setup errors</li>
<li>HTTP bridge configuration errors</li>
</ul>
<h3 id="constants-1"><a class="header" href="#constants-1">Constants</a></h3>
<ul>
<li><code>DEFAULT_MAX_MESSAGE_SIZE</code>: Default maximum message size (4MB)</li>
</ul>
<h3 id="feature-flags-2"><a class="header" href="#feature-flags-2">Feature Flags</a></h3>
<ul>
<li><code>data-faker</code>: Enables advanced data synthesis features</li>
</ul>
<h2 id="examples-17"><a class="header" href="#examples-17">Examples</a></h2>
<h3 id="basic-grpc-server-3"><a class="header" href="#basic-grpc-server-3">Basic gRPC Server</a></h3>
<pre><pre class="playground"><code class="language-rust">use mockforge_grpc::start;

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error + Send + Sync&gt;&gt; {
    // Starts server on port 50051 with default config
    // Automatically discovers services from ./proto directory
    start(50051).await?;
    Ok(())
}</code></pre></pre>
<h3 id="server-with-reflection"><a class="header" href="#server-with-reflection">Server with Reflection</a></h3>
<pre><pre class="playground"><code class="language-rust">use mockforge_grpc::{start_with_config, DynamicGrpcConfig};

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error + Send + Sync&gt;&gt; {
    let config = DynamicGrpcConfig {
        proto_dir: "./proto".to_string(),
        enable_reflection: true,  // Enable gRPC reflection
        ..Default::default()
    };

    start_with_config(50051, None, config).await?;

    // Now you can use grpcurl:
    // grpcurl -plaintext localhost:50051 list
    // grpcurl -plaintext localhost:50051 describe MyService
    Ok(())
}</code></pre></pre>
<h3 id="server-with-http-bridge"><a class="header" href="#server-with-http-bridge">Server with HTTP Bridge</a></h3>
<pre><pre class="playground"><code class="language-rust">use mockforge_grpc::{start_with_config, DynamicGrpcConfig};
use mockforge_grpc::dynamic::http_bridge::HttpBridgeConfig;

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error + Send + Sync&gt;&gt; {
    let config = DynamicGrpcConfig {
        proto_dir: "./proto".to_string(),
        http_bridge: Some(HttpBridgeConfig {
            enabled: true,
            port: 8080,
            generate_openapi: true,
        }),
        ..Default::default()
    };

    start_with_config(50051, None, config).await?;

    // gRPC available on localhost:50051
    // REST API available on localhost:8080
    // OpenAPI docs at http://localhost:8080/api/docs
    Ok(())
}</code></pre></pre>
<h3 id="manual-service-discovery"><a class="header" href="#manual-service-discovery">Manual Service Discovery</a></h3>
<pre><pre class="playground"><code class="language-rust">use mockforge_grpc::{discover_services, DynamicGrpcConfig};

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error + Send + Sync&gt;&gt; {
    let config = DynamicGrpcConfig {
        proto_dir: "./proto".to_string(),
        excluded_services: vec!["HealthService".to_string()],
        ..Default::default()
    };

    let registry = discover_services(&amp;config).await?;

    println!("Discovered services:");
    for service_name in registry.service_names() {
        println!("  - {}", service_name);
    }

    // Access service descriptors
    if let Some(descriptor) = registry.descriptor_pool().get_service_by_name("MyService") {
        println!("Service methods:");
        for method in descriptor.methods() {
            println!("  - {}", method.name());
        }
    }

    Ok(())
}</code></pre></pre>
<h3 id="custom-service-implementation-1"><a class="header" href="#custom-service-implementation-1">Custom Service Implementation</a></h3>
<pre><pre class="playground"><code class="language-rust">use mockforge_grpc::dynamic::service_generator::DynamicGrpcService;
use mockforge_grpc::dynamic::proto_parser::{ProtoParser, ProtoService};

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error + Send + Sync&gt;&gt; {
    // Parse proto files
    let mut parser = ProtoParser::new();
    parser.parse_directory("./proto").await?;

    // Get a specific service
    if let Some(proto_service) = parser.services().get("MyService") {
        // Create dynamic service
        let dynamic_service = DynamicGrpcService::new(proto_service.clone(), None);

        // The service will automatically handle all RPC methods
        // with mock responses based on the protobuf definitions
    }

    Ok(())
}</code></pre></pre>
<h3 id="using-grpc-reflection"><a class="header" href="#using-grpc-reflection">Using gRPC Reflection</a></h3>
<pre><pre class="playground"><code class="language-rust">use mockforge_grpc::reflection::{MockReflectionProxy, ProxyConfig};
use std::sync::Arc;

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error + Send + Sync&gt;&gt; {
    let config = DynamicGrpcConfig {
        proto_dir: "./proto".to_string(),
        enable_reflection: true,
        ..Default::default()
    };

    let registry = discover_services(&amp;config).await?;
    let registry_arc = Arc::new(registry);

    let proxy_config = ProxyConfig::default();
    let reflection_proxy = MockReflectionProxy::new(proxy_config, registry_arc).await?;

    // The reflection proxy enables:
    // - Service listing: reflection_proxy.list_services()
    // - Service descriptors: reflection_proxy.get_service_descriptor("MyService")
    // - Method descriptors: reflection_proxy.get_method_descriptor("MyService", "MyMethod")

    Ok(())
}</code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="websocket-module"><a class="header" href="#websocket-module">WebSocket Module</a></h1>
<p>The <code>mockforge_ws</code> crate provides comprehensive WebSocket mocking with replay, proxy, and AI-powered event generation capabilities.</p>
<h2 id="modules-2"><a class="header" href="#modules-2">Modules</a></h2>
<h3 id="core-functions-2"><a class="header" href="#core-functions-2">Core Functions</a></h3>
<h4 id="router"><a class="header" href="#router"><code>router</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn router() -&gt; Router
<span class="boring">}</span></code></pre></pre>
<p>Creates a basic WebSocket router with echo functionality.</p>
<p><strong>Returns:</strong> Axum <code>Router</code> configured for WebSocket connections</p>
<p><strong>Example:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_ws::router;

let app = router();
// Routes WebSocket connections to /ws
<span class="boring">}</span></code></pre></pre>
<h4 id="router_with_latency"><a class="header" href="#router_with_latency"><code>router_with_latency</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn router_with_latency(latency_injector: LatencyInjector) -&gt; Router
<span class="boring">}</span></code></pre></pre>
<p>Creates a WebSocket router with latency simulation.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>latency_injector</code>: Latency injection configuration</li>
</ul>
<p><strong>Returns:</strong> Axum <code>Router</code> with latency simulation</p>
<p><strong>Example:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_ws::router_with_latency;
use mockforge_core::{LatencyProfile, latency::LatencyInjector};

let latency = LatencyProfile::slow(); // 300-800ms
let injector = LatencyInjector::new(latency, Default::default());
let app = router_with_latency(injector);
<span class="boring">}</span></code></pre></pre>
<h4 id="router_with_proxy"><a class="header" href="#router_with_proxy"><code>router_with_proxy</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn router_with_proxy(proxy_handler: WsProxyHandler) -&gt; Router
<span class="boring">}</span></code></pre></pre>
<p>Creates a WebSocket router with proxy capabilities.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>proxy_handler</code>: WebSocket proxy handler configuration</li>
</ul>
<p><strong>Returns:</strong> Axum <code>Router</code> with proxy functionality</p>
<p><strong>Example:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_ws::router_with_proxy;
use mockforge_core::{WsProxyConfig, WsProxyHandler};

let proxy_config = WsProxyConfig {
    upstream_url: "wss://api.example.com/ws".to_string(),
    should_proxy: true,
    ..Default::default()
};
let proxy = WsProxyHandler::new(proxy_config);
let app = router_with_proxy(proxy);
<span class="boring">}</span></code></pre></pre>
<h3 id="server-functions-1"><a class="header" href="#server-functions-1">Server Functions</a></h3>
<h4 id="start_with_latency"><a class="header" href="#start_with_latency"><code>start_with_latency</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub async fn start_with_latency(
    port: u16,
    latency: Option&lt;LatencyProfile&gt;,
) -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt;
<span class="boring">}</span></code></pre></pre>
<p>Starts a WebSocket server with optional latency simulation.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>port</code>: Port number to bind to</li>
<li><code>latency</code>: Optional latency profile</li>
</ul>
<p><strong>Returns:</strong> <code>Result&lt;(), Error&gt;</code> indicating server startup success</p>
<p><strong>Example:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_ws::start_with_latency;
use mockforge_core::LatencyProfile;

start_with_latency(3001, Some(LatencyProfile::normal())).await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="ai-event-generation-1"><a class="header" href="#ai-event-generation-1">AI Event Generation</a></h3>
<h4 id="aieventgenerator"><a class="header" href="#aieventgenerator"><code>AiEventGenerator</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct AiEventGenerator { /* fields omitted */ }
<span class="boring">}</span></code></pre></pre>
<p>Generator for AI-powered WebSocket event streams.</p>
<p><strong>Methods:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl AiEventGenerator {
    pub fn new(config: ReplayAugmentationConfig) -&gt; Result&lt;Self&gt;

    pub async fn stream_events(
        &amp;self,
        socket: WebSocket,
        max_events: Option&lt;usize&gt;,
    )

    pub async fn stream_events_with_rate(
        &amp;self,
        socket: WebSocket,
        max_events: Option&lt;usize&gt;,
        events_per_second: f64,
    )
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Example:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_ws::AiEventGenerator;
use mockforge_data::ReplayAugmentationConfig;

let config = ReplayAugmentationConfig {
    narrative: "Simulate stock market trading".to_string(),
    ..Default::default()
};

let generator = AiEventGenerator::new(config)?;
generator.stream_events(socket, Some(100)).await?;
<span class="boring">}</span></code></pre></pre>
<h4 id="websocketaiconfig"><a class="header" href="#websocketaiconfig"><code>WebSocketAiConfig</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct WebSocketAiConfig {
    pub enabled: bool,
    pub replay: Option&lt;ReplayAugmentationConfig&gt;,
    pub max_events: Option&lt;usize&gt;,
}
<span class="boring">}</span></code></pre></pre>
<p>Configuration for WebSocket AI features.</p>
<p><strong>Fields:</strong></p>
<ul>
<li><code>enabled</code>: Whether AI features are enabled</li>
<li><code>replay</code>: Optional replay augmentation configuration</li>
<li><code>max_events</code>: Maximum number of events to generate</li>
</ul>
<h3 id="tracing-functions"><a class="header" href="#tracing-functions">Tracing Functions</a></h3>
<h4 id="create_ws_connection_span"><a class="header" href="#create_ws_connection_span"><code>create_ws_connection_span</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn create_ws_connection_span(request: &amp;Request) -&gt; Span
<span class="boring">}</span></code></pre></pre>
<p>Creates an OpenTelemetry span for WebSocket connection establishment.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>request</code>: HTTP request that initiated the WebSocket connection</li>
</ul>
<p><strong>Returns:</strong> OpenTelemetry <code>Span</code> for connection tracking</p>
<h4 id="create_ws_message_span"><a class="header" href="#create_ws_message_span"><code>create_ws_message_span</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn create_ws_message_span(message_size: usize, direction: &amp;str) -&gt; Span
<span class="boring">}</span></code></pre></pre>
<p>Creates an OpenTelemetry span for WebSocket message processing.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>message_size</code>: Size of the message in bytes</li>
<li><code>direction</code>: Message direction (‚Äúin‚Äù or ‚Äúout‚Äù)</li>
</ul>
<p><strong>Returns:</strong> OpenTelemetry <code>Span</code> for message tracking</p>
<h4 id="record_ws_connection_success"><a class="header" href="#record_ws_connection_success"><code>record_ws_connection_success</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn record_ws_connection_success(span: &amp;Span)
<span class="boring">}</span></code></pre></pre>
<p>Records successful WebSocket connection establishment.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>span</code>: Connection span to record success on</li>
</ul>
<h4 id="record_ws_message_success"><a class="header" href="#record_ws_message_success"><code>record_ws_message_success</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn record_ws_message_success(span: &amp;Span, message_size: usize)
<span class="boring">}</span></code></pre></pre>
<p>Records successful WebSocket message processing.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>span</code>: Message span to record success on</li>
<li><code>message_size</code>: Size of processed message</li>
</ul>
<h4 id="record_ws_error"><a class="header" href="#record_ws_error"><code>record_ws_error</code></a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn record_ws_error(span: &amp;Span, error: &amp;str)
<span class="boring">}</span></code></pre></pre>
<p>Records WebSocket error.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>span</code>: Span to record error on</li>
<li><code>error</code>: Error description</li>
</ul>
<h3 id="template-expansion-1"><a class="header" href="#template-expansion-1">Template Expansion</a></h3>
<h4 id="token-expansion-functions"><a class="header" href="#token-expansion-functions">Token Expansion Functions</a></h4>
<p>The crate includes internal template expansion functionality for replay files:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn expand_tokens(text: &amp;str) -&gt; String
<span class="boring">}</span></code></pre></pre>
<p>Expands template tokens in replay file content.</p>
<p><strong>Supported Tokens:</strong></p>
<ul>
<li><code>{{uuid}}</code>: Generates random UUID</li>
<li><code>{{now}}</code>: Current timestamp in RFC3339 format</li>
<li><code>{{now+1m}}</code>: Timestamp 1 minute from now</li>
<li><code>{{now+1h}}</code>: Timestamp 1 hour from now</li>
<li><code>{{randInt min max}}</code>: Random integer between min and max</li>
</ul>
<p><strong>Example:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let text = "Hello {{uuid}} at {{now}}";
let expanded = expand_tokens(text);
// Result: "Hello 550e8400-e29b-41d4-a716-446655440000 at 2024-01-15T10:30:00Z"
<span class="boring">}</span></code></pre></pre>
<h3 id="internal-types"><a class="header" href="#internal-types">Internal Types</a></h3>
<h4 id="websocket-message-handling"><a class="header" href="#websocket-message-handling">WebSocket Message Handling</a></h4>
<p>The crate uses Axum‚Äôs WebSocket types internally:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use axum::extract::ws::{Message, WebSocket, WebSocketUpgrade};
<span class="boring">}</span></code></pre></pre>
<p><strong>Message Types:</strong></p>
<ul>
<li><code>Message::Text(String)</code>: Text message</li>
<li><code>Message::Binary(Vec&lt;u8&gt;)</code>: Binary message</li>
<li><code>Message::Close(Option&lt;CloseFrame&gt;)</code>: Connection close</li>
<li><code>Message::Ping(Vec&lt;u8&gt;)</code>: Ping message</li>
<li><code>Message::Pong(Vec&lt;u8&gt;)</code>: Pong message</li>
</ul>
<h3 id="error-handling-10"><a class="header" href="#error-handling-10">Error Handling</a></h3>
<p>All public functions return <code>Result&lt;T, Box&lt;dyn std::error::Error&gt;&gt;</code>. Common errors include:</p>
<ul>
<li>Server binding errors</li>
<li>WebSocket protocol errors</li>
<li>File I/O errors (for replay files)</li>
<li>AI service errors</li>
<li>Template expansion errors</li>
</ul>
<h3 id="constants-2"><a class="header" href="#constants-2">Constants</a></h3>
<ul>
<li>Default WebSocket path: <code>/ws</code></li>
<li>Default server port: 3001</li>
</ul>
<h3 id="feature-flags-3"><a class="header" href="#feature-flags-3">Feature Flags</a></h3>
<ul>
<li><code>data-faker</code>: Enables rich data generation features</li>
</ul>
<h2 id="examples-18"><a class="header" href="#examples-18">Examples</a></h2>
<h3 id="basic-websocket-server-2"><a class="header" href="#basic-websocket-server-2">Basic WebSocket Server</a></h3>
<pre><pre class="playground"><code class="language-rust">use mockforge_ws::router;

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    let app = router();

    let addr = "0.0.0.0:3001".parse()?;
    let listener = tokio::net::TcpListener::bind(addr).await?;
    axum::serve(listener, app).await?;
    Ok(())
}</code></pre></pre>
<h3 id="server-with-latency-simulation"><a class="header" href="#server-with-latency-simulation">Server with Latency Simulation</a></h3>
<pre><pre class="playground"><code class="language-rust">use mockforge_ws::start_with_latency;
use mockforge_core::LatencyProfile;

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    // Add 50-200ms latency to all messages
    start_with_latency(3001, Some(LatencyProfile::normal())).await?;
    Ok(())
}</code></pre></pre>
<h3 id="proxy-server"><a class="header" href="#proxy-server">Proxy Server</a></h3>
<pre><pre class="playground"><code class="language-rust">use mockforge_ws::router_with_proxy;
use mockforge_core::{WsProxyConfig, WsProxyHandler};

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    let proxy_config = WsProxyConfig {
        upstream_url: "wss://echo.websocket.org".to_string(),
        should_proxy: true,
        message_transform: None,
    };

    let proxy = WsProxyHandler::new(proxy_config);
    let app = router_with_proxy(proxy);

    let addr = "0.0.0.0:3001".parse()?;
    let listener = tokio::net::TcpListener::bind(addr).await?;
    axum::serve(listener, app).await?;
    Ok(())
}</code></pre></pre>
<h3 id="replay-mode-3"><a class="header" href="#replay-mode-3">Replay Mode</a></h3>
<pre><pre class="playground"><code class="language-rust">use mockforge_ws::router;

// Set replay file via environment variable
std::env::set_var("MOCKFORGE_WS_REPLAY_FILE", "./replay.jsonl");

// Enable template expansion
std::env::set_var("MOCKFORGE_RESPONSE_TEMPLATE_EXPAND", "1");

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    let app = router();

    let addr = "0.0.0.0:3001".parse()?;
    let listener = tokio::net::TcpListener::bind(addr).await?;
    axum::serve(listener, app).await?;
    Ok(())
}</code></pre></pre>
<h3 id="ai-event-generation-2"><a class="header" href="#ai-event-generation-2">AI Event Generation</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_ws::AiEventGenerator;
use mockforge_data::ReplayAugmentationConfig;
use axum::extract::ws::WebSocket;

async fn handle_ai_events(mut socket: WebSocket) {
    let config = ReplayAugmentationConfig {
        narrative: "Simulate a live chat conversation with multiple users".to_string(),
        event_count: 50,
        provider: "openai".to_string(),
        ..Default::default()
    };

    let generator = AiEventGenerator::new(config)?;
    generator.stream_events_with_rate(socket, None, 2.0).await?; // 2 events/sec
}
<span class="boring">}</span></code></pre></pre>
<h3 id="custom-websocket-handler"><a class="header" href="#custom-websocket-handler">Custom WebSocket Handler</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use axum::{
    extract::ws::{WebSocket, WebSocketUpgrade},
    response::IntoResponse,
};

async fn custom_ws_handler(ws: WebSocketUpgrade) -&gt; impl IntoResponse {
    ws.on_upgrade(|socket| handle_custom_socket(socket))
}

async fn handle_custom_socket(mut socket: WebSocket) {
    while let Some(msg) = socket.recv().await {
        match msg {
            Ok(axum::extract::ws::Message::Text(text)) =&gt; {
                // Process text message
                let response = format!("Echo: {}", text);
                if socket.send(axum::extract::ws::Message::Text(response.into())).await.is_err() {
                    break;
                }
            }
            Ok(axum::extract::ws::Message::Close(_)) =&gt; {
                break;
            }
            Err(e) =&gt; {
                eprintln!("WebSocket error: {}", e);
                break;
            }
            _ =&gt; {}
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="tracing-integration-3"><a class="header" href="#tracing-integration-3">Tracing Integration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_ws::{create_ws_connection_span, record_ws_connection_success};
use axum::extract::ws::WebSocketUpgrade;

async fn traced_ws_handler(
    ws: WebSocketUpgrade,
    request: axum::http::Request&lt;axum::body::Body&gt;,
) -&gt; impl IntoResponse {
    // Create connection span
    let span = create_ws_connection_span(&amp;request);

    // Record successful connection
    record_ws_connection_success(&amp;span);

    ws.on_upgrade(|socket| handle_socket_with_tracing(socket, span))
}

async fn handle_socket_with_tracing(mut socket: WebSocket, connection_span: tracing::Span) {
    let _guard = connection_span.enter();

    while let Some(msg) = socket.recv().await {
        match msg {
            Ok(axum::extract::ws::Message::Text(text)) =&gt; {
                let message_span = create_ws_message_span(text.len(), "in");
                let _msg_guard = message_span.enter();

                // Process message...

                record_ws_message_success(&amp;message_span, text.len());
            }
            // ... other message types
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="replay-file-format-1"><a class="header" href="#replay-file-format-1">Replay File Format</a></h3>
<p>Replay files use JSON Lines format with the following structure:</p>
<pre><code class="language-json">{"ts":0,"dir":"out","text":"HELLO {{uuid}}","waitFor":"^CLIENT_READY$"}
{"ts":10,"dir":"out","text":"{\"type\":\"welcome\",\"sessionId\":\"{{uuid}}\"}"}
{"ts":20,"dir":"out","text":"{\"data\":{{randInt 1 100}}}","waitFor":"^ACK$"}
</code></pre>
<p><strong>Fields:</strong></p>
<ul>
<li><code>ts</code>: Timestamp offset in milliseconds</li>
<li><code>dir</code>: Direction (‚Äúin‚Äù for received, ‚Äúout‚Äù for sent)</li>
<li><code>text</code>: Message content (supports template expansion)</li>
<li><code>waitFor</code>: Optional regex pattern to wait for before sending</li>
</ul>
<h3 id="environment-variables-19"><a class="header" href="#environment-variables-19">Environment Variables</a></h3>
<ul>
<li><code>MOCKFORGE_WS_REPLAY_FILE</code>: Path to replay file for replay mode</li>
<li><code>MOCKFORGE_RESPONSE_TEMPLATE_EXPAND</code>: Enable template expansion (‚Äú1‚Äù or ‚Äútrue‚Äù)</li>
</ul>
<h3 id="integration-with-mockforge-core"><a class="header" href="#integration-with-mockforge-core">Integration with MockForge Core</a></h3>
<p>The WebSocket crate integrates with core MockForge functionality:</p>
<ul>
<li><strong>Latency Injection</strong>: Uses <code>LatencyInjector</code> for network simulation</li>
<li><strong>Proxy Handler</strong>: Uses <code>WsProxyHandler</code> for upstream forwarding</li>
<li><strong>Metrics</strong>: Integrates with global metrics registry</li>
<li><strong>Tracing</strong>: Uses OpenTelemetry for distributed tracing</li>
<li><strong>Data Generation</strong>: Supports AI-powered content generation</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="development-setup-2"><a class="header" href="#development-setup-2">Development Setup</a></h1>
<p>This guide helps contributors get started with MockForge development, including environment setup, development workflow, and project structure.</p>
<h2 id="prerequisites-9"><a class="header" href="#prerequisites-9">Prerequisites</a></h2>
<p>Before contributing to MockForge, ensure you have the following installed:</p>
<h3 id="required-tools"><a class="header" href="#required-tools">Required Tools</a></h3>
<ul>
<li><strong>Rust</strong>: Version 1.70.0 or later</li>
<li><strong>Cargo</strong>: Included with Rust</li>
<li><strong>Git</strong>: For version control</li>
<li><strong>C/C++ Compiler</strong>: For native dependencies</li>
<li><strong>Docker</strong>: For containerized development and testing</li>
</ul>
<h3 id="recommended-tools"><a class="header" href="#recommended-tools">Recommended Tools</a></h3>
<ul>
<li><strong>Visual Studio Code</strong> or <strong>IntelliJ/CLion</strong> with Rust plugins</li>
<li><strong>cargo-watch</strong> for automatic rebuilds</li>
<li><strong>cargo-edit</strong> for dependency management</li>
<li><strong>cargo-audit</strong> for security scanning</li>
<li><strong>mdbook</strong> for documentation development</li>
</ul>
<h2 id="environment-setup"><a class="header" href="#environment-setup">Environment Setup</a></h2>
<h3 id="1-install-rust"><a class="header" href="#1-install-rust">1. Install Rust</a></h3>
<pre><code class="language-bash"># Install Rust using rustup
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh

# Add Cargo to PATH
source $HOME/.cargo/env

# Verify installation
rustc --version
cargo --version
</code></pre>
<h3 id="2-clone-the-repository"><a class="header" href="#2-clone-the-repository">2. Clone the Repository</a></h3>
<pre><code class="language-bash"># Clone with SSH (recommended for contributors)
git clone git@github.com:SaaSy-Solutions/mockforge.git

# Or with HTTPS
git clone https://github.com/SaaSy-Solutions/mockforge.git

cd mockforge

# Initialize submodules if any
git submodule update --init --recursive
</code></pre>
<h3 id="3-install-development-tools"><a class="header" href="#3-install-development-tools">3. Install Development Tools</a></h3>
<pre><code class="language-bash"># Install cargo-watch for automatic rebuilds
cargo install cargo-watch

# Install cargo-edit for dependency management
cargo install cargo-edit

# Install cargo-audit for security scanning
cargo install cargo-audit

# Install mdbook for documentation
cargo install mdbook mdbook-linkcheck mdbook-toc

# Install additional development tools
cargo install cargo-tarpaulin cargo-udeps cargo-outdated
</code></pre>
<h3 id="4-verify-setup"><a class="header" href="#4-verify-setup">4. Verify Setup</a></h3>
<pre><code class="language-bash"># Build the project
cargo build

# Run tests
cargo test

# Check code quality
cargo clippy
cargo fmt --check
</code></pre>
<h2 id="development-workflow-6"><a class="header" href="#development-workflow-6">Development Workflow</a></h2>
<h3 id="daily-development"><a class="header" href="#daily-development">Daily Development</a></h3>
<ol>
<li>
<p><strong>Create a feature branch</strong>:</p>
<pre><code class="language-bash">git checkout -b feature/your-feature-name
</code></pre>
</li>
<li>
<p><strong>Make changes</strong> with frequent testing:</p>
<pre><code class="language-bash"># Run tests automatically on changes
cargo watch -x test

# Or build automatically
cargo watch -x build
</code></pre>
</li>
<li>
<p><strong>Follow code quality standards</strong>:</p>
<pre><code class="language-bash"># Format code
cargo fmt

# Lint code
cargo clippy -- -W clippy::pedantic

# Run security audit
cargo audit
</code></pre>
</li>
<li>
<p><strong>Write tests</strong> for new functionality:</p>
<pre><code class="language-bash"># Add unit tests
cargo test --lib

# Add integration tests
cargo test --test integration
</code></pre>
</li>
</ol>
<h3 id="ide-configuration"><a class="header" href="#ide-configuration">IDE Configuration</a></h3>
<h4 id="visual-studio-code"><a class="header" href="#visual-studio-code">Visual Studio Code</a></h4>
<ol>
<li>
<p>Install extensions:</p>
<ul>
<li><code>rust-lang.rust-analyzer</code> - Rust language support</li>
<li><code>ms-vscode.vscode-json</code> - JSON support</li>
<li><code>redhat.vscode-yaml</code> - YAML support</li>
<li><code>ms-vscode.vscode-docker</code> - Docker support</li>
</ul>
</li>
<li>
<p>Recommended settings in <code>.vscode/settings.json</code>:</p>
<pre><code class="language-json">{
  "rust-analyzer.checkOnSave.command": "clippy",
  "rust-analyzer.cargo.allFeatures": true,
  "editor.formatOnSave": true,
  "editor.codeActionsOnSave": {
    "source.fixAll": "explicit"
  }
}
</code></pre>
</li>
</ol>
<h4 id="intellijclion-1"><a class="header" href="#intellijclion-1">IntelliJ/CLion</a></h4>
<ol>
<li>Install Rust plugin from marketplace</li>
<li>Enable external linter (clippy)</li>
<li>Configure code style to match project standards</li>
</ol>
<h3 id="pre-commit-setup"><a class="header" href="#pre-commit-setup">Pre-commit Setup</a></h3>
<p>Install pre-commit hooks to ensure code quality:</p>
<pre><code class="language-bash"># Install pre-commit if not already installed
pip install pre-commit

# Install hooks
pre-commit install

# Run on all files
pre-commit run --all-files
</code></pre>
<h2 id="project-structure-1"><a class="header" href="#project-structure-1">Project Structure</a></h2>
<pre><code>mockforge/
‚îú‚îÄ‚îÄ crates/                    # Rust crates
‚îÇ   ‚îú‚îÄ‚îÄ mockforge-cli/        # Command-line interface
‚îÇ   ‚îú‚îÄ‚îÄ mockforge-core/       # Shared core functionality
‚îÇ   ‚îú‚îÄ‚îÄ mockforge-http/       # HTTP REST API mocking
‚îÇ   ‚îú‚îÄ‚îÄ mockforge-ws/         # WebSocket connection mocking
‚îÇ   ‚îú‚îÄ‚îÄ mockforge-grpc/       # gRPC service mocking
‚îÇ   ‚îú‚îÄ‚îÄ mockforge-data/       # Synthetic data generation
‚îÇ   ‚îî‚îÄ‚îÄ mockforge-ui/         # Web-based admin interface
‚îú‚îÄ‚îÄ docs/                     # Technical documentation
‚îú‚îÄ‚îÄ examples/                 # Usage examples
‚îú‚îÄ‚îÄ book/                     # User documentation (mdBook)
‚îÇ   ‚îî‚îÄ‚îÄ src/
‚îú‚îÄ‚îÄ fixtures/                 # Test fixtures
‚îú‚îÄ‚îÄ scripts/                  # Development scripts
‚îú‚îÄ‚îÄ tools/                    # Development tools
‚îú‚îÄ‚îÄ Cargo.toml               # Workspace configuration
‚îú‚îÄ‚îÄ Cargo.lock               # Dependency lock file
‚îú‚îÄ‚îÄ Makefile                # Development tasks
‚îú‚îÄ‚îÄ docker-compose.yml      # Development environment
‚îî‚îÄ‚îÄ README.md               # Project overview
</code></pre>
<h2 id="development-tasks"><a class="header" href="#development-tasks">Development Tasks</a></h2>
<h3 id="common-make-targets"><a class="header" href="#common-make-targets">Common Make Targets</a></h3>
<pre><code class="language-bash"># Build all crates
make build

# Run tests
make test

# Run integration tests
make test-integration

# Build documentation
make docs

# Serve documentation locally
make docs-serve

# Run linter
make lint

# Format code
make format

# Clean build artifacts
make clean
</code></pre>
<h3 id="custom-development-scripts"><a class="header" href="#custom-development-scripts">Custom Development Scripts</a></h3>
<p>Several development scripts are available in the <code>scripts/</code> directory:</p>
<pre><code class="language-bash"># Update dependencies
./scripts/update-deps.sh

# Generate API documentation
./scripts/gen-docs.sh

# Run performance benchmarks
./scripts/benchmark.sh

# Check for unused dependencies
./scripts/check-deps.sh
</code></pre>
<h2 id="testing-strategy"><a class="header" href="#testing-strategy">Testing Strategy</a></h2>
<h3 id="unit-tests-2"><a class="header" href="#unit-tests-2">Unit Tests</a></h3>
<pre><code class="language-bash"># Run unit tests for all crates
cargo test --lib

# Run unit tests for specific crate
cargo test -p mockforge-core

# Run with coverage
cargo tarpaulin --out Html
</code></pre>
<h3 id="integration-tests-4"><a class="header" href="#integration-tests-4">Integration Tests</a></h3>
<pre><code class="language-bash"># Run integration tests
cargo test --test integration

# Run with verbose output
cargo test --test integration -- --nocapture
</code></pre>
<h3 id="end-to-end-tests"><a class="header" href="#end-to-end-tests">End-to-End Tests</a></h3>
<pre><code class="language-bash"># Run E2E tests (requires Docker)
make test-e2e

# Or run manually
./scripts/test-e2e.sh
</code></pre>
<h2 id="docker-development"><a class="header" href="#docker-development">Docker Development</a></h2>
<h3 id="development-container"><a class="header" href="#development-container">Development Container</a></h3>
<pre><code class="language-bash"># Build development container
docker build -f Dockerfile.dev -t mockforge-dev .

# Run development environment
docker run -it --rm \
  -v $(pwd):/app \
  -p 3000:3000 \
  -p 3001:3001 \
  -p 50051:50051 \
  -p 9080:9080 \
  mockforge-dev
</code></pre>
<h3 id="testing-with-docker"><a class="header" href="#testing-with-docker">Testing with Docker</a></h3>
<pre><code class="language-bash"># Run tests in container
docker run --rm -v $(pwd):/app mockforge-dev cargo test

# Build release binaries
docker run --rm -v $(pwd):/app mockforge-dev cargo build --release
</code></pre>
<h2 id="contributing-workflow"><a class="header" href="#contributing-workflow">Contributing Workflow</a></h2>
<h3 id="1-choose-an-issue"><a class="header" href="#1-choose-an-issue">1. Choose an Issue</a></h3>
<ul>
<li>Check <a href="https://github.com/SaaSy-Solutions/mockforge/issues">GitHub Issues</a> for open tasks</li>
<li>Look for issues labeled <code>good first issue</code> or <code>help wanted</code></li>
<li>Comment on the issue to indicate you‚Äôre working on it</li>
</ul>
<h3 id="2-create-a-branch"><a class="header" href="#2-create-a-branch">2. Create a Branch</a></h3>
<pre><code class="language-bash"># Create feature branch
git checkout -b feature/issue-number-description

# Or create bugfix branch
git checkout -b bugfix/issue-number-description
</code></pre>
<h3 id="3-make-changes"><a class="header" href="#3-make-changes">3. Make Changes</a></h3>
<ul>
<li>Write clear, focused commits</li>
<li>Follow the <a href="contributing/style.html">code style guide</a></li>
<li>Add tests for new functionality</li>
<li>Update documentation as needed</li>
</ul>
<h3 id="4-test-your-changes"><a class="header" href="#4-test-your-changes">4. Test Your Changes</a></h3>
<pre><code class="language-bash"># Run full test suite
make test

# Run integration tests
make test-integration

# Test manually if applicable
cargo run -- serve --spec examples/openapi-demo.json
</code></pre>
<h3 id="5-update-documentation"><a class="header" href="#5-update-documentation">5. Update Documentation</a></h3>
<pre><code class="language-bash"># Update user-facing docs if needed
mdbook build

# Update API docs
cargo doc

# Test documentation links
mdbook test
</code></pre>
<h3 id="6-submit-a-pull-request"><a class="header" href="#6-submit-a-pull-request">6. Submit a Pull Request</a></h3>
<pre><code class="language-bash"># Ensure branch is up to date
git fetch origin
git rebase origin/main

# Push your branch
git push origin feature/your-feature

# Create PR on GitHub with:
# - Clear title and description
# - Reference to issue number
# - Screenshots/videos for UI changes
# - Test results
</code></pre>
<h2 id="getting-help-1"><a class="header" href="#getting-help-1">Getting Help</a></h2>
<h3 id="communication-channels"><a class="header" href="#communication-channels">Communication Channels</a></h3>
<ul>
<li><strong>GitHub Issues</strong>: For bugs, features, and general discussion</li>
<li><strong>GitHub Discussions</strong>: For questions and longer-form discussion</li>
<li><strong>Discord</strong>: <a href="https://discord.gg/2FxXqKpa">Join our community chat</a> - For real-time chat</li>
</ul>
<h3 id="when-to-ask-for-help"><a class="header" href="#when-to-ask-for-help">When to Ask for Help</a></h3>
<ul>
<li>Stuck on a technical problem for more than 2 hours</li>
<li>Unsure about design decisions</li>
<li>Need clarification on requirements</li>
<li>Found a potential security issue</li>
</ul>
<h3 id="code-review-process"><a class="header" href="#code-review-process">Code Review Process</a></h3>
<ul>
<li>All PRs require review from at least one maintainer</li>
<li>CI must pass all checks</li>
<li>Code coverage should not decrease significantly</li>
<li>Documentation must be updated for user-facing changes</li>
</ul>
<p>This setup guide ensures you have everything needed to contribute effectively to MockForge. Happy coding! üöÄ</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="code-style-guide"><a class="header" href="#code-style-guide">Code Style Guide</a></h1>
<p>This guide outlines the coding standards and style guidelines for MockForge development. Consistent code style improves readability, maintainability, and collaboration.</p>
<h2 id="rust-code-style"><a class="header" href="#rust-code-style">Rust Code Style</a></h2>
<p>MockForge follows the official Rust style guidelines with some project-specific conventions.</p>
<h3 id="formatting-1"><a class="header" href="#formatting-1">Formatting</a></h3>
<p>Use <code>rustfmt</code> for automatic code formatting:</p>
<pre><code class="language-bash"># Format all code
cargo fmt

# Check formatting without modifying files
cargo fmt --check
</code></pre>
<h3 id="linting-1"><a class="header" href="#linting-1">Linting</a></h3>
<p>Use <code>clippy</code> for additional code quality checks:</p>
<pre><code class="language-bash"># Run clippy with project settings
cargo clippy

# Run with pedantic mode for stricter checks
cargo clippy -- -W clippy::pedantic
</code></pre>
<h3 id="naming-conventions-1"><a class="header" href="#naming-conventions-1">Naming Conventions</a></h3>
<h4 id="functions-and-variables"><a class="header" href="#functions-and-variables">Functions and Variables</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good: snake_case for functions and variables
fn process_user_data(user_id: i32, data: &amp;str) -&gt; Result&lt;User, Error&gt; {
    let processed_data = validate_and_clean(data)?;
    let user_record = create_user_record(user_id, &amp;processed_data)?;
    Ok(user_record)
}

// Bad: camelCase or PascalCase
fn processUserData(userId: i32, data: &amp;str) -&gt; Result&lt;User, Error&gt; {
    let ProcessedData = validate_and_clean(data)?;
    let userRecord = create_user_record(userId, &amp;ProcessedData)?;
    Ok(userRecord)
}
<span class="boring">}</span></code></pre></pre>
<h4 id="types-and-traits"><a class="header" href="#types-and-traits">Types and Traits</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good: PascalCase for types
pub struct HttpServer {
    config: ServerConfig,
    router: Router,
}

pub trait RequestHandler {
    fn handle_request(&amp;self, request: Request) -&gt; Response;
}

// Bad: snake_case for types
pub struct http_server {
    config: ServerConfig,
    router: Router,
}
<span class="boring">}</span></code></pre></pre>
<h4 id="constants-3"><a class="header" href="#constants-3">Constants</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good: SCREAMING_SNAKE_CASE for constants
const MAX_CONNECTIONS: usize = 1000;
const DEFAULT_TIMEOUT_SECS: u64 = 30;

// Bad: camelCase or PascalCase
const maxConnections: usize = 1000;
const DefaultTimeoutSecs: u64 = 30;
<span class="boring">}</span></code></pre></pre>
<h4 id="modules-and-files"><a class="header" href="#modules-and-files">Modules and Files</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good: snake_case for module names
pub mod request_handler;
pub mod template_engine;

// File: request_handler.rs
// Module: request_handler
<span class="boring">}</span></code></pre></pre>
<h3 id="documentation-2"><a class="header" href="#documentation-2">Documentation</a></h3>
<h4 id="function-documentation"><a class="header" href="#function-documentation">Function Documentation</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// Processes a user request and returns a response.
///
/// This function handles the complete request processing pipeline:
/// 1. Validates the request data
/// 2. Applies business logic
/// 3. Returns appropriate response
///
/// # Arguments
///
/// * `user_id` - The ID of the user making the request
/// * `request_data` - The request payload as JSON
///
/// # Returns
///
/// Returns a `Result&lt;Response, Error&gt;` where:
/// - `Ok(response)` contains the successful response
/// - `Err(error)` contains details about what went wrong
///
/// # Errors
///
/// This function will return an error if:
/// - The user ID is invalid
/// - The request data is malformed
/// - Database operations fail
///
/// # Examples
///
/// ```rust
/// let user_id = 123;
/// let request_data = r#"{"action": "update_profile"}"#;
/// let response = process_user_request(user_id, request_data)?;
/// assert_eq!(response.status(), 200);
/// ```
pub fn process_user_request(user_id: i32, request_data: &amp;str) -&gt; Result&lt;Response, Error&gt; {
    // Implementation
}
<span class="boring">}</span></code></pre></pre>
<h4 id="module-documentation"><a class="header" href="#module-documentation">Module Documentation</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>//! # HTTP Server Module
//!
//! This module provides HTTP server functionality for MockForge,
//! including request routing, middleware support, and response handling.
//!
//! ## Architecture
//!
//! The HTTP server uses axum as the underlying web framework and provides:
//! - OpenAPI specification integration
//! - Template-based response generation
//! - Middleware for logging and validation
//!
//! ## Example
//!
//! ```rust
//! use mockforge_http::HttpServer;
//!
//! let server = HttpServer::new(config);
//! server.serve("127.0.0.1:3000").await?;
//! ```
<span class="boring">}</span></code></pre></pre>
<h3 id="error-handling-11"><a class="header" href="#error-handling-11">Error Handling</a></h3>
<h4 id="custom-error-types"><a class="header" href="#custom-error-types">Custom Error Types</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use thiserror::Error;

#[derive(Error, Debug)]
pub enum MockForgeError {
    #[error("Configuration error: {message}")]
    Config { message: String },

    #[error("I/O error: {source}")]
    Io {
        #[from]
        source: std::io::Error,
    },

    #[error("Template rendering error: {message}")]
    Template { message: String },

    #[error("HTTP error: {status} - {message}")]
    Http { status: u16, message: String },
}
<span class="boring">}</span></code></pre></pre>
<h4 id="result-types"><a class="header" href="#result-types">Result Types</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good: Use Result&lt;T, MockForgeError&gt; for fallible operations
pub fn load_config(path: &amp;Path) -&gt; Result&lt;Config, MockForgeError&gt; {
    let content = fs::read_to_string(path)
        .map_err(|e| MockForgeError::Io { source: e })?;

    let config: Config = serde_yaml::from_str(&amp;content)
        .map_err(|e| MockForgeError::Config {
            message: format!("Failed to parse YAML: {}", e),
        })?;

    Ok(config)
}

// Bad: Using Option when you should use Result
pub fn load_config_bad(path: &amp;Path) -&gt; Option&lt;Config&gt; {
    // This loses error information
    None
}
<span class="boring">}</span></code></pre></pre>
<h3 id="async-code"><a class="header" href="#async-code">Async Code</a></h3>
<h4 id="async-function-signatures"><a class="header" href="#async-function-signatures">Async Function Signatures</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good: Clear async function signatures
pub async fn process_request(request: Request) -&gt; Result&lt;Response, Error&gt; {
    let data = validate_request(&amp;request).await?;
    let result = process_data(data).await?;
    Ok(create_response(result))
}

// Bad: Unclear async boundaries
pub fn process_request(request: Request) -&gt; impl Future&lt;Output = Result&lt;Response, Error&gt;&gt; {
    async move {
        // Implementation
    }
}
<span class="boring">}</span></code></pre></pre>
<h4 id="tokio-usage"><a class="header" href="#tokio-usage">Tokio Usage</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tokio::sync::{Mutex, RwLock};

// Good: Use appropriate synchronization primitives
pub struct SharedState {
    data: RwLock&lt;HashMap&lt;String, String&gt;&gt;,
    counter: Mutex&lt;i64&gt;,
}

impl SharedState {
    pub async fn get_data(&amp;self, key: &amp;str) -&gt; Option&lt;String&gt; {
        let data = self.data.read().await;
        data.get(key).cloned()
    }

    pub async fn increment_counter(&amp;self) -&gt; i64 {
        let mut counter = self.counter.lock().await;
        *counter += 1;
        *counter
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="testing-6"><a class="header" href="#testing-6">Testing</a></h3>
<h4 id="unit-test-structure"><a class="header" href="#unit-test-structure">Unit Test Structure</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_function_basic_case() {
        // Given
        let input = "test input";
        let expected = "expected output";

        // When
        let result = process_input(input);

        // Then
        assert_eq!(result, expected);
    }

    #[test]
    fn test_function_error_case() {
        // Given
        let input = "";

        // When
        let result = process_input(input);

        // Then
        assert!(result.is_err());
        assert!(matches!(result.unwrap_err(), Error::InvalidInput(_)));
    }

    #[tokio::test]
    async fn test_async_function() {
        // Given
        let client = create_test_client().await;

        // When
        let response = client.make_request().await.unwrap();

        // Then
        assert_eq!(response.status(), 200);
    }
}
<span class="boring">}</span></code></pre></pre>
<h4 id="test-organization"><a class="header" href="#test-organization">Test Organization</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// tests/integration_tests.rs
#[cfg(test)]
mod integration_tests {
    use mockforge_core::config::MockForgeConfig;

    #[tokio::test]
    async fn test_full_http_flow() {
        // Test complete request/response cycle
        let server = TestServer::new().await;
        let client = TestClient::new(server.url());

        let response = client.get("/api/users").await;
        assert_eq!(response.status(), 200);
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="performance-considerations-5"><a class="header" href="#performance-considerations-5">Performance Considerations</a></h3>
<h4 id="memory-management-2"><a class="header" href="#memory-management-2">Memory Management</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good: Use references when possible
pub fn process_data(data: &amp;str) -&gt; Result&lt;String, Error&gt; {
    // Avoid cloning unless necessary
    if data.is_empty() {
        return Err(Error::EmptyInput);
    }
    Ok(data.to_uppercase())
}

// Good: Use Cow for flexible ownership
use std::borrow::Cow;

pub fn normalize_string&lt;'a&gt;(input: &amp;'a str) -&gt; Cow&lt;'a, str&gt; {
    if input.chars().all(|c| c.is_lowercase()) {
        Cow::Borrowed(input)
    } else {
        Cow::Owned(input.to_lowercase())
    }
}
<span class="boring">}</span></code></pre></pre>
<h4 id="zero-cost-abstractions"><a class="header" href="#zero-cost-abstractions">Zero-Cost Abstractions</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good: Use iterators for memory efficiency
pub fn find_active_users(users: &amp;[User]) -&gt; impl Iterator&lt;Item = &amp;User&gt; {
    users.iter().filter(|user| user.is_active)
}

// Bad: Collect into Vec unnecessarily
pub fn find_active_users_bad(users: &amp;[User]) -&gt; Vec&lt;&amp;User&gt; {
    users.iter().filter(|user| user.is_active).collect()
}
<span class="boring">}</span></code></pre></pre>
<h2 id="project-specific-conventions"><a class="header" href="#project-specific-conventions">Project-Specific Conventions</a></h2>
<h3 id="configuration-handling"><a class="header" href="#configuration-handling">Configuration Handling</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good: Use builder pattern for complex configuration
#[derive(Debug, Clone)]
pub struct ServerConfig {
    pub host: String,
    pub port: u16,
    pub tls: Option&lt;TlsConfig&gt;,
}

impl Default for ServerConfig {
    fn default() -&gt; Self {
        Self {
            host: "127.0.0.1".to_string(),
            port: 3000,
            tls: None,
        }
    }
}

impl ServerConfig {
    pub fn builder() -&gt; ServerConfigBuilder {
        ServerConfigBuilder::default()
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="logging-4"><a class="header" href="#logging-4">Logging</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tracing::{info, warn, error, debug, instrument};

// Good: Use structured logging
#[instrument(skip(config))]
pub async fn start_server(config: &amp;ServerConfig) -&gt; Result&lt;(), Error&gt; {
    info!("Starting server", host = %config.host, port = config.port);

    if let Err(e) = setup_server(config).await {
        error!("Failed to start server", error = %e);
        return Err(e);
    }

    info!("Server started successfully");
    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<h3 id="feature-flags-4"><a class="header" href="#feature-flags-4">Feature Flags</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good: Use feature flags for optional functionality
#[cfg(feature = "grpc")]
pub mod grpc {
    // gRPC-specific code
}

#[cfg(feature = "websocket")]
pub mod websocket {
    // WebSocket-specific code
}
<span class="boring">}</span></code></pre></pre>
<h2 id="code-review-checklist"><a class="header" href="#code-review-checklist">Code Review Checklist</a></h2>
<p>Before submitting code for review, ensure:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Code is formatted with <code>cargo fmt</code></li>
<li><input disabled="" type="checkbox"/>
No clippy warnings remain</li>
<li><input disabled="" type="checkbox"/>
All tests pass</li>
<li><input disabled="" type="checkbox"/>
Documentation is updated</li>
<li><input disabled="" type="checkbox"/>
No TODO comments left in production code</li>
<li><input disabled="" type="checkbox"/>
Error messages are user-friendly</li>
<li><input disabled="" type="checkbox"/>
Performance considerations are addressed</li>
<li><input disabled="" type="checkbox"/>
Security implications are reviewed</li>
</ul>
<h2 id="tools-and-automation"><a class="header" href="#tools-and-automation">Tools and Automation</a></h2>
<h3 id="pre-commit-hooks"><a class="header" href="#pre-commit-hooks">Pre-commit Hooks</a></h3>
<pre><code class="language-bash">#!/bin/bash
# .git/hooks/pre-commit

# Format code
cargo fmt --check
if [ $? -ne 0 ]; then
    echo "Code is not formatted. Run 'cargo fmt' to fix."
    exit 1
fi

# Run clippy
cargo clippy -- -D warnings
if [ $? -ne 0 ]; then
    echo "Clippy found issues. Fix them before committing."
    exit 1
fi

# Run tests
cargo test
if [ $? -ne 0 ]; then
    echo "Tests are failing. Fix them before committing."
    exit 1
fi
</code></pre>
<h3 id="ci-configuration"><a class="header" href="#ci-configuration">CI Configuration</a></h3>
<pre><code class="language-yaml"># .github/workflows/ci.yml
name: CI

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - uses: actions-rs/toolchain@v1
      with:
        toolchain: stable

    - name: Check formatting
      run: cargo fmt --check

    - name: Run clippy
      run: cargo clippy -- -D warnings

    - name: Run tests
      run: cargo test --verbose

    - name: Run security audit
      run: cargo audit
</code></pre>
<p>This style guide ensures MockForge maintains high code quality and consistency across the entire codebase. Following these guidelines makes the code more readable, maintainable, and collaborative.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="testing-guidelines"><a class="header" href="#testing-guidelines">Testing Guidelines</a></h1>
<p>This guide outlines the testing standards and practices for MockForge contributions. Quality testing ensures code reliability, prevents regressions, and maintains system stability.</p>
<h2 id="testing-philosophy"><a class="header" href="#testing-philosophy">Testing Philosophy</a></h2>
<h3 id="testing-pyramid"><a class="header" href="#testing-pyramid">Testing Pyramid</a></h3>
<p>MockForge follows a testing pyramid approach with different types of tests serving different purposes:</p>
<pre><code>End-to-End Tests (E2E)
        ‚Üë
Integration Tests
        ‚Üë
Unit Tests
       Base
</code></pre>
<ul>
<li><strong>Unit Tests</strong>: Test individual functions and modules in isolation</li>
<li><strong>Integration Tests</strong>: Test component interactions and data flow</li>
<li><strong>End-to-End Tests</strong>: Test complete user workflows and system behavior</li>
</ul>
<h3 id="testing-principles"><a class="header" href="#testing-principles">Testing Principles</a></h3>
<ol>
<li><strong>Test First</strong>: Write tests before implementation when possible</li>
<li><strong>Test Behavior</strong>: Test what the code does, not how it does it</li>
<li><strong>Test Boundaries</strong>: Focus on edge cases and error conditions</li>
<li><strong>Keep Tests Fast</strong>: Tests should run quickly to encourage frequent execution</li>
<li><strong>Make Tests Reliable</strong>: Tests should be deterministic and not flaky</li>
</ol>
<h2 id="unit-testing-requirements"><a class="header" href="#unit-testing-requirements">Unit Testing Requirements</a></h2>
<h3 id="test-coverage-1"><a class="header" href="#test-coverage-1">Test Coverage</a></h3>
<p>All new code must include unit tests with the following minimum coverage:</p>
<ul>
<li><strong>Functions</strong>: Test all public functions with valid inputs</li>
<li><strong>Error Cases</strong>: Test all error conditions and edge cases</li>
<li><strong>Branches</strong>: Test all conditional branches (if/else, match arms)</li>
<li><strong>Loops</strong>: Test loop boundaries (empty, single item, multiple items)</li>
</ul>
<h3 id="test-structure"><a class="header" href="#test-structure">Test Structure</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_function_name_description() {
        // Given: Set up test data and preconditions
        let input = create_test_input();
        let expected = create_expected_output();

        // When: Execute the function under test
        let result = function_under_test(input);

        // Then: Verify the result matches expectations
        assert_eq!(result, expected);
    }

    #[test]
    fn test_function_name_error_case() {
        // Given: Set up error condition
        let invalid_input = create_invalid_input();

        // When: Execute the function
        let result = function_under_test(invalid_input);

        // Then: Verify error handling
        assert!(result.is_err());
        let error = result.unwrap_err();
        assert!(matches!(error, ExpectedError::Variant));
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="test-naming-conventions"><a class="header" href="#test-naming-conventions">Test Naming Conventions</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good: Descriptive test names
#[test]
fn test_parse_openapi_spec_validates_required_fields() { ... }
#[test]
fn test_template_engine_handles_missing_variables() { ... }
#[test]
fn test_http_server_rejects_invalid_content_type() { ... }

// Bad: Non-descriptive names
#[test]
fn test_function() { ... }
#[test]
fn test_case_1() { ... }
#[test]
fn test_error() { ... }
<span class="boring">}</span></code></pre></pre>
<h3 id="test-data-management"><a class="header" href="#test-data-management">Test Data Management</a></h3>
<h4 id="test-fixtures"><a class="header" href="#test-fixtures">Test Fixtures</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Use shared test fixtures for common data
pub fn sample_openapi_spec() -&gt; &amp;'static str {
    r#"
    openapi: 3.0.3
    info:
      title: Test API
      version: 1.0.0
    paths:
      /users:
        get:
          responses:
            '200':
              description: Success
    "#
}

pub fn sample_user_data() -&gt; User {
    User {
        id: "123".to_string(),
        name: "John Doe".to_string(),
        email: "john@example.com".to_string(),
    }
}
<span class="boring">}</span></code></pre></pre>
<h4 id="test-utilities"><a class="header" href="#test-utilities">Test Utilities</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Create test utilities for common setup
pub struct TestServer {
    server_handle: Option&lt;JoinHandle&lt;()&gt;&gt;,
    base_url: String,
}

impl TestServer {
    pub async fn new() -&gt; Self {
        // Start test server
        // Return configured instance
    }

    pub fn url(&amp;self) -&gt; &amp;str {
        &amp;self.base_url
    }
}

impl Drop for TestServer {
    fn drop(&amp;mut self) {
        // Clean up server
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="integration-testing-standards"><a class="header" href="#integration-testing-standards">Integration Testing Standards</a></h2>
<h3 id="when-to-write-integration-tests"><a class="header" href="#when-to-write-integration-tests">When to Write Integration Tests</a></h3>
<p>Integration tests are required for:</p>
<ul>
<li><strong>API Boundaries</strong>: HTTP endpoints, gRPC services, WebSocket connections</li>
<li><strong>Database Operations</strong>: Data persistence and retrieval</li>
<li><strong>External Services</strong>: Third-party API integrations</li>
<li><strong>File I/O</strong>: Configuration loading, fixture management</li>
<li><strong>Component Communication</strong>: Cross-crate interactions</li>
</ul>
<h3 id="integration-test-structure"><a class="header" href="#integration-test-structure">Integration Test Structure</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod integration_tests {
    use mockforge_core::config::MockForgeConfig;

    #[tokio::test]
    async fn test_http_server_startup() {
        // Given: Configure test server
        let config = create_test_config();
        let server = HttpServer::new(config);

        // When: Start the server
        let addr = server.local_addr();
        tokio::spawn(async move {
            server.serve().await.unwrap();
        });

        // Wait for startup
        tokio::time::sleep(Duration::from_millis(100)).await;

        // Then: Verify server is responding
        let client = reqwest::Client::new();
        let response = client
            .get(format!("http://{}/health", addr))
            .send()
            .await
            .unwrap();

        assert_eq!(response.status(), 200);
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="database-testing"><a class="header" href="#database-testing">Database Testing</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod database_tests {
    use sqlx::PgPool;

    #[sqlx::test]
    async fn test_user_creation(pool: PgPool) {
        // Given: Clean database state
        sqlx::query!("DELETE FROM users").execute(&amp;pool).await.unwrap();

        // When: Create a user
        let user_id = create_user(&amp;pool, "test@example.com").await.unwrap();

        // Then: Verify user exists
        let user = sqlx::query!("SELECT * FROM users WHERE id = $1", user_id)
            .fetch_one(&amp;pool)
            .await
            .unwrap();

        assert_eq!(user.email, "test@example.com");
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="end-to-end-testing-requirements"><a class="header" href="#end-to-end-testing-requirements">End-to-End Testing Requirements</a></h2>
<h3 id="e2e-test-scenarios"><a class="header" href="#e2e-test-scenarios">E2E Test Scenarios</a></h3>
<p>E2E tests must cover:</p>
<ul>
<li><strong>Happy Path</strong>: Complete successful user workflows</li>
<li><strong>Error Recovery</strong>: System behavior under failure conditions</li>
<li><strong>Data Persistence</strong>: State changes across operations</li>
<li><strong>Performance</strong>: Response times and resource usage</li>
<li><strong>Security</strong>: Authentication and authorization flows</li>
</ul>
<h3 id="e2e-test-implementation"><a class="header" href="#e2e-test-implementation">E2E Test Implementation</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod e2e_tests {
    use std::process::Command;
    use std::time::Duration;

    #[test]
    fn test_complete_api_workflow() {
        // Start MockForge server
        let mut server = Command::new("cargo")
            .args(&amp;["run", "--release", "--", "serve", "--spec", "test-api.yaml"])
            .spawn()
            .unwrap();

        // Wait for server startup
        std::thread::sleep(Duration::from_secs(3));

        // Execute complete workflow
        let result = run_workflow_test();
        assert!(result.is_ok());

        // Cleanup
        server.kill().unwrap();
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="test-quality-standards"><a class="header" href="#test-quality-standards">Test Quality Standards</a></h2>
<h3 id="code-coverage-requirements"><a class="header" href="#code-coverage-requirements">Code Coverage Requirements</a></h3>
<ul>
<li><strong>Minimum Coverage</strong>: 80% overall, 90% for critical paths</li>
<li><strong>Branch Coverage</strong>: All conditional branches must be tested</li>
<li><strong>Error Path Coverage</strong>: All error conditions must be tested</li>
</ul>
<h3 id="performance-testing-2"><a class="header" href="#performance-testing-2">Performance Testing</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod performance_tests {
    use criterion::Criterion;

    fn benchmark_template_rendering(c: &amp;mut Criterion) {
        let engine = TemplateEngine::new();

        c.bench_function("render_simple_template", |b| {
            b.iter(|| {
                engine.render("Hello {{name}}", &amp;[("name", "World")]);
            })
        });
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="load-testing-5"><a class="header" href="#load-testing-5">Load Testing</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod load_tests {
    use tokio::time::{Duration, Instant};

    #[tokio::test]
    async fn test_concurrent_requests() {
        let client = reqwest::Client::new();
        let start = Instant::now();

        // Spawn 100 concurrent requests
        let handles: Vec&lt;_&gt; = (0..100).map(|_| {
            let client = client.clone();
            tokio::spawn(async move {
                client.get("http://localhost:3000/api/users")
                    .send()
                    .await
                    .unwrap()
            })
        }).collect();

        // Wait for all requests to complete
        for handle in handles {
            let response = handle.await.unwrap();
            assert_eq!(response.status(), 200);
        }

        let duration = start.elapsed();
        assert!(duration &lt; Duration::from_secs(5), "Load test took too long: {:?}", duration);
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="testing-tools-and-frameworks"><a class="header" href="#testing-tools-and-frameworks">Testing Tools and Frameworks</a></h2>
<h3 id="required-testing-dependencies"><a class="header" href="#required-testing-dependencies">Required Testing Dependencies</a></h3>
<pre><code class="language-toml">[dev-dependencies]
tokio-test = "0.4"
proptest = "1.0"          # Property-based testing
criterion = "0.4"         # Benchmarking
assert_cmd = "2.0"        # CLI testing
predicates = "2.1"        # Value assertions
tempfile = "3.0"          # Temporary files
</code></pre>
<h3 id="mocking-and-stubbing"><a class="header" href="#mocking-and-stubbing">Mocking and Stubbing</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod mock_tests {
    use mockall::mock;

    #[mockall::mock]
    trait Database {
        async fn get_user(&amp;self, id: i32) -&gt; Result&lt;User, Error&gt;;
        async fn save_user(&amp;self, user: User) -&gt; Result&lt;(), Error&gt;;
    }

    #[tokio::test]
    async fn test_service_with_mocks() {
        let mut mock_db = MockDatabase::new();

        mock_db
            .expect_get_user()
            .with(eq(123))
            .returning(|_| Ok(User { id: 123, name: "Test".to_string() }));

        let service = UserService::new(mock_db);
        let user = service.get_user(123).await.unwrap();

        assert_eq!(user.name, "Test");
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="property-based-testing"><a class="header" href="#property-based-testing">Property-Based Testing</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod property_tests {
    use proptest::prelude::*;

    proptest! {
        #[test]
        fn test_template_rendering_with_random_input(
            input in "\\PC*",  // Any printable character except control chars
            name in "[a-zA-Z]{1,10}"
        ) {
            let engine = TemplateEngine::new();
            let context = &amp;[("name", &amp;name)];

            // Should not panic regardless of input
            let _result = engine.render(&amp;input, context);
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="test-organization-and-naming"><a class="header" href="#test-organization-and-naming">Test Organization and Naming</a></h2>
<h3 id="file-structure"><a class="header" href="#file-structure">File Structure</a></h3>
<pre><code>src/
‚îú‚îÄ‚îÄ lib.rs
‚îú‚îÄ‚îÄ module.rs
‚îî‚îÄ‚îÄ module/
    ‚îú‚îÄ‚îÄ mod.rs
    ‚îî‚îÄ‚îÄ submodule.rs

tests/
‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îú‚îÄ‚îÄ module_tests.rs
‚îÇ   ‚îî‚îÄ‚îÄ submodule_tests.rs
‚îú‚îÄ‚îÄ integration/
‚îÇ   ‚îú‚îÄ‚îÄ api_tests.rs
‚îÇ   ‚îî‚îÄ‚îÄ database_tests.rs
‚îî‚îÄ‚îÄ e2e/
    ‚îú‚îÄ‚îÄ workflow_tests.rs
    ‚îî‚îÄ‚îÄ performance_tests.rs
</code></pre>
<h3 id="test-module-organization"><a class="header" href="#test-module-organization">Test Module Organization</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// tests/unit/template_tests.rs
#[cfg(test)]
mod template_tests {
    use mockforge_core::templating::TemplateEngine;

    // Unit tests for template functionality
}

// tests/integration/http_tests.rs
#[cfg(test)]
mod http_integration_tests {
    use mockforge_http::HttpServer;

    // Integration tests for HTTP server
}

// tests/e2e/api_workflow_tests.rs
#[cfg(test)]
mod e2e_tests {
    // End-to-end workflow tests
}
<span class="boring">}</span></code></pre></pre>
<h2 id="cicd-integration-10"><a class="header" href="#cicd-integration-10">CI/CD Integration</a></h2>
<h3 id="github-actions-testing-1"><a class="header" href="#github-actions-testing-1">GitHub Actions Testing</a></h3>
<pre><code class="language-yaml">name: Test

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v3
    - uses: dtolnay/rust-toolchain@stable

    - name: Cache dependencies
      uses: Swatinem/rust-cache@v2

    - name: Check formatting
      run: cargo fmt --check

    - name: Run clippy
      run: cargo clippy -- -D warnings

    - name: Run tests
      run: cargo test --verbose

    - name: Run integration tests
      run: cargo test --test integration

    - name: Generate coverage
      run: |
        cargo install cargo-tarpaulin
        cargo tarpaulin --out Xml --output-dir coverage

    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        file: coverage/cobertura.xml
</code></pre>
<h3 id="test-result-reporting"><a class="header" href="#test-result-reporting">Test Result Reporting</a></h3>
<pre><code class="language-yaml">- name: Run tests with JUnit output
  run: |
    cargo install cargo2junit
    cargo test -- -Z unstable-options --format json | cargo2junit &gt; test-results.xml

- name: Publish test results
  uses: EnricoMi/publish-unit-test-result-action@v2
  with:
    files: test-results.xml
</code></pre>
<h2 id="best-practices-58"><a class="header" href="#best-practices-58">Best Practices</a></h2>
<h3 id="test-isolation"><a class="header" href="#test-isolation">Test Isolation</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod isolated_tests {
    use tempfile::TempDir;

    #[test]
    fn test_file_operations() {
        // Use temporary directory for isolation
        let temp_dir = TempDir::new().unwrap();
        let file_path = temp_dir.path().join("test.txt");

        // Test file operations
        write_test_file(&amp;file_path);
        assert!(file_path.exists());

        // Cleanup happens automatically
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="test-data-management-1"><a class="header" href="#test-data-management-1">Test Data Management</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod test_data {
    use once_cell::sync::Lazy;

    static TEST_USERS: Lazy&lt;Vec&lt;User&gt;&gt; = Lazy::new(|| {
        vec![
            User { id: 1, name: "Alice".to_string() },
            User { id: 2, name: "Bob".to_string() },
        ]
    });

    #[test]
    fn test_user_operations() {
        let users = TEST_USERS.clone();
        // Use shared test data
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="asynchronous-testing"><a class="header" href="#asynchronous-testing">Asynchronous Testing</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod async_tests {
    use tokio::time::{timeout, Duration};

    #[tokio::test]
    async fn test_async_operation_with_timeout() {
        let result = timeout(Duration::from_secs(5), async_operation()).await;

        match result {
            Ok(Ok(data)) =&gt; assert!(data.is_valid()),
            Ok(Err(e)) =&gt; panic!("Operation failed: {}", e),
            Err(_) =&gt; panic!("Operation timed out"),
        }
    }

    #[tokio::test]
    async fn test_concurrent_operations() {
        let (result1, result2) = tokio::join(
            operation1(),
            operation2()
        );

        assert!(result1.is_ok());
        assert!(result2.is_ok());
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="test-flakiness-prevention"><a class="header" href="#test-flakiness-prevention">Test Flakiness Prevention</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod reliable_tests {
    #[test]
    fn test_with_retries() {
        let mut attempts = 0;
        let max_attempts = 3;

        loop {
            attempts += 1;

            match potentially_flaky_operation() {
                Ok(result) =&gt; {
                    assert!(result.is_valid());
                    break;
                }
                Err(e) if attempts &lt; max_attempts =&gt; {
                    eprintln!("Attempt {} failed: {}, retrying...", attempts, e);
                    std::thread::sleep(Duration::from_millis(100));
                    continue;
                }
                Err(e) =&gt; panic!("Operation failed after {} attempts: {}", max_attempts, e),
            }
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="security-testing-1"><a class="header" href="#security-testing-1">Security Testing</a></h2>
<h3 id="input-validation-testing"><a class="header" href="#input-validation-testing">Input Validation Testing</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod security_tests {
    #[test]
    fn test_sql_injection_prevention() {
        let malicious_input = "'; DROP TABLE users; --";
        let result = sanitize_sql_input(malicious_input);

        assert!(!result.contains("DROP"));
        assert!(!result.contains(";"));
    }

    #[test]
    fn test_xss_prevention() {
        let malicious_input = "&lt;script&gt;alert('xss')&lt;/script&gt;";
        let result = sanitize_html_input(malicious_input);

        assert!(!result.contains("&lt;script&gt;"));
        assert!(result.contains("&amp;lt;script&amp;gt;"));
    }

    #[test]
    fn test_path_traversal_prevention() {
        let malicious_input = "../../../etc/passwd";
        let result = validate_file_path(malicious_input);

        assert!(result.is_err());
        assert!(matches!(result.unwrap_err(), ValidationError::PathTraversal));
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="authentication-testing"><a class="header" href="#authentication-testing">Authentication Testing</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod auth_tests {
    #[tokio::test]
    async fn test_unauthorized_access() {
        let client = create_test_client();

        let response = client
            .get("/admin/users")
            .send()
            .await
            .unwrap();

        assert_eq!(response.status(), 401);
    }

    #[tokio::test]
    async fn test_authorized_access() {
        let client = create_authenticated_client();

        let response = client
            .get("/admin/users")
            .send()
            .await
            .unwrap();

        assert_eq!(response.status(), 200);
    }
}
<span class="boring">}</span></code></pre></pre>
<p>This comprehensive testing guide ensures MockForge maintains high quality and reliability through thorough automated testing at all levels.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="release-process"><a class="header" href="#release-process">Release Process</a></h1>
<p>This guide outlines the complete process for releasing new versions of MockForge, from planning through deployment and post-release activities.</p>
<h2 id="release-planning"><a class="header" href="#release-planning">Release Planning</a></h2>
<h3 id="version-numbering"><a class="header" href="#version-numbering">Version Numbering</a></h3>
<p>MockForge follows <a href="https://semver.org/">Semantic Versioning</a> (SemVer):</p>
<pre><code>MAJOR.MINOR.PATCH[-PRERELEASE][+BUILD]

Examples:
- 1.0.0 (stable release)
- 1.1.0 (minor release with new features)
- 1.1.1 (patch release with bug fixes)
- 2.0.0-alpha.1 (pre-release)
- 1.0.0+20230912 (build metadata)
</code></pre>
<h4 id="when-to-increment"><a class="header" href="#when-to-increment">When to Increment</a></h4>
<ul>
<li><strong>MAJOR</strong> (X.0.0): Breaking changes to public API</li>
<li><strong>MINOR</strong> (X.Y.0): New features, backward compatible</li>
<li><strong>PATCH</strong> (X.Y.Z): Bug fixes, backward compatible</li>
</ul>
<h3 id="release-types"><a class="header" href="#release-types">Release Types</a></h3>
<h4 id="major-releases"><a class="header" href="#major-releases">Major Releases</a></h4>
<ul>
<li>Breaking API changes</li>
<li>Major feature additions</li>
<li>Architectural changes</li>
<li>Extended testing period (2-4 weeks beta)</li>
</ul>
<h4 id="minor-releases"><a class="header" href="#minor-releases">Minor Releases</a></h4>
<ul>
<li>New features and enhancements</li>
<li>Backward compatible API changes</li>
<li>Standard testing period (1-2 weeks)</li>
</ul>
<h4 id="patch-releases"><a class="header" href="#patch-releases">Patch Releases</a></h4>
<ul>
<li>Critical bug fixes</li>
<li>Security patches</li>
<li>Documentation updates</li>
<li>Minimal testing period (3-5 days)</li>
</ul>
<h4 id="pre-releases"><a class="header" href="#pre-releases">Pre-releases</a></h4>
<ul>
<li>Alpha/Beta/RC versions</li>
<li>Feature previews</li>
<li>Breaking change previews</li>
<li>Limited distribution</li>
</ul>
<h2 id="pre-release-checklist"><a class="header" href="#pre-release-checklist">Pre-Release Checklist</a></h2>
<h3 id="1-code-quality-verification"><a class="header" href="#1-code-quality-verification">1. Code Quality Verification</a></h3>
<pre><code class="language-bash"># Run complete test suite
make test

# Run integration tests
make test-integration

# Run E2E tests
make test-e2e

# Check code quality
make lint
make format-check

# Security audit
cargo audit

# Check for unused dependencies
cargo +nightly udeps

# Performance benchmarks
make benchmark
</code></pre>
<h3 id="2-documentation-updates"><a class="header" href="#2-documentation-updates">2. Documentation Updates</a></h3>
<pre><code class="language-bash"># Update CHANGELOG.md with release notes
# IMPORTANT: Tag all changelog entries with pillars: [Reality], [Contracts], [DevX], [Cloud], [AI]
# See docs/PILLARS.md for pillar definitions and examples
# Update version numbers in documentation
# Build and test documentation
make docs
make docs-serve

# Test documentation links
mdbook test
</code></pre>
<p><strong>Changelog Pillar Tagging Requirements:</strong></p>
<p>All changelog entries must be tagged with at least one pillar. The release scripts will validate this automatically.</p>
<p><strong>Format:</strong></p>
<pre><code class="language-markdown">- **[Reality] Feature description**

- **[Contracts][DevX] Multi-pillar feature**
</code></pre>
<p><strong>Pillars:</strong></p>
<ul>
<li><strong>[Reality]</strong> ‚Äì Everything that makes mocks feel like a real, evolving backend</li>
<li><strong>[Contracts]</strong> ‚Äì Schema, drift, validation, and safety nets</li>
<li><strong>[DevX]</strong> ‚Äì SDKs, generators, playgrounds, ergonomics</li>
<li><strong>[Cloud]</strong> ‚Äì Registry, orgs, governance, monetization, marketplace</li>
<li><strong>[AI]</strong> ‚Äì LLM/voice flows, AI diff/assist, generative behaviors</li>
</ul>
<p>See <a href="contributing/../../../docs/PILLARS.html">docs/PILLARS.md</a> for detailed pillar definitions, feature mappings, and examples.</p>
<h3 id="3-version-bump"><a class="header" href="#3-version-bump">3. Version Bump</a></h3>
<pre><code class="language-bash"># Update version in Cargo.toml files
# Update version in package metadata
# Update version in documentation

# Example version bump script
#!/bin/bash
NEW_VERSION=$1

# Update workspace Cargo.toml
sed -i "s/^version = .*/version = \"$NEW_VERSION\"/" Cargo.toml

# Update all crate Cargo.toml files
find crates -name "Cargo.toml" -exec sed -i "s/^version = .*/version = \"$NEW_VERSION\"/" {} \;

# Update README and documentation version references
sed -i "s/mockforge [0-9]\+\.[0-9]\+\.[0-9]\+/mockforge $NEW_VERSION/g" README.md
</code></pre>
<h3 id="4-branch-management"><a class="header" href="#4-branch-management">4. Branch Management</a></h3>
<pre><code class="language-bash"># Create release branch
git checkout -b release/v$NEW_VERSION

# Cherry-pick approved commits
# Or merge from develop/main

# Tag the release
git tag -a v$NEW_VERSION -m "Release version $NEW_VERSION"

# Push branch and tag
git push origin release/v$NEW_VERSION
git push origin v$NEW_VERSION
</code></pre>
<h2 id="release-build-process"><a class="header" href="#release-build-process">Release Build Process</a></h2>
<h3 id="1-build-verification"><a class="header" href="#1-build-verification">1. Build Verification</a></h3>
<pre><code class="language-bash"># Clean build
cargo clean

# Build all targets
cargo build --release --all-targets

# Build specific platforms if needed
cargo build --release --target x86_64-unknown-linux-gnu
cargo build --release --target x86_64-apple-darwin
cargo build --release --target x86_64-pc-windows-msvc

# Test release build
./target/release/mockforge-cli --version
</code></pre>
<h3 id="2-binary-distribution"><a class="header" href="#2-binary-distribution">2. Binary Distribution</a></h3>
<h4 id="linuxmacos-packages"><a class="header" href="#linuxmacos-packages">Linux/macOS Packages</a></h4>
<pre><code class="language-bash"># Strip debug symbols
strip target/release/mockforge-cli

# Create distribution archives
VERSION=1.0.0
tar -czf mockforge-v${VERSION}-x86_64-linux.tar.gz \
  -C target/release mockforge-cli

tar -czf mockforge-v${VERSION}-x86_64-macos.tar.gz \
  -C target/release mockforge-cli
</code></pre>
<h4 id="debian-packages"><a class="header" href="#debian-packages">Debian Packages</a></h4>
<pre><code class="language-bash"># Install cargo-deb
cargo install cargo-deb

# Build .deb package
cargo deb

# Test package installation
sudo dpkg -i target/debian/mockforge_*.deb
</code></pre>
<h4 id="docker-images"><a class="header" href="#docker-images">Docker Images</a></h4>
<pre><code class="language-dockerfile"># Dockerfile.release
FROM rust:1.70-slim AS builder
WORKDIR /app
COPY . .
RUN cargo build --release

FROM debian:bookworm-slim
RUN apt-get update &amp;&amp; apt-get install -y ca-certificates &amp;&amp; rm -rf /var/lib/apt/lists/*
COPY --from=builder /app/target/release/mockforge-cli /usr/local/bin/mockforge-cli
EXPOSE 3000 3001 50051 9080
CMD ["mockforge-cli", "serve"]
</code></pre>
<pre><code class="language-bash"># Build and push Docker image
docker build -f Dockerfile.release -t mockforge:$VERSION .
docker tag mockforge:$VERSION mockforge:latest
docker push mockforge:$VERSION
docker push mockforge:latest
</code></pre>
<h3 id="3-cross-platform-builds"><a class="header" href="#3-cross-platform-builds">3. Cross-Platform Builds</a></h3>
<pre><code class="language-bash"># Use cross for cross-compilation
cargo install cross

# Build for different architectures
cross build --release --target aarch64-unknown-linux-gnu
cross build --release --target x86_64-unknown-linux-musl

# Create release archives for each platform
for target in x86_64-unknown-linux-gnu aarch64-unknown-linux-gnu x86_64-apple-darwin x86_64-pc-windows-msvc; do
  cross build --release --target $target
  if [[ $target == *"windows"* ]]; then
    zip -j mockforge-$VERSION-$target.zip target/$target/release/mockforge-cli.exe
  else
    tar -czf mockforge-$VERSION-$target.tar.gz -C target/$target/release mockforge-cli
  fi
done
</code></pre>
<h2 id="release-deployment"><a class="header" href="#release-deployment">Release Deployment</a></h2>
<h3 id="1-github-release"><a class="header" href="#1-github-release">1. GitHub Release</a></h3>
<pre><code class="language-bash"># Create GitHub release (manual or automated)
gh release create v$VERSION \
  --title "MockForge v$VERSION" \
  --notes-file release-notes.md \
  --draft

# Upload release assets
gh release upload v$VERSION \
  mockforge-v$VERSION-x86_64-linux.tar.gz \
  mockforge-v$VERSION-x86_64-macos.tar.gz \
  mockforge-v$VERSION-x86_64-windows.zip \
  mockforge_$VERSION_amd64.deb

# Publish release
gh release edit v$VERSION --draft=false
</code></pre>
<h3 id="2-package-registries"><a class="header" href="#2-package-registries">2. Package Registries</a></h3>
<h4 id="cratesio-publication"><a class="header" href="#cratesio-publication">Crates.io Publication</a></h4>
<pre><code class="language-bash"># Publish all crates to crates.io
# Note: Must be done in dependency order

# Publish core first
cd crates/mockforge-core
cargo publish

# Then other crates
cd ../mockforge-http
cargo publish

cd ../mockforge-ws
cargo publish

cd ../mockforge-grpc
cargo publish

cd ../mockforge-data
cargo publish

cd ../mockforge-ui
cargo publish

# Finally CLI
cd ../mockforge-cli
cargo publish
</code></pre>
<h4 id="docker-hub"><a class="header" href="#docker-hub">Docker Hub</a></h4>
<blockquote>
<p><strong>Note</strong>: Docker Hub publishing is planned for future releases. The organization and repository need to be set up first.</p>
</blockquote>
<p>Once Docker Hub is configured, use these commands:</p>
<pre><code class="language-bash"># Build the Docker image with version tag
docker build -t saasy-solutions/mockforge:$VERSION .
docker tag saasy-solutions/mockforge:$VERSION saasy-solutions/mockforge:latest

# Push to Docker Hub (requires authentication)
docker login
docker push saasy-solutions/mockforge:$VERSION
docker push saasy-solutions/mockforge:latest
</code></pre>
<p>For now, users should build the Docker image locally as documented in the <a href="contributing/../getting-started/installation.html#method-2-docker-containerized">Installation Guide</a>.</p>
<h3 id="3-homebrew-macos"><a class="header" href="#3-homebrew-macos">3. Homebrew (macOS)</a></h3>
<pre><code class="language-ruby"># Formula/mockforge.rb
class Mockforge &lt; Formula
  desc "Advanced API Mocking Platform"
  homepage "https://github.com/SaaSy-Solutions/mockforge"
  url "https://github.com/SaaSy-Solutions/mockforge/releases/download/v#{version}/mockforge-v#{version}-x86_64-macos.tar.gz"
  sha256 "..."

  def install
    bin.install "mockforge-cli"
  end

  test do
    system "#{bin}/mockforge-cli", "--version"
  end
end
</code></pre>
<h3 id="4-package-managers"><a class="header" href="#4-package-managers">4. Package Managers</a></h3>
<h4 id="apt-repository-ubuntudebian"><a class="header" href="#apt-repository-ubuntudebian">APT Repository (Ubuntu/Debian)</a></h4>
<pre><code class="language-bash"># Set up PPA or repository
# Upload .deb packages
# Update package indices
</code></pre>
<h4 id="snapcraft"><a class="header" href="#snapcraft">Snapcraft</a></h4>
<pre><code class="language-yaml"># snapcraft.yaml
name: mockforge
version: '1.0.0'
summary: Advanced API Mocking Platform
description: |
  MockForge is a comprehensive API mocking platform supporting HTTP, WebSocket, and gRPC protocols.

grade: stable
confinement: strict

apps:
  mockforge:
    command: mockforge-cli
    plugs: [network, network-bind]

parts:
  mockforge:
    plugin: rust
    source: .
    build-packages: [pkg-config, libssl-dev]
</code></pre>
<h2 id="post-release-activities"><a class="header" href="#post-release-activities">Post-Release Activities</a></h2>
<h3 id="1-announcement"><a class="header" href="#1-announcement">1. Announcement</a></h3>
<h4 id="github-release-notes"><a class="header" href="#github-release-notes">GitHub Release Notes</a></h4>
<pre><code class="language-markdown">## What's New in MockForge v1.0.0

### üöÄ Major Features
- Multi-protocol support (HTTP, WebSocket, gRPC)
- Advanced templating system
- Web-based admin UI
- Comprehensive testing framework

### üêõ Bug Fixes
- Fixed template rendering performance
- Resolved WebSocket connection stability
- Improved error messages

### üìö Documentation
- Complete API reference
- Getting started guides
- Troubleshooting documentation

### ü§ù Contributors
Special thanks to all contributors!

### üîó Links
- [Documentation](https://docs.mockforge.dev)
- [GitHub Repository](https://github.com/SaaSy-Solutions/mockforge)
- [Issue Tracker](https://github.com/SaaSy-Solutions/mockforge/issues)
</code></pre>
<h4 id="social-media--community"><a class="header" href="#social-media--community">Social Media &amp; Community</a></h4>
<pre><code class="language-bash"># Post to social media
# Update Discord/Slack channels
# Send email newsletter
# Update website/blog
</code></pre>
<h3 id="2-monitoring--support"><a class="header" href="#2-monitoring--support">2. Monitoring &amp; Support</a></h3>
<h4 id="release-health-checks"><a class="header" href="#release-health-checks">Release Health Checks</a></h4>
<pre><code class="language-bash"># Monitor installation success
# Check for immediate bug reports
# Monitor CI/CD pipelines
# Track adoption metrics

# Example monitoring script
#!/bin/bash
VERSION=$1

# Check GitHub release downloads
gh release view v$VERSION --json assets -q '.assets[].downloadCount'

# Check crates.io download stats
curl -s "https://crates.io/api/v1/crates/mockforge-cli/downloads" | jq '.versions[0].downloads'

# Monitor error reports
gh issue list --label bug --state open --limit 10
</code></pre>
<h4 id="support-channels"><a class="header" href="#support-channels">Support Channels</a></h4>
<ul>
<li><strong>GitHub Issues</strong>: Bug reports and feature requests</li>
<li><strong>GitHub Discussions</strong>: General questions and support</li>
<li><strong>Discord</strong>: <a href="https://discord.gg/2FxXqKpa">Join our community chat</a> - Real-time community support</li>
<li><strong>Documentation</strong>: Self-service troubleshooting</li>
</ul>
<h3 id="3-follow-up-releases"><a class="header" href="#3-follow-up-releases">3. Follow-up Releases</a></h3>
<h4 id="hotfix-process"><a class="header" href="#hotfix-process">Hotfix Process</a></h4>
<p>For critical issues discovered post-release:</p>
<pre><code class="language-bash"># Create hotfix branch from release tag
git checkout -b hotfix/critical-bug-fix v1.0.0

# Apply fix
# Write test
# Update CHANGELOG

# Create patch release
NEW_VERSION=1.0.1
git tag -a v$NEW_VERSION
git push origin v$NEW_VERSION

# Deploy hotfix
</code></pre>
<h3 id="4-analytics--metrics"><a class="header" href="#4-analytics--metrics">4. Analytics &amp; Metrics</a></h3>
<h4 id="release-metrics"><a class="header" href="#release-metrics">Release Metrics</a></h4>
<ul>
<li>Download counts across platforms</li>
<li>Installation success rates</li>
<li>User adoption and usage patterns</li>
<li>Performance benchmarks vs previous versions</li>
<li>Community feedback and sentiment</li>
</ul>
<h4 id="continuous-improvement"><a class="header" href="#continuous-improvement">Continuous Improvement</a></h4>
<pre><code class="language-yaml"># Post-release retrospective template
## Release Summary
- Version: v1.0.0
- Release Date: YYYY-MM-DD
- Duration: X weeks

## What Went Well
- [ ] Smooth release process
- [ ] No critical bugs found
- [ ] Good community reception

## Areas for Improvement
- [ ] Documentation could be clearer
- [ ] Testing took longer than expected
- [ ] More platform support needed

## Action Items
- [ ] Improve release documentation
- [ ] Automate more of the process
- [ ] Add more platform builds
</code></pre>
<h2 id="release-automation"><a class="header" href="#release-automation">Release Automation</a></h2>
<h3 id="github-actions-release-workflow"><a class="header" href="#github-actions-release-workflow">GitHub Actions Release Workflow</a></h3>
<pre><code class="language-yaml"># .github/workflows/release.yml
name: Release

on:
  push:
    tags:
      - 'v*'

jobs:
  release:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v3

    - name: Set version
      run: echo "VERSION=${GITHUB_REF#refs/tags/v}" &gt;&gt; $GITHUB_ENV

    - name: Build release binaries
      run: |
        cargo build --release
        strip target/release/mockforge-cli

    - name: Create release archives
      run: |
        tar -czf mockforge-${VERSION}-linux-x64.tar.gz -C target/release mockforge-cli
        zip mockforge-${VERSION}-linux-x64.zip target/release/mockforge-cli

    - name: Create GitHub release
      uses: actions/create-release@v1
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      with:
        tag_name: ${{ github.ref }}
        release_name: MockForge ${{ env.VERSION }}
        body: |
          ## What's New

          See [CHANGELOG.md](CHANGELOG.md) for details.

          ## Downloads

          - Linux x64: [mockforge-${{ env.VERSION }}-linux-x64.tar.gz](mockforge-${{ env.VERSION }}-linux-x64.tar.gz)
        draft: false
        prerelease: false

    - name: Upload release assets
      uses: actions/upload-release-asset@v1
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      with:
        upload_url: ${{ steps.create_release.outputs.upload_url }}
        asset_path: ./mockforge-${{ env.VERSION }}-linux-x64.tar.gz
        asset_name: mockforge-${{ env.VERSION }}-linux-x64.tar.gz
        asset_content_type: application/gzip
</code></pre>
<h3 id="automated-publishing"><a class="header" href="#automated-publishing">Automated Publishing</a></h3>
<pre><code class="language-yaml"># Publish to crates.io on release
- name: Publish to crates.io
  run: cargo publish --token ${{ secrets.CRATES_IO_TOKEN }}
  if: startsWith(github.ref, 'refs/tags/')

# Build and push Docker image
- name: Build and push Docker image
  uses: docker/build-push-action@v3
  with:
    context: .
    push: true
    tags: mockforge/mockforge:${{ env.VERSION }},mockforge/mockforge:latest
</code></pre>
<h2 id="emergency-releases"><a class="header" href="#emergency-releases">Emergency Releases</a></h2>
<h3 id="security-vulnerabilities"><a class="header" href="#security-vulnerabilities">Security Vulnerabilities</a></h3>
<p>For security issues requiring immediate release:</p>
<ol>
<li><strong>Assess Severity</strong>: Determine CVSS score and impact</li>
<li><strong>Develop Fix</strong>: Create minimal fix with comprehensive tests</li>
<li><strong>Bypass Normal Process</strong>: Skip extended testing for critical security fixes</li>
<li><strong>Accelerated Release</strong>: 24-48 hour release cycle</li>
<li><strong>Public Disclosure</strong>: Coordinate with security community</li>
</ol>
<h3 id="critical-bug-fixes"><a class="header" href="#critical-bug-fixes">Critical Bug Fixes</a></h3>
<p>For show-stopping bugs affecting production:</p>
<ol>
<li><strong>Immediate Assessment</strong>: Evaluate user impact and severity</li>
<li><strong>Rapid Development</strong>: 1-2 day fix development</li>
<li><strong>Limited Testing</strong>: Focus on regression and critical path tests</li>
<li><strong>Fast-Track Release</strong>: 3-5 day release cycle</li>
</ol>
<p>This comprehensive release process ensures MockForge releases are reliable, well-tested, and properly distributed across all supported platforms and package managers.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="configuration-schema"><a class="header" href="#configuration-schema">Configuration Schema</a></h1>
<p>MockForge supports comprehensive configuration through YAML files. This schema reference documents all available configuration options, their types, defaults, and usage examples.</p>
<h2 id="complete-configuration-template-1"><a class="header" href="#complete-configuration-template-1">Complete Configuration Template</a></h2>
<p>For a <strong>fully annotated configuration template</strong> with all options documented inline, see:</p>
<p><strong><a href="https://github.com/SaaSy-Solutions/mockforge/blob/main/config.template.yaml">config.template.yaml</a></strong></p>
<p>This template includes:</p>
<ul>
<li>Every configuration field with inline documentation</li>
<li>Default values and valid ranges</li>
<li>Example configurations for common scenarios</li>
<li>Comments explaining each option‚Äôs purpose</li>
</ul>
<h2 id="quick-start-27"><a class="header" href="#quick-start-27">Quick Start</a></h2>
<pre><code class="language-bash"># Initialize a new configuration
mockforge init my-project

# Validate your configuration
mockforge config validate

# Start with validated config
mockforge serve --config mockforge.yaml
</code></pre>
<p>See the <a href="reference/config-validation.html">Configuration Validation Guide</a> for validation best practices.</p>
<h2 id="file-format-1"><a class="header" href="#file-format-1">File Format</a></h2>
<p>Configuration files use YAML format with the following structure:</p>
<pre><code class="language-yaml"># Top-level configuration sections
server:        # Server port and binding configuration
admin:         # Admin UI settings
validation:    # Request validation settings
response:      # Response processing options
chaos:         # Chaos engineering features
grpc:          # gRPC-specific settings
websocket:     # WebSocket-specific settings
logging:       # Logging configuration
</code></pre>
<h2 id="server-configuration-1"><a class="header" href="#server-configuration-1">Server Configuration</a></h2>
<h3 id="serverhttp_port-integer-default-3000"><a class="header" href="#serverhttp_port-integer-default-3000"><code>server.http_port</code> (integer, default: 3000)</a></h3>
<p>HTTP server port for REST API endpoints.</p>
<pre><code class="language-yaml">server:
  http_port: 9080
</code></pre>
<h3 id="serverws_port-integer-default-3001"><a class="header" href="#serverws_port-integer-default-3001"><code>server.ws_port</code> (integer, default: 3001)</a></h3>
<p>WebSocket server port for real-time connections.</p>
<pre><code class="language-yaml">server:
  ws_port: 8081
</code></pre>
<h3 id="servergrpc_port-integer-default-50051"><a class="header" href="#servergrpc_port-integer-default-50051"><code>server.grpc_port</code> (integer, default: 50051)</a></h3>
<p>gRPC server port for protocol buffer services.</p>
<pre><code class="language-yaml">server:
  grpc_port: 9090
</code></pre>
<h3 id="serverbind-string-default-0000"><a class="header" href="#serverbind-string-default-0000"><code>server.bind</code> (string, default: ‚Äú0.0.0.0‚Äù)</a></h3>
<p>Network interface to bind servers to.</p>
<pre><code class="language-yaml">server:
  bind: "127.0.0.1"  # Bind to localhost only
</code></pre>
<h2 id="admin-ui-configuration-2"><a class="header" href="#admin-ui-configuration-2">Admin UI Configuration</a></h2>
<h3 id="adminenabled-boolean-default-false"><a class="header" href="#adminenabled-boolean-default-false"><code>admin.enabled</code> (boolean, default: false)</a></h3>
<p>Enable the web-based admin interface.</p>
<pre><code class="language-yaml">admin:
  enabled: true
</code></pre>
<h3 id="adminport-integer-default-9080"><a class="header" href="#adminport-integer-default-9080"><code>admin.port</code> (integer, default: 9080)</a></h3>
<p>Port for the admin UI server.</p>
<pre><code class="language-yaml">admin:
  port: 9090
</code></pre>
<h3 id="adminembedded-boolean-default-false"><a class="header" href="#adminembedded-boolean-default-false"><code>admin.embedded</code> (boolean, default: false)</a></h3>
<p>Embed admin UI under the main HTTP server instead of running standalone.</p>
<pre><code class="language-yaml">admin:
  embedded: true
</code></pre>
<h3 id="adminmount_path-string-default-admin"><a class="header" href="#adminmount_path-string-default-admin"><code>admin.mount_path</code> (string, default: ‚Äú/admin‚Äù)</a></h3>
<p>URL path where embedded admin UI is accessible.</p>
<pre><code class="language-yaml">admin:
  embedded: true
  mount_path: "/mockforge-admin"
</code></pre>
<h3 id="adminstandalone-boolean-default-true"><a class="header" href="#adminstandalone-boolean-default-true"><code>admin.standalone</code> (boolean, default: true)</a></h3>
<p>Force standalone admin UI server (overrides embedded setting).</p>
<pre><code class="language-yaml">admin:
  standalone: true
</code></pre>
<h3 id="admindisable_api-boolean-default-false"><a class="header" href="#admindisable_api-boolean-default-false"><code>admin.disable_api</code> (boolean, default: false)</a></h3>
<p>Disable admin API endpoints while keeping the UI interface.</p>
<pre><code class="language-yaml">admin:
  disable_api: false
</code></pre>
<h2 id="validation-configuration-1"><a class="header" href="#validation-configuration-1">Validation Configuration</a></h2>
<h3 id="validationmode-string-default-enforce"><a class="header" href="#validationmode-string-default-enforce"><code>validation.mode</code> (string, default: ‚Äúenforce‚Äù)</a></h3>
<p>Request validation mode. Options: ‚Äúoff‚Äù, ‚Äúwarn‚Äù, ‚Äúenforce‚Äù</p>
<pre><code class="language-yaml">validation:
  mode: warn  # Log warnings but allow invalid requests
</code></pre>
<h3 id="validationaggregate_errors-boolean-default-false"><a class="header" href="#validationaggregate_errors-boolean-default-false"><code>validation.aggregate_errors</code> (boolean, default: false)</a></h3>
<p>Combine multiple validation errors into a single JSON array response.</p>
<pre><code class="language-yaml">validation:
  aggregate_errors: true
</code></pre>
<h3 id="validationvalidate_responses-boolean-default-false"><a class="header" href="#validationvalidate_responses-boolean-default-false"><code>validation.validate_responses</code> (boolean, default: false)</a></h3>
<p>Validate response payloads against OpenAPI schemas (warn-only).</p>
<pre><code class="language-yaml">validation:
  validate_responses: true
</code></pre>
<h3 id="validationstatus_code-integer-default-400"><a class="header" href="#validationstatus_code-integer-default-400"><code>validation.status_code</code> (integer, default: 400)</a></h3>
<p>HTTP status code to return for validation errors.</p>
<pre><code class="language-yaml">validation:
  status_code: 422  # Use 422 Unprocessable Entity
</code></pre>
<h3 id="validationskip_admin_validation-boolean-default-true"><a class="header" href="#validationskip_admin_validation-boolean-default-true"><code>validation.skip_admin_validation</code> (boolean, default: true)</a></h3>
<p>Skip validation for admin UI routes.</p>
<pre><code class="language-yaml">validation:
  skip_admin_validation: true
</code></pre>
<h3 id="validationoverrides-object"><a class="header" href="#validationoverrides-object"><code>validation.overrides</code> (object)</a></h3>
<p>Per-route validation overrides.</p>
<pre><code class="language-yaml">validation:
  overrides:
    "/api/users": "off"      # Disable validation for this route
    "/api/admin/**": "warn"  # Warning mode for admin routes
</code></pre>
<h2 id="response-configuration-2"><a class="header" href="#response-configuration-2">Response Configuration</a></h2>
<h3 id="responsetemplate_expand-boolean-default-false"><a class="header" href="#responsetemplate_expand-boolean-default-false"><code>response.template_expand</code> (boolean, default: false)</a></h3>
<p>Enable template variable expansion in responses.</p>
<pre><code class="language-yaml">response:
  template_expand: true
</code></pre>
<h3 id="responsecaching-object"><a class="header" href="#responsecaching-object"><code>response.caching</code> (object)</a></h3>
<p>Response caching configuration.</p>
<pre><code class="language-yaml">response:
  caching:
    enabled: true
    ttl_seconds: 300
    max_size_mb: 100
</code></pre>
<h2 id="chaos-engineering-2"><a class="header" href="#chaos-engineering-2">Chaos Engineering</a></h2>
<h3 id="chaoslatency_enabled-boolean-default-false"><a class="header" href="#chaoslatency_enabled-boolean-default-false"><code>chaos.latency_enabled</code> (boolean, default: false)</a></h3>
<p>Enable response latency simulation.</p>
<pre><code class="language-yaml">chaos:
  latency_enabled: true
</code></pre>
<h3 id="chaoslatency_min_ms-integer-default-0"><a class="header" href="#chaoslatency_min_ms-integer-default-0"><code>chaos.latency_min_ms</code> (integer, default: 0)</a></h3>
<p>Minimum response latency in milliseconds.</p>
<pre><code class="language-yaml">chaos:
  latency_min_ms: 100
</code></pre>
<h3 id="chaoslatency_max_ms-integer-default-1000"><a class="header" href="#chaoslatency_max_ms-integer-default-1000"><code>chaos.latency_max_ms</code> (integer, default: 1000)</a></h3>
<p>Maximum response latency in milliseconds.</p>
<pre><code class="language-yaml">chaos:
  latency_max_ms: 2000
</code></pre>
<h3 id="chaosfailures_enabled-boolean-default-false"><a class="header" href="#chaosfailures_enabled-boolean-default-false"><code>chaos.failures_enabled</code> (boolean, default: false)</a></h3>
<p>Enable random failure injection.</p>
<pre><code class="language-yaml">chaos:
  failures_enabled: true
</code></pre>
<h3 id="chaosfailure_rate-float-default-00"><a class="header" href="#chaosfailure_rate-float-default-00"><code>chaos.failure_rate</code> (float, default: 0.0)</a></h3>
<p>Probability of random failures (0.0 to 1.0).</p>
<pre><code class="language-yaml">chaos:
  failure_rate: 0.05  # 5% failure rate
</code></pre>
<h3 id="chaosfailure_status_codes-array-of-integers"><a class="header" href="#chaosfailure_status_codes-array-of-integers"><code>chaos.failure_status_codes</code> (array of integers)</a></h3>
<p>HTTP status codes to return for injected failures.</p>
<pre><code class="language-yaml">chaos:
  failure_status_codes: [500, 502, 503, 504]
</code></pre>
<h2 id="grpc-configuration"><a class="header" href="#grpc-configuration">gRPC Configuration</a></h2>
<h3 id="grpcproto_dir-string-default-proto"><a class="header" href="#grpcproto_dir-string-default-proto"><code>grpc.proto_dir</code> (string, default: ‚Äúproto/‚Äù)</a></h3>
<p>Directory containing Protocol Buffer files.</p>
<pre><code class="language-yaml">grpc:
  proto_dir: "my-protos/"
</code></pre>
<h3 id="grpcenable_reflection-boolean-default-true"><a class="header" href="#grpcenable_reflection-boolean-default-true"><code>grpc.enable_reflection</code> (boolean, default: true)</a></h3>
<p>Enable gRPC server reflection for service discovery.</p>
<pre><code class="language-yaml">grpc:
  enable_reflection: true
</code></pre>
<h3 id="grpcexcluded_services-array-of-strings"><a class="header" href="#grpcexcluded_services-array-of-strings"><code>grpc.excluded_services</code> (array of strings)</a></h3>
<p>gRPC services to exclude from automatic registration.</p>
<pre><code class="language-yaml">grpc:
  excluded_services:
    - "grpc.reflection.v1alpha.ServerReflection"
</code></pre>
<h3 id="grpcmax_message_size-integer-default-4194304"><a class="header" href="#grpcmax_message_size-integer-default-4194304"><code>grpc.max_message_size</code> (integer, default: 4194304)</a></h3>
<p>Maximum message size in bytes (4MB default).</p>
<pre><code class="language-yaml">grpc:
  max_message_size: 8388608  # 8MB
</code></pre>
<h3 id="grpcconcurrency_limit-integer-default-32"><a class="header" href="#grpcconcurrency_limit-integer-default-32"><code>grpc.concurrency_limit</code> (integer, default: 32)</a></h3>
<p>Maximum concurrent requests per connection.</p>
<pre><code class="language-yaml">grpc:
  concurrency_limit: 64
</code></pre>
<h2 id="websocket-configuration"><a class="header" href="#websocket-configuration">WebSocket Configuration</a></h2>
<h3 id="websocketreplay_file-string"><a class="header" href="#websocketreplay_file-string"><code>websocket.replay_file</code> (string)</a></h3>
<p>Path to WebSocket replay file for scripted interactions.</p>
<pre><code class="language-yaml">websocket:
  replay_file: "examples/ws-demo.jsonl"
</code></pre>
<h3 id="websocketmax_connections-integer-default-1000"><a class="header" href="#websocketmax_connections-integer-default-1000"><code>websocket.max_connections</code> (integer, default: 1000)</a></h3>
<p>Maximum concurrent WebSocket connections.</p>
<pre><code class="language-yaml">websocket:
  max_connections: 500
</code></pre>
<h3 id="websocketmessage_timeout-integer-default-30000"><a class="header" href="#websocketmessage_timeout-integer-default-30000"><code>websocket.message_timeout</code> (integer, default: 30000)</a></h3>
<p>Timeout for WebSocket messages in milliseconds.</p>
<pre><code class="language-yaml">websocket:
  message_timeout: 60000
</code></pre>
<h3 id="websocketheartbeat_interval-integer-default-30000"><a class="header" href="#websocketheartbeat_interval-integer-default-30000"><code>websocket.heartbeat_interval</code> (integer, default: 30000)</a></h3>
<p>Heartbeat interval for long-running connections.</p>
<pre><code class="language-yaml">websocket:
  heartbeat_interval: 45000
</code></pre>
<h2 id="logging-configuration-1"><a class="header" href="#logging-configuration-1">Logging Configuration</a></h2>
<h3 id="logginglevel-string-default-info"><a class="header" href="#logginglevel-string-default-info"><code>logging.level</code> (string, default: ‚Äúinfo‚Äù)</a></h3>
<p>Log level. Options: ‚Äúerror‚Äù, ‚Äúwarn‚Äù, ‚Äúinfo‚Äù, ‚Äúdebug‚Äù, ‚Äútrace‚Äù</p>
<pre><code class="language-yaml">logging:
  level: debug
</code></pre>
<h3 id="loggingformat-string-default-text"><a class="header" href="#loggingformat-string-default-text"><code>logging.format</code> (string, default: ‚Äútext‚Äù)</a></h3>
<p>Log output format. Options: ‚Äútext‚Äù, ‚Äújson‚Äù</p>
<pre><code class="language-yaml">logging:
  format: json
</code></pre>
<h3 id="loggingfile-string"><a class="header" href="#loggingfile-string"><code>logging.file</code> (string)</a></h3>
<p>Path to log file (if not specified, logs to stdout).</p>
<pre><code class="language-yaml">logging:
  file: "/var/log/mockforge.log"
</code></pre>
<h3 id="loggingmax_size_mb-integer-default-10"><a class="header" href="#loggingmax_size_mb-integer-default-10"><code>logging.max_size_mb</code> (integer, default: 10)</a></h3>
<p>Maximum log file size in megabytes before rotation.</p>
<pre><code class="language-yaml">logging:
  max_size_mb: 50
</code></pre>
<h3 id="loggingmax_files-integer-default-5"><a class="header" href="#loggingmax_files-integer-default-5"><code>logging.max_files</code> (integer, default: 5)</a></h3>
<p>Maximum number of rotated log files to keep.</p>
<pre><code class="language-yaml">logging:
  max_files: 10
</code></pre>
<h2 id="complete-configuration-example"><a class="header" href="#complete-configuration-example">Complete Configuration Example</a></h2>
<pre><code class="language-yaml"># Complete MockForge configuration example
server:
  http_port: 3000
  ws_port: 3001
  grpc_port: 50051
  bind: "0.0.0.0"

admin:
  enabled: true
  port: 9080
  embedded: false
  standalone: true

validation:
  mode: enforce
  aggregate_errors: false
  validate_responses: false
  status_code: 400

response:
  template_expand: true

chaos:
  latency_enabled: false
  failures_enabled: false

grpc:
  proto_dir: "proto/"
  enable_reflection: true
  max_message_size: 4194304

websocket:
  replay_file: "examples/ws-demo.jsonl"
  max_connections: 1000

logging:
  level: info
  format: text
</code></pre>
<h2 id="configuration-precedence-2"><a class="header" href="#configuration-precedence-2">Configuration Precedence</a></h2>
<p>Configuration values are applied in order of priority (highest to lowest):</p>
<ol>
<li><strong>Command-line arguments</strong> - Override all other settings</li>
<li><strong>Environment variables</strong> - Override config file settings</li>
<li><strong>Configuration file</strong> - Default values from YAML file</li>
<li><strong>Compiled defaults</strong> - Built-in fallback values</li>
</ol>
<h2 id="environment-variable-mapping"><a class="header" href="#environment-variable-mapping">Environment Variable Mapping</a></h2>
<p>All configuration options can be set via environment variables using the <code>MOCKFORGE_</code> prefix with underscore-separated paths:</p>
<pre><code class="language-bash"># Server configuration
export MOCKFORGE_SERVER_HTTP_PORT=9080
export MOCKFORGE_SERVER_BIND="127.0.0.1"

# Admin UI
export MOCKFORGE_ADMIN_ENABLED=true
export MOCKFORGE_ADMIN_PORT=9090

# Validation
export MOCKFORGE_VALIDATION_MODE=warn
export MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true

# Protocol-specific
export MOCKFORGE_GRPC_PROTO_DIR="my-protos/"
export MOCKFORGE_WEBSOCKET_REPLAY_FILE="replay.jsonl"
</code></pre>
<h2 id="validation-3"><a class="header" href="#validation-3">Validation</a></h2>
<p>MockForge validates configuration files at startup and reports errors clearly:</p>
<pre><code class="language-bash"># Validate configuration without starting server
mockforge-cli validate-config config.yaml

# Check for deprecated options
mockforge-cli validate-config --check-deprecated config.yaml
</code></pre>
<h2 id="hot-reloading-1"><a class="header" href="#hot-reloading-1">Hot Reloading</a></h2>
<p>Some configuration options support runtime updates without restart:</p>
<ul>
<li>Validation mode changes</li>
<li>Template expansion toggle</li>
<li>Admin UI settings</li>
<li>Logging level adjustments</li>
</ul>
<pre><code class="language-bash"># Update validation mode at runtime
curl -X POST http://localhost:9080/__mockforge/config \
  -H "Content-Type: application/json" \
  -d '{"validation": {"mode": "warn"}}'
</code></pre>
<h2 id="best-practices-59"><a class="header" href="#best-practices-59">Best Practices</a></h2>
<h3 id="development-configuration-2"><a class="header" href="#development-configuration-2">Development Configuration</a></h3>
<pre><code class="language-yaml"># development.yaml
server:
  http_port: 3000
  ws_port: 3001

admin:
  enabled: true
  embedded: true

validation:
  mode: warn

response:
  template_expand: true

logging:
  level: debug
</code></pre>
<h3 id="production-configuration-1"><a class="header" href="#production-configuration-1">Production Configuration</a></h3>
<pre><code class="language-yaml"># production.yaml
server:
  http_port: 9080
  bind: "127.0.0.1"

admin:
  enabled: true
  standalone: true
  port: 9090

validation:
  mode: enforce

chaos:
  latency_enabled: false
  failures_enabled: false

logging:
  level: warn
  file: "/var/log/mockforge.log"
</code></pre>
<h3 id="testing-configuration-1"><a class="header" href="#testing-configuration-1">Testing Configuration</a></h3>
<pre><code class="language-yaml"># test.yaml
server:
  http_port: 3000

validation:
  mode: off

response:
  template_expand: true

logging:
  level: debug
</code></pre>
<h2 id="migration-guide"><a class="header" href="#migration-guide">Migration Guide</a></h2>
<h3 id="upgrading-from-cli-only-configuration"><a class="header" href="#upgrading-from-cli-only-configuration">Upgrading from CLI-only Configuration</a></h3>
<p>If migrating from command-line only configuration:</p>
<ol>
<li>Create a <code>config.yaml</code> file with your current settings</li>
<li>Test the configuration with <code>mockforge-cli validate-config</code></li>
<li>Gradually move settings from environment variables to the config file</li>
<li>Update deployment scripts to use the config file</li>
</ol>
<h3 id="version-compatibility"><a class="header" href="#version-compatibility">Version Compatibility</a></h3>
<p>Configuration options may change between versions. Check the changelog for breaking changes and use the validation command to identify deprecated options:</p>
<pre><code class="language-bash">mockforge-cli validate-config --check-deprecated config.yaml
</code></pre>
<p>This schema provides comprehensive control over MockForge‚Äôs behavior across all protocols and features.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="configuration-validation-guide"><a class="header" href="#configuration-validation-guide">Configuration Validation Guide</a></h1>
<p>MockForge provides configuration validation to help you catch errors before starting the server. This guide explains how to validate your configuration and troubleshoot common issues.</p>
<h2 id="quick-start-28"><a class="header" href="#quick-start-28">Quick Start</a></h2>
<h3 id="initialize-a-new-configuration-1"><a class="header" href="#initialize-a-new-configuration-1">Initialize a New Configuration</a></h3>
<pre><code class="language-bash"># Create a new project with template configuration
mockforge init my-project

# Or initialize in current directory
mockforge init .
</code></pre>
<p>This creates:</p>
<ul>
<li><code>mockforge.yaml</code> - Main configuration file</li>
<li><code>examples/</code> - Example OpenAPI spec and data files (unless <code>--no-examples</code> is used)</li>
</ul>
<h3 id="validate-configuration"><a class="header" href="#validate-configuration">Validate Configuration</a></h3>
<pre><code class="language-bash"># Validate the current directory's config
mockforge config validate

# Validate a specific config file
mockforge config validate --config ./my-config.yaml

# Auto-discover config in parent directories
mockforge config validate
</code></pre>
<h2 id="what-gets-validated"><a class="header" href="#what-gets-validated">What Gets Validated</a></h2>
<p>MockForge‚Äôs <code>config validate</code> command currently performs these checks:</p>
<h3 id="1-file-existence"><a class="header" href="#1-file-existence">1. File Existence</a></h3>
<ul>
<li>Checks if the config file exists</li>
<li>Auto-discovers <code>mockforge.yaml</code> or <code>mockforge.yml</code> in current and parent directories</li>
</ul>
<h3 id="2-yaml-syntax"><a class="header" href="#2-yaml-syntax">2. YAML Syntax</a></h3>
<ul>
<li>Validates YAML syntax and structure</li>
<li>Reports parsing errors with line numbers</li>
</ul>
<h3 id="3-basic-structure"><a class="header" href="#3-basic-structure">3. Basic Structure</a></h3>
<ul>
<li>Counts HTTP endpoints</li>
<li>Counts request chains</li>
<li>Warns about missing sections (HTTP, admin, WebSocket, gRPC)</li>
</ul>
<h3 id="4-summary-report"><a class="header" href="#4-summary-report">4. Summary Report</a></h3>
<pre><code>‚úÖ Configuration is valid

üìä Summary:
   Found 5 HTTP endpoints
   Found 2 chains

‚ö†Ô∏è  Warnings:
   - No WebSocket configuration found
</code></pre>
<h2 id="manual-validation-checklist"><a class="header" href="#manual-validation-checklist">Manual Validation Checklist</a></h2>
<p>Since validation is currently basic, here‚Äôs a manual checklist for comprehensive validation:</p>
<h3 id="required-fields"><a class="header" href="#required-fields">Required Fields</a></h3>
<h4 id="http-configuration"><a class="header" href="#http-configuration">HTTP Configuration</a></h4>
<pre><code class="language-yaml">http:
  port: 3000              # ‚úÖ Required
  host: "0.0.0.0"        # ‚úÖ Required
</code></pre>
<h4 id="admin-configuration"><a class="header" href="#admin-configuration">Admin Configuration</a></h4>
<pre><code class="language-yaml">admin:
  enabled: true           # ‚úÖ Required if using admin UI
  port: 9080             # ‚úÖ Required in standalone mode
</code></pre>
<h3 id="common-mistakes"><a class="header" href="#common-mistakes">Common Mistakes</a></h3>
<h4 id="1-invalid-port-numbers"><a class="header" href="#1-invalid-port-numbers">1. Invalid Port Numbers</a></h4>
<pre><code class="language-yaml"># ‚ùå Wrong - port must be 1-65535
http:
  port: 70000

# ‚úÖ Correct
http:
  port: 3000
</code></pre>
<h4 id="2-invalid-file-paths"><a class="header" href="#2-invalid-file-paths">2. Invalid File Paths</a></h4>
<pre><code class="language-yaml"># ‚ùå Wrong - file doesn't exist
http:
  openapi_spec: "./nonexistent.json"

# ‚úÖ Correct - verify file exists
http:
  openapi_spec: "./examples/openapi.json"
</code></pre>
<p>Test the path:</p>
<pre><code class="language-bash">ls -la ./examples/openapi.json
</code></pre>
<h4 id="3-invalid-validation-mode"><a class="header" href="#3-invalid-validation-mode">3. Invalid Validation Mode</a></h4>
<pre><code class="language-yaml"># ‚ùå Wrong - invalid mode
validation:
  mode: "strict"

# ‚úÖ Correct - must be: off, warn, or enforce
validation:
  mode: "enforce"
</code></pre>
<h4 id="4-invalid-latency-configuration"><a class="header" href="#4-invalid-latency-configuration">4. Invalid Latency Configuration</a></h4>
<pre><code class="language-yaml"># ‚ùå Wrong - base_ms is too high
core:
  default_latency:
    base_ms: 100000

# ‚úÖ Correct - reasonable latency
core:
  default_latency:
    base_ms: 100
    jitter_ms: 50
</code></pre>
<h4 id="5-missing-required-fields-in-routes"><a class="header" href="#5-missing-required-fields-in-routes">5. Missing Required Fields in Routes</a></h4>
<pre><code class="language-yaml"># ‚ùå Wrong - missing response status
http:
  routes:
    - path: /test
      method: GET
      response:
        body: "test"

# ‚úÖ Correct - include status code
http:
  routes:
    - path: /test
      method: GET
      response:
        status: 200
        body: "test"
</code></pre>
<h4 id="6-invalid-environment-variable-names"><a class="header" href="#6-invalid-environment-variable-names">6. Invalid Environment Variable Names</a></h4>
<pre><code class="language-bash"># ‚ùå Wrong - incorrect prefix
export MOCK_FORGE_HTTP_PORT=3000

# ‚úÖ Correct - use MOCKFORGE_ prefix
export MOCKFORGE_HTTP_PORT=3000
</code></pre>
<h4 id="7-conflicting-mount-path-configuration"><a class="header" href="#7-conflicting-mount-path-configuration">7. Conflicting Mount Path Configuration</a></h4>
<pre><code class="language-yaml"># ‚ùå Wrong - both standalone and embedded
admin:
  enabled: true
  port: 9080
  mount_path: "/admin"    # Conflicts with standalone mode

# ‚úÖ Correct - choose one mode
admin:
  enabled: true
  mount_path: "/admin"    # Embedded under HTTP server
  # OR
  port: 9080              # Standalone mode (no mount_path)
</code></pre>
<h4 id="8-advanced-validation-configuration"><a class="header" href="#8-advanced-validation-configuration">8. Advanced Validation Configuration</a></h4>
<pre><code class="language-yaml"># ‚úÖ Complete validation configuration
validation:
  mode: enforce                    # off | warn | enforce
  aggregate_errors: true          # Combine multiple errors
  validate_responses: false       # Validate response payloads
  status_code: 400                # Error status code (400 or 422)
  skip_admin_validation: true     # Skip validation for admin routes

  # Per-route overrides
  overrides:
    "GET /health": "off"          # Disable validation for health checks
    "POST /api/users": "warn"     # Warning mode for user creation
    "/api/internal/**": "off"     # Disable for internal endpoints
</code></pre>
<h2 id="validation-tools"><a class="header" href="#validation-tools">Validation Tools</a></h2>
<h3 id="1-yaml-syntax-validator"><a class="header" href="#1-yaml-syntax-validator">1. YAML Syntax Validator</a></h3>
<p>Use <code>yamllint</code> for syntax validation:</p>
<pre><code class="language-bash"># Install yamllint
pip install yamllint

# Validate YAML syntax
yamllint mockforge.yaml
</code></pre>
<h3 id="2-json-schema-validation-future"><a class="header" href="#2-json-schema-validation-future">2. JSON Schema Validation (Future)</a></h3>
<p>MockForge doesn‚Äôt currently provide JSON Schema validation, but you can use the template as a reference:</p>
<pre><code class="language-bash"># Copy the complete template
cp config.template.yaml mockforge.yaml

# Edit with your settings, keeping structure intact
</code></pre>
<h3 id="3-test-your-configuration"><a class="header" href="#3-test-your-configuration">3. Test Your Configuration</a></h3>
<p>The best validation is starting the server:</p>
<pre><code class="language-bash"># Try to start the server
mockforge serve --config mockforge.yaml

# Check for error messages in logs
</code></pre>
<h2 id="troubleshooting-60"><a class="header" href="#troubleshooting-60">Troubleshooting</a></h2>
<h3 id="error-configuration-file-not-found"><a class="header" href="#error-configuration-file-not-found">Error: ‚ÄúConfiguration file not found‚Äù</a></h3>
<p><strong>Cause</strong>: Config file doesn‚Äôt exist or isn‚Äôt in expected location</p>
<p><strong>Solution</strong>:</p>
<pre><code class="language-bash"># Check current directory
ls -la mockforge.yaml

# Create from template
mockforge init .

# Or specify path explicitly
mockforge serve --config /path/to/config.yaml
</code></pre>
<h3 id="error-invalid-yaml-syntax"><a class="header" href="#error-invalid-yaml-syntax">Error: ‚ÄúInvalid YAML syntax‚Äù</a></h3>
<p><strong>Cause</strong>: YAML parsing error (usually indentation or quotes)</p>
<p><strong>Solution</strong>:</p>
<pre><code class="language-bash"># Use yamllint to find the exact error
yamllint mockforge.yaml

# Common fixes:
# - Fix indentation (use 2 spaces, not tabs)
# - Quote strings with special characters
# - Match opening/closing brackets and braces
</code></pre>
<h3 id="warning-no-http-configuration-found"><a class="header" href="#warning-no-http-configuration-found">Warning: ‚ÄúNo HTTP configuration found‚Äù</a></h3>
<p><strong>Cause</strong>: Missing <code>http:</code> section</p>
<p><strong>Solution</strong>:</p>
<pre><code class="language-yaml"># Add minimal HTTP config
http:
  port: 3000
  host: "0.0.0.0"
</code></pre>
<h3 id="error-port-already-in-use"><a class="header" href="#error-port-already-in-use">Error: ‚ÄúPort already in use‚Äù</a></h3>
<p><strong>Cause</strong>: Another process is using the configured port</p>
<p><strong>Solution</strong>:</p>
<pre><code class="language-bash"># Find what's using the port
lsof -i :3000

# Kill the process or change the port
# Change port in config:
http:
  port: 3001  # Use different port
</code></pre>
<h3 id="openapi-spec-not-loading"><a class="header" href="#openapi-spec-not-loading">OpenAPI Spec Not Loading</a></h3>
<p><strong>Cause</strong>: File path is incorrect or spec is invalid</p>
<p><strong>Solution</strong>:</p>
<pre><code class="language-bash"># Verify file exists
ls -la examples/openapi.json

# Validate OpenAPI spec at https://editor.swagger.io/
# Or use swagger-cli:
npm install -g @apidevtools/swagger-cli
swagger-cli validate examples/openapi.json
</code></pre>
<h2 id="best-practices-60"><a class="header" href="#best-practices-60">Best Practices</a></h2>
<h3 id="1-use-version-control-1"><a class="header" href="#1-use-version-control-1">1. Use Version Control</a></h3>
<pre><code class="language-bash"># Track your config in Git
git add mockforge.yaml
git commit -m "Add MockForge configuration"
</code></pre>
<h3 id="2-environment-specific-configs"><a class="header" href="#2-environment-specific-configs">2. Environment-Specific Configs</a></h3>
<pre><code class="language-bash"># Create configs for different environments
mockforge.dev.yaml      # Development
mockforge.test.yaml     # Testing
mockforge.prod.yaml     # Production

# Use with:
mockforge serve --config mockforge.dev.yaml
</code></pre>
<h3 id="3-document-custom-settings"><a class="header" href="#3-document-custom-settings">3. Document Custom Settings</a></h3>
<pre><code class="language-yaml">http:
  port: 3000

  # Custom validation override for legacy endpoint
  # TODO: Remove when v2 API is live
  validation_overrides:
    "POST /legacy/users": "off"
</code></pre>
<h3 id="4-start-simple-add-complexity"><a class="header" href="#4-start-simple-add-complexity">4. Start Simple, Add Complexity</a></h3>
<pre><code class="language-yaml"># Start with minimal config
http:
  port: 3000
  openapi_spec: "./api.json"

admin:
  enabled: true

# Add features incrementally:
# 1. Template expansion
# 2. Latency simulation
# 3. Failure injection
# 4. Custom plugins
</code></pre>
<h3 id="5-use-the-complete-template"><a class="header" href="#5-use-the-complete-template">5. Use the Complete Template</a></h3>
<pre><code class="language-bash"># Copy the complete annotated template
cp config.template.yaml mockforge.yaml

# Remove sections you don't need
# Keep comments for reference
</code></pre>
<h2 id="complete-configuration-template-2"><a class="header" href="#complete-configuration-template-2">Complete Configuration Template</a></h2>
<p>See the <a href="https://github.com/SaaSy-Solutions/mockforge/blob/main/config.template.yaml">complete annotated configuration template</a> for all available options with documentation.</p>
<h2 id="validation-roadmap"><a class="header" href="#validation-roadmap">Validation Roadmap</a></h2>
<p>Future versions of MockForge will include:</p>
<ul>
<li><strong>JSON Schema Validation</strong>: Full schema validation for all fields</li>
<li><strong>Field Type Checking</strong>: Validate types, ranges, and formats</li>
<li><strong>Cross-Field Validation</strong>: Check for conflicts between settings</li>
<li><strong>External Resource Validation</strong>: Verify files, URLs, and connections</li>
<li><strong>Deprecation Warnings</strong>: Warn about deprecated options</li>
<li><strong>Migration Assistance</strong>: Auto-migrate old configs to new formats</li>
</ul>
<p>Track progress: <a href="https://github.com/SaaSy-Solutions/mockforge/issues">MockForge Issue #XXX</a></p>
<h2 id="getting-help-2"><a class="header" href="#getting-help-2">Getting Help</a></h2>
<p><strong>Configuration not working as expected?</strong></p>
<ol>
<li>Run <code>mockforge config validate</code> first</li>
<li>Check the <a href="reference/config-schema.html">Configuration Schema Reference</a></li>
<li>Review <a href="https://github.com/SaaSy-Solutions/mockforge/tree/main/examples">example configurations</a></li>
<li>Ask on <a href="https://github.com/SaaSy-Solutions/mockforge/discussions">GitHub Discussions</a></li>
<li>Report bugs at <a href="https://github.com/SaaSy-Solutions/mockforge/issues">GitHub Issues</a></li>
</ol>
<hr />
<p><strong>Pro Tip</strong>: Keep a backup of your working configuration before making significant changes. Use <code>cp mockforge.yaml mockforge.yaml.backup</code> before editing.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="supported-formats"><a class="header" href="#supported-formats">Supported Formats</a></h1>
<p>MockForge supports various data formats for configuration, specifications, and data exchange. This reference documents all supported formats, their usage, and conversion utilities.</p>
<h2 id="openapi-specifications"><a class="header" href="#openapi-specifications">OpenAPI Specifications</a></h2>
<h3 id="json-format-primary"><a class="header" href="#json-format-primary">JSON Format (Primary)</a></h3>
<p>MockForge primarily supports OpenAPI 3.0+ specifications in JSON format:</p>
<pre><code class="language-json">{
  "openapi": "3.0.3",
  "info": {
    "title": "User API",
    "version": "1.0.0"
  },
  "paths": {
    "/users": {
      "get": {
        "summary": "List users",
        "responses": {
          "200": {
            "description": "Success",
            "content": {
              "application/json": {
                "schema": {
                  "type": "array",
                  "items": {
                    "$ref": "#/components/schemas/User"
                  }
                }
              }
            }
          }
        }
      }
    }
  },
  "components": {
    "schemas": {
      "User": {
        "type": "object",
        "properties": {
          "id": {"type": "string"},
          "name": {"type": "string"},
          "email": {"type": "string"}
        }
      }
    }
  }
}
</code></pre>
<h3 id="yaml-format-alternative"><a class="header" href="#yaml-format-alternative">YAML Format (Alternative)</a></h3>
<p>OpenAPI specifications can also be provided in YAML format:</p>
<pre><code class="language-yaml">openapi: 3.0.3
info:
  title: User API
  version: 1.0.0
paths:
  /users:
    get:
      summary: List users
      responses:
        '200':
          description: Success
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: '#/components/schemas/User'
components:
  schemas:
    User:
      type: object
      properties:
        id:
          type: string
        name:
          type: string
        email:
          type: string
</code></pre>
<h3 id="conversion-between-formats"><a class="header" href="#conversion-between-formats">Conversion Between Formats</a></h3>
<pre><code class="language-bash"># Convert JSON to YAML
node -e "
const fs = require('fs');
const yaml = require('js-yaml');
const spec = JSON.parse(fs.readFileSync('api.json', 'utf8'));
fs.writeFileSync('api.yaml', yaml.dump(spec));
"

# Convert YAML to JSON
node -e "
const fs = require('fs');
const yaml = require('js-yaml');
const spec = yaml.load(fs.readFileSync('api.yaml', 'utf8'));
fs.writeFileSync('api.json', JSON.stringify(spec, null, 2));
"
</code></pre>
<h2 id="protocol-buffers-1"><a class="header" href="#protocol-buffers-1">Protocol Buffers</a></h2>
<h3 id="proto-files"><a class="header" href="#proto-files">.proto Files</a></h3>
<p>gRPC services use Protocol Buffer definitions:</p>
<pre><code class="language-protobuf">syntax = "proto3";

package myapp.user;

service UserService {
  rpc GetUser(GetUserRequest) returns (User);
  rpc ListUsers(ListUsersRequest) returns (stream User);
  rpc CreateUser(CreateUserRequest) returns (User);
}

message GetUserRequest {
  string user_id = 1;
}

message User {
  string user_id = 1;
  string name = 2;
  string email = 3;
  google.protobuf.Timestamp created_at = 4;
}

message ListUsersRequest {
  int32 page_size = 1;
  string page_token = 2;
}

message CreateUserRequest {
  string name = 1;
  string email = 2;
}
</code></pre>
<h3 id="generated-code"><a class="header" href="#generated-code">Generated Code</a></h3>
<p>MockForge automatically generates Rust code from <code>.proto</code> files:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Generated code structure
pub mod myapp {
    pub mod user {
        tonic::include_proto!("myapp.user");

        // Generated service trait
        #[tonic::async_trait]
        pub trait UserService: Send + Sync + 'static {
            async fn get_user(
                &amp;self,
                request: tonic::Request&lt;GetUserRequest&gt;,
            ) -&gt; Result&lt;tonic::Response&lt;User&gt;, tonic::Status&gt;;

            async fn list_users(
                &amp;self,
                request: tonic::Request&lt;ListUsersRequest&gt;,
            ) -&gt; Result&lt;tonic::Response&lt;Self::ListUsersStream&gt;, tonic::Status&gt;;
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="websocket-replay-files"><a class="header" href="#websocket-replay-files">WebSocket Replay Files</a></h2>
<h3 id="jsonl-format-1"><a class="header" href="#jsonl-format-1">JSONL Format</a></h3>
<p>WebSocket interactions use JSON Lines format:</p>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"Welcome to chat!","waitFor":"^HELLO$"}
{"ts":1000,"dir":"out","text":"How can I help you?"}
{"ts":2000,"dir":"out","text":"Please wait while I process your request..."}
{"ts":5000,"dir":"out","text":"Here's your response: ..."}
</code></pre>
<h3 id="extended-jsonl-with-templates"><a class="header" href="#extended-jsonl-with-templates">Extended JSONL with Templates</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"Session {{uuid}} started at {{now}}"}
{"ts":1000,"dir":"out","text":"Connected to server {{server_id}}"}
{"ts":2000,"dir":"out","text":"{{#if authenticated}}Welcome back!{{else}}Please authenticate{{/if}}"}
</code></pre>
<h3 id="binary-message-support-2"><a class="header" href="#binary-message-support-2">Binary Message Support</a></h3>
<pre><code class="language-jsonl">{"ts":0,"dir":"out","text":"iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNkYPhfDwAChwGA60e6kgAAAABJRU5ErkJggg==","binary":true}
{"ts":1000,"dir":"out","text":"Image data sent"}
</code></pre>
<h2 id="configuration-files-2"><a class="header" href="#configuration-files-2">Configuration Files</a></h2>
<h3 id="yaml-configuration"><a class="header" href="#yaml-configuration">YAML Configuration</a></h3>
<p>MockForge uses YAML for configuration files:</p>
<pre><code class="language-yaml"># Server configuration
server:
  http_port: 3000
  ws_port: 3001
  grpc_port: 50051

# Validation settings
validation:
  mode: enforce
  aggregate_errors: false

# Response processing
response:
  template_expand: true

# Protocol-specific settings
grpc:
  proto_dir: "proto/"
  enable_reflection: true

websocket:
  replay_file: "examples/demo.jsonl"
</code></pre>
<h3 id="json-configuration-alternative"><a class="header" href="#json-configuration-alternative">JSON Configuration (Alternative)</a></h3>
<p>Configuration can also be provided as JSON:</p>
<pre><code class="language-json">{
  "server": {
    "http_port": 3000,
    "ws_port": 3001,
    "grpc_port": 50051
  },
  "validation": {
    "mode": "enforce",
    "aggregate_errors": false
  },
  "response": {
    "template_expand": true
  },
  "grpc": {
    "proto_dir": "proto/",
    "enable_reflection": true
  },
  "websocket": {
    "replay_file": "examples/demo.jsonl"
  }
}
</code></pre>
<h2 id="data-generation-formats"><a class="header" href="#data-generation-formats">Data Generation Formats</a></h2>
<h3 id="json-output"><a class="header" href="#json-output">JSON Output</a></h3>
<p>Generated test data in JSON format:</p>
<pre><code class="language-json">[
  {
    "id": "550e8400-e29b-41d4-a716-446655440000",
    "name": "John Doe",
    "email": "john.doe@example.com",
    "created_at": "2025-09-12T10:00:00Z"
  },
  {
    "id": "550e8400-e29b-41d4-a716-446655440001",
    "name": "Jane Smith",
    "email": "jane.smith@example.com",
    "created_at": "2025-09-12T11:00:00Z"
  }
]
</code></pre>
<h3 id="yaml-output"><a class="header" href="#yaml-output">YAML Output</a></h3>
<p>Same data in YAML format:</p>
<pre><code class="language-yaml">- id: 550e8400-e29b-41d4-a716-446655440000
  name: John Doe
  email: john.doe@example.com
  created_at: '2025-09-12T10:00:00Z'
- id: 550e8400-e29b-41d4-a716-446655440001
  name: Jane Smith
  email: jane.smith@example.com
  created_at: '2025-09-12T11:00:00Z'
</code></pre>
<h3 id="csv-output"><a class="header" href="#csv-output">CSV Output</a></h3>
<p>Tabular data in CSV format:</p>
<pre><code class="language-csv">id,name,email,created_at
550e8400-e29b-41d4-a716-446655440000,John Doe,john.doe@example.com,2025-09-12T10:00:00Z
550e8400-e29b-41d4-a716-446655440001,Jane Smith,jane.smith@example.com,2025-09-12T11:00:00Z
</code></pre>
<h2 id="log-formats"><a class="header" href="#log-formats">Log Formats</a></h2>
<h3 id="text-format-default"><a class="header" href="#text-format-default">Text Format (Default)</a></h3>
<p>Human-readable log output:</p>
<pre><code>2025-09-12T10:00:00Z INFO mockforge::http: Server started on 0.0.0.0:3000
2025-09-12T10:00:01Z INFO mockforge::http: Request: GET /users
2025-09-12T10:00:01Z DEBUG mockforge::template: Template expanded: {{uuid}} -&gt; 550e8400-e29b-41d4-a716-446655440000
2025-09-12T10:00:01Z INFO mockforge::http: Response: 200 OK
</code></pre>
<h3 id="json-format"><a class="header" href="#json-format">JSON Format</a></h3>
<p>Structured JSON logging:</p>
<pre><code class="language-json">{"timestamp":"2025-09-12T10:00:00Z","level":"INFO","module":"mockforge::http","message":"Server started on 0.0.0.0:3000"}
{"timestamp":"2025-09-12T10:00:01Z","level":"INFO","module":"mockforge::http","message":"Request: GET /users","method":"GET","path":"/users","user_agent":"curl/7.68.0"}
{"timestamp":"2025-09-12T10:00:01Z","level":"DEBUG","module":"mockforge::template","message":"Template expanded","template":"{{uuid}}","result":"550e8400-e29b-41d4-a716-446655440000"}
{"timestamp":"2025-09-12T10:00:01Z","level":"INFO","module":"mockforge::http","message":"Response: 200 OK","status":200,"duration_ms":15}
</code></pre>
<h2 id="template-syntax"><a class="header" href="#template-syntax">Template Syntax</a></h2>
<h3 id="handlebars-templates"><a class="header" href="#handlebars-templates">Handlebars Templates</a></h3>
<p>MockForge uses Handlebars-style templates:</p>
<pre><code class="language-handlebars">{{variable}}
{{object.property}}
{{array.[0]}}
{{#if condition}}content{{/if}}
{{#each items}}{{this}}{{/each}}
{{helper arg1 arg2}}
</code></pre>
<h3 id="built-in-helpers"><a class="header" href="#built-in-helpers">Built-in Helpers</a></h3>
<pre><code class="language-handlebars">&lt;!-- Data generation --&gt;
{{uuid}}                    &lt;!-- Random UUID --&gt;
{{now}}                     &lt;!-- Current timestamp --&gt;
{{now+1h}}                  &lt;!-- Future timestamp --&gt;
{{randInt 1 100}}          &lt;!-- Random integer --&gt;
{{randFloat 0.0 1.0}}      &lt;!-- Random float --&gt;
{{randWord}}               &lt;!-- Random word --&gt;
{{randSentence}}           &lt;!-- Random sentence --&gt;
{{randParagraph}}          &lt;!-- Random paragraph --&gt;

&lt;!-- Request context --&gt;
{{request.path.id}}        &lt;!-- URL path parameter --&gt;
{{request.query.limit}}    &lt;!-- Query parameter --&gt;
{{request.header.auth}}    &lt;!-- HTTP header --&gt;
{{request.body.name}}      &lt;!-- Request body field --&gt;

&lt;!-- Logic helpers --&gt;
{{#if user.authenticated}}
  Welcome back, {{user.name}}!
{{else}}
  Please log in.
{{/if}}

{{#each users}}
  &lt;li&gt;{{name}} - {{email}}&lt;/li&gt;
{{/each}}
</code></pre>
<h2 id="conversion-utilities"><a class="header" href="#conversion-utilities">Conversion Utilities</a></h2>
<h3 id="format-conversion-scripts"><a class="header" href="#format-conversion-scripts">Format Conversion Scripts</a></h3>
<pre><code class="language-bash">#!/bin/bash
# convert-format.sh - Convert between supported formats

input_file=$1
output_format=$2

case $output_format in
    "yaml")
        python3 -c "
import sys, yaml, json
data = json.load(sys.stdin)
yaml.dump(data, sys.stdout, default_flow_style=False)
" &lt; "$input_file"
        ;;
    "json")
        python3 -c "
import sys, yaml, json
data = yaml.safe_load(sys.stdin)
json.dump(data, sys.stdout, indent=2)
" &lt; "$input_file"
        ;;
    "xml")
        python3 -c "
import sys, json, dicttoxml
data = json.load(sys.stdin)
xml = dicttoxml.dicttoxml(data, custom_root='root', attr_type=False)
print(xml.decode())
" &lt; "$input_file"
        ;;
    *)
        echo "Unsupported format: $output_format"
        echo "Supported: yaml, json, xml"
        exit 1
        ;;
esac
</code></pre>
<h3 id="validation-scripts"><a class="header" href="#validation-scripts">Validation Scripts</a></h3>
<pre><code class="language-bash">#!/bin/bash
# validate-format.sh - Validate file formats

file=$1
format=$(basename "$file" | sed 's/.*\.//')

case $format in
    "json")
        python3 -c "
import sys, json
try:
    json.load(sys.stdin)
    print('‚úì Valid JSON')
except Exception as e:
    print('‚úó Invalid JSON:', e)
    sys.exit(1)
" &lt; "$file"
        ;;
    "yaml")
        python3 -c "
import sys, yaml
try:
    yaml.safe_load(sys.stdin)
    print('‚úì Valid YAML')
except Exception as e:
    print('‚úó Invalid YAML:', e)
    sys.exit(1)
" &lt; "$file"
        ;;
    "xml")
        python3 -c "
import sys, xml.etree.ElementTree as ET
try:
    ET.parse(sys.stdin)
    print('‚úì Valid XML')
except Exception as e:
    print('‚úó Invalid XML:', e)
    sys.exit(1)
" &lt; "$file"
        ;;
    *)
        echo "Unsupported format: $format"
        exit 1
        ;;
esac
</code></pre>
<h2 id="best-practices-61"><a class="header" href="#best-practices-61">Best Practices</a></h2>
<h3 id="choosing-the-right-format"><a class="header" href="#choosing-the-right-format">Choosing the Right Format</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Use Case</th><th>Recommended Format</th><th>Reason</th></tr></thead><tbody>
<tr><td>API Specifications</td><td>OpenAPI YAML</td><td>More readable, better for version control</td></tr>
<tr><td>Configuration</td><td>YAML</td><td>Human-readable, supports comments</td></tr>
<tr><td>Data Exchange</td><td>JSON</td><td>Universally supported, compact</td></tr>
<tr><td>Logs</td><td>JSON</td><td>Structured, searchable</td></tr>
<tr><td>Templates</td><td>Handlebars</td><td>Expressive, logic support</td></tr>
</tbody></table>
</div>
<h3 id="format-conversion-workflow"><a class="header" href="#format-conversion-workflow">Format Conversion Workflow</a></h3>
<pre><code class="language-bash"># API development workflow
# 1. Design API in YAML (readable)
swagger-editor

# 2. Convert to JSON for tools that require it
./convert-format.sh api.yaml json &gt; api.json

# 3. Validate both formats
./validate-format.sh api.yaml
./validate-format.sh api.json

# 4. Generate documentation
swagger-codegen generate -i api.yaml -l html -o docs/

# 5. Commit YAML version (better diff)
git add api.yaml
</code></pre>
<h3 id="performance-considerations-6"><a class="header" href="#performance-considerations-6">Performance Considerations</a></h3>
<ul>
<li><strong>JSON</strong>: Fastest parsing, smallest size</li>
<li><strong>YAML</strong>: Slower parsing, larger size, better readability</li>
<li><strong>XML</strong>: Slowest parsing, largest size, most verbose</li>
<li><strong>Binary formats</strong>: Fastest for large data, not human-readable</li>
</ul>
<h3 id="compatibility-matrix"><a class="header" href="#compatibility-matrix">Compatibility Matrix</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Format</th><th>MockForge Support</th><th>Readability</th><th>Tool Support</th><th>Size</th></tr></thead><tbody>
<tr><td>JSON</td><td>‚úÖ Full</td><td>Medium</td><td>Excellent</td><td>Small</td></tr>
<tr><td>YAML</td><td>‚úÖ Full</td><td>High</td><td>Good</td><td>Medium</td></tr>
<tr><td>XML</td><td>‚ùå None</td><td>Low</td><td>Good</td><td>Large</td></tr>
<tr><td>Protocol Buffers</td><td>‚úÖ gRPC only</td><td>Low</td><td>Limited</td><td>Small</td></tr>
<tr><td>JSONL</td><td>‚úÖ WebSocket</td><td>Medium</td><td>Basic</td><td>Medium</td></tr>
</tbody></table>
</div>
<p>This format reference ensures you can work effectively with all data formats supported by MockForge across different use cases and workflows.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="templating-reference"><a class="header" href="#templating-reference">Templating Reference</a></h1>
<p>MockForge supports lightweight templating across HTTP responses, overrides, and (soon) WS/gRPC). This page documents all supported tokens and controls.</p>
<h2 id="enabling"><a class="header" href="#enabling">Enabling</a></h2>
<ul>
<li>Environment: <code>MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true|false</code> (default: false)</li>
<li>Config: <code>http.response_template_expand: true|false</code></li>
<li>CLI: <code>--response-template-expand</code></li>
<li>Determinism: <code>MOCKFORGE_FAKE_TOKENS=false</code> disables faker token expansion.</li>
</ul>
<h2 id="time-tokens"><a class="header" href="#time-tokens">Time Tokens</a></h2>
<ul>
<li><code>{{now}}</code> ‚Äî RFC3339 timestamp.</li>
<li><code>{{now¬±Nd|Nh|Nm|Ns}}</code> ‚Äî Offset from now by Days/Hours/Minutes/Seconds.
<ul>
<li>Examples: <code>{{now+2h}}</code>, <code>{{now-30m}}</code>, <code>{{now+10s}}</code>, <code>{{now-1d}}</code>.</li>
</ul>
</li>
</ul>
<h2 id="random-tokens"><a class="header" href="#random-tokens">Random Tokens</a></h2>
<ul>
<li><code>{{rand.int}}</code> ‚Äî random integer in [0, 1_000_000].</li>
<li><code>{{rand.float}}</code> ‚Äî random float in [0,1).</li>
<li><code>{{randInt a b}}</code> / <code>{{rand.int a b}}</code> ‚Äî random integer between a and b (order-agnostic, negatives allowed).
<ul>
<li>Examples: <code>{{randInt 10 99}}</code>, <code>{{randInt -5 5}}</code>.</li>
</ul>
</li>
</ul>
<h2 id="uuid"><a class="header" href="#uuid">UUID</a></h2>
<ul>
<li><code>{{uuid}}</code> ‚Äî UUID v4.</li>
</ul>
<h2 id="request-data-access-2"><a class="header" href="#request-data-access-2">Request Data Access</a></h2>
<ul>
<li><code>{{request.body.field}}</code> ‚Äî Access fields from request body JSON.
<ul>
<li>Example: <code>{{request.body.name}}</code> extracts the <code>name</code> field from request body.</li>
</ul>
</li>
<li><code>{{request.path.param}}</code> ‚Äî Access path parameters.
<ul>
<li>Example: <code>{{request.path.id}}</code> extracts the <code>id</code> path parameter.</li>
</ul>
</li>
<li><code>{{request.query.param}}</code> ‚Äî Access query parameters.
<ul>
<li>Example: <code>{{request.query.limit}}</code> extracts the <code>limit</code> query parameter.</li>
</ul>
</li>
</ul>
<h2 id="faker-tokens"><a class="header" href="#faker-tokens">Faker Tokens</a></h2>
<p>Faker expansions can be disabled via <code>MOCKFORGE_FAKE_TOKENS=false</code>.</p>
<ul>
<li>Minimal (always available): <code>{{faker.uuid}}</code>, <code>{{faker.email}}</code>, <code>{{faker.name}}</code>.</li>
<li>Extended (when feature <code>data-faker</code> is enabled):
<ul>
<li><code>{{faker.address}}</code>, <code>{{faker.phone}}</code>, <code>{{faker.company}}</code>, <code>{{faker.url}}</code>, <code>{{faker.ip}}</code></li>
<li><code>{{faker.color}}</code>, <code>{{faker.word}}</code>, <code>{{faker.sentence}}</code>, <code>{{faker.paragraph}}</code></li>
</ul>
</li>
</ul>
<h2 id="where-templating-applies"><a class="header" href="#where-templating-applies">Where Templating Applies</a></h2>
<ul>
<li>HTTP (OpenAPI): media-level <code>example</code> bodies and synthesized responses.</li>
<li>HTTP Overrides: YAML patches loaded via <code>validation_overrides</code>.</li>
<li>WS/gRPC: provider is registered now; expansion hooks will be added as features land.</li>
</ul>
<h2 id="status-codes-for-validation-errors"><a class="header" href="#status-codes-for-validation-errors">Status Codes for Validation Errors</a></h2>
<ul>
<li><code>MOCKFORGE_VALIDATION_STATUS=400|422</code> (default 400). Affects HTTP request validation failures in enforce mode.</li>
</ul>
<h2 id="security--determinism-notes"><a class="header" href="#security--determinism-notes">Security &amp; Determinism Notes</a></h2>
<ul>
<li>Tokens inject random/time-based values; disable faker to reduce variability.</li>
<li>For deterministic integration tests, set <code>MOCKFORGE_FAKE_TOKENS=false</code> and prefer explicit literals.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="request-chaining-1"><a class="header" href="#request-chaining-1">Request Chaining</a></h1>
<p>MockForge supports request chaining, which allows you to create complex workflows where requests can depend on responses from previous requests in the chain. This is particularly useful for testing API workflows that require authentication, data flow between endpoints, or multi-step operations.</p>
<h2 id="overview-51"><a class="header" href="#overview-51">Overview</a></h2>
<p>Request chaining enables you to:</p>
<ul>
<li>Execute requests in a predefined sequence with dependencies</li>
<li>Reference data from previous responses using template variables</li>
<li>Extract and store specific values from responses for reuse</li>
<li>Validate response status codes and content</li>
<li>Implement parallel execution for independent requests</li>
<li>Handle complex authentication and authorization flows</li>
</ul>
<h2 id="chain-definition"><a class="header" href="#chain-definition">Chain Definition</a></h2>
<p>Chains are defined using YAML or JSON configuration files with the following structure:</p>
<pre><code class="language-yaml">id: my-chain
name: My Chain
description: A description of what this chain does
config:
  enabled: true
  maxChainLength: 20
  globalTimeoutSecs: 300
  enableParallelExecution: false
links:
  # Define your requests here
  - request:
      id: step1
      method: POST
      url: https://api.example.com/auth/login
      headers:
        Content-Type: application/json
      body:
        username: "testuser"
        password: "password123"
    extract:
      token: body.access_token
    storeAs: login_response
    dependsOn: []
variables:
  base_url: https://api.example.com
tags:
  - authentication
  - workflow
</code></pre>
<h2 id="chain-configuration"><a class="header" href="#chain-configuration">Chain Configuration</a></h2>
<p>The <code>config</code> section controls how the chain behaves:</p>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>enabled</code></td><td>boolean</td><td><code>false</code></td><td>Whether this chain is enabled</td></tr>
<tr><td><code>maxChainLength</code></td><td>integer</td><td><code>20</code></td><td>Maximum number of requests in the chain</td></tr>
<tr><td><code>globalTimeoutSecs</code></td><td>integer</td><td><code>300</code></td><td>Total timeout for chain execution</td></tr>
<tr><td><code>enableParallelExecution</code></td><td>boolean</td><td><code>false</code></td><td>Enable parallel execution of independent requests</td></tr>
</tbody></table>
</div>
<h2 id="request-links"><a class="header" href="#request-links">Request Links</a></h2>
<p>Each link in the chain defines a single HTTP request and its behavior:</p>
<h3 id="request-definition"><a class="header" href="#request-definition">Request Definition</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Required</th><th>Description</th></tr></thead><tbody>
<tr><td><code>id</code></td><td>string</td><td>Yes</td><td>Unique identifier for this request</td></tr>
<tr><td><code>method</code></td><td>string</td><td>Yes</td><td>HTTP method (GET, POST, PUT, DELETE, etc.)</td></tr>
<tr><td><code>url</code></td><td>string</td><td>Yes</td><td>Request URL (supports template variables)</td></tr>
<tr><td><code>headers</code></td><td>object</td><td>No</td><td>Request headers</td></tr>
<tr><td><code>body</code></td><td>any</td><td>No</td><td>Request body (supports template variables)</td></tr>
<tr><td><code>dependsOn</code></td><td>array</td><td>No</td><td>List of request IDs this request depends on</td></tr>
<tr><td><code>timeoutSecs</code></td><td>number</td><td>No</td><td>Individual request timeout</td></tr>
<tr><td><code>expectedStatus</code></td><td>array</td><td>No</td><td>Expected status codes for validation</td></tr>
</tbody></table>
</div>
<h3 id="response-processing-1"><a class="header" href="#response-processing-1">Response Processing</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Required</th><th>Description</th></tr></thead><tbody>
<tr><td><code>extract</code></td><td>object</td><td>No</td><td>Extract values from response into variables</td></tr>
<tr><td><code>storeAs</code></td><td>string</td><td>No</td><td>Store entire response with this name</td></tr>
</tbody></table>
</div>
<h2 id="template-variables-4"><a class="header" href="#template-variables-4">Template Variables</a></h2>
<p>Chain requests support powerful templating that can reference:</p>
<h3 id="previous-response-data"><a class="header" href="#previous-response-data">Previous Response Data</a></h3>
<p>Use <code>{{chain.&lt;response_name&gt;.&lt;path&gt;}}</code> to reference data from previous responses:</p>
<pre><code class="language-yaml">url: https://api.example.com/users/{{chain.login_response.body.user_id}}/posts
headers:
  Authorization: "Bearer {{chain.auth_response.body.access_token}}"
</code></pre>
<h3 id="variable-extraction"><a class="header" href="#variable-extraction">Variable Extraction</a></h3>
<p>Extract values from responses into reusable variables:</p>
<pre><code class="language-yaml">extract:
  user_id: body.user.id
  token: body.access_token
storeAs: user_response
</code></pre>
<h3 id="built-in-template-functions-1"><a class="header" href="#built-in-template-functions-1">Built-in Template Functions</a></h3>
<p>All standard MockForge templating functions are available:</p>
<ul>
<li><code>{{uuid}}</code> - Random UUID</li>
<li><code>{{faker.email}}</code> - Fake email address</li>
<li><code>{{faker.name}}</code> - Fake name</li>
<li><code>{{rand.int}}</code> - Random integer</li>
<li><code>{{now}}</code> - Current timestamp</li>
</ul>
<h2 id="advanced-features-8"><a class="header" href="#advanced-features-8">Advanced Features</a></h2>
<h3 id="dependency-resolution"><a class="header" href="#dependency-resolution">Dependency Resolution</a></h3>
<p>Requests can depend on other requests using the <code>dependsOn</code> field. MockForge automatically resolves dependencies using topological sorting:</p>
<pre><code class="language-yaml">links:
  - request:
      id: login
      method: POST
      url: https://api.example.com/auth/login
      body:
        username: "user"
        password: "pass"
    storeAs: auth

  - request:
      id: get_profile
      method: GET
      url: https://api.example.com/user/profile
      headers:
        Authorization: "Bearer {{chain.auth.body.token}}"
    dependsOn:
      - login
</code></pre>
<h3 id="parallel-execution"><a class="header" href="#parallel-execution">Parallel Execution</a></h3>
<p>Enable <code>enableParallelExecution: true</code> to allow independent requests to run simultaneously:</p>
<pre><code class="language-yaml">config:
  enableParallelExecution: true
links:
  - request:
      id: get_profile
      method: GET
      url: https://api.example.com/profile
    dependsOn:
      - login

  - request:
      id: get_preferences
      method: GET
      url: https://api.example.com/preferences
    dependsOn:
      - login
  # These two requests will run in parallel
</code></pre>
<h3 id="response-validation-1"><a class="header" href="#response-validation-1">Response Validation</a></h3>
<p>Validate response status codes and content:</p>
<pre><code class="language-yaml">links:
  - request:
      id: create_user
      method: POST
      url: https://api.example.com/users
      body:
        name: "John Doe"
    expectedStatus: [201, 202]  # Expect 201 or 202 status codes
</code></pre>
<h2 id="json-path-support"><a class="header" href="#json-path-support">JSON Path Support</a></h2>
<p>Chain templating supports JSON path syntax for accessing nested data:</p>
<h3 id="simple-properties"><a class="header" href="#simple-properties">Simple Properties</a></h3>
<pre><code class="language-yaml">extract:
  user_id: body.id
  name: body.profile.name
</code></pre>
<h3 id="array-access"><a class="header" href="#array-access">Array Access</a></h3>
<pre><code class="language-yaml">extract:
  first_user: body.users.[0].name
  user_count: body.users.[*]  # Get array length
</code></pre>
<h3 id="complex-nesting"><a class="header" href="#complex-nesting">Complex Nesting</a></h3>
<pre><code class="language-yaml">url: https://api.example.com/users/{{chain.login_response.body.user.id}}/projects/{{chain.project_response.body.data.[0].id}}
</code></pre>
<h2 id="response-function-new-ui-feature"><a class="header" href="#response-function-new-ui-feature">Response Function (New UI Feature)</a></h2>
<p>MockForge also supports a <code>response()</code> function for use in the Admin UI and other editing contexts:</p>
<h3 id="syntax"><a class="header" href="#syntax">Syntax</a></h3>
<pre><code class="language-javascript">response('request_name', 'json_path')
</code></pre>
<h3 id="examples-19"><a class="header" href="#examples-19">Examples</a></h3>
<pre><code class="language-javascript">// Simple usage
response('login', 'body.user_id')

// Complex JSON path
response('user_profile', 'body.data.employee.name')

// Environment variable usage
let userId = response('login', 'body.user_id');
let updateUrl = `/users/${userId}/profile`;
</code></pre>
<h3 id="ui-integration"><a class="header" href="#ui-integration">UI Integration</a></h3>
<ol>
<li><strong>Autocomplete</strong>: Type <code>response(</code> in any input field in the UI and use Ctrl+Space for autocomplete</li>
<li><strong>Configuration Dialog</strong>: Click the blue template tag next to the function to open the configuration dialog</li>
<li><strong>Request Selection</strong>: Choose from available requests in the current chain</li>
<li><strong>Path Specification</strong>: Enter the JSONPath to extract the desired value</li>
</ol>
<h2 id="prepost-request-scripting"><a class="header" href="#prepost-request-scripting">Pre/Post Request Scripting</a></h2>
<p>MockForge supports JavaScript scripting for complex request processing and data manipulation in request chains.</p>
<h3 id="enable-scripting"><a class="header" href="#enable-scripting">Enable Scripting</a></h3>
<p>Add scripting configuration to any request in your chain:</p>
<pre><code class="language-yaml">links:
  - request:
      id: process_data
      method: POST
      url: https://api.example.com/process
      scripting:
        pre_script: |
          // Execute before request
          console.log('Processing request with mockforge context');
          console.log('Request URL:', mockforge.request.url);

          if (mockforge.variables.skip_processing) {
            request.body.skip_processing = true;
          }
        post_script: |
          // Execute after request
          console.log('Request completed in', mockforge.response.duration_ms, 'ms');

          if (mockforge.response.status === 429) {
            throw new Error('Rate limited - retry needed');
          }

          // Store custom data for next request
          setVariable('processed_user_id', mockforge.response.body.user_id);
        runtime: javascript
        timeout_ms: 5000
</code></pre>
<h3 id="pre-scripts"><a class="header" href="#pre-scripts">Pre-Scripts</a></h3>
<p>Executed before the HTTP request:</p>
<pre><code class="language-javascript">// Available context in mockforge object:
mockforge.request     // Current request (id, method, url, headers)
mockforge.chain       // Previous responses: mockforge.chain.login.body.user_id
mockforge.variables   // Chain variables
mockforge.env         // Environment variables

// Direct access to functions:
console.log('Starting request processing');

// Modify request before it goes out
if (mockforge.variables.enable_debug) {
  request.headers['X-Debug'] = 'true';
  request.body.debug_mode = true;
}

// Set variables for this request
setVariable('request_start_time', Date.now());

// Example: Add authentication from previous response
request.headers['Authorization'] = 'Bearer ' + mockforge.chain.login.body.token;
</code></pre>
<h3 id="post-scripts"><a class="header" href="#post-scripts">Post-Scripts</a></h3>
<p>Executed after the HTTP response:</p>
<pre><code class="language-javascript">// Available context in mockforge object:
mockforge.response    // Current response (status, headers, body, duration_ms)
mockforge.request     // Original request
mockforge.chain       // Previous responses
mockforge.variables   // Chain variables
mockforge.env         // Environment variables

// Example: Validate response and extract data
if (mockforge.response.status !== 200) {
  throw new Error('Request failed with status ' + mockforge.response.status);
}

// Extract and store data for next requests
setVariable('user_profile', mockforge.response.body);
setVariable('session_cookie', mockforge.response.headers['Set-Cookie']);

// Example: Transform response data
if (mockforge.response.body &amp;&amp; mockforge.response.body.user) {
  mockforge.response.body.processed_user = {
    fullName: mockforge.response.body.user.first_name + ' ' + mockforge.response.body.user.last_name,
    age: mockforge.response.body.user.age,
    isActive: mockforge.response.body.user.status === 'active'
  };
}
</code></pre>
<h3 id="built-in-functions"><a class="header" href="#built-in-functions">Built-in Functions</a></h3>
<h4 id="logging-and-diagnostics"><a class="header" href="#logging-and-diagnostics">Logging and Diagnostics</a></h4>
<pre><code class="language-javascript">console.log('Debug message:', mockforge.request.url);
console.warn('Warning:', mockforge.response.status);
console.error('Error occurred');
</code></pre>
<h4 id="variable-management"><a class="header" href="#variable-management">Variable Management</a></h4>
<pre><code class="language-javascript">// Set a variable for use in next requests
setVariable('api_token', mockforge.response.body.token);

// Access environment variables
const configUrl = mockforge.env['API_CONFIG_URL'];
</code></pre>
<h4 id="data-validation"><a class="header" href="#data-validation">Data Validation</a></h4>
<pre><code class="language-javascript">// Simple assertions
assert(mockforge.response.status === 200, 'Expected status 200');

// Complex validation
if (!mockforge.response.body || !mockforge.response.body.items) {
  throw new Error('Response missing required "items" field');
}

if (mockforge.response.body.items.length === 0) {
  console.warn('Response contains empty items array');
}
</code></pre>
<h3 id="error-handling-12"><a class="header" href="#error-handling-12">Error Handling</a></h3>
<p>Scripts can throw errors to fail the chain:</p>
<pre><code class="language-javascript">if (mockforge.response.status &gt;= 400) {
  throw new Error('HTTP ' + mockforge.response.status + ': ' + mockforge.response.body.error);
}

if (mockforge.response.duration_ms &gt; 30000) {
  throw new Error('Request took too long: ' + mockforge.response.duration_ms + 'ms');
}
</code></pre>
<h3 id="security-and-isolation"><a class="header" href="#security-and-isolation">Security and Isolation</a></h3>
<ul>
<li><strong>Timeout Protection</strong>: Scripts are limited by <code>timeout_ms</code> (default: 5 seconds)</li>
<li><strong>Sandboxing</strong>: Scripts run in isolated JavaScript contexts</li>
<li><strong>Resource Limits</strong>: CPU and memory usage is monitored and limited</li>
<li><strong>Network Restrictions</strong>: Scripts cannot make outbound network calls</li>
<li><strong>File System Access</strong>: Read-only file access through <code>fs.readFile()</code> function</li>
</ul>
<h3 id="best-practices-62"><a class="header" href="#best-practices-62">Best Practices</a></h3>
<ol>
<li><strong>Keep Scripts Simple</strong>: Break complex logic into smaller, focused scripts</li>
<li><strong>Validate Inputs</strong>: Always check that expected data exists before processing</li>
<li><strong>Set Appropriate Timeouts</strong>: Use shorter timeouts for simple scripts</li>
<li><strong>Use Environment Variables</strong>: Store configuration in environment variables</li>
<li><strong>Error Handling</strong>: Always check for error conditions and fail fast when needed</li>
<li><strong>Documentation</strong>: Comment complex business logic in your scripts</li>
<li><strong>Testing</strong>: Test scripts with various response scenarios</li>
</ol>
<h3 id="environment-variables-20"><a class="header" href="#environment-variables-20">Environment Variables</a></h3>
<p>For multiple uses of the same response value, store it in an environment variable:</p>
<pre><code class="language-javascript">// In environment variables
RESPONSE_USER_ID = response('login', 'body.user_id')

// Then use in multiple places
let url1 = `/users/${RESPONSE_USER_ID}`;
let url2 = `/profile/${RESPONSE_USER_ID}`;
</code></pre>
<h3 id="benefits-over-traditional-templates"><a class="header" href="#benefits-over-traditional-templates">Benefits Over Traditional Templates</a></h3>
<ul>
<li><strong>Cleaner Syntax</strong>: More readable than <code>{{chain.request_name.body.path}}</code></li>
<li><strong>Type Safety</strong>: JSONPath validation in the UI</li>
<li><strong>Better UX</strong>: Visual configuration through dialogs</li>
<li><strong>Autocomplete</strong>: Intelligent suggestions for request names and paths</li>
</ul>
<h2 id="error-handling-13"><a class="header" href="#error-handling-13">Error Handling</a></h2>
<p>Chains provide comprehensive error handling:</p>
<ul>
<li><strong>Dependency errors</strong>: Missing or invalid dependencies</li>
<li><strong>Circular dependencies</strong>: Automatic detection and prevention</li>
<li><strong>Timeout errors</strong>: Individual and global timeouts</li>
<li><strong>Status validation</strong>: Expected status code validation</li>
<li><strong>Network errors</strong>: Connection and HTTP errors</li>
</ul>
<h2 id="chain-management"><a class="header" href="#chain-management">Chain Management</a></h2>
<p>Chains can be managed programmatically or via configuration files:</p>
<h3 id="loading-chains"><a class="header" href="#loading-chains">Loading Chains</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_core::RequestChainRegistry;

let registry = RequestChainRegistry::new(chain_config);
// Load from YAML
registry.register_from_yaml(yaml_content).await?;
// Load from JSON
registry.register_from_json(json_content).await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="executing-chains"><a class="header" href="#executing-chains">Executing Chains</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_core::ChainExecutionEngine;

let engine = ChainExecutionEngine::new(registry, config);
// Execute a chain
let result = engine.execute_chain("my-chain").await?;
println!("Chain executed in {}ms", result.total_duration_ms);
<span class="boring">}</span></code></pre></pre>
<h2 id="complete-example-2"><a class="header" href="#complete-example-2">Complete Example</a></h2>
<p>See the provided examples in the <code>examples/</code> directory:</p>
<ul>
<li><code>examples/chain-example.yaml</code> - Comprehensive user management workflow</li>
<li><code>examples/simple-chain.json</code> - Simple authentication chain</li>
</ul>
<h2 id="working-with-large-values"><a class="header" href="#working-with-large-values">Working With Large Values</a></h2>
<p>MockForge provides several strategies to handle large values efficiently without affecting performance or crashing the user interface. The system automatically hides large text values by default, but extremely large values can still impact performance.</p>
<h3 id="file-system-template-functions"><a class="header" href="#file-system-template-functions">File System Template Functions</a></h3>
<p>MockForge supports the <code>fs.readFile()</code> template function for reading file contents directly into templates. This is particularly useful for including large text content within structured data.</p>
<p><strong>Syntax:</strong></p>
<pre><code class="language-yaml">{{fs.readFile "path/to/file.txt"}}
{{fs.readFile('path/to/file.txt')}}
</code></pre>
<p><strong>Example usage in request chaining:</strong></p>
<pre><code class="language-yaml">links:
  - request:
      id: upload_large_data
      method: POST
      url: https://api.example.com/upload
      headers:
        Content-Type: application/json
      body:
        metadata:
          filename: "large_document.txt"
          size: 1048576
        content: "{{fs.readFile('/path/to/large/file.txt')}}"
</code></pre>
<p><strong>Error handling:</strong></p>
<ul>
<li>If the file doesn‚Äôt exist: <code>&lt;fs.readFile error: No such file or directory (os error 2)&gt;</code></li>
<li>If the path is empty: <code>&lt;fs.readFile: empty path&gt;</code></li>
</ul>
<h3 id="binary-file-request-bodies"><a class="header" href="#binary-file-request-bodies">Binary File Request Bodies</a></h3>
<p>For truly large binary files (images, videos, documents), MockForge supports binary file request bodies that reference files on disk rather than loading them into memory.</p>
<p><strong>YAML Configuration:</strong></p>
<pre><code class="language-yaml">links:
  - request:
      id: upload_image
      method: POST
      url: https://api.example.com/upload
      body:
        type: binary_file
        data:
          path: "/path/to/image.jpg"
          content_type: "image/jpeg"
</code></pre>
<p><strong>JSON Configuration:</strong></p>
<pre><code class="language-json">{
  "id": "upload_image",
  "method": "POST",
  "url": "https://api.example.com/upload",
  "body": {
    "type": "binary_file",
    "data": {
      "path": "/path/to/image.jpg",
      "content_type": "image/jpeg"
    }
  }
}
</code></pre>
<p><strong>Key Features:</strong></p>
<ul>
<li><strong>Path templating</strong>: File paths support template expansion (e.g., <code>"{{chain.previous_response.body.file_path}}"</code>)</li>
<li><strong>Content type</strong>: Optional content-type header (defaults to none for binary files)</li>
<li><strong>Memory efficient</strong>: Files are read only when the request is executed</li>
<li><strong>Error handling</strong>: Clear error messages for missing files</li>
</ul>
<h3 id="performance-best-practices"><a class="header" href="#performance-best-practices">Performance Best Practices</a></h3>
<ol>
<li><strong>Use binary_file for large binary content</strong> (images, videos, large documents)</li>
<li><strong>Use fs.readFile for large text content</strong> within structured JSON/XML bodies</li>
<li><strong>Template file paths</strong> to make configurations dynamic</li>
<li><strong>Validate file paths</strong> before running chains to avoid runtime errors</li>
<li><strong>Consider file size limits</strong> based on your system‚Äôs memory constraints</li>
</ol>
<h2 id="best-practices-63"><a class="header" href="#best-practices-63">Best Practices</a></h2>
<ol>
<li><strong>Keep chains focused</strong>: Each chain should have a single, clear purpose</li>
<li><strong>Use meaningful IDs</strong>: Choose descriptive names for requests and chains</li>
<li><strong>Handle dependencies carefully</strong>: Ensure dependency chains are logical and avoid cycles</li>
<li><strong>Validate responses</strong>: Use <code>expectedStatus</code> and <code>extract</code> for critical paths</li>
<li><strong>Use parallel execution</strong>: Enable for independent requests to improve performance</li>
<li><strong>Template effectively</strong>: Leverage chain context variables for dynamic content</li>
<li><strong>Error handling</strong>: Plan for failure scenarios in your chains</li>
<li><strong>Handle large values efficiently</strong>: Use <code>fs.readFile()</code> for large text content and <code>binary_file</code> request bodies for large binary files to maintain performance</li>
</ol>
<h2 id="limitations-3"><a class="header" href="#limitations-3">Limitations</a></h2>
<ul>
<li>Maximum chain length is configurable (default: 20 requests)</li>
<li>Global execution timeout applies to entire chain</li>
<li>Circular dependencies are automatically prevented</li>
<li>Parallel execution requires careful dependency management</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="fixtures-and-smoke-testing"><a class="header" href="#fixtures-and-smoke-testing">Fixtures and Smoke Testing</a></h1>
<p>MockForge supports recording and replaying HTTP requests and responses as fixtures, which can be used for smoke testing your APIs.</p>
<h2 id="recording-fixtures"><a class="header" href="#recording-fixtures">Recording Fixtures</a></h2>
<p>To record fixtures, enable recording by setting the environment variable:</p>
<pre><code>MOCKFORGE_RECORD_ENABLED=true
</code></pre>
<p>By default, all HTTP requests will be recorded. To record only GET requests, set:</p>
<pre><code>MOCKFORGE_RECORD_GET_ONLY=true
</code></pre>
<p>Fixtures are saved in the <code>fixtures</code> directory by default. You can change this location with:</p>
<pre><code>MOCKFORGE_FIXTURES_DIR=/path/to/fixtures
</code></pre>
<h2 id="replay-fixtures"><a class="header" href="#replay-fixtures">Replay Fixtures</a></h2>
<p>To replay recorded fixtures, enable replay by setting the environment variable:</p>
<pre><code>MOCKFORGE_REPLAY_ENABLED=true
</code></pre>
<p>When replay is enabled, MockForge will serve recorded responses for matching requests instead of generating new ones.</p>
<h2 id="ready-to-run-fixtures"><a class="header" href="#ready-to-run-fixtures">Ready-to-Run Fixtures</a></h2>
<p>Fixtures can be marked as ‚Äúready-to-run‚Äù for smoke testing by adding a metadata field <code>smoke_test</code> with the value <code>true</code>. These fixtures will be listed in the smoke test endpoints.</p>
<p>Example fixture with smoke test metadata:</p>
<pre><code class="language-json">{
  "fingerprint": {
    "method": "GET",
    "path": "/api/users",
    "query_params": {},
    "headers": {}
  },
  "timestamp": "2024-01-15T10:30:00Z",
  "status_code": 200,
  "response_headers": {
    "content-type": "application/json"
  },
  "response_body": "{\"users\": []}",
  "metadata": {
    "smoke_test": "true",
    "name": "Get Users Endpoint"
  }
}
</code></pre>
<h2 id="smoke-testing"><a class="header" href="#smoke-testing">Smoke Testing</a></h2>
<p>MockForge provides endpoints to list and run smoke tests:</p>
<ul>
<li><code>GET /__mockforge/smoke</code> - List available smoke test endpoints</li>
<li><code>GET /__mockforge/smoke/run</code> - Run all smoke tests</li>
</ul>
<p>These endpoints are also available in the Admin UI under the ‚ÄúSmoke Tests‚Äù tab.</p>
<h2 id="admin-ui-integration"><a class="header" href="#admin-ui-integration">Admin UI Integration</a></h2>
<p>The Admin UI provides a graphical interface for managing fixtures and running smoke tests:</p>
<ol>
<li>View all recorded fixtures in the ‚ÄúFixtures‚Äù tab</li>
<li>Mark fixtures as ready-to-run for smoke testing</li>
<li>Run smoke tests with a single click</li>
<li>View smoke test results and status</li>
</ol>
<h2 id="configuration-37"><a class="header" href="#configuration-37">Configuration</a></h2>
<p>The following environment variables control fixture and smoke test behavior:</p>
<h3 id="core-settings"><a class="header" href="#core-settings">Core Settings</a></h3>
<ul>
<li><code>MOCKFORGE_FIXTURES_DIR</code> - Directory where fixtures are stored (default: <code>./fixtures</code>)</li>
<li><code>MOCKFORGE_RECORD_ENABLED</code> - Enable recording of requests (default: <code>false</code>)</li>
<li><code>MOCKFORGE_REPLAY_ENABLED</code> - Enable replay of recorded requests (default: <code>false</code>)</li>
</ul>
<h3 id="recording-options"><a class="header" href="#recording-options">Recording Options</a></h3>
<ul>
<li><code>MOCKFORGE_RECORD_GET_ONLY</code> - Record only GET requests (default: <code>false</code>)</li>
<li><code>MOCKFORGE_LATENCY_ENABLED</code> - Include latency in recorded fixtures (default: <code>true</code>)</li>
<li><code>MOCKFORGE_RESPONSE_TEMPLATE_EXPAND</code> - Expand templates when recording (default: <code>false</code>)</li>
</ul>
<h3 id="validation-and-testing-1"><a class="header" href="#validation-and-testing-1">Validation and Testing</a></h3>
<ul>
<li><code>MOCKFORGE_REQUEST_VALIDATION</code> - Validation level during recording (default: <code>enforce</code>)</li>
<li><code>MOCKFORGE_RESPONSE_VALIDATION</code> - Validate responses during replay (default: <code>false</code>)</li>
</ul>
<h3 id="configuration-file-support"><a class="header" href="#configuration-file-support">Configuration File Support</a></h3>
<p>You can also configure fixtures through YAML:</p>
<pre><code class="language-yaml"># In your configuration file
core:
  fixtures:
    dir: "./fixtures"
    record_enabled: false
    replay_enabled: false
    record_get_only: false
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="troubleshooting-61"><a class="header" href="#troubleshooting-61">Troubleshooting</a></h1>
<p>This guide helps you diagnose and resolve common issues with MockForge. If you‚Äôre experiencing problems, follow the steps below to identify and fix the issue.</p>
<h2 id="quick-diagnosis"><a class="header" href="#quick-diagnosis">Quick Diagnosis</a></h2>
<h3 id="check-server-status"><a class="header" href="#check-server-status">Check Server Status</a></h3>
<p>First, verify that MockForge is running and accessible:</p>
<pre><code class="language-bash"># Check if processes are running
ps aux | grep mockforge

# Check listening ports
netstat -tlnp | grep -E ":(3000|3001|50051|9080)"

# Test basic connectivity
curl -I http://localhost:3000/health 2&gt;/dev/null || echo "HTTP server not responding"
curl -I http://localhost:9080/health 2&gt;/dev/null || echo "Admin UI not responding"
</code></pre>
<h3 id="check-logs"><a class="header" href="#check-logs">Check Logs</a></h3>
<p>Enable verbose logging to see detailed information:</p>
<pre><code class="language-bash"># Run with debug logging
RUST_LOG=mockforge=debug mockforge serve --spec api-spec.yaml

# View recent logs
tail -f mockforge.log

# Filter logs by component
grep "ERROR" mockforge.log
grep "WARN" mockforge.log
</code></pre>
<h2 id="http-api-issues"><a class="header" href="#http-api-issues">HTTP API Issues</a></h2>
<h3 id="server-wont-start-2"><a class="header" href="#server-wont-start-2">Server Won‚Äôt Start</a></h3>
<p><strong>Symptoms</strong>: <code>mockforge serve</code> exits immediately with error</p>
<p><strong>Common causes and solutions</strong>:</p>
<ol>
<li>
<p><strong>Port already in use</strong>:</p>
<pre><code class="language-bash"># Find what's using the port
lsof -i :3000

# Kill conflicting process
kill -9 &lt;PID&gt;

# Or use different port
mockforge serve --http-port 3001
</code></pre>
</li>
<li>
<p><strong>Invalid OpenAPI specification</strong>:</p>
<pre><code class="language-bash"># Validate YAML syntax
yamllint api-spec.yaml

# Validate OpenAPI structure
swagger-cli validate api-spec.yaml

# Test with minimal spec
mockforge serve --spec examples/openapi-demo.json
</code></pre>
</li>
<li>
<p><strong>File permissions</strong>:</p>
<pre><code class="language-bash"># Check file access
ls -la api-spec.yaml

# Fix permissions if needed
chmod 644 api-spec.yaml
</code></pre>
</li>
</ol>
<h3 id="404-errors-for-valid-routes"><a class="header" href="#404-errors-for-valid-routes">404 Errors for Valid Routes</a></h3>
<p><strong>Symptoms</strong>: API returns 404 for endpoints that should exist</p>
<p><strong>Possible causes</strong>:</p>
<ol>
<li>
<p><strong>OpenAPI spec not loaded correctly</strong>:</p>
<pre><code class="language-bash"># Check if spec was loaded
grep "OpenAPI spec loaded" mockforge.log

# Verify file path
ls -la api-spec.yaml
</code></pre>
</li>
<li>
<p><strong>Path matching issues</strong>:</p>
<ul>
<li>Ensure paths in spec match request URLs</li>
<li>Check for trailing slashes</li>
<li>Verify HTTP methods match</li>
</ul>
</li>
<li>
<p><strong>Template expansion disabled</strong>:</p>
<pre><code class="language-bash"># Enable template expansion
mockforge serve --response-template-expand --spec api-spec.yaml
</code></pre>
</li>
</ol>
<h3 id="template-variables-not-working-1"><a class="header" href="#template-variables-not-working-1">Template Variables Not Working</a></h3>
<p><strong>Symptoms</strong>: <code>{{variable}}</code> appears literally in responses</p>
<p><strong>Solutions</strong>:</p>
<ol>
<li>
<p><strong>Enable template expansion</strong>:</p>
<pre><code class="language-bash"># Via command line
mockforge serve --response-template-expand --spec api-spec.yaml

# Via environment variable
MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true mockforge serve --spec api-spec.yaml

# Via config file
echo "response:\n  template_expand: true" &gt; config.yaml
mockforge serve --config config.yaml --spec api-spec.yaml
</code></pre>
</li>
<li>
<p><strong>Check template syntax</strong>:</p>
<ul>
<li>Use <code>{{variable}}</code> not <code>${variable}</code></li>
<li>Ensure variables are defined in spec examples</li>
<li>Check for typos in variable names</li>
</ul>
</li>
</ol>
<h3 id="validation-errors-3"><a class="header" href="#validation-errors-3">Validation Errors</a></h3>
<p><strong>Symptoms</strong>: Requests return 400/422 with validation errors</p>
<p><strong>Solutions</strong>:</p>
<ol>
<li>
<p><strong>Adjust validation mode</strong>:</p>
<pre><code class="language-bash"># Disable validation
mockforge serve --validation off --spec api-spec.yaml

# Use warning mode
mockforge serve --validation warn --spec api-spec.yaml
</code></pre>
</li>
<li>
<p><strong>Fix request format</strong>:</p>
<ul>
<li>Ensure Content-Type header matches request body format</li>
<li>Verify required fields are present</li>
<li>Check parameter formats match OpenAPI spec</li>
</ul>
</li>
</ol>
<h2 id="websocket-issues"><a class="header" href="#websocket-issues">WebSocket Issues</a></h2>
<h3 id="connection-fails"><a class="header" href="#connection-fails">Connection Fails</a></h3>
<p><strong>Symptoms</strong>: WebSocket client cannot connect</p>
<p><strong>Common causes</strong>:</p>
<ol>
<li>
<p><strong>Wrong port or path</strong>:</p>
<pre><code class="language-bash"># Check WebSocket port
netstat -tlnp | grep :3001

# Test connection
websocat ws://localhost:3001/ws
</code></pre>
</li>
<li>
<p><strong>Replay file not found</strong>:</p>
<pre><code class="language-bash"># Check file exists
ls -la ws-replay.jsonl

# Run without replay file
mockforge serve --ws-port 3001  # No replay file specified
</code></pre>
</li>
</ol>
<h3 id="messages-not-received-1"><a class="header" href="#messages-not-received-1">Messages Not Received</a></h3>
<p><strong>Symptoms</strong>: WebSocket connection established but no messages</p>
<p><strong>Solutions</strong>:</p>
<ol>
<li>
<p><strong>Check replay file format</strong>:</p>
<pre><code class="language-bash"># Validate JSONL syntax
node -e "
const fs = require('fs');
const lines = fs.readFileSync('ws-replay.jsonl', 'utf8').split('\n');
lines.forEach((line, i) =&gt; {
  if (line.trim()) {
    try { JSON.parse(line); }
    catch (e) { console.log(\`Line \${i+1}: \${e.message}\`); }
  }
});
"
</code></pre>
</li>
<li>
<p><strong>Verify message timing</strong>:</p>
<ul>
<li>Check <code>ts</code> values are in milliseconds</li>
<li>Ensure messages have required fields (<code>ts</code>, <code>dir</code>, <code>text</code>)</li>
</ul>
</li>
</ol>
<h3 id="interactive-mode-issues"><a class="header" href="#interactive-mode-issues">Interactive Mode Issues</a></h3>
<p><strong>Symptoms</strong>: Client messages not triggering responses</p>
<p><strong>Debug steps</strong>:</p>
<ol>
<li>
<p><strong>Check regex patterns</strong>:</p>
<pre><code class="language-bash"># Test regex patterns
node -e "
const pattern = '^HELLO';
const test = 'HELLO world';
console.log('Match:', test.match(new RegExp(pattern)));
"
</code></pre>
</li>
<li>
<p><strong>Verify state management</strong>:</p>
<ul>
<li>Check that state variables are properly set</li>
<li>Ensure conditional logic is correct</li>
</ul>
</li>
</ol>
<h2 id="grpc-issues"><a class="header" href="#grpc-issues">gRPC Issues</a></h2>
<h3 id="service-not-found"><a class="header" href="#service-not-found">Service Not Found</a></h3>
<p><strong>Symptoms</strong>: <code>grpcurl list</code> shows no services</p>
<p><strong>Solutions</strong>:</p>
<ol>
<li>
<p><strong>Check proto directory</strong>:</p>
<pre><code class="language-bash"># Verify proto files exist
find proto/ -name "*.proto"

# Check directory path
MOCKFORGE_PROTO_DIR=proto/ mockforge serve --grpc-port 50051
</code></pre>
</li>
<li>
<p><strong>Compilation errors</strong>:</p>
<pre><code class="language-bash"># Check for proto compilation errors
cargo build --verbose 2&gt;&amp;1 | grep -i proto
</code></pre>
</li>
<li>
<p><strong>Reflection disabled</strong>:</p>
<pre><code class="language-bash"># Enable gRPC reflection
MOCKFORGE_GRPC_REFLECTION_ENABLED=true mockforge serve --grpc-port 50051
</code></pre>
</li>
</ol>
<h3 id="method-calls-fail"><a class="header" href="#method-calls-fail">Method Calls Fail</a></h3>
<p><strong>Symptoms</strong>: gRPC calls return errors</p>
<p><strong>Debug steps</strong>:</p>
<ol>
<li>
<p><strong>Check service definition</strong>:</p>
<pre><code class="language-bash"># List service methods
grpcurl -plaintext localhost:50051 describe mockforge.user.UserService
</code></pre>
</li>
<li>
<p><strong>Validate request format</strong>:</p>
<pre><code class="language-bash"># Test with verbose output
grpcurl -plaintext -v -d '{"user_id": "123"}' localhost:50051 mockforge.user.UserService/GetUser
</code></pre>
</li>
<li>
<p><strong>Check proto compatibility</strong>:</p>
<ul>
<li>Ensure client and server use same proto definitions</li>
<li>Verify message field names and types match</li>
</ul>
</li>
</ol>
<h2 id="admin-ui-issues"><a class="header" href="#admin-ui-issues">Admin UI Issues</a></h2>
<h3 id="ui-not-loading"><a class="header" href="#ui-not-loading">UI Not Loading</a></h3>
<p><strong>Symptoms</strong>: Browser shows connection error</p>
<p><strong>Solutions</strong>:</p>
<ol>
<li>
<p><strong>Check admin port</strong>:</p>
<pre><code class="language-bash"># Verify port is listening
curl -I http://localhost:9080 2&gt;/dev/null || echo "Admin UI not accessible"

# Try different port
mockforge serve --admin --admin-port 9090
</code></pre>
</li>
<li>
<p><strong>CORS issues</strong>:</p>
<ul>
<li>Admin UI should work from any origin by default</li>
<li>Check browser console for CORS errors</li>
</ul>
</li>
<li>
<p><strong>Embedded vs standalone</strong>:</p>
<pre><code class="language-bash"># Force standalone mode
mockforge serve --admin --admin-standalone

# Or embedded mode
mockforge serve --admin --admin-embed
</code></pre>
</li>
</ol>
<h3 id="api-endpoints-not-working"><a class="header" href="#api-endpoints-not-working">API Endpoints Not Working</a></h3>
<p><strong>Symptoms</strong>: UI loads but API calls fail</p>
<p><strong>Solutions</strong>:</p>
<ol>
<li>
<p><strong>Check admin API</strong>:</p>
<pre><code class="language-bash"># Test admin API directly
curl http://localhost:9080/__mockforge/status
</code></pre>
</li>
<li>
<p><strong>Enable admin API</strong>:</p>
<pre><code class="language-bash"># Ensure admin API is not disabled
mockforge serve --admin  # Don't use --disable-admin-api
</code></pre>
</li>
</ol>
<h2 id="configuration-issues"><a class="header" href="#configuration-issues">Configuration Issues</a></h2>
<h3 id="config-file-not-loading"><a class="header" href="#config-file-not-loading">Config File Not Loading</a></h3>
<p><strong>Symptoms</strong>: Settings from config file are ignored</p>
<p><strong>Solutions</strong>:</p>
<ol>
<li>
<p><strong>Validate YAML syntax</strong>:</p>
<pre><code class="language-bash"># Check YAML format
python3 -c "import yaml; yaml.safe_load(open('config.yaml'))"

# Or use yamllint
yamllint config.yaml
</code></pre>
</li>
<li>
<p><strong>Check file path</strong>:</p>
<pre><code class="language-bash"># Use absolute path
mockforge serve --config /full/path/to/config.yaml

# Verify file permissions
ls -la config.yaml
</code></pre>
</li>
<li>
<p><strong>Environment variable override</strong>:</p>
<ul>
<li>Remember that environment variables override config file settings</li>
<li>Command-line arguments override both</li>
</ul>
</li>
</ol>
<h3 id="environment-variables-not-working"><a class="header" href="#environment-variables-not-working">Environment Variables Not Working</a></h3>
<p><strong>Symptoms</strong>: Environment variables are ignored</p>
<p><strong>Common issues</strong>:</p>
<ol>
<li>
<p><strong>Shell not reloaded</strong>:</p>
<pre><code class="language-bash"># Export variable and reload shell
export MOCKFORGE_HTTP_PORT=3001
exec $SHELL
</code></pre>
</li>
<li>
<p><strong>Variable name typos</strong>:</p>
<pre><code class="language-bash"># Check variable is set
echo $MOCKFORGE_HTTP_PORT

# List all MockForge variables
env | grep MOCKFORGE
</code></pre>
</li>
</ol>
<h2 id="performance-issues-6"><a class="header" href="#performance-issues-6">Performance Issues</a></h2>
<h3 id="high-memory-usage"><a class="header" href="#high-memory-usage">High Memory Usage</a></h3>
<p><strong>Symptoms</strong>: MockForge consumes excessive memory</p>
<p><strong>Solutions</strong>:</p>
<ol>
<li>
<p><strong>Reduce concurrent connections</strong>:</p>
<pre><code class="language-bash"># Limit connection pool
MOCKFORGE_MAX_CONNECTIONS=100 mockforge serve
</code></pre>
</li>
<li>
<p><strong>Disable unnecessary features</strong>:</p>
<pre><code class="language-bash"># Run with minimal features
mockforge serve --validation off --response-template-expand false
</code></pre>
</li>
<li>
<p><strong>Monitor resource usage</strong>:</p>
<pre><code class="language-bash"># Check memory usage
ps aux | grep mockforge

# Monitor over time
htop -p $(pgrep mockforge)
</code></pre>
</li>
</ol>
<h3 id="slow-response-times"><a class="header" href="#slow-response-times">Slow Response Times</a></h3>
<p><strong>Symptoms</strong>: API responses are slow</p>
<p><strong>Debug steps</strong>:</p>
<ol>
<li>
<p><strong>Enable latency logging</strong>:</p>
<pre><code class="language-bash">RUST_LOG=mockforge=debug mockforge serve --spec api-spec.yaml 2&gt;&amp;1 | grep -i latency
</code></pre>
</li>
<li>
<p><strong>Check template complexity</strong>:</p>
<ul>
<li>Complex templates can slow response generation</li>
<li>Consider caching for frequently used templates</li>
</ul>
</li>
<li>
<p><strong>Profile performance</strong>:</p>
<pre><code class="language-bash"># Use cargo flamegraph for profiling
cargo flamegraph --bin mockforge-cli -- serve --spec api-spec.yaml
</code></pre>
</li>
</ol>
<h2 id="docker-issues"><a class="header" href="#docker-issues">Docker Issues</a></h2>
<h3 id="container-wont-start"><a class="header" href="#container-wont-start">Container Won‚Äôt Start</a></h3>
<p><strong>Symptoms</strong>: Docker container exits immediately</p>
<p><strong>Solutions</strong>:</p>
<ol>
<li>
<p><strong>Check container logs</strong>:</p>
<pre><code class="language-bash">docker logs &lt;container-id&gt;

# Run with verbose output
docker run --rm mockforge mockforge serve --spec api-spec.yaml
</code></pre>
</li>
<li>
<p><strong>Volume mounting issues</strong>:</p>
<pre><code class="language-bash"># Ensure spec file is accessible
docker run -v $(pwd)/api-spec.yaml:/app/api-spec.yaml \
  mockforge mockforge serve --spec /app/api-spec.yaml
</code></pre>
</li>
<li>
<p><strong>Port conflicts</strong>:</p>
<pre><code class="language-bash"># Use different ports
docker run -p 3001:3000 -p 3002:3001 mockforge
</code></pre>
</li>
</ol>
<h3 id="port-already-in-use-1"><a class="header" href="#port-already-in-use-1">Port Already in Use</a></h3>
<p><strong>Symptoms</strong>: Container fails to start with ‚Äúaddress already in use‚Äù error</p>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Check what's using the ports
netstat -tlnp | grep :3000
# Or on macOS:
lsof -i :3000

# Use different ports
docker run -p 3001:3000 -p 3002:3001 mockforge

# Or in docker-compose.yml
services:
  mockforge:
    ports:
      - "3001:3000"  # Map host 3001 to container 3000
      - "3002:3001"  # Map host 3002 to container 3001
</code></pre>
<h3 id="permission-issues"><a class="header" href="#permission-issues">Permission Issues</a></h3>
<p><strong>Symptoms</strong>: Container can‚Äôt read/write mounted volumes</p>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Fix volume permissions (Linux)
sudo chown -R 1000:1000 fixtures/
sudo chown -R 1000:1000 logs/

# Or run container as your user
docker run --user $(id -u):$(id -g) \
  -v $(pwd)/fixtures:/app/fixtures \
  mockforge

# macOS typically doesn't need permission fixes
</code></pre>
<h3 id="build-issues"><a class="header" href="#build-issues">Build Issues</a></h3>
<p><strong>Symptoms</strong>: Docker build fails or takes too long</p>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Clear Docker cache
docker system prune -a

# Rebuild without cache
docker build --no-cache -t mockforge .

# Check disk space
df -h

# Remove unused images
docker image prune -a
</code></pre>
<h3 id="container-performance-issues"><a class="header" href="#container-performance-issues">Container Performance Issues</a></h3>
<p><strong>Symptoms</strong>: Slow response times in Docker</p>
<p><strong>Solutions</strong>:</p>
<ol>
<li>
<p><strong>Increase resources</strong> (Docker Desktop):</p>
<ul>
<li>Settings ‚Üí Resources ‚Üí Memory: Increase to 4GB+</li>
<li>Settings ‚Üí Resources ‚Üí CPUs: Increase to 2+</li>
</ul>
</li>
<li>
<p><strong>Reduce logging verbosity</strong>:</p>
<pre><code class="language-bash">docker run -e RUST_LOG=info mockforge
# Instead of RUST_LOG=debug
</code></pre>
</li>
<li>
<p><strong>Use Docker volumes instead of bind mounts</strong> for better performance:</p>
<pre><code class="language-yaml">volumes:
  - mockforge-data:/app/data  # Named volume (faster)
  # Instead of:
  # - ./data:/app/data       # Bind mount (slower on macOS/Windows)
</code></pre>
</li>
</ol>
<h3 id="networking-issues"><a class="header" href="#networking-issues">Networking Issues</a></h3>
<p><strong>Symptoms</strong>: Can‚Äôt connect to MockForge from other containers</p>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Use Docker network
docker network create mockforge-net

docker run --network mockforge-net --name mockforge \
  -p 3000:3000 mockforge

# Other containers on same network can access via:
# http://mockforge:3000
</code></pre>
<p>In <code>docker-compose.yml</code>:</p>
<pre><code class="language-yaml">services:
  mockforge:
    networks:
      - app-network

  frontend:
    environment:
      API_URL: http://mockforge:3000
    networks:
      - app-network

networks:
  app-network:
    driver: bridge
</code></pre>
<h2 id="getting-help-3"><a class="header" href="#getting-help-3">Getting Help</a></h2>
<h3 id="log-analysis-2"><a class="header" href="#log-analysis-2">Log Analysis</a></h3>
<pre><code class="language-bash"># Extract error patterns
grep "ERROR" mockforge.log | head -10

# Find recent issues
tail -100 mockforge.log | grep -E "(ERROR|WARN)"

# Count error types
grep "ERROR" mockforge.log | sed 's/.*ERROR //' | sort | uniq -c | sort -nr
</code></pre>
<h3 id="debug-commands-5"><a class="header" href="#debug-commands-5">Debug Commands</a></h3>
<pre><code class="language-bash"># Full system information
echo "=== System Info ==="
uname -a
echo "=== Rust Version ==="
rustc --version
echo "=== Cargo Version ==="
cargo --version
echo "=== Running Processes ==="
ps aux | grep mockforge
echo "=== Listening Ports ==="
netstat -tlnp | grep -E ":(3000|3001|50051|9080)"
echo "=== Disk Space ==="
df -h
echo "=== Memory Usage ==="
free -h
</code></pre>
<h3 id="community-support"><a class="header" href="#community-support">Community Support</a></h3>
<p>If you can‚Äôt resolve the issue:</p>
<ol>
<li><strong>Check existing issues</strong>: Search GitHub issues for similar problems</li>
<li><strong>Create a minimal reproduction</strong>: Isolate the issue with minimal configuration</li>
<li><strong>Include debug information</strong>: Attach logs, configuration, and system details</li>
<li><strong>Use descriptive titles</strong>: Clearly describe the problem in issue titles</li>
</ol>
<h3 id="emergency-stop"><a class="header" href="#emergency-stop">Emergency Stop</a></h3>
<p>If MockForge is causing issues:</p>
<pre><code class="language-bash"># Kill all MockForge processes
pkill -f mockforge

# Kill specific process
kill -9 &lt;mockforge-pid&gt;

# Clean up any leftover files
rm -f mockforge.log
</code></pre>
<p>This troubleshooting guide covers the most common issues. For more specific problems, check the logs and consider creating an issue on GitHub with detailed information about your setup and the problem you‚Äôre experiencing.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="common-issues--solutions"><a class="header" href="#common-issues--solutions">Common Issues &amp; Solutions</a></h1>
<p>This guide addresses the most frequently encountered issues when using MockForge and provides quick solutions.</p>
<h2 id="server-issues"><a class="header" href="#server-issues">Server Issues</a></h2>
<h3 id="port-already-in-use-2"><a class="header" href="#port-already-in-use-2">Port Already in Use</a></h3>
<p><strong>Problem</strong>: <code>Error: Address already in use (os error 98)</code></p>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Find what's using the port
lsof -i :3000
# On Windows: netstat -ano | findstr :3000

# Kill the process
kill -9 &lt;PID&gt;

# Or use a different port
mockforge serve --spec api.json --http-port 3001
</code></pre>
<p><strong>Prevention</strong>: Check ports before starting:</p>
<pre><code class="language-bash"># Quick check script
ports=(3000 3001 9080 50051)
for port in "${ports[@]}"; do
  if lsof -i :$port &gt; /dev/null; then
    echo "Port $port is in use"
  fi
end
</code></pre>
<h3 id="server-wont-start-3"><a class="header" href="#server-wont-start-3">Server Won‚Äôt Start</a></h3>
<p><strong>Problem</strong>: MockForge exits immediately or fails silently</p>
<p><strong>Debugging Steps</strong>:</p>
<ol>
<li><strong>Check configuration</strong></li>
</ol>
<pre><code class="language-bash"># Validate config file
mockforge config validate --config mockforge.yaml
</code></pre>
<ol start="2">
<li><strong>Check logs</strong></li>
</ol>
<pre><code class="language-bash"># Enable verbose logging
RUST_LOG=debug mockforge serve --spec api.json 2&gt;&amp;1 | tee mockforge.log
</code></pre>
<ol start="3">
<li><strong>Test with minimal config</strong></li>
</ol>
<pre><code class="language-bash"># Start with just the spec
mockforge serve --spec examples/openapi-demo.json --http-port 3000
</code></pre>
<ol start="4">
<li><strong>Check file permissions</strong></li>
</ol>
<pre><code class="language-bash">ls -la api.json mockforge.yaml
chmod 644 api.json mockforge.yaml
</code></pre>
<h2 id="template--data-issues"><a class="header" href="#template--data-issues">Template &amp; Data Issues</a></h2>
<h3 id="template-variables-not-expanding-2"><a class="header" href="#template-variables-not-expanding-2">Template Variables Not Expanding</a></h3>
<p><strong>Problem</strong>: <code>{{uuid}}</code> appears literally in responses instead of generating UUIDs</p>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Enable template expansion via environment variable
MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true mockforge serve --spec api.json

# Or via config file
# mockforge.yaml
http:
  response_template_expand: true

# Or via CLI flag
mockforge serve --spec api.json --response-template-expand
</code></pre>
<p><strong>Common Mistake</strong>: Forgetting that template expansion is opt-in for security reasons.</p>
<h3 id="faker-functions-not-working-1"><a class="header" href="#faker-functions-not-working-1">Faker Functions Not Working</a></h3>
<p><strong>Problem</strong>: <code>{{faker.name}}</code> not generating fake data</p>
<p><strong>Solutions</strong>:</p>
<ol>
<li><strong>Enable template expansion</strong> (see above)</li>
<li><strong>Check faker function name</strong>: Use lowercase, e.g., <code>{{faker.name}}</code> not <code>{{Faker.Name}}</code></li>
<li><strong>Install faker if required</strong>: Some advanced faker features may require additional setup</li>
</ol>
<p><strong>Valid faker functions</strong>:</p>
<ul>
<li><code>{{faker.name}}</code> - Person name</li>
<li><code>{{faker.email}}</code> - Email address</li>
<li><code>{{faker.address}}</code> - Street address</li>
<li><code>{{faker.phone}}</code> - Phone number</li>
<li><code>{{faker.company}}</code> - Company name</li>
</ul>
<p>See <a href="reference/templating.html">Templating Reference</a> for complete list.</p>
<h3 id="invalid-datetimestamp-format"><a class="header" href="#invalid-datetimestamp-format">Invalid Date/Timestamp Format</a></h3>
<p><strong>Problem</strong>: <code>{{now}}</code> generates invalid date format</p>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-yaml"># Use proper format in OpenAPI spec
properties:
  createdAt:
    type: string
    format: date-time  # Important!
    example: "{{now}}"
</code></pre>
<p><strong>Alternative</strong>: Use custom format</p>
<pre><code class="language-json">{
  "timestamp": "{{now | date:'%Y-%m-%d'}}"
}
</code></pre>
<h2 id="openapi-spec-issues"><a class="header" href="#openapi-spec-issues">OpenAPI Spec Issues</a></h2>
<h3 id="spec-not-loading"><a class="header" href="#spec-not-loading">Spec Not Loading</a></h3>
<p><strong>Problem</strong>: <code>Error: Failed to parse OpenAPI specification</code></p>
<p><strong>Solutions</strong>:</p>
<ol>
<li><strong>Validate spec syntax</strong></li>
</ol>
<pre><code class="language-bash"># Using swagger-cli
swagger-cli validate api.json

# Or online
# https://editor.swagger.io/
</code></pre>
<ol start="2">
<li><strong>Check file format</strong></li>
</ol>
<pre><code class="language-bash"># JSON
cat api.json | jq .

# YAML
yamllint api.yaml
</code></pre>
<ol start="3">
<li><strong>Check OpenAPI version</strong></li>
</ol>
<pre><code class="language-json">{
  "openapi": "3.0.3",  // Not "3.0" or "swagger": "2.0"
  ...
}
</code></pre>
<ol start="4">
<li><strong>Resolve JSON schema references</strong></li>
</ol>
<pre><code class="language-bash"># Use json-schema-ref-resolver if needed
npm install -g json-schema-ref-resolver
json-schema-ref-resolver api.json &gt; resolved-api.json
</code></pre>
<h3 id="404-for-valid-routes"><a class="header" href="#404-for-valid-routes">404 for Valid Routes</a></h3>
<p><strong>Problem</strong>: Endpoints return 404 even though they exist in the spec</p>
<p><strong>Debugging</strong>:</p>
<ol>
<li><strong>Check path matching</strong></li>
</ol>
<pre><code class="language-bash"># Verify paths don't have trailing slashes mismatch
# Spec: /users (should match request: GET /users)
curl http://localhost:3000/users  # ‚úÖ
curl http://localhost:3000/users/ # ‚ùå May not match
</code></pre>
<ol start="2">
<li><strong>Check HTTP method</strong></li>
</ol>
<pre><code class="language-bash"># Ensure method matches spec
# Spec defines GET but you're using POST
curl -X GET http://localhost:3000/users  # ‚úÖ
curl -X POST http://localhost:3000/users # ‚ùå May not match
</code></pre>
<ol start="3">
<li><strong>Enable debug logging</strong></li>
</ol>
<pre><code class="language-bash">RUST_LOG=mockforge_http=debug mockforge serve --spec api.json
</code></pre>
<h2 id="cors-issues"><a class="header" href="#cors-issues">CORS Issues</a></h2>
<h3 id="cors-errors-in-browser"><a class="header" href="#cors-errors-in-browser">CORS Errors in Browser</a></h3>
<p><strong>Problem</strong>: <code>Access to fetch at 'http://localhost:3000/users' from origin 'http://localhost:3001' has been blocked by CORS policy</code></p>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-yaml"># mockforge.yaml
http:
  cors:
    enabled: true
    allowed_origins:
      - "http://localhost:3000"
      - "http://localhost:3001"
      - "http://localhost:5173"  # Vite default
    allowed_methods: ["GET", "POST", "PUT", "DELETE", "PATCH", "OPTIONS"]
    allowed_headers: ["Content-Type", "Authorization"]
</code></pre>
<p><strong>Or via environment variable</strong>:</p>
<pre><code class="language-bash">MOCKFORGE_CORS_ENABLED=true \
MOCKFORGE_CORS_ALLOWED_ORIGINS="http://localhost:3001,http://localhost:5173" \
mockforge serve --spec api.json
</code></pre>
<p><strong>Debugging</strong>: Check browser console for exact CORS error message - it will tell you which header is missing.</p>
<h2 id="validation-issues"><a class="header" href="#validation-issues">Validation Issues</a></h2>
<h3 id="valid-requests-getting-rejected"><a class="header" href="#valid-requests-getting-rejected">Valid Requests Getting Rejected</a></h3>
<p><strong>Problem</strong>: Requests return 422/400 even though they look correct</p>
<p><strong>Solutions</strong>:</p>
<ol>
<li><strong>Check validation mode</strong></li>
</ol>
<pre><code class="language-bash"># Use 'warn' instead of 'enforce' for development
MOCKFORGE_REQUEST_VALIDATION=warn mockforge serve --spec api.json
</code></pre>
<ol start="2">
<li><strong>Check Content-Type header</strong></li>
</ol>
<pre><code class="language-bash"># Ensure Content-Type matches spec
curl -X POST http://localhost:3000/users \
  -H "Content-Type: application/json" \
  -d '{"name": "John"}'
</code></pre>
<ol start="3">
<li><strong>Check required fields</strong></li>
</ol>
<pre><code class="language-bash"># Spec may require fields you're not sending
# Check spec for 'required' array
</code></pre>
<ol start="4">
<li><strong>Validate request body structure</strong></li>
</ol>
<pre><code class="language-bash"># Use Admin UI to see exact request received
# Visit http://localhost:9080 to inspect requests
</code></pre>
<h3 id="validation-too-strict"><a class="header" href="#validation-too-strict">Validation Too Strict</a></h3>
<p><strong>Problem</strong>: Validation rejects requests that should be valid</p>
<p><strong>Solutions</strong>:</p>
<ol>
<li><strong>Temporarily disable validation</strong></li>
</ol>
<pre><code class="language-bash">mockforge serve --spec api.json --validation off
</code></pre>
<ol start="2">
<li><strong>Fix spec if it‚Äôs incorrect</strong></li>
</ol>
<pre><code class="language-json">// Spec might mark optional fields as required
"properties": {
  "name": { "type": "string" },
  "email": { "type": "string" }
},
"required": []  // Empty array = all optional
</code></pre>
<h2 id="websocket-issues-1"><a class="header" href="#websocket-issues-1">WebSocket Issues</a></h2>
<h3 id="connection-refused-3"><a class="header" href="#connection-refused-3">Connection Refused</a></h3>
<p><strong>Problem</strong>: WebSocket connection fails immediately</p>
<p><strong>Solutions</strong>:</p>
<ol>
<li><strong>Check WebSocket port</strong></li>
</ol>
<pre><code class="language-bash"># Verify port is open
netstat -tlnp | grep :3001
</code></pre>
<ol start="2">
<li><strong>Check replay file exists</strong></li>
</ol>
<pre><code class="language-bash"># Ensure file path is correct
ls -la ws-replay.jsonl
MOCKFORGE_WS_REPLAY_FILE=./ws-replay.jsonl mockforge serve --ws-port 3001
</code></pre>
<ol start="3">
<li><strong>Check WebSocket enabled</strong></li>
</ol>
<pre><code class="language-bash"># Ensure WebSocket server is started
mockforge serve --ws-port 3001  # Explicit port needed
</code></pre>
<h3 id="messages-not-received-2"><a class="header" href="#messages-not-received-2">Messages Not Received</a></h3>
<p><strong>Problem</strong>: WebSocket connects but no messages arrive</p>
<p><strong>Solutions</strong>:</p>
<ol>
<li><strong>Check replay file format</strong></li>
</ol>
<pre><code class="language-bash"># Validate JSONL syntax
cat ws-replay.jsonl | jq -r '.'  # Should parse each line as JSON
</code></pre>
<ol start="2">
<li><strong>Check message timing</strong></li>
</ol>
<pre><code class="language-json">// Replay file format
{"ts": 0, "dir": "out", "text": "Welcome"}
{"ts": 1000, "dir": "out", "text": "Next message"}
</code></pre>
<ol start="3">
<li><strong>Check waitFor patterns</strong></li>
</ol>
<pre><code class="language-json">// Ensure regex patterns match
{"waitFor": "^CLIENT_READY$", "text": "Acknowledged"}
</code></pre>
<h2 id="configuration-issues-1"><a class="header" href="#configuration-issues-1">Configuration Issues</a></h2>
<h3 id="config-file-not-found"><a class="header" href="#config-file-not-found">Config File Not Found</a></h3>
<p><strong>Problem</strong>: <code>Error: Configuration file not found</code></p>
<p><strong>Solutions</strong>:</p>
<ol>
<li><strong>Use absolute path</strong></li>
</ol>
<pre><code class="language-bash">mockforge serve --config /full/path/to/mockforge.yaml
</code></pre>
<ol start="2">
<li><strong>Check file name</strong></li>
</ol>
<pre><code class="language-bash"># Valid names
mockforge.yaml
mockforge.yml
.mockforge.yaml
.mockforge.yml
mockforge.config.ts
mockforge.config.js
</code></pre>
<ol start="3">
<li><strong>Check current directory</strong></li>
</ol>
<pre><code class="language-bash">pwd
ls -la mockforge.yaml
</code></pre>
<h3 id="environment-variables-not-applied"><a class="header" href="#environment-variables-not-applied">Environment Variables Not Applied</a></h3>
<p><strong>Problem</strong>: Environment variables seem to be ignored</p>
<p><strong>Solutions</strong>:</p>
<ol>
<li><strong>Check variable names</strong></li>
</ol>
<pre><code class="language-bash"># Correct format: MOCKFORGE_&lt;SECTION&gt;_&lt;OPTION&gt;
MOCKFORGE_HTTP_PORT=3000       # ‚úÖ
MOCKFORGE_PORT=3000            # ‚ùå Wrong
</code></pre>
<ol start="2">
<li><strong>Check shell reload</strong></li>
</ol>
<pre><code class="language-bash"># Export and verify
export MOCKFORGE_HTTP_PORT=3000
echo $MOCKFORGE_HTTP_PORT  # Should show 3000

# Or use inline
MOCKFORGE_HTTP_PORT=3000 mockforge serve --spec api.json
</code></pre>
<ol start="3">
<li><strong>Check precedence</strong></li>
</ol>
<pre><code class="language-bash"># CLI flags override env vars
mockforge serve --spec api.json --http-port 3001
# Even if MOCKFORGE_HTTP_PORT=3000, port will be 3001
</code></pre>
<h2 id="performance-issues-7"><a class="header" href="#performance-issues-7">Performance Issues</a></h2>
<h3 id="slow-response-times-1"><a class="header" href="#slow-response-times-1">Slow Response Times</a></h3>
<p><strong>Problem</strong>: API responses are slow</p>
<p><strong>Solutions</strong>:</p>
<ol>
<li><strong>Disable template expansion if not needed</strong></li>
</ol>
<pre><code class="language-bash"># Template expansion adds overhead
mockforge serve --spec api.json  # No templates = faster
</code></pre>
<ol start="2">
<li><strong>Reduce validation overhead</strong></li>
</ol>
<pre><code class="language-bash"># Validation adds latency
mockforge serve --spec api.json --validation warn  # Faster than 'enforce'
</code></pre>
<ol start="3">
<li><strong>Check response complexity</strong></li>
</ol>
<pre><code class="language-bash"># Large responses or complex templates slow things down
# Consider simplifying responses for development
</code></pre>
<ol start="4">
<li><strong>Monitor resource usage</strong></li>
</ol>
<pre><code class="language-bash"># Check CPU/memory
top -p $(pgrep mockforge)
</code></pre>
<h3 id="high-memory-usage-1"><a class="header" href="#high-memory-usage-1">High Memory Usage</a></h3>
<p><strong>Problem</strong>: MockForge consumes too much memory</p>
<p><strong>Solutions</strong>:</p>
<ol>
<li><strong>Limit connection pool</strong></li>
</ol>
<pre><code class="language-bash">MOCKFORGE_MAX_CONNECTIONS=100 mockforge serve --spec api.json
</code></pre>
<ol start="2">
<li><strong>Disable features not needed</strong></li>
</ol>
<pre><code class="language-bash"># Minimal configuration
mockforge serve --spec api.json \
  --validation off \
  --response-template-expand false \
  --admin false
</code></pre>
<ol start="3">
<li><strong>Check for memory leaks</strong></li>
</ol>
<pre><code class="language-bash"># Monitor over time
watch -n 1 'ps aux | grep mockforge | grep -v grep'
</code></pre>
<h2 id="docker-issues-1"><a class="header" href="#docker-issues-1">Docker Issues</a></h2>
<h3 id="container-exits-immediately"><a class="header" href="#container-exits-immediately">Container Exits Immediately</a></h3>
<p><strong>Problem</strong>: Docker container starts then immediately stops</p>
<p><strong>Solutions</strong>:</p>
<ol>
<li><strong>Check logs</strong></li>
</ol>
<pre><code class="language-bash">docker logs &lt;container-id&gt;
docker logs -f &lt;container-id&gt;  # Follow logs
</code></pre>
<ol start="2">
<li><strong>Run interactively</strong></li>
</ol>
<pre><code class="language-bash">docker run -it --rm mockforge mockforge serve --spec api.json
</code></pre>
<ol start="3">
<li><strong>Check volume mounts</strong></li>
</ol>
<pre><code class="language-bash"># Ensure spec file is accessible
docker run -v $(pwd)/api.json:/app/api.json \
  mockforge mockforge serve --spec /app/api.json
</code></pre>
<h3 id="port-mapping-issues"><a class="header" href="#port-mapping-issues">Port Mapping Issues</a></h3>
<p><strong>Problem</strong>: Can‚Äôt access MockForge from host</p>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Proper port mapping
docker run -p 3000:3000 -p 9080:9080 mockforge

# Verify ports are exposed
docker port &lt;container-id&gt;
</code></pre>
<h3 id="permission-issues-1"><a class="header" href="#permission-issues-1">Permission Issues</a></h3>
<p><strong>Problem</strong>: Can‚Äôt read/write mounted volumes</p>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Fix permissions
sudo chown -R 1000:1000 ./fixtures ./logs

# Or run as specific user
docker run --user $(id -u):$(id -g) \
  -v $(pwd)/fixtures:/app/fixtures \
  mockforge
</code></pre>
<h2 id="admin-ui-issues-1"><a class="header" href="#admin-ui-issues-1">Admin UI Issues</a></h2>
<h3 id="admin-ui-not-loading"><a class="header" href="#admin-ui-not-loading">Admin UI Not Loading</a></h3>
<p><strong>Problem</strong>: Can‚Äôt access http://localhost:9080</p>
<p><strong>Solutions</strong>:</p>
<ol>
<li><strong>Enable admin UI</strong></li>
</ol>
<pre><code class="language-bash">mockforge serve --spec api.json --admin --admin-port 9080
</code></pre>
<ol start="2">
<li><strong>Check port</strong></li>
</ol>
<pre><code class="language-bash"># Verify port is listening
curl http://localhost:9080
netstat -tlnp | grep :9080
</code></pre>
<ol start="3">
<li><strong>Try different port</strong></li>
</ol>
<pre><code class="language-bash">mockforge serve --spec api.json --admin --admin-port 9090
# Access at http://localhost:9090
</code></pre>
<h3 id="admin-api-not-working"><a class="header" href="#admin-api-not-working">Admin API Not Working</a></h3>
<p><strong>Problem</strong>: Admin UI loads but API calls fail</p>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Test admin API directly
curl http://localhost:9080/__mockforge/status

# Enable admin API explicitly
mockforge serve --spec api.json --admin --admin-api-enabled
</code></pre>
<h2 id="plugin-issues-1"><a class="header" href="#plugin-issues-1">Plugin Issues</a></h2>
<h3 id="plugin-wont-load-1"><a class="header" href="#plugin-wont-load-1">Plugin Won‚Äôt Load</a></h3>
<p><strong>Problem</strong>: <code>Error: Failed to load plugin</code></p>
<p><strong>Solutions</strong>:</p>
<ol>
<li><strong>Check plugin format</strong></li>
</ol>
<pre><code class="language-bash"># Validate WASM file
file plugin.wasm  # Should show: WebAssembly

# Check plugin manifest
mockforge plugin validate plugin.wasm
</code></pre>
<ol start="2">
<li><strong>Check permissions</strong></li>
</ol>
<pre><code class="language-bash"># Ensure plugin file is readable
chmod 644 plugin.wasm
</code></pre>
<ol start="3">
<li><strong>Check compatibility</strong></li>
</ol>
<pre><code class="language-bash"># Plugin may be for different MockForge version
mockforge --version
# Check plugin requirements
</code></pre>
<h3 id="plugin-crashes"><a class="header" href="#plugin-crashes">Plugin Crashes</a></h3>
<p><strong>Problem</strong>: Plugin causes MockForge to crash</p>
<p><strong>Solutions</strong>:</p>
<ol>
<li><strong>Check plugin logs</strong></li>
</ol>
<pre><code class="language-bash">RUST_LOG=mockforge_plugin=debug mockforge serve --plugin ./plugin.wasm
</code></pre>
<ol start="2">
<li><strong>Check resource limits</strong></li>
</ol>
<pre><code class="language-yaml"># plugin.yaml
capabilities:
  resources:
    max_memory_bytes: 67108864  # 64MB
    max_cpu_time_ms: 5000      # 5 seconds
</code></pre>
<h2 id="getting-more-help"><a class="header" href="#getting-more-help">Getting More Help</a></h2>
<p>If none of these solutions work:</p>
<ol>
<li><strong>Collect debug information</strong></li>
</ol>
<pre><code class="language-bash"># System info
uname -a
rustc --version
mockforge --version

# Check logs
RUST_LOG=debug mockforge serve --spec api.json 2&gt;&amp;1 | tee debug.log

# Test with minimal config
mockforge serve --spec examples/openapi-demo.json --http-port 3000
</code></pre>
<ol start="2">
<li>
<p><strong>Search existing issues</strong></p>
<ul>
<li>Check <a href="https://github.com/SaaSy-Solutions/mockforge/issues">GitHub Issues</a></li>
<li>Search for similar problems</li>
</ul>
</li>
<li>
<p><strong>Create minimal reproduction</strong></p>
<ul>
<li>Create smallest possible config that reproduces issue</li>
<li>Include OpenAPI spec (if relevant)</li>
<li>Include error logs</li>
</ul>
</li>
<li>
<p><strong>Open GitHub issue</strong></p>
<ul>
<li>Use descriptive title</li>
<li>Include system info, version, logs</li>
<li>Attach minimal reproduction</li>
</ul>
</li>
</ol>
<hr />
<p><strong>See Also</strong>:</p>
<ul>
<li><a href="reference/troubleshooting.html">Troubleshooting Guide</a> - Detailed diagnostic steps</li>
<li><a href="reference/faq.html">FAQ</a> - Common questions and answers</li>
<li><a href="reference/../configuration/files.html">Configuration Reference</a> - All configuration options</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="frequently-asked-questions-faq"><a class="header" href="#frequently-asked-questions-faq">Frequently Asked Questions (FAQ)</a></h1>
<p>Quick answers to common questions about MockForge.</p>
<h2 id="general-questions"><a class="header" href="#general-questions">General Questions</a></h2>
<h3 id="what-is-mockforge-1"><a class="header" href="#what-is-mockforge-1">What is MockForge?</a></h3>
<p>MockForge is a comprehensive multi-protocol mocking framework for APIs. It allows you to create realistic mock servers for HTTP/REST, gRPC, WebSocket, and GraphQL without writing code. Perfect for frontend development, integration testing, and parallel team development.</p>
<h3 id="is-mockforge-free"><a class="header" href="#is-mockforge-free">Is MockForge free?</a></h3>
<p>Yes, MockForge is completely free and open-source under MIT/Apache-2.0 licenses. There are no premium tiers, paid features, or usage limits.</p>
<h3 id="what-protocols-does-mockforge-support"><a class="header" href="#what-protocols-does-mockforge-support">What protocols does MockForge support?</a></h3>
<p>MockForge supports:</p>
<ul>
<li><strong>HTTP/REST</strong>: OpenAPI/Swagger-based mocking with full validation</li>
<li><strong>gRPC</strong>: Dynamic service discovery from <code>.proto</code> files with HTTP Bridge</li>
<li><strong>WebSocket</strong>: Replay mode, interactive mode, and AI event generation</li>
<li><strong>GraphQL</strong>: Schema-based mocking with automatic resolver generation</li>
</ul>
<h3 id="how-does-mockforge-compare-to-wiremock-mockoon-or-mockserver"><a class="header" href="#how-does-mockforge-compare-to-wiremock-mockoon-or-mockserver">How does MockForge compare to WireMock, Mockoon, or MockServer?</a></h3>
<p>See our <a href="https://github.com/SaaSy-Solutions/mockforge#-why-mockforge">detailed comparison table</a> in the README. Key differentiators:</p>
<ul>
<li><strong>Multi-protocol</strong> in a single binary</li>
<li><strong>AI-powered</strong> mock generation and data drift</li>
<li><strong>WASM plugin system</strong> for extensibility</li>
<li><strong>gRPC HTTP Bridge</strong> for REST access to gRPC services</li>
<li><strong>Built-in encryption</strong> for sensitive data</li>
<li><strong>Rust performance</strong> with native compilation</li>
<li><strong>Multi-language SDKs</strong> - Native support for 6 languages vs WireMock‚Äôs Java-first approach</li>
</ul>
<p>For detailed ecosystem comparison, see <a href="reference/../../docs/ECOSYSTEM_COMPARISON.html">Ecosystem Comparison Guide</a>.</p>
<h3 id="can-i-use-mockforge-in-production"><a class="header" href="#can-i-use-mockforge-in-production">Can I use MockForge in production?</a></h3>
<p>Yes! MockForge is production-ready with:</p>
<ul>
<li>Comprehensive test coverage</li>
<li>Security audits</li>
<li>Performance benchmarks</li>
<li>Docker deployment support</li>
<li>Observability (Prometheus metrics, tracing)</li>
</ul>
<p>However, it‚Äôs primarily designed for <strong>development and testing</strong>. For production API mocking, ensure proper security configurations.</p>
<hr />
<h2 id="getting-started-5"><a class="header" href="#getting-started-5">Getting Started</a></h2>
<h3 id="how-do-i-install-mockforge"><a class="header" href="#how-do-i-install-mockforge">How do I install MockForge?</a></h3>
<p>Three options:</p>
<pre><code class="language-bash"># 1. From crates.io (requires Rust)
cargo install mockforge-cli

# 2. From source
git clone https://github.com/SaaSy-Solutions/mockforge
cd mockforge &amp;&amp; make setup &amp;&amp; make install

# 3. Using Docker
docker pull ghcr.io/saasy-solutions/mockforge:latest
</code></pre>
<p>See the <a href="reference/../getting-started/installation.html">Installation Guide</a> for details.</p>
<h3 id="whats-the-fastest-way-to-get-started"><a class="header" href="#whats-the-fastest-way-to-get-started">What‚Äôs the fastest way to get started?</a></h3>
<p>Follow our <strong><a href="reference/../getting-started/five-minute-api.html">5-Minute Tutorial</a></strong>:</p>
<ol>
<li><code>cargo install mockforge-cli</code></li>
<li><code>mockforge init my-project</code></li>
<li><code>mockforge serve --config mockforge.yaml</code></li>
<li>Test with <code>curl</code></li>
</ol>
<h3 id="do-i-need-to-know-rust-to-use-mockforge"><a class="header" href="#do-i-need-to-know-rust-to-use-mockforge">Do I need to know Rust to use MockForge?</a></h3>
<p><strong>No.</strong> MockForge is a CLI tool you can use without Rust knowledge. You only need Rust if:</p>
<ul>
<li>Building from source</li>
<li>Developing custom plugins</li>
<li>Embedding MockForge as a library</li>
</ul>
<h3 id="what-programming-languages-are-supported"><a class="header" href="#what-programming-languages-are-supported">What programming languages are supported?</a></h3>
<p>MockForge provides native SDKs for 6 languages:</p>
<ul>
<li><strong>Rust</strong> - Native SDK with zero-overhead embedding</li>
<li><strong>Node.js/TypeScript</strong> - Full TypeScript support</li>
<li><strong>Python</strong> - Context manager support with type hints</li>
<li><strong>Go</strong> - Idiomatic Go API</li>
<li><strong>Java</strong> - Maven/Gradle integration</li>
<li><strong>.NET/C#</strong> - NuGet package</li>
</ul>
<p>All SDKs support embedded mock servers in your test suites. See <a href="reference/../../sdk/README.html">SDK Documentation</a> for examples.</p>
<h3 id="can-i-use-mockforge-from-pythonnodejsgoetc"><a class="header" href="#can-i-use-mockforge-from-pythonnodejsgoetc">Can I use MockForge from Python/Node.js/Go/etc.?</a></h3>
<p>Yes! MockForge provides native SDKs for multiple languages. You can embed mock servers directly in your test code:</p>
<p><strong>Python</strong>:</p>
<pre><code class="language-python">from mockforge_sdk import MockServer

with MockServer(port=3000) as server:
    server.stub_response('GET', '/api/users/123', {'id': 123})
    # Your test code here
</code></pre>
<p><strong>Node.js</strong>:</p>
<pre><code class="language-typescript">import { MockServer } from '@mockforge/sdk';

const server = await MockServer.start({ port: 3000 });
await server.stubResponse('GET', '/api/users/123', { id: 123 });
</code></pre>
<p><strong>Go</strong>:</p>
<pre><code class="language-go">server := mockforge.NewMockServer(mockforge.MockServerConfig{Port: 3000})
server.Start()
defer server.Stop()
</code></pre>
<p>See <a href="reference/../../docs/ECOSYSTEM_AND_USE_CASES.html">Ecosystem &amp; Use Cases Guide</a> for complete examples in all languages.</p>
<h3 id="how-do-i-create-my-first-mock-api"><a class="header" href="#how-do-i-create-my-first-mock-api">How do I create my first mock API?</a></h3>
<pre><code class="language-bash"># 1. Initialize a project
mockforge init my-api

# 2. Edit the generated mockforge.yaml
vim mockforge.yaml

# 3. Start the server
mockforge serve --config mockforge.yaml

# 4. Test it
curl http://localhost:3000/your-endpoint
</code></pre>
<p>Or use an existing OpenAPI spec:</p>
<pre><code class="language-bash">mockforge serve --spec your-api.json
</code></pre>
<hr />
<h2 id="configuration--setup"><a class="header" href="#configuration--setup">Configuration &amp; Setup</a></h2>
<h3 id="how-do-i-configure-mockforge"><a class="header" href="#how-do-i-configure-mockforge">How do I configure MockForge?</a></h3>
<p>Three ways (in order of priority):</p>
<ol>
<li><strong>CLI flags</strong>: <code>mockforge serve --http-port 3000</code></li>
<li><strong>Environment variables</strong>: <code>export MOCKFORGE_HTTP_PORT=3000</code></li>
<li><strong>Config file</strong>: <code>mockforge serve --config config.yaml</code></li>
</ol>
<p>See the <a href="reference/../configuration/files.html">Configuration Guide</a> and <a href="https://github.com/SaaSy-Solutions/mockforge/blob/main/config.template.yaml">Complete Config Template</a>.</p>
<h3 id="where-should-i-put-my-configuration-file"><a class="header" href="#where-should-i-put-my-configuration-file">Where should I put my configuration file?</a></h3>
<p>MockForge looks for config files in this order:</p>
<ol>
<li>Path specified with <code>--config</code></li>
<li><code>MOCKFORGE_CONFIG_FILE</code> environment variable</li>
<li><code>./mockforge.yaml</code> or <code>./mockforge.yml</code> in current directory</li>
<li>Auto-discovered in parent directories</li>
</ol>
<h3 id="can-i-use-environment-variables-for-all-settings"><a class="header" href="#can-i-use-environment-variables-for-all-settings">Can I use environment variables for all settings?</a></h3>
<p>Yes! Every config option can be set via environment variables using the <code>MOCKFORGE_</code> prefix:</p>
<pre><code class="language-bash">export MOCKFORGE_HTTP_PORT=3000
export MOCKFORGE_ADMIN_ENABLED=true
export MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true
</code></pre>
<h3 id="how-do-i-validate-my-configuration"><a class="header" href="#how-do-i-validate-my-configuration">How do I validate my configuration?</a></h3>
<pre><code class="language-bash">mockforge config validate
mockforge config validate --config my-config.yaml
</code></pre>
<p>See the <a href="reference/config-validation.html">Configuration Validation Guide</a>.</p>
<hr />
<h2 id="openapi--http-mocking"><a class="header" href="#openapi--http-mocking">OpenAPI &amp; HTTP Mocking</a></h2>
<h3 id="can-i-use-swaggeropenapi-specs"><a class="header" href="#can-i-use-swaggeropenapi-specs">Can I use Swagger/OpenAPI specs?</a></h3>
<p>Yes! Both OpenAPI 3.0 and Swagger 2.0 are supported:</p>
<pre><code class="language-bash">mockforge serve --spec openapi.json
mockforge serve --spec swagger.yaml
</code></pre>
<p>MockForge automatically generates mock endpoints from your specification.</p>
<h3 id="how-does-request-validation-work"><a class="header" href="#how-does-request-validation-work">How does request validation work?</a></h3>
<p>Three modes:</p>
<ul>
<li><strong><code>off</code></strong>: No validation (accept all requests)</li>
<li><strong><code>warn</code></strong>: Log validation errors but accept requests</li>
<li><strong><code>enforce</code></strong>: Reject invalid requests with 400/422</li>
</ul>
<pre><code class="language-bash">mockforge serve --validation enforce --spec api.json
</code></pre>
<h3 id="why-arent-my-template-variables-working"><a class="header" href="#why-arent-my-template-variables-working">Why aren‚Äôt my template variables working?</a></h3>
<p>Template expansion must be <strong>explicitly enabled</strong>:</p>
<pre><code class="language-bash"># Via CLI
mockforge serve --response-template-expand

# Via environment
export MOCKFORGE_RESPONSE_TEMPLATE_EXPAND=true

# Via config
http:
  response_template_expand: true
</code></pre>
<p>This is a security feature to prevent accidental template processing.</p>
<h3 id="what-template-variables-are-available"><a class="header" href="#what-template-variables-are-available">What template variables are available?</a></h3>
<pre><code>{{uuid}}          - Random UUID v4
{{now}}           - Current timestamp (ISO 8601)
{{now+2h}}        - Timestamp 2 hours from now
{{now-30m}}       - Timestamp 30 minutes ago
{{randInt 1 100}} - Random integer 1-100
{{rand.float}}    - Random float
{{faker.email}}   - Fake email address
{{faker.name}}    - Fake person name
{{request.body.field}}   - Access request data
{{request.path.id}}      - Path parameters
{{request.header.Auth}}  - Request headers
</code></pre>
<p>See the <a href="reference/templating.html">Templating Reference</a> for complete details.</p>
<h3 id="can-i-override-specific-endpoints"><a class="header" href="#can-i-override-specific-endpoints">Can I override specific endpoints?</a></h3>
<p>Yes! Define custom routes in your config that override OpenAPI spec:</p>
<pre><code class="language-yaml">http:
  openapi_spec: api.json
  routes:
    - path: /custom/endpoint
      method: GET
      response:
        status: 200
        body: '{"custom": "response"}'
</code></pre>
<hr />
<h2 id="grpc-mocking-1"><a class="header" href="#grpc-mocking-1">gRPC Mocking</a></h2>
<h3 id="do-i-need-to-compile-my-proto-files"><a class="header" href="#do-i-need-to-compile-my-proto-files">Do I need to compile my proto files?</a></h3>
<p><strong>No.</strong> MockForge dynamically parses <code>.proto</code> files at runtime. Just:</p>
<ol>
<li>Put <code>.proto</code> files in <code>./proto</code> directory</li>
<li>Start MockForge: <code>mockforge serve --grpc-port 50051</code></li>
<li>Services are automatically discovered and mocked</li>
</ol>
<h3 id="how-do-i-access-grpc-services-via-http"><a class="header" href="#how-do-i-access-grpc-services-via-http">How do I access gRPC services via HTTP?</a></h3>
<p>Enable the <strong>HTTP Bridge</strong>:</p>
<pre><code class="language-yaml">grpc:
  dynamic:
    enabled: true
    http_bridge:
      enabled: true
      base_path: "/api"
</code></pre>
<p>Now access gRPC services as REST APIs:</p>
<pre><code class="language-bash"># gRPC
grpcurl -d '{"id": "123"}' localhost:50051 UserService/GetUser

# HTTP (via bridge)
curl -X POST http://localhost:8080/api/userservice/getuser \
  -d '{"id": "123"}'
</code></pre>
<h3 id="can-i-use-grpc-reflection"><a class="header" href="#can-i-use-grpc-reflection">Can I use gRPC reflection?</a></h3>
<p>Yes, it‚Äôs enabled by default:</p>
<pre><code class="language-bash"># List services
grpcurl -plaintext localhost:50051 list

# Describe a service
grpcurl -plaintext localhost:50051 describe UserService
</code></pre>
<h3 id="does-mockforge-support-grpc-streaming"><a class="header" href="#does-mockforge-support-grpc-streaming">Does MockForge support gRPC streaming?</a></h3>
<p>Yes, all four streaming modes:</p>
<ul>
<li>Unary (single request ‚Üí single response)</li>
<li>Server streaming (single request ‚Üí stream of responses)</li>
<li>Client streaming (stream of requests ‚Üí single response)</li>
<li>Bidirectional streaming (stream ‚Üî stream)</li>
</ul>
<hr />
<h2 id="websocket-mocking-1"><a class="header" href="#websocket-mocking-1">WebSocket Mocking</a></h2>
<h3 id="how-do-i-create-websocket-replay-files"><a class="header" href="#how-do-i-create-websocket-replay-files">How do I create WebSocket replay files?</a></h3>
<p>Use JSON Lines (JSONL) format:</p>
<pre><code class="language-json">{"ts":0,"dir":"out","text":"Welcome!","waitFor":"^CLIENT_READY$"}
{"ts":100,"dir":"out","text":"{{uuid}}"}
{"ts":200,"dir":"in","text":"ACK"}
</code></pre>
<ul>
<li><code>ts</code>: Milliseconds timestamp</li>
<li><code>dir</code>: ‚Äúin‚Äù (received) or ‚Äúout‚Äù (sent)</li>
<li><code>text</code>: Message content (supports templates)</li>
<li><code>waitFor</code>: Optional regex/JSONPath pattern</li>
</ul>
<p>See <a href="reference/../user-guide/websocket-mocking/replay.html">WebSocket Replay Mode</a>.</p>
<h3 id="can-i-match-json-messages"><a class="header" href="#can-i-match-json-messages">Can I match JSON messages?</a></h3>
<p>Yes, use JSONPath in <code>waitFor</code>:</p>
<pre><code class="language-json">{"waitFor": "$.type", "text": "Matched type field"}
{"waitFor": "$.user.id", "text": "Matched user ID"}
</code></pre>
<p>See <a href="https://github.com/SaaSy-Solutions/mockforge/blob/main/examples/README-websocket-jsonpath.md">README-websocket-jsonpath.md</a>.</p>
<h3 id="whats-ai-event-generation"><a class="header" href="#whats-ai-event-generation">What‚Äôs AI event generation?</a></h3>
<p>Generate realistic WebSocket event streams from narrative descriptions:</p>
<pre><code class="language-bash">mockforge serve --ws-ai-enabled \
  --ws-ai-narrative "Simulate 5 minutes of stock trading" \
  --ws-ai-event-count 20
</code></pre>
<p>Perfect for testing real-time features without manually scripting events.</p>
<hr />
<h2 id="ai-features"><a class="header" href="#ai-features">AI Features</a></h2>
<h3 id="do-i-need-an-api-key-for-ai-features"><a class="header" href="#do-i-need-an-api-key-for-ai-features">Do I need an API key for AI features?</a></h3>
<p>Not necessarily. Three options:</p>
<ol>
<li>
<p><strong>Ollama (Free, Local)</strong>: No API key needed</p>
<pre><code class="language-bash">ollama pull llama2
mockforge serve --ai-enabled --rag-provider ollama
</code></pre>
</li>
<li>
<p><strong>OpenAI (Paid)</strong>: ~$0.01 per 1,000 requests</p>
<pre><code class="language-bash">export MOCKFORGE_RAG_API_KEY=sk-...
mockforge serve --ai-enabled --rag-provider openai
</code></pre>
</li>
<li>
<p><strong>Anthropic, or OpenAI-compatible APIs</strong>: Similar to OpenAI</p>
</li>
</ol>
<h3 id="what-are-ai-features-used-for"><a class="header" href="#what-are-ai-features-used-for">What are AI features used for?</a></h3>
<ul>
<li><strong>Intelligent Mock Generation</strong>: Generate responses from natural language prompts</li>
<li><strong>Data Drift Simulation</strong>: Realistic data evolution (order status, stock levels, etc.)</li>
<li><strong>AI Event Streams</strong>: Generate WebSocket event sequences from narratives</li>
</ul>
<p>See <a href="https://github.com/SaaSy-Solutions/mockforge/blob/main/docs/AI_DRIVEN_MOCKING.md">AI_DRIVEN_MOCKING.md</a>.</p>
<h3 id="how-much-does-ai-cost"><a class="header" href="#how-much-does-ai-cost">How much does AI cost?</a></h3>
<ul>
<li><strong>Ollama</strong>: Free (runs locally)</li>
<li><strong>OpenAI GPT-3.5</strong>: ~$0.01 per 1,000 requests</li>
<li><strong>OpenAI GPT-4</strong>: ~$0.10 per 1,000 requests</li>
<li><strong>Anthropic Claude</strong>: Similar to GPT-4</li>
</ul>
<p>Use Ollama for development, OpenAI for production if needed.</p>
<hr />
<h2 id="plugins"><a class="header" href="#plugins">Plugins</a></h2>
<h3 id="how-do-i-install-plugins"><a class="header" href="#how-do-i-install-plugins">How do I install plugins?</a></h3>
<pre><code class="language-bash"># From URL
mockforge plugin install https://example.com/plugin.wasm

# From Git with version
mockforge plugin install https://github.com/user/plugin#v1.0.0

# From local file
mockforge plugin install ./my-plugin.wasm

# List installed
mockforge plugin list
</code></pre>
<h3 id="can-i-create-custom-plugins"><a class="header" href="#can-i-create-custom-plugins">Can I create custom plugins?</a></h3>
<p>Yes! Plugins are written in Rust and compiled to WebAssembly:</p>
<ol>
<li>Use <code>mockforge-plugin-sdk</code> crate</li>
<li>Implement plugin traits</li>
<li>Compile to WASM target</li>
<li>Install and use</li>
</ol>
<p>See the <a href="reference/../user-guide/plugins.html">Plugin Development Guide</a> and <a href="reference/../tutorials/add-custom-plugin.html">Add a Custom Plugin Tutorial</a>.</p>
<h3 id="are-plugins-sandboxed"><a class="header" href="#are-plugins-sandboxed">Are plugins sandboxed?</a></h3>
<p>Yes. Plugins run in a <strong>WebAssembly sandbox</strong> with:</p>
<ul>
<li>Memory isolation</li>
<li>CPU/memory limits</li>
<li>No network access (unless explicitly allowed)</li>
<li>No file system access (unless explicitly allowed)</li>
</ul>
<p>See <a href="reference/../../docs/plugins/security/model.html">Plugin Security Model</a>.</p>
<hr />
<h2 id="admin-ui-1"><a class="header" href="#admin-ui-1">Admin UI</a></h2>
<h3 id="how-do-i-access-the-admin-ui"><a class="header" href="#how-do-i-access-the-admin-ui">How do I access the Admin UI?</a></h3>
<p>Two modes:</p>
<p><strong>Standalone</strong> (separate port):</p>
<pre><code class="language-bash">mockforge serve --admin --admin-port 9080
# Access: http://localhost:9080
</code></pre>
<p><strong>Embedded</strong> (under HTTP server):</p>
<pre><code class="language-bash">mockforge serve --admin-embed --admin-mount-path /admin
# Access: http://localhost:3000/admin
</code></pre>
<h3 id="is-authentication-available"><a class="header" href="#is-authentication-available">Is authentication available?</a></h3>
<p><strong>Not yet.</strong> Role-based authentication (Admin/Viewer) is planned for v1.1. The frontend UI components are built, but backend JWT/OAuth integration is pending.</p>
<p>Currently, the Admin UI is accessible without authentication.</p>
<h3 id="what-can-i-do-in-the-admin-ui"><a class="header" href="#what-can-i-do-in-the-admin-ui">What can I do in the Admin UI?</a></h3>
<ul>
<li>View real-time request logs (via Server-Sent Events)</li>
<li>Monitor performance metrics</li>
<li>Manage fixtures with drag-and-drop</li>
<li>Configure latency and fault injection</li>
<li>Search requests and logs</li>
<li>View server health and statistics</li>
</ul>
<p>See <a href="reference/../tutorials/admin-ui-walkthrough.html">Admin UI Walkthrough</a>.</p>
<hr />
<h2 id="deployment"><a class="header" href="#deployment">Deployment</a></h2>
<h3 id="can-i-run-mockforge-in-docker"><a class="header" href="#can-i-run-mockforge-in-docker">Can I run MockForge in Docker?</a></h3>
<p>Yes:</p>
<pre><code class="language-bash"># Using Docker Compose
docker-compose up

# Using Docker directly
docker run -p 3000:3000 -p 9080:9080 mockforge
</code></pre>
<p>See <a href="https://github.com/SaaSy-Solutions/mockforge/blob/main/DOCKER.md">DOCKER.md</a> for complete documentation.</p>
<h3 id="how-do-i-deploy-to-kubernetes"><a class="header" href="#how-do-i-deploy-to-kubernetes">How do I deploy to Kubernetes?</a></h3>
<p>Use the Helm chart or create Deployment/Service manifests:</p>
<pre><code class="language-bash"># Using Helm (if available)
helm install mockforge ./charts/mockforge

# Or use kubectl
kubectl apply -f k8s/deployment.yaml
</code></pre>
<h3 id="what-ports-does-mockforge-use"><a class="header" href="#what-ports-does-mockforge-use">What ports does MockForge use?</a></h3>
<p>Default ports:</p>
<ul>
<li><strong>3000</strong>: HTTP server</li>
<li><strong>3001</strong>: WebSocket server</li>
<li><strong>50051</strong>: gRPC server</li>
<li><strong>4000</strong>: GraphQL server</li>
<li><strong>9080</strong>: Admin UI</li>
<li><strong>9090</strong>: Prometheus metrics</li>
</ul>
<p>All ports are configurable.</p>
<hr />
<h2 id="performance--limits"><a class="header" href="#performance--limits">Performance &amp; Limits</a></h2>
<h3 id="how-many-requests-can-mockforge-handle"><a class="header" href="#how-many-requests-can-mockforge-handle">How many requests can MockForge handle?</a></h3>
<p>Typical performance (modern hardware):</p>
<ul>
<li><strong>HTTP</strong>: 10,000+ req/s</li>
<li><strong>WebSocket</strong>: 1,000+ concurrent connections</li>
<li><strong>gRPC</strong>: 5,000+ req/s</li>
</ul>
<p>Performance depends on:</p>
<ul>
<li>Response complexity</li>
<li>Template expansion</li>
<li>Validation enabled</li>
<li>Hardware specs</li>
</ul>
<p>See our <a href="https://github.com/SaaSy-Solutions/mockforge/tree/main/benches">benchmarks</a>.</p>
<h3 id="does-mockforge-scale-horizontally"><a class="header" href="#does-mockforge-scale-horizontally">Does MockForge scale horizontally?</a></h3>
<p>Yes. Run multiple instances behind a load balancer:</p>
<pre><code class="language-bash"># Instance 1
mockforge serve --http-port 3000

# Instance 2
mockforge serve --http-port 3001

# Load balancer distributes traffic
</code></pre>
<p>For stateless mocking (no shared state), this works great.</p>
<h3 id="what-are-the-resource-requirements"><a class="header" href="#what-are-the-resource-requirements">What are the resource requirements?</a></h3>
<p>Minimal:</p>
<ul>
<li><strong>Memory</strong>: ~50MB base + ~10MB per 1,000 concurrent connections</li>
<li><strong>CPU</strong>: 1-2 cores sufficient for most workloads</li>
<li><strong>Disk</strong>: ~100MB for binary + storage for logs/fixtures</li>
</ul>
<hr />
<h2 id="troubleshooting-62"><a class="header" href="#troubleshooting-62">Troubleshooting</a></h2>
<h3 id="server-wont-start---port-already-in-use"><a class="header" href="#server-wont-start---port-already-in-use">Server won‚Äôt start - port already in use</a></h3>
<pre><code class="language-bash"># Find what's using the port
lsof -i :3000

# Use a different port
mockforge serve --http-port 3001
</code></pre>
<h3 id="template-variables-appear-literally-in-responses"><a class="header" href="#template-variables-appear-literally-in-responses">Template variables appear literally in responses</a></h3>
<p>Enable template expansion:</p>
<pre><code class="language-bash">mockforge serve --response-template-expand
</code></pre>
<h3 id="validation-rejecting-valid-requests"><a class="header" href="#validation-rejecting-valid-requests">Validation rejecting valid requests</a></h3>
<p>Adjust validation mode:</p>
<pre><code class="language-bash">mockforge serve --validation warn  # or 'off'
</code></pre>
<h3 id="websocket-connection-fails-1"><a class="header" href="#websocket-connection-fails-1">WebSocket connection fails</a></h3>
<p>Check the WebSocket port and replay file:</p>
<pre><code class="language-bash"># Verify port
netstat -tlnp | grep :3001

# Check replay file exists
ls -la ws-replay.jsonl
</code></pre>
<h3 id="admin-ui-not-loading-1"><a class="header" href="#admin-ui-not-loading-1">Admin UI not loading</a></h3>
<p>Verify the admin UI is enabled and port is correct:</p>
<pre><code class="language-bash">mockforge serve --admin --admin-port 9080
curl http://localhost:9080
</code></pre>
<p>For more issues, see the <a href="reference/troubleshooting.html">Troubleshooting Guide</a>.</p>
<hr />
<h2 id="development--contributing"><a class="header" href="#development--contributing">Development &amp; Contributing</a></h2>
<h3 id="can-i-embed-mockforge-in-my-application"><a class="header" href="#can-i-embed-mockforge-in-my-application">Can I embed MockForge in my application?</a></h3>
<p>Yes! Use MockForge crates as libraries:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mockforge_http::build_router;
use mockforge_core::{ValidationOptions, Config};

let router = build_router(
    Some("api.json".to_string()),
    Some(ValidationOptions::enforce()),
    None,
).await;
<span class="boring">}</span></code></pre></pre>
<p>See the <a href="https://docs.rs/mockforge-core">Rust API Documentation</a>.</p>
<h3 id="how-do-i-contribute-to-mockforge"><a class="header" href="#how-do-i-contribute-to-mockforge">How do I contribute to MockForge?</a></h3>
<ol>
<li>Check <a href="https://github.com/SaaSy-Solutions/mockforge/blob/main/CONTRIBUTING.md">CONTRIBUTING.md</a></li>
<li>Look for ‚Äúgood first issue‚Äù labels</li>
<li>Fork, make changes, submit PR</li>
<li>Ensure tests pass: <code>cargo test</code></li>
<li>Follow code style: <code>cargo fmt &amp;&amp; cargo clippy</code></li>
</ol>
<h3 id="where-can-i-report-bugs"><a class="header" href="#where-can-i-report-bugs">Where can I report bugs?</a></h3>
<p><a href="https://github.com/SaaSy-Solutions/mockforge/issues">GitHub Issues</a></p>
<p>Please include:</p>
<ul>
<li>MockForge version</li>
<li>Operating system</li>
<li>Configuration file (if applicable)</li>
<li>Steps to reproduce</li>
<li>Expected vs actual behavior</li>
<li>Error logs</li>
</ul>
<h3 id="is-there-a-community-forum"><a class="header" href="#is-there-a-community-forum">Is there a community forum?</a></h3>
<ul>
<li><strong>GitHub Discussions</strong>: <a href="https://github.com/SaaSy-Solutions/mockforge/discussions">Community Forum</a></li>
<li><strong>GitHub Issues</strong>: <a href="https://github.com/SaaSy-Solutions/mockforge/issues">Bug Reports &amp; Feature Requests</a></li>
<li><strong>Discord</strong>: <a href="https://discord.gg/2FxXqKpa">Join our community chat</a></li>
</ul>
<hr />
<h2 id="licensing--commercial-use"><a class="header" href="#licensing--commercial-use">Licensing &amp; Commercial Use</a></h2>
<h3 id="what-license-is-mockforge-under"><a class="header" href="#what-license-is-mockforge-under">What license is MockForge under?</a></h3>
<p>Dual-licensed: <strong>MIT OR Apache-2.0</strong></p>
<p>You can choose either license for your use case.</p>
<h3 id="can-i-use-mockforge-commercially"><a class="header" href="#can-i-use-mockforge-commercially">Can I use MockForge commercially?</a></h3>
<p><strong>Yes, absolutely.</strong> Both MIT and Apache-2.0 are permissive licenses that allow commercial use without restrictions.</p>
<h3 id="do-i-need-to-open-source-my-configurations"><a class="header" href="#do-i-need-to-open-source-my-configurations">Do I need to open-source my configurations?</a></h3>
<p><strong>No.</strong> Your configuration files, mock data, and custom plugins are yours. Only if you modify MockForge source code and distribute it do licensing terms apply.</p>
<h3 id="can-i-sell-mockforge-based-services"><a class="header" href="#can-i-sell-mockforge-based-services">Can I sell MockForge-based services?</a></h3>
<p>Yes. You can offer:</p>
<ul>
<li>Hosted MockForge instances</li>
<li>Custom plugins</li>
<li>Support services</li>
<li>Training/consulting</li>
</ul>
<hr />
<h2 id="use-cases-17"><a class="header" href="#use-cases-17">Use Cases</a></h2>
<h3 id="what-use-cases-does-mockforge-support"><a class="header" href="#what-use-cases-does-mockforge-support">What use cases does MockForge support?</a></h3>
<p>MockForge supports a wide range of use cases:</p>
<ol>
<li><strong>Unit Tests</strong> - Embed mock servers directly in test suites across all supported languages</li>
<li><strong>Integration Tests</strong> - Test complex multi-service interactions with stateful mocking</li>
<li><strong>Service Virtualization</strong> - Replace external dependencies with mocks using proxy mode</li>
<li><strong>Development Environments</strong> - Create local development environments without backend dependencies</li>
<li><strong>Isolating from Flaky Dependencies</strong> - Simulate network failures and slow responses</li>
<li><strong>Simulating APIs That Don‚Äôt Exist Yet</strong> - Generate mocks from API specifications before implementation</li>
</ol>
<p>See <a href="reference/../../docs/ECOSYSTEM_AND_USE_CASES.html">Ecosystem &amp; Use Cases Guide</a> for detailed examples and code samples.</p>
<h3 id="can-i-use-mockforge-for-unit-testing"><a class="header" href="#can-i-use-mockforge-for-unit-testing">Can I use MockForge for unit testing?</a></h3>
<p>Yes! MockForge SDKs allow you to embed mock servers directly in your unit tests:</p>
<p><strong>Rust</strong>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let mut server = MockServer::new().port(0).start().await?;
server.stub_response("GET", "/api/users/123", json!({"id": 123})).await?;
<span class="boring">}</span></code></pre></pre>
<p><strong>Python</strong>:</p>
<pre><code class="language-python">with MockServer(port=0) as server:
    server.stub_response('GET', '/api/users/123', {'id': 123})
</code></pre>
<p>No separate server process required. See <a href="reference/../../sdk/README.html">SDK Documentation</a> for examples.</p>
<h3 id="how-do-i-replace-external-apis-in-my-tests"><a class="header" href="#how-do-i-replace-external-apis-in-my-tests">How do I replace external APIs in my tests?</a></h3>
<p>Use MockForge‚Äôs proxy mode with record/replay:</p>
<pre><code class="language-bash"># Record real API interactions
mockforge serve --proxy-enabled \
  --proxy-target https://api.external-service.com \
  --record-responses ./recordings/

# Replay from recordings
mockforge serve --replay-from ./recordings/
</code></pre>
<p>Or use the SDK to programmatically stub responses. See <a href="reference/../../docs/ECOSYSTEM_AND_USE_CASES.html#use-case-3-service-virtualization">Service Virtualization</a> for details.</p>
<h3 id="can-i-simulate-network-failures-and-slow-responses"><a class="header" href="#can-i-simulate-network-failures-and-slow-responses">Can I simulate network failures and slow responses?</a></h3>
<p>Yes! MockForge provides built-in latency and fault injection:</p>
<pre><code class="language-bash"># Add latency
mockforge serve --latency-mode normal --latency-mean-ms 500

# Inject failures
mockforge serve --failure-rate 0.1 --failure-codes 500,503
</code></pre>
<p>Or configure in your SDK:</p>
<pre><code class="language-typescript">const server = await MockServer.start({
  latency: { mode: 'normal', meanMs: 500 },
  failures: { enabled: true, failureRate: 0.1 }
});
</code></pre>
<p>See <a href="reference/../../docs/ECOSYSTEM_AND_USE_CASES.html#use-case-5-isolating-from-flaky-dependencies">Isolating from Flaky Dependencies</a> for examples.</p>
<h3 id="how-do-i-mock-an-api-that-doesnt-exist-yet"><a class="header" href="#how-do-i-mock-an-api-that-doesnt-exist-yet">How do I mock an API that doesn‚Äôt exist yet?</a></h3>
<p>Generate mocks from API specifications:</p>
<pre><code class="language-bash"># From OpenAPI spec
mockforge serve --spec api-spec.yaml

# From GraphQL schema
mockforge serve --graphql-schema schema.graphql

# From gRPC proto files
mockforge serve --grpc-port 50051 --proto-dir ./proto
</code></pre>
<p>All endpoints are automatically available with schema-validated responses. See <a href="reference/../../docs/ECOSYSTEM_AND_USE_CASES.html#use-case-6-simulating-apis-that-dont-exist-yet">Simulating APIs That Don‚Äôt Exist Yet</a> for details.</p>
<h2 id="whats-next-7"><a class="header" href="#whats-next-7">What‚Äôs Next?</a></h2>
<p><strong>Ready to start?</strong> Try our <strong><a href="reference/../getting-started/five-minute-api.html">5-Minute Tutorial</a></strong>!</p>
<p><strong>Need more help?</strong></p>
<ul>
<li><a href="https://docs.mockforge.dev/">Full Documentation</a></li>
<li><a href="reference/../../docs/ECOSYSTEM_AND_USE_CASES.html">Ecosystem &amp; Use Cases Guide</a></li>
<li><a href="https://github.com/SaaSy-Solutions/mockforge/issues">GitHub Issues</a></li>
<li><a href="https://github.com/SaaSy-Solutions/mockforge/discussions">Community Discussions</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="unreleased"><a class="header" href="#unreleased">[Unreleased]</a></h2>
<h3 id="added"><a class="header" href="#added">Added</a></h3>
<ul>
<li><strong>[Reality] Reality Profiles Marketplace</strong>: Pre-tuned ‚Äúrealism packs‚Äù bundling personas, scenarios, chaos rules, latency curves, error distributions, data mutation, and protocol behaviors. Includes E-Commerce Peak Season, Fintech Fraud, Healthcare HL7, and IoT Device Fleet Chaos packs.</li>
<li><strong>[Reality] Behavioral Economics Engine</strong>: Mocks react to pressure, load, pricing, fraud suspicion, and customer segments. Supports declarative and scriptable rules for cart conversion drops, transaction declines, and user churn simulation.</li>
<li><strong>[Reality] Synthetic ‚Üí Recorded Drift Learning</strong>: Mocks learn from traffic patterns and adapt behavior. Supports behavioral, statistical, and hybrid learning modes with configurable sensitivity and decay rates.</li>
<li><strong>[Reality] World State Engine</strong>: Unified visualization of all MockForge state systems (personas, lifecycle, reality, time, multi-protocol state, behavior trees, generative schemas, recorded data, AI modifiers) with graph visualization and time travel capabilities.</li>
<li><strong>[Reality] Performance Mode</strong>: Lightweight load simulation for running scenarios at N RPS, simulating bottlenecks, recording latencies, and observing response changes under load.</li>
<li><strong>[Contracts] API Change Forecasting</strong>: Predicts likely future contract breaks based on historical drift patterns. Includes pattern analysis, statistical modeling, and multi-window forecasting (30/90/180 days).</li>
<li><strong>[Contracts] Semantic Drift Notifications</strong>: Detects when the meaning of an API changes, not just structure. Includes description changes, enum narrowing, soft-breaking changes, nullable changes, and error code removals with LLM-powered analysis.</li>
<li><strong>[Contracts] Contract Threat Modeling</strong>: Analyzes APIs for security risks including PII exposure, DoS risk (unbounded arrays), error leakage (stack traces), and schema design issues with AI-powered remediation suggestions.</li>
<li><strong>[DevX] Zero-Config Mode (Runtime Daemon)</strong>: Automatically creates mocks, generates types, creates client stubs, updates OpenAPI schema, and sets up scenarios when hitting non-existent endpoints (404). Full integration with AI generation.</li>
<li><strong>[DevX] DevTools Browser Integration</strong>: Enhanced ForgeConnect extension with DevTools panel featuring ‚ÄúMock this endpoint‚Äù functionality, live response modification, persona/scenario toggling, reverse-injection into workspace, and snapshot diff visualization.</li>
<li><strong>[DevX] Snapshot Diff Between Environments</strong>: Side-by-side visualization for comparing mock behavior between environments, personas, scenarios, or reality levels. Supports test vs prod, persona comparisons, and reality level comparisons.</li>
<li><strong>[DevX] Mock-Oriented Development (MOD)</strong>: Complete methodology documentation for mock-first design, contract-driven development, reality progression, and scenario-driven testing.</li>
<li><strong>[Cloud] MockOps Pipelines</strong>: GitHub Actions-like automation for mock lifecycle management. Event-driven pipelines for schema changes ‚Üí auto-regenerate SDK, scenario promotion, and drift threshold ‚Üí auto-generate Git PR.</li>
<li><strong>[Cloud] Multi-Workspace Federation</strong>: Compose multiple mock workspaces into one federated ‚Äúvirtual system‚Äù for microservices architectures. Supports service boundaries, system-wide scenarios, and per-service reality level control.</li>
<li><strong>[Cloud] Analytics Dashboard</strong>: Leadership insight into coverage, risk, and usage. Includes scenario usage heatmaps, persona CI hit tracking, endpoint coverage analysis, reality level staleness detection, and drift percentage tracking.</li>
<li><strong>[AI] API Architecture Critique</strong>: LLM-powered analysis of API schemas to detect anti-patterns, redundancies, naming issues, emotional tone problems, and provide restructuring recommendations.</li>
<li><strong>[AI] Natural Language to System Generation</strong>: Generate complete backend systems from natural language descriptions. Creates 20-30 REST endpoints, 4-5 personas, 6-10 lifecycle states, WebSocket topics, payment failure scenarios, surge pricing chaos profiles, full OpenAPI spec, GraphQL schema, typings, and CI pipeline templates.</li>
<li><strong>[AI] AI Behavioral Simulation Engine</strong>: Models users as narrative agents that react to app state, form intentions (shop, browse, buy, abandon), respond to errors, and trigger multi-step interactions automatically.</li>
</ul>
<h3 id="changed"><a class="header" href="#changed">Changed</a></h3>
<ul>
<li><strong>[DevX] Enhanced ForgeConnect SDK Documentation</strong>: Added comprehensive DevTools panel features including ‚ÄúMock this endpoint‚Äù functionality, live response modification, persona/scenario toggling, reverse-injection, and snapshot diff visualization.</li>
</ul>
<h3 id="deprecated"><a class="header" href="#deprecated">Deprecated</a></h3>
<ul>
<li>Nothing yet.</li>
</ul>
<h3 id="removed"><a class="header" href="#removed">Removed</a></h3>
<ul>
<li>Nothing yet.</li>
</ul>
<h3 id="fixed"><a class="header" href="#fixed">Fixed</a></h3>
<ul>
<li>Nothing yet.</li>
</ul>
<h3 id="security-4"><a class="header" href="#security-4">Security</a></h3>
<ul>
<li>Nothing yet.</li>
</ul>
<h2 id="030---2025-11-17"><a class="header" href="#030---2025-11-17">[0.3.0] - 2025-11-17</a></h2>
<h3 id="added-1"><a class="header" href="#added-1">Added</a></h3>
<ul>
<li><strong>[DevX] Pillars &amp; Tagged Changelog</strong>: Complete pillar system implementation with documentation and tooling</li>
<li><strong>[Reality] Smart Personas &amp; Reality Continuum v2</strong>: Complete persona graph and lifecycle system</li>
<li><strong>[Contracts] Drift Budget &amp; GitOps for API Sync</strong>: Complete drift management system</li>
<li><strong>[Reality] Behavioral Cloning v1</strong>: Multi-step flow recording and replay</li>
<li><strong>[AI][DevX] LLM/Voice Interface for Workspace Creation</strong>: Natural language to complete workspace</li>
</ul>
<p>See <a href="reference/../../../CHANGELOG.html">CHANGELOG.md</a> for detailed release notes.</p>
<h2 id="020---2025-10-29"><a class="header" href="#020---2025-10-29">[0.2.0] - 2025-10-29</a></h2>
<h3 id="added-2"><a class="header" href="#added-2">Added</a></h3>
<ul>
<li><strong>[DevX] Output control features</strong> for MockForge generator with comprehensive configuration options</li>
<li><strong>[DevX] Unified spec parser</strong> with enhanced validation and error reporting</li>
<li><strong>[DevX] Multi-framework client generation</strong> with Angular and Svelte support</li>
<li><strong>[Reality] Enhanced mock data generation</strong> with OpenAPI support</li>
<li><strong>[DevX] Configuration file support</strong> for mock generation</li>
<li><strong>[DevX] Browser mobile proxy mode</strong> implementation</li>
<li><strong>[DevX] Comprehensive documentation</strong> and example workflows</li>
</ul>
<h3 id="changed-1"><a class="header" href="#changed-1">Changed</a></h3>
<ul>
<li><strong>[DevX] Enhanced CLI</strong> with progress indicators, error handling, and code quality improvements</li>
<li><strong>[DevX] Comprehensive plugin architecture documentation</strong></li>
</ul>
<h3 id="fixed-1"><a class="header" href="#fixed-1">Fixed</a></h3>
<ul>
<li><strong>[DevX] Remove tests that access private fields</strong> in mock data tests</li>
<li><strong>[DevX] Fix compilation issues</strong> in mockforge-collab and mockforge-ui</li>
<li><strong>[DevX] Update mockforge-plugin-core version</strong> to 0.1.6 in plugin-sdk</li>
<li><strong>[DevX] Enable SQLx offline mode</strong> for mockforge-collab publishing</li>
<li><strong>[DevX] Add description field</strong> to mockforge-analytics</li>
<li><strong>[DevX] Add version requirements</strong> to all mockforge path dependencies</li>
<li><strong>[DevX] Fix publish order dependencies</strong> (mockforge-chaos before mockforge-reporting)</li>
<li><strong>[DevX] Update Cargo.lock</strong> and format client generator tests</li>
</ul>
<h2 id="013---2025-10-22"><a class="header" href="#013---2025-10-22">[0.1.3] - 2025-10-22</a></h2>
<h3 id="changes"><a class="header" href="#changes">Changes</a></h3>
<ul>
<li><strong>[DevX] docs: prepare release 0.1.3</strong></li>
<li><strong>[DevX] docs: update CHANGELOG for 0.1.3 release</strong></li>
<li><strong>[DevX] docs: add roadmap completion summary</strong></li>
<li><strong>[DevX] feat: add Kubernetes-style health endpoint aliases and dashboard shortcut</strong></li>
<li><strong>[DevX] feat: add unified config &amp; profiles with multi-format support</strong></li>
<li><strong>[Reality] feat: add capture scrubbing and deterministic replay</strong></li>
<li><strong>[DevX] feat: add native GraphQL operation handlers with advanced features</strong></li>
<li><strong>[Reality] feat: add programmable WebSocket handlers</strong></li>
<li><strong>[Reality] feat: add HTTP scenario switching for OpenAPI response examples</strong></li>
<li><strong>[DevX] feat: add mockforge-test crate and integration testing examples</strong></li>
<li><strong>[DevX] build: enable publishing for mockforge-ui and mockforge-cli</strong></li>
<li><strong>[DevX] build: extend publish script for internal crates</strong></li>
<li><strong>[DevX] build: parameterize publish script with workspace version</strong></li>
</ul>
<h2 id="012---2025-10-17"><a class="header" href="#012---2025-10-17">[0.1.2] - 2025-10-17</a></h2>
<h3 id="changes-1"><a class="header" href="#changes-1">Changes</a></h3>
<ul>
<li><strong>[DevX] build: make version update tolerant</strong></li>
<li><strong>[DevX] build: manage version references via wrapper</strong></li>
<li><strong>[DevX] build: mark example crates as non-publishable</strong></li>
<li><strong>[DevX] build: drop publish-order for cargo-release 0.25</strong></li>
<li><strong>[DevX] build: centralize release metadata in release.toml</strong></li>
<li><strong>[DevX] build: remove per-crate release metadata</strong></li>
<li><strong>[DevX] build: fix release metadata field name</strong></li>
<li><strong>[DevX] build: move workspace release metadata into Cargo.toml</strong></li>
<li><strong>[DevX] build: require execute flag for release wrapper</strong></li>
<li><strong>[DevX] build: automate changelog generation during release</strong></li>
<li><strong>[DevX] build: add release wrapper with changelog guard</strong></li>
<li><strong>[DevX] build: align release tooling with cargo-release 0.25</strong></li>
</ul>
<h2 id="011---2025-10-17"><a class="header" href="#011---2025-10-17">[0.1.1] - 2025-10-17</a></h2>
<h3 id="added-3"><a class="header" href="#added-3">Added</a></h3>
<ul>
<li><strong>[Contracts] OpenAPI request validation</strong> (path/query/header/cookie/body) with deep $ref resolution and composite schemas (oneOf/anyOf/allOf).</li>
<li><strong>[Contracts] Validation modes</strong>: <code>disabled</code>, <code>warn</code>, <code>enforce</code>, with aggregate error reporting and detailed error objects.</li>
<li><strong>[DevX] Runtime Admin UI panel</strong> to view/toggle validation mode and per-route overrides; Admin API endpoint <code>/__mockforge/validation</code>.</li>
<li><strong>[DevX] CLI flags and config options</strong> to control validation (including <code>skip_admin_validation</code> and per-route <code>validation_overrides</code>).</li>
<li><strong>[DevX] New e2e tests</strong> for 2xx/422 request validation and response example expansion across HTTP routes.</li>
<li><strong>[DevX] Templating reference docs</strong> and examples; WS templating tests and demo update.</li>
<li><strong>[Reality] Initial release of MockForge</strong> - Multi-protocol mocking framework</li>
<li><strong>[Reality] HTTP API mocking</strong> with OpenAPI support</li>
<li><strong>[Reality] gRPC service mocking</strong> with Protocol Buffers</li>
<li><strong>[Reality] WebSocket connection mocking</strong> with replay functionality</li>
<li><strong>[DevX] CLI tool</strong> for easy local development</li>
<li><strong>[DevX] Admin UI</strong> for managing mock servers</li>
<li><strong>[DevX] Comprehensive documentation</strong> with mdBook</li>
<li><strong>[DevX] GitHub Actions CI/CD pipeline</strong></li>
<li><strong>[DevX] Security audit integration</strong></li>
<li><strong>[DevX] Pre-commit hooks</strong> for code quality</li>
</ul>
<h3 id="changed-2"><a class="header" href="#changed-2">Changed</a></h3>
<ul>
<li><strong>[Contracts] HTTP handlers now perform request validation</strong> before routing; invalid requests return 400 with structured details (when <code>enforce</code>).</li>
<li><strong>[Contracts] Bump <code>jsonschema</code> to 0.33</strong> and adapt validator API; enable draft selection and format checks internally.</li>
<li><strong>[Contracts] Improve route registry and OpenAPI parameter parsing</strong>, including styles/explode and array coercion for query/header/cookie parameters.</li>
</ul>
<h3 id="deprecated-1"><a class="header" href="#deprecated-1">Deprecated</a></h3>
<ul>
<li>N/A</li>
</ul>
<h3 id="removed-1"><a class="header" href="#removed-1">Removed</a></h3>
<ul>
<li>N/A</li>
</ul>
<h3 id="fixed-2"><a class="header" href="#fixed-2">Fixed</a></h3>
<ul>
<li><strong>[DevX] Resolve admin mount prefix</strong> from config and exclude admin routes from validation when configured.</li>
<li><strong>[Contracts] Various small correctness fixes</strong> in OpenAPI schema mapping and parameter handling; clearer error messages.</li>
</ul>
<h3 id="security-5"><a class="header" href="#security-5">Security</a></h3>
<ul>
<li>N/A</li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>



        <script>
            window.playground_line_numbers = true;
        </script>

        <script>
            window.playground_copyable = true;
        </script>

        <script src="ace.js"></script>
        <script src="mode-rust.js"></script>
        <script src="editor.js"></script>
        <script src="theme-dawn.js"></script>
        <script src="theme-tomorrow_night.js"></script>

        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->
        <script src="custom.js"></script>

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>


    </div>
    </body>
</html>
